Conference,Year,Title,DOI,id,cite_to_list,cited_by_list,Link,FirstPage,LastPage,PaperType,Abstract,AuthorNames-Deduped,AuthorNames,AuthorAffiliation,InternalReferences,AuthorKeywords,AminerCitationCount_02-2020,XploreCitationCount - 2020-01,PubsCited,Award
InfoVis,2014,Exploring the Placement and Design of Word-Scale Visualizations,10.1109/TVCG.2014.2346435,1022,"[640, 641, 739, 868, 549, 934, 327, 266, 246]","[1412, 1433, 1472, 1557, 1579, 1584]",http://dx.doi.org/10.1109/TVCG.2014.2346435,2291,2300,J,"We present an exploration and a design space that characterize the usage and placement of word-scale visualizations within text documents. Word-scale visualizations are a more general version of sparklines-small, word-sized data graphics that allow meta-information to be visually presented in-line with document text. In accordance with Edward Tufte's definition, sparklines are traditionally placed directly before or after words in the text. We describe alternative placements that permit a wider range of word-scale graphics and more flexible integration with text layouts. These alternative placements include positioning visualizations between lines, within additional vertical and horizontal space in the document, and as interactive overlays on top of the text. Each strategy changes the dimensions of the space available to display the visualizations, as well as the degree to which the text must be adjusted or reflowed to accommodate them. We provide an illustrated design space of placement options for word-scale visualizations and identify six important variables that control the placement of the graphics and the level of disruption of the source text. We also contribute a quantitative analysis that highlights the effect of different placements on readability and text disruption. Finally, we use this analysis to propose guidelines to support the design and placement of word-scale visualizations.",Pascal Goffin;Wesley Willett;Jean-Daniel Fekete;Petra Isenberg,Pascal Goffin;Wesley Willett;Jean-Daniel Fekete;Petra Isenberg,Inria;Inria;Inria;Inria,10.1109/TVCG.2013.192;10.1109/TVCG.2006.163;10.1109/TVCG.2012.196;10.1109/TVCG.2011.185;10.1109/TVCG.2007.70589;10.1109/TVCG.2011.183;10.1109/TVCG.2013.120;10.1109/TVCG.2010.194;10.1109/INFVIS.2005.1532144,"Information visualization, text visualization, sparklines, glyphs, design space, word-scale visualizations",18.0,21.0,34.0,
InfoVis,2018,Glanceable Visualization: Studies of Data Comparison Performance on Smartwatches,10.1109/TVCG.2018.2865142,1584,"[739, 934, 775, 552, 327, 246, 989, 1022]",[],http://dx.doi.org/10.1109/TVCG.2018.2865142,630,640,J,"We present the results of two perception studies to assess how quickly people can perform a simple data comparison task for small-scale visualizations on a smartwatch. The main goal of these studies is to extend our understanding of design constraints for smartwatch visualizations. Previous work has shown that a vast majority of smartwatch interactions last under 5 s. It is still unknown what people can actually perceive from visualizations during such short glances, in particular with such a limited display space of smartwatches. To shed light on this question, we conducted two perception studies that assessed the lower bounds of task time for a simple data comparison task. We tested three chart types common on smartwatches: bar charts, donut charts, and radial bar charts with three different data sizes: 7, 12, and 24 data values. In our first study, we controlled the differences of the two target bars to be compared, while the second study varied the difference randomly. For both studies, we found that participants performed the task on average in &lt;;300 ms for the bar chart, &lt;;220 ms for the donut chart, and in &lt;; 1780 ms for the radial bar chart. Thresholds in the second study per chart type were on average 1.14-1.35× higher than in the first study. Our results show that bar and donut charts should be preferred on smartwatch displays when quick data comparisons are necessary.",Tanja Blascheck;Lonni Besançon;Anastasia Bezerianos;Bongshin Lee;Petra Isenberg,Tanja Blascheck;Lonni Besançon;Anastasia Bezerianos;Bongshin Lee;Petra Isenberg,Inria;Université Paris Saclay;Université Paris SudInriaCNRSUniversité Paris Saclay;Microsoft Research;Inria,10.1109/TVCG.2014.2346435;10.1109/TVCG.2012.233;10.1109/TVCG.2010.162;10.1109/TVCG.2013.192;10.1109/INFVIS.2005.1532144;10.1109/TVCG.2012.196;10.1109/TVCG.2014.2346320;10.1109/TVCG.2007.70589,"Glanceable visualization,smartwatch,perception,quantitative evaluation,data comparison",0.0,3.0,52.0,
