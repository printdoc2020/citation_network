Conference,Year,Title,DOI,id,cite_to_list,cited_by_list,Link,FirstPage,LastPage,PaperType,Abstract,AuthorNames-Deduped,AuthorNames,AuthorAffiliation,InternalReferences,AuthorKeywords,AminerCitationCount_02-2020,XploreCitationCount - 2020-01,PubsCited,Award
VAST,2010,A continuous analysis process between desktop and collaborative visual analytics environments,10.1109/VAST.2010.5652958,620,[],[],http://dx.doi.org/10.1109/VAST.2010.5652958,231,232,M,"Since its inception, the field of visual analytics has undergone tremendous growth in understanding how to create interactive visual tools to solve analytical problems. However, with few exceptions, most of these tools have been designed for single users in desktop environments. While often effective on their own, most single-user systems do not reflect the collaborative nature of solving real-world analytical tasks. Many intelligence analysts, for example, have been observed to switch repeatedly between working alone and collaborating with members of a small team. In this paper, we propose that a complete visual analytical system designed for solving real-world tasks ought to have two integrated components: a single-user desktop system and a mirroring system suitable for a collaborative environment.",Dong Hyun Jeong;Evan A. Suma;Thomas Butkiewicz;William Ribarsky;Remco Chang,Dong Hyun Jeong;Evan Suma;Thomas Butkiewicz;William Ribarsky;Remco Chang,Univ. of the District of Columbia;Univ. of Southern California;Univ. of North Carolina at Charlotte;Univ. of North Carolina at Charlotte;Tufts University,,,1.0,1.0,2.0,
VAST,2016,Squares: Supporting Interactive Performance Analysis for Multiclass Classifiers,10.1109/TVCG.2016.2598828,1324,"[641, 811, 688, 598, 1050]","[1423, 1432, 1436, 1487, 1488, 1495, 1514, 1525]",http://dx.doi.org/10.1109/TVCG.2016.2598828,61,70,J,"Performance analysis is critical in applied machine learning because it influences the models practitioners produce. Current performance analysis tools suffer from issues including obscuring important characteristics of model behavior and dissociating performance from data. In this work, we present Squares, a performance visualization for multiclass classification problems. Squares supports estimating common performance metrics while displaying instance-level distribution information necessary for helping practitioners prioritize efforts and access data. Our controlled study shows that practitioners can assess performance significantly faster and more accurately with Squares than a confusion matrix, a common performance analysis tool in machine learning.",Donghao Ren;Saleema Amershi;Bongshin Lee;Jina Suh;Jason D. Williams,Donghao Ren;Saleema Amershi;Bongshin Lee;Jina Suh;Jason D. Williams,"University of California, Santa Barbara;Microsoft Research;Microsoft Research;Microsoft Research;Microsoft Research",10.1109/VISUAL.2000.885740;10.1109/VAST.2010.5652443;10.1109/TVCG.2012.277;10.1109/TVCG.2014.2346660;10.1109/VAST.2011.6102453;10.1109/TVCG.2011.185,Performance analysis;classification;usable machine learning,18.0,33.0,38.0,
VAST,2016,Towards Better Analysis of Deep Convolutional Neural Networks,10.1109/TVCG.2016.2598831,1327,"[388, 325, 1224, 1068, 1201, 1175, 667, 1020]","[1403, 1423, 1427, 1432, 1436, 1442, 1444, 1488, 1496, 1498, 1514, 1521, 1525, 1528, 1544, 1554, 1555, 1562, 1567, 1580, 1582, 1598, 1616]",http://dx.doi.org/10.1109/TVCG.2016.2598831,91,100,J,"Deep convolutional neural networks (CNNs) have achieved breakthrough performance in many pattern recognition tasks such as image classification. However, the development of high-quality deep models typically relies on a substantial amount of trial-and-error, as there is still no clear understanding of when and why a deep model works. In this paper, we present a visual analytics approach for better understanding, diagnosing, and refining deep CNNs. We formulate a deep CNN as a directed acyclic graph. Based on this formulation, a hybrid visualization is developed to disclose the multiple facets of each neuron and the interactions between them. In particular, we introduce a hierarchical rectangle packing algorithm and a matrix reordering algorithm to show the derived features of a neuron cluster. We also propose a biclustering-based edge bundling method to reduce visual clutter caused by a large number of connections between neurons. We evaluated our method on a set of CNNs and the results are generally favorable.",Mengchen Liu;Jiaxin Shi;Zhen Li;Chongxuan Li;Jun Zhu 0001;Shixia Liu,Mengchen Liu;Jiaxin Shi;Zhen Li;Chongxuan Li;Jun Zhu;Shixia Liu,"School of Software and TNListTsinghua University;Dept. of Comp. Sci. &#x0026; Tech., State Key Lab of Intell. Tech. &#x0026; Sys.TNList LabCBICR Center;School of Software and TNListTsinghua University;Dept. of Comp. Sci. &#x0026; Tech., State Key Lab of Intell. Tech. &#x0026; Sys.TNList LabCBICR Center;School of Software and TNListTsinghua University;School of Software and TNListTsinghua University",10.1109/TVCG.2015.2468151;10.1109/TVCG.2015.2467554;10.1109/TVCG.2015.2467813;10.1109/TVCG.2010.132;10.1109/TVCG.2008.135;10.1109/TVCG.2014.2346919;10.1109/TVCG.2011.239;10.1109/VISUAL.1991.175815;10.1109/VISUAL.2005.1532820;10.1109/TVCG.2007.70582;10.1109/TVCG.2014.2346433,Deep convolutional neural networks;rectangle packing;matrix reordering;edge bundling;biclustering,40.0,97.0,60.0,
VAST,2016,Visualizing the Hidden Activity of Artificial Neural Networks,10.1109/TVCG.2016.2598838,1328,"[384, 897, 658, 1046, 1174, 637]","[1403, 1421, 1423, 1432, 1436, 1444, 1488, 1495, 1514, 1525, 1562, 1614, 1616]",http://dx.doi.org/10.1109/TVCG.2016.2598838,101,110,J,"In machine learning, pattern classification assigns high-dimensional vectors (observations) to classes based on generalization from examples. Artificial neural networks currently achieve state-of-the-art results in this task. Although such networks are typically used as black-boxes, they are also widely believed to learn (high-dimensional) higher-level representations of the original observations. In this paper, we propose using dimensionality reduction for two tasks: visualizing the relationships between learned representations of observations, and visualizing the relationships between artificial neurons. Through experiments conducted in three traditional image classification benchmark datasets, we show how visualization can provide highly valuable feedback for network designers. For instance, our discoveries in one of these datasets (SVHN) include the presence of interpretable clusters of learned representations, and the partitioning of artificial neurons into groups with apparently related discriminative roles.",Paulo E. Rauber;Samuel G. Fadel;Alexandre X. Falcão;Alexandru Telea,Paulo E. Rauber;Samuel G. Fadel;Alexandre X. Falcão;Alexandru C. Telea,University of GroningenUniversity of Campinas;University of São Paulo;University of Campinas;University of Groningen,10.1109/TVCG.2011.178;10.1109/TVCG.2011.220;10.1109/TVCG.2013.150;10.1109/TVCG.2014.2346578;10.1109/TVCG.2008.125;10.1109/TVCG.2015.2467553,Artificial neural networks;dimensionality reduction;algorithm understanding,21.0,70.0,50.0,
InfoVis,2017,LSTMVis: A Tool for Visual Analysis of Hidden State Dynamics in Recurrent Neural Networks,10.1109/TVCG.2017.2744158,1403,"[1328, 1327]","[1432, 1495, 1496, 1498, 1514, 1525, 1562, 1570, 1598, 1616]",http://dx.doi.org/10.1109/TVCG.2017.2744158,667,676,J,"Recurrent neural networks, and in particular long short-term memory (LSTM) networks, are a remarkably effective tool for sequence modeling that learn a dense black-box hidden representation of their sequential input. Researchers interested in better understanding these models have studied the changes in hidden state representations over time and noticed some interpretable patterns but also significant noise. In this work, we present LSTMVis, a visual analysis tool for recurrent neural networks with a focus on understanding these hidden state dynamics. The tool allows users to select a hypothesis input range to focus on local state changes, to match these states changes to similar patterns in a large data set, and to align these results with structural annotations from their domain. We show several use cases of the tool for analyzing specific hidden state properties on dataset containing nesting, phrase structure, and chord progressions, and demonstrate how the tool can be used to isolate patterns for further statistical analysis. We characterize the domain, the different stakeholders, and their goals and tasks. Long-term usage data after putting the tool online revealed great interest in the machine learning community.",Hendrik Strobelt;Sebastian Gehrmann;Hanspeter Pfister;Alexander M. Rush,Hendrik Strobelt;Sebastian Gehrmann;Hanspeter Pfister;Alexander M. Rush,Harvard SEAS;Harvard SEAS;Harvard SEAS;Harvard SEAS,10.1109/TVCG.2016.2598831;10.1109/TVCG.2016.2598838;10.1109/VISUAL.2005.1532820,"Visualization,Machine Learning,Recurrent Neural Networks,LSTM",14.0,30.0,35.0,
VAST,2017,DeepEyes: Progressive Visual Analytics for Designing Deep Neural Networks,10.1109/TVCG.2017.2744358,1421,"[1328, 1044, 1046, 1275, 1277]","[1496, 1498, 1514, 1525, 1562, 1598, 1616]",http://dx.doi.org/10.1109/TVCG.2017.2744358,98,108,J,"Deep neural networks are now rivaling human accuracy in several pattern recognition problems. Compared to traditional classifiers, where features are handcrafted, neural networks learn increasingly complex features directly from the data. Instead of handcrafting the features, it is now the network architecture that is manually engineered. The network architecture parameters such as the number of layers or the number of filters per layer and their interconnections are essential for good performance. Even though basic design guidelines exist, designing a neural network is an iterative trial-and-error process that takes days or even weeks to perform due to the large datasets used for training. In this paper, we present DeepEyes, a Progressive Visual Analytics system that supports the design of neural networks during training. We present novel visualizations, supporting the identification of layers that learned a stable set of patterns and, therefore, are of interest for a detailed analysis. The system facilitates the identification of problems, such as superfluous filters or layers, and information that is not being captured by the network. We demonstrate the effectiveness of our system through multiple use cases, showing how a trained network can be compressed, reshaped and adapted to different problems.",Nicola Pezzotti;Thomas Höllt;Jan C. van Gemert;Boudewijn P. F. Lelieveldt;Elmar Eisemann;Anna Vilanova,Nicola Pezzotti;Thomas Höllt;Jan Van Gemert;Boudewijn P.F. Lelieveldt;Elmar Eisemann;Anna Vilanova,"Intelligent Systems department, Delft University of Technology, Delft, The Netherlands;Intelligent Systems department, Delft University of Technology, Delft, The Netherlands;Intelligent Systems department, Delft University of Technology, Delft, The Netherlands;Department of Radiology, Division of Image Processing, Leiden University Medical Center, Leiden, The Netherlands;Intelligent Systems department, Delft University of Technology, Delft, The Netherlands;Intelligent Systems department, Delft University of Technology, Delft, The Netherlands",10.1109/TVCG.2016.2598468;10.1109/TVCG.2014.2346578;10.1109/TVCG.2016.2598838;10.1109/TVCG.2014.2346574;10.1109/TVCG.2016.2598470,"Progressive visual analytics,deep neural networks,machine learning",10.0,23.0,50.0,
VAST,2017,Visual Diagnosis of Tree Boosting Methods,10.1109/TVCG.2017.2744378,1423,"[833, 811, 1324, 1327, 1328, 688, 598, 1050]","[1491, 1495, 1525, 1528]",http://dx.doi.org/10.1109/TVCG.2017.2744378,163,173,J,"Tree boosting, which combines weak learners (typically decision trees) to generate a strong learner, is a highly effective and widely used machine learning method. However, the development of a high performance tree boosting model is a time-consuming process that requires numerous trial-and-error experiments. To tackle this issue, we have developed a visual diagnosis tool, BOOSTVis, to help experts quickly analyze and diagnose the training process of tree boosting. In particular, we have designed a temporal confusion matrix visualization, and combined it with a t-SNE projection and a tree visualization. These visualization components work together to provide a comprehensive overview of a tree boosting model, and enable an effective diagnosis of an unsatisfactory training process. Two case studies that were conducted on the Otto Group Product Classification Challenge dataset demonstrate that BOOSTVis can provide informative feedback and guidance to improve understanding and diagnosis of tree boosting algorithms.",Shixia Liu;Jiannan Xiao;Junlin Liu;Xiting Wang;Jing Wu;Jun Zhu 0001,Shixia Liu;Jiannan Xiao;Junlin Liu;Xiting Wang;Jing Wu;Jun Zhu,Tsinghua University and National Engineering Lab for Big Data Software;Tsinghua University and National Engineering Lab for Big Data Software;Tsinghua University and National Engineering Lab for Big Data Software;Microsoft Research;Cardiff University;Tsinghua University and National Engineering Lab for Big Data Software,10.1109/TVCG.2014.2346660;10.1109/VAST.2010.5652443;10.1109/TVCG.2012.277;10.1109/VAST.2012.6400492;10.1109/TVCG.2016.2598831;10.1109/TVCG.2016.2598838;10.1109/TVCG.2016.2598828;10.1109/VISUAL.2000.885740;10.1109/VISUAL.2005.1532820;10.1109/VAST.2011.6102453,"tree boosting,model analysis,temporal confusion matrix,tree visualization",2.0,6.0,68.0,
VAST,2017,Do Convolutional Neural Networks Learn Class Hierarchy?,10.1109/TVCG.2017.2744683,1432,"[1324, 1327, 1328, 688, 1241, 1050, 1403]","[1496, 1498, 1514, 1525, 1598, 1616]",http://dx.doi.org/10.1109/TVCG.2017.2744683,152,162,J,"Convolutional Neural Networks (CNNs) currently achieve state-of-the-art accuracy in image classification. With a growing number of classes, the accuracy usually drops as the possibilities of confusion increase. Interestingly, the class confusion patterns follow a hierarchical structure over the classes. We present visual-analytics methods to reveal and analyze this hierarchy of similar classes in relation with CNN-internal data. We found that this hierarchy not only dictates the confusion patterns between the classes, it furthermore dictates the learning behavior of CNNs. In particular, the early layers in these networks develop feature detectors that can separate high-level groups of classes quite well, even after a few training epochs. In contrast, the latter layers require substantially more epochs to develop specialized feature detectors that can separate individual classes. We demonstrate how these insights are key to significant improvement in accuracy by designing hierarchy-aware CNNs that accelerate model convergence and alleviate overfitting. We further demonstrate how our methods help in identifying various quality issues in the training data.",Bilal Alsallakh;Amin Jourabloo;Mao Ye;Xiaoming Liu 0002;Liu Ren,Alsallakh Bilal;Amin Jourabloo;Mao Ye;Xiaoming Liu;Liu Ren,"Bosch Research North AmericaPalo Alto, CA;Michigan State University;Bosch Research North AmericaPalo Alto, CA;Michigan State University;Bosch Research North AmericaPalo Alto, CA",10.1109/TVCG.2014.2346660;10.1109/VAST.2015.7347637;10.1109/TVCG.2016.2598831;10.1109/TVCG.2016.2598838;10.1109/TVCG.2016.2598828;10.1109/TVCG.2017.2744158;10.1109/VISUAL.2005.1532820;10.1109/VAST.2011.6102453,"Convolutional Neural Networks,deep learning,image classification,large-scale classification,confusion matrix",9.0,12.0,77.0,
VAST,2017,ActiVis: Visual Exploration of Industry-Scale Deep Neural Network Models,10.1109/TVCG.2017.2744718,1436,"[1187, 904, 1324, 1327, 1328, 1041, 688, 598, 1241]","[1495, 1496, 1498, 1514, 1525, 1562, 1570, 1598, 1616]",http://dx.doi.org/10.1109/TVCG.2017.2744718,88,97,J,"While deep learning models have achieved state-of-the-art accuracies for many prediction tasks, understanding these models remains a challenge. Despite the recent interest in developing visual tools to help users interpret deep learning models, the complexity and wide variety of models deployed in industry, and the large-scale datasets that they used, pose unique design challenges that are inadequately addressed by existing work. Through participatory design sessions with over 15 researchers and engineers at Facebook, we have developed, deployed, and iteratively improved ActiVis, an interactive visualization system for interpreting large-scale deep learning models and results. By tightly integrating multiple coordinated views, such as a computation graph overview of the model architecture, and a neuron activation view for pattern discovery and comparison, users can explore complex deep neural network models at both the instance-and subset-level. ActiVis has been deployed on Facebook's machine learning platform. We present case studies with Facebook researchers and engineers, and usage scenarios of how ActiVis may work with different models.",Minsuk Kahng;Pierre Y. Andrews;Aditya Kalro;Duen Horng Chau,Minsuk Kahng;Pierre Y. Andrews;Aditya Kalro;Duen Horng (Polo) Chau,Georgia Institute of Technology;Facebook;Facebook;Georgia Institute of Technology,10.1109/VAST.2015.7347637;10.1109/VAST.2010.5652443;10.1109/TVCG.2013.157;10.1109/TVCG.2014.2346482;10.1109/TVCG.2015.2467622;10.1109/TVCG.2016.2598831;10.1109/TVCG.2016.2598838;10.1109/TVCG.2016.2598828;10.1109/VISUAL.2005.1532820;10.1109/VAST.2011.6102453,"Visual analytics,deep learning,machine learning,information visualization",18.0,32.0,38.0,
VAST,2017,Visualizing Dataflow Graphs of Deep Learning Models in TensorFlow,10.1109/TVCG.2017.2744878,1442,"[263, 232, 1327, 1168, 210, 1145, 191]","[1495, 1496, 1514, 1525, 1562, 1598, 1616]",http://dx.doi.org/10.1109/TVCG.2017.2744878,1,12,J,"We present a design study of the TensorFlow Graph Visualizer, part of the TensorFlow machine intelligence platform. This tool helps users understand complex machine learning architectures by visualizing their underlying dataflow graphs. The tool works by applying a series of graph transformations that enable standard layout techniques to produce a legible interactive diagram. To declutter the graph, we decouple non-critical nodes from the layout. To provide an overview, we build a clustered graph using the hierarchical structure annotated in the source code. To support exploration of nested structure on demand, we perform edge bundling to enable stable and responsive cluster expansion. Finally, we detect and highlight repeated structures to emphasize a model's modular composition. To demonstrate the utility of the visualizer, we describe example usage scenarios and report user feedback. Overall, users find the visualizer useful for understanding, debugging, and sharing the structures of their models.",Kanit Wongsuphasawat;Daniel Smilkov;James Wexler;Jimbo Wilson;Dan Mané;Doug Fritz;Dilip Krishnan;Fernanda B. Viégas;Martin Wattenberg,Kanit Wongsuphasawat;Daniel Smilkov;James Wexler;Jimbo Wilson;Dandelion Mané;Doug Fritz;Dilip Krishnan;Fernanda B. Viégas;Martin Wattenberg,Paul G. Allen School of Computer Science & EngineeringUniversity of Washington;Google Research;Google Research;Google Research;Google Research;Google Research;Google Research;Google Research;Google Research,10.1109/INFVIS.2005.1532130;10.1109/TVCG.2006.156;10.1109/INFVIS.2004.66;10.1109/TVCG.2015.2467451;10.1109/TVCG.2016.2598831;10.1109/VISUAL.2005.1532820;10.1109/INFVIS.2004.43;10.1109/TVCG.2015.2467251,"Neural Network,Graph Visualization,Dataflow Graph,Clustered Graph",14.0,33.0,57.0,BP
VAST,2017,Analyzing the Training Processes of Deep Generative Models,10.1109/TVCG.2017.2744938,1444,"[1282, 1319, 1325, 1327, 1328, 1366, 1048, 667, 1310]","[1495, 1496, 1498, 1525, 1528, 1582, 1598, 1616]",http://dx.doi.org/10.1109/TVCG.2017.2744938,77,87,J,"Among the many types of deep models, deep generative models (DGMs) provide a solution to the important problem of unsupervised and semi-supervised learning. However, training DGMs requires more skill, experience, and know-how because their training is more complex than other types of deep models such as convolutional neural networks (CNNs). We develop a visual analytics approach for better understanding and diagnosing the training process of a DGM. To help experts understand the overall training process, we first extract a large amount of time series data that represents training dynamics (e.g., activation changes over time). A blue-noise polyline sampling scheme is then introduced to select time series samples, which can both preserve outliers and reduce visual clutter. To further investigate the root cause of a failed training process, we propose a credit assignment algorithm that indicates how other neurons contribute to the output of the neuron causing the training failure. Two case studies are conducted with machine learning experts to demonstrate how our approach helps understand and diagnose the training processes of DGMs. We also show how our approach can be directly used to analyze other types of deep models, such as CNNs.",Mengchen Liu;Jiaxin Shi;Kelei Cao;Jun Zhu 0001;Shixia Liu,Mengchen Liu;Jiaxin Shi;Kelei Cao;Jun Zhu;Shixia Liu,Tsinghua UniversityNational Engineering Lab for Big Data Software;Tsinghua University;Tsinghua UniversityNational Engineering Lab for Big Data Software;Tsinghua University;Tsinghua UniversityNational Engineering Lab for Big Data Software,10.1109/TVCG.2016.2598496;10.1109/TVCG.2014.2346594;10.1109/TVCG.2010.131;10.1109/TVCG.2011.239;10.1109/TVCG.2016.2598831;10.1109/TVCG.2016.2598797;10.1109/TVCG.2016.2598838;10.1109/TVCG.2016.2598829;10.1109/VISUAL.2005.1532820;10.1109/VAST.2016.7883511;10.1109/TVCG.2016.2598664,"deep learning,deep generative models,blue noise sampling,credit assignment",6.0,21.0,55.0,
VAST,2017,Understanding Hidden Memories of Recurrent Neural Networks,10.1109/VAST.2017.8585721,1488,"[1324, 1327, 656, 1328, 598, 790, 1272, 1241, 1051]","[1496, 1498, 1514, 1562]",http://dx.doi.org/10.1109/VAST.2017.8585721,13,24,C,"Recurrent neural networks (RNNs) have been successfully applied to various natural language processing (NLP) tasks and achieved better results than conventional methods. However, the lack of understanding of the mechanisms behind their effectiveness limits further improvements on their architectures. In this paper, we present a visual analytics method for understanding and comparing RNN models for NLP tasks. We propose a technique to explain the function of individual hidden state units based on their expected response to input texts. We then co-cluster hidden state units and words based on the expected response and visualize co-clustering results as memory chips and word clouds to provide more structured knowledge on RNNs' hidden states. We also propose a glyph-based sequence visualization based on aggregate information to analyze the behavior of an RNN's hidden state at the sentence-level. The usability and effectiveness of our method are demonstrated through case studies and reviews from domain experts.",Yao Ming;Shaozu Cao;Ruixiang Zhang;Zhen Li;Yuanzhe Chen;Yangqiu Song;Huamin Qu,Yao Ming;Shaozu Cao;Ruixiang Zhang;Zhen Li;Yuanzhe Chen;Yangqiu Song;Huamin Qu,Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology,10.1109/VAST.2015.7347637;10.1109/VAST.2010.5652443;10.1109/TVCG.2012.252;10.1109/TVCG.2016.2598831;10.1109/TVCG.2011.212;10.1109/TVCG.2016.2598838;10.1109/TVCG.2016.2598838;10.1109/TVCG.2016.2598828;10.1109/TVCG.2016.2598465;10.1109/TVCG.2014.2346665,"recurrent neural networks,visual analytics,understanding neural model,co-clustering",9.0,17.0,52.0,
VAST,2018,RuleMatrix: Visualizing and Understanding Classifiers with Rules,10.1109/TVCG.2018.2864812,1514,"[1442, 1324, 1421, 1327, 1488, 1487, 1328, 688, 1432, 1403, 1436]",[],http://dx.doi.org/10.1109/TVCG.2018.2864812,342,352,J,"With the growing adoption of machine learning techniques, there is a surge of research interest towards making machine learning systems more transparent and interpretable. Various visualizations have been developed to help model developers understand, diagnose, and refine machine learning models. However, a large number of potential but neglected users are the domain experts with little knowledge of machine learning but are expected to work with machine learning systems. In this paper, we present an interactive visualization technique to help users with little expertise in machine learning to understand, explore and validate predictive models. By viewing the model as a black box, we extract a standardized rule-based knowledge representation from its input-output behavior. Then, we design RuleMatrix, a matrix-based visualization of rules to help users navigate and verify the rules and the black-box model. We evaluate the effectiveness of RuleMatrix via two use cases and a usability study.",Yao Ming;Huamin Qu;Enrico Bertini,Yao Ming;Huamin Qu;Enrico Bertini,University of Science and Technology;University of Science and Technology;New York University,10.1109/TVCG.2017.2744683;10.1109/TVCG.2017.2744718;10.1109/VAST.2017.8585720;10.1109/TVCG.2016.2598831;10.1109/VAST.2017.8585721;10.1109/TVCG.2017.2744358;10.1109/TVCG.2016.2598838;10.1109/TVCG.2016.2598828;10.1109/TVCG.2017.2744158;10.1109/VISUAL.2005.1532820;10.1109/VAST.2011.6102453;10.1109/TVCG.2017.2744878,"explainable machine learning,rule visualization,visual analytics",0.0,7.0,48.0,
