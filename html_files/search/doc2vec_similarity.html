<html>
<head>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/vis/4.16.1/vis.css" type="text/css" />
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/vis/4.16.1/vis-network.min.js"> </script>
<center>
<h2>Paper Similarity using Doc2Vec</h2>
</center>

<!-- <link rel="stylesheet" href="../node_modules/vis/dist/vis.min.css" type="text/css" />
<script type="text/javascript" src="../node_modules/vis/dist/vis.js"> </script>-->

<style type="text/css">

        #mynetwork {
            width: 100%;
            height: 500px;
            background-color: #ffffff;
            border: 1px solid lightgray;
            position: relative;
            float: left;
        }

        
        #loadingBar {
            position:absolute;
            top:0px;
            left:0px;
            width: 100%;
            height: 500px;
            background-color:rgba(200,200,200,0.8);
            -webkit-transition: all 0.5s ease;
            -moz-transition: all 0.5s ease;
            -ms-transition: all 0.5s ease;
            -o-transition: all 0.5s ease;
            transition: all 0.5s ease;
            opacity:1;
        }

        #bar {
            position:absolute;
            top:0px;
            left:0px;
            width:20px;
            height:20px;
            margin:auto auto auto auto;
            border-radius:11px;
            border:2px solid rgba(30,30,30,0.05);
            background: rgb(0, 173, 246); /* Old browsers */
            box-shadow: 2px 0px 4px rgba(0,0,0,0.4);
        }

        #border {
            position:absolute;
            top:10px;
            left:10px;
            width:500px;
            height:23px;
            margin:auto auto auto auto;
            box-shadow: 0px 0px 4px rgba(0,0,0,0.2);
            border-radius:10px;
        }

        #text {
            position:absolute;
            top:8px;
            left:530px;
            width:30px;
            height:50px;
            margin:auto auto auto auto;
            font-size:22px;
            color: #000000;
        }

        div.outerBorder {
            position:relative;
            top:400px;
            width:600px;
            height:44px;
            margin:auto auto auto auto;
            border:8px solid rgba(0,0,0,0.1);
            background: rgb(252,252,252); /* Old browsers */
            background: -moz-linear-gradient(top,  rgba(252,252,252,1) 0%, rgba(237,237,237,1) 100%); /* FF3.6+ */
            background: -webkit-gradient(linear, left top, left bottom, color-stop(0%,rgba(252,252,252,1)), color-stop(100%,rgba(237,237,237,1))); /* Chrome,Safari4+ */
            background: -webkit-linear-gradient(top,  rgba(252,252,252,1) 0%,rgba(237,237,237,1) 100%); /* Chrome10+,Safari5.1+ */
            background: -o-linear-gradient(top,  rgba(252,252,252,1) 0%,rgba(237,237,237,1) 100%); /* Opera 11.10+ */
            background: -ms-linear-gradient(top,  rgba(252,252,252,1) 0%,rgba(237,237,237,1) 100%); /* IE10+ */
            background: linear-gradient(to bottom,  rgba(252,252,252,1) 0%,rgba(237,237,237,1) 100%); /* W3C */
            filter: progid:DXImageTransform.Microsoft.gradient( startColorstr='#fcfcfc', endColorstr='#ededed',GradientType=0 ); /* IE6-9 */
            border-radius:72px;
            box-shadow: 0px 0px 10px rgba(0,0,0,0.2);
        }
        

        

        
        /* position absolute is important and the container has to be relative or absolute as well. */
	    div.popup {
            position:absolute;
            top:0px;
            left:0px;
            display:none;
            background-color:#f5f4ed;
            -moz-border-radius: 3px;
            -webkit-border-radius: 3px;
            border-radius: 3px;
            border: 1px solid #808074;
            box-shadow: 3px 3px 10px rgba(0, 0, 0, 0.2);
	    }

	    /* hide the original tooltip */
	    .vis-network-tooltip {
	      display:none;
	    }
        
</style>

</head>

<body>
<div id = "mynetwork"></div>


<script type="text/javascript">

    // initialize global variables.
    var edges;
    var nodes;
    var network; 
    var container;
    var options, data;

    
    // This method is responsible for drawing the graph, returns the drawn network
    function drawGraph() {
        var container = document.getElementById('mynetwork');
        
        

        // parsing and collecting nodes and edges from the python
        nodes = new vis.DataSet([{"color": "gray", "id": 15, "label": 15, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 15 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.1995.528695\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: C.A. Burton;L.J. Johnston;E.A. Sonenberg; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Case study: an empirical investigation of thumbnail image recognition; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The use of thumbnails (i.e., miniatures) in the user-interface of image databases allows searching and selection of images without the need for naming policies. Treating parent images prior to reduction with edge-detecting smoothing, lossy image compression, or static codebook compression resulted in thumbnails where the distortion caused by reduction was lessened. An experiment assessing these techniques found resulting thumbnails could be recognised more quickly and accurately than thumbnails of the same parent images that had been reduced without treatment. This pretreatment in thumbnail creation is offered as an improvement."}, {"color": "gray", "id": 18, "label": 18, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 18 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.1996.559210\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: S.F. Roth;P. Lucas;J.A. Senn;C.C. Gomberg;M.B. Burks;P.J. Stroffolino;A.J. Kolojechick;C. Dunmire; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visage: a user interface environment for exploring information; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Visage is a prototype user interface environment for exploring and analyzing information. It represents an approach to coordinating multiple visualizations, analysis and presentation tools in data-intensive domains. Visage is based on an information-centric approach to user interface design which strives to eliminate impediments to direct user access to information objects across applications and visualizations. Visage consists of a set of data manipulation operations, an intelligent system for generating a wide variety of data visualizations (SAGE) and a briefing tool that supports the conversion of visual displays used during exploration into interactive presentation slides. This paper presents the user interface components and styles of interaction that are central to Visage\u0027s information-centric approach."}, {"color": "gray", "id": 21, "label": 21, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 21 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.1996.559213\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: M.C. Chuah;S.F. Roth; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: On the semantics of interactive visualizations; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Interactive techniques are powerful tools for manipulating visualizations to analyze, communicate and acquire information. This is especially true for large data sets or complex 3D visualizations. Although many new types of interaction have been introduced recently, very little work has been done on understanding what their components are, how they are related and how they can be combined. This paper begins to address these issues with a framework for classifying interactive visualizations. Our goal is a framework that will enable us to develop toolkits for assembling visualization interfaces both interactively and automatically."}, {"color": "gray", "id": 25, "label": 25, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 25 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.1996.559218\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: K. Andrews;M. Pichler;P. Wolf; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Towards rich information landscapes for visualising structured Web spaces; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The Harmony browser for the Hyper-G Web server utilises Hyper-G\u0027s rich data model to provide a number of tightly-coupled, two- and three-dimensional visualisation and navigational facilities. In particular the Harmony Information Landscape visualises the hierarchical structure of Hyper-G spaces upon a plane in three-dimensional space. The Harmony Information Landscape has now been extended to display a combined structure and link map by selectively superimposing hyperlink relationships in the vertical dimension above and below the hierarchy map. In addition, documents returned by search queries may be selectively \"plotted\" in the landscape, indicating their whereabouts in a broader context, and several sets of 3D icons are available for representing the various document types."}, {"color": "gray", "id": 30, "label": 30, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 30 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.1996.559223\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: C.L. Bentley;M.O. Ward; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Animating multidimensional scaling to visualize N-dimensional data sets; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Many techniques have been developed for visualizing multivariate (multidimensional) data. Most, if not all, are limited by the number of dimensions which can be effectively displayed. Multidimensional scaling (MDS) is an iterative non-linear technique for projecting n-D data down to a lower number of dimensions. This work presents extensions to MDS that enhance visualization of high-dimensional data sets. These extensions include animation, stochastic perturbation, and flow visualization techniques."}, {"color": "gray", "id": 36, "label": 36, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 36 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.1996.559229\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Liqun Jin;D.C. Banks; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visualizing a tennis match; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: This paper describes our work on visualizing the information of a tennis match. We use competition trees to organize the information of a tennis match and visualize the competition trees by the top-nesting layered maps with translucent colored layers. We create iconic representations to describe the detailed information of athletic events in an intuitive manner. Specialized views of the information are displayed by applying multiple Magic Lens filters on the top-nesting layered maps. The dynamic nature of the tennis match is depicted by the time-varying display. The approach we present in this paper can be used to visualize other sports information, information with competition property, or information with hierarchical structure."}, {"color": "gray", "id": 38, "label": 38, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 38 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.1997.636759\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: M.H. Gross;T.C. Sprenger;J. Finger; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visualizing information on a sphere; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We describe a method for the visualization of information units on spherical domains which is employed in the banking industry for risk analysis, stock prediction and other tasks. The system is based on a quantification of the similarity of related objects that governs the parameters of a mass-spring system. Unlike existing approaches we initialize all information units onto the inner surface of two concentric spheres and attach them with springs to the outer sphere. Since the spring stiffnesses correspond to the computed similarity measures, the system converges into an energy minimum which reveals multidimensional relations and adjacencies in terms of spatial neighborhoods. Depending on the application scenario our approach supports different topological arrangements of related objects. In order to cope with large data sets we propose a blobby clustering mechanism that enables encapsulation of similar objects by implicit shapes. In addition, we implemented various interaction techniques allowing semantic analysis of the underlying data sets. Our prototype system IVORY is written in Java, and its versatility is illustrated by an example from financial service providers."}, {"color": "gray", "id": 42, "label": 42, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 42 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.1997.636784\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: M.-A.D. Storey;K. Wong;F.D. Fracchia;H.A. Muller; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: On integrating visualization techniques for effective software exploration; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: This paper describes the SHriMP visualization technique for seamlessly exploring software structure and browsing source code, with a focus on effectively assisting hybrid program comprehension strategies. The technique integrates both pan+zoom and fisheye-view visualization approaches for exploring a nested graph view of software structure. The fisheye-view approach handles multiple focal points, which are necessary when examining several subsystems and their mutual interconnections. Source code is presented by embedding code fragments within the nodes of the nested graph. Finer connections among these fragments are represented by a network that is navigated using a hypertext link-following metaphor. SHriMP combines this hypertext metaphor with animated panning and zooming motions over the nested graph to provide continuous orientation and contextual cues for the user. The SHriMP tool is being evaluated in several user studies. Observations of users performing program understanding tasks with the tool are discussed."}, {"color": "gray", "id": 46, "label": 46, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 46 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.1997.636788\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: M. Derthick;S.F. Roth;J. Kolojejchick; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Coordinating declarative queries with a direct manipulation data exploration environment; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Interactive visualization techniques allow data exploration to be a continuous process, rather than a discrete sequence of queries and results as in traditional database systems. However limitations in expressive power of current visualization systems force users to go outside the system and form a new dataset in order to perform certain operations, such as those involving the relationship among multiple objects. Further, there is no support for integrating data from the new dataset into previous visualizations, so users must recreate them. Visage\u0027s information centric paradigm provides an architectural hook for linking data across multiple queries, removing this overhead. This paper describes the addition to Visage of a visual query language, called VQE, which allows users to express more complicated queries than in previous interactive visualization systems. Visualizations can be created from queries and vice versa. When either is updated, the other changes to maintain consistency."}, {"color": "gray", "id": 50, "label": 50, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 50 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.1997.636792\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: S.K. Card;J. Mackinlay; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: The structure of the information visualization design space; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Research on information visualization has reached the point where a number of successful point designs have been proposed and a variety of techniques have been discovered. It is now appropriate to describe and analyze portions of the design space so as to understand the differences among designs and to suggest new possibilities. This paper proposes an organization of the information visualization literature and illustrates it with a series of examples. The result is a framework for designing new visualizations and augmenting existing designs."}, {"color": "gray", "id": 52, "label": 52, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 52 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.1997.636794\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: R. Brath; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Metrics for effective information visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Metrics for information visualization will help designers create and evaluate 3D information visualizations. Based on experience from 60+ 3D information visualizations, the metrics we propose are: number of data points and data density; number of dimensions and cognitive overhead; occlusion percentage; and reference context and percentage of identifiable points."}, {"color": "gray", "id": 56, "label": 56, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 56 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.1998.729556\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: G.J. Wills; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: An interactive view for hierarchical clustering; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The paper describes a visualization of a general hierarchical clustering algorithm that allows the user to manipulate the number of classes produced by the clustering method without requiring a radical re-drawing of the clustering tree. The visual method used, a space filling recursive division of a rectangular area, keeps the items under consideration at the same screen position, even while the number of classes is under interactive control. As well as presenting a compact representation of the clustering with different cluster numbers, this method is particularly useful in a linked views environment where additional information can be added to a display to encode other information, without this added level of detail being perturbed when changes are made to the number of clusters."}, {"color": "gray", "id": 57, "label": 57, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 57 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.1998.729557\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: M.C. Chuah; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Dynamic aggregation with circular visual designs; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: One very effective method for managing large data sets is aggregation or binning. We consider two aggregation methods that are tightly coupled with interactive manipulation and the visual representation of the data. Through this integration we hope to provide effective support for the aggregation process, specifically by enabling: 1) automatic aggregation, 2) continuous change and control of the aggregation level, 3) spatially based aggregates, 4) context maintenance across different aggregate levels, and 5) feedback on the level of aggregation."}, {"color": "gray", "id": 71, "label": 71, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 71 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.1999.801851\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: J.J. Van Wijk;E.R. Van Selow; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Cluster and calendar based visualization of time series data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: A new method is presented to get an insight into univariate time series data. The problem addressed is how to identify patterns and trends on multiple time scales (days, weeks, seasons) simultaneously. The solution presented is to cluster similar daily data patterns, and to visualize the average patterns as graphs and the corresponding days on a calendar. This presentation provides a quick insight into both standard and exceptional patterns. Furthermore, it is well suited to interactive exploration. Two applications, numbers of employees present and energy consumption, are presented."}, {"color": "gray", "id": 75, "label": 75, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 75 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.1999.801855\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: K. Rodden;W. Basalaj;D. Sinclair;K. Wood; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Evaluating a visualisation of image similarity as a tool for image browsing; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: A similarity metric based on the low-level content of images can be used to create a visualisation in which visually similar images are displayed close to each other. We are carrying out a series of experiments to evaluate the usefulness of this type of visualisation as an image browsing aid. The initial experiment, described, considered whether people would find a given photograph more quickly in a visualisation than in a randomly arranged grid of images. The results show that the subjects were faster with the visualisation, although in post-experiment interviews many of them said that they preferred the clarity and regularity of the grid. We describe an algorithm with which the best aspects of the two layout types can be combined."}, {"color": "gray", "id": 78, "label": 78, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 78 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.1999.801858\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Ying-Huey Fua;M.O. Ward;E.A. Rundensteiner; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Navigating hierarchies with structure-based brushes; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Interactive selection is a critical component in exploratory visualization, allowing users to isolate subsets of the displayed information for highlighting, deleting, analysis, or focussed investigation. Brushing, a popular method for implementing the selection process, has traditionally been performed in either screen space or data space. We introduce the concept of a structure-based brush, which can be used to perform selection in hierarchically structured data sets. Our structure-based brush allows users to navigate hierarchies by specifying focal extents and level-of-detail on a visual representation of the structure. Proximity-based coloring, which maps similar colors to data that are closely related within the structure, helps convey both structural relationships and anomalies. We describe the design and implementation of our structure-based brushing tool. We also validate its usefulness using two distinct hierarchical visualization techniques, namely hierarchical parallel coordinates and tree-maps."}, {"color": "gray", "id": 79, "label": 79, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 79 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.1999.801859\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: R.M. Wilson;R.D. Bergeron; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Dynamic hierarchy specification and visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: This paper describes concepts that underlie the design and implementation of an information exploration system that allows users to impose arbitrary hierarchical organizations on their data. Such hierarchies allow a user to embed important semantic information into the hierarchy definition. Our goal is to recognize the significance of this implicit information and to utilize it in the hierarchy visualization. The innovative features of our system include the dynamic modification of the hierarchy definitions and the definition and implementation of a set of layout algorithms that utilize semantic information implicit in the tree construction."}, {"color": "gray", "id": 80, "label": 80, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 80 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.1999.801860\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: J.J. Van Wijk;H. Van de Wetering; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Cushion treemaps: visualization of hierarchical information; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: A new method is presented for the visualization of hierarchical information, such as directory structures and organization structures. Cushion treemaps inherit the elegance of standard treemaps: compact, space-filling displays of hierarchical information, based on recursive subdivision of a rectangular image space. Intuitive shading is used to provide insight in the hierarchical structure. During the subdivision, ridges are added per rectangle, which are rendered with a simple shading model. The result is a surface that consists of recursive cushions. The method is efficient, effective, easy to use and implement, and has a wide applicability."}, {"color": "gray", "id": 83, "label": 83, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 83 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.1999.801863\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: J.K. Rayson; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Aggregate Towers: scale sensitive visualization and decluttering of geospatial data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We have developed a technique, Aggregate Towers, that allows geospatial data to be visualized across a range of map scales. We use a combination of data aggregation algorithms and dynamically aggregating data markers (e.g., icons or symbols) to accommodate interactive zooming by a user while maintaining a representation that remains intuitive, consistent across multiple scales and uncluttered. This approach implicitly generates multiple levels of overview displays from a single set of underlying data."}, {"color": "gray", "id": 89, "label": 89, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 89 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.1999.801869\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: T. Munzner;F. Guimbretiere;G. Robertson; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Constellation: a visualization tool for linguistic queries from MindNet; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Constellation is a visualization system for the results of queries from the MindNet natural language semantic network. Constellation is targeted at helping MindNet\u0027s creators and users refine their algorithms, as opposed to understanding the structure of language. We designed a special-purpose graph layout algorithm which exploits higher-level structure in addition to the basic node and edge connectivity. Our layout prioritizes the creation of a semantic space to encode plausibility instead of traditional graph drawing metrics like minimizing edge crossings. We make careful use of several perceptual channels both to minimize the visual impact of edge crossings and to emphasize highlighted constellations of nodes and edges."}, {"color": "gray", "id": 93, "label": 93, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 93 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2000.885093\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: I. Fujishiro;Y. Ichikawa;R. Furuhata;Y. Takeshima; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: GADGET/IV: a taxonomic approach to semi-automatic design of information visualization applications using modular visualization environment; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Since novice users of visualization systems lack knowledge and expertise in data visualization, it is a tough task for them to generate efficient and effective visualizations that allow them to comprehend information that is embedded in the data. Therefore, systems supporting the users to design appropriate visualizations are of great importance. The GADGET (Goal-oriented Application Design Guidance for modular visualization EnvironmenTs) system, which has been developed by the authors (1997), interactively helps users to design scientific visualization applications by presenting appropriate MVE (Modular Visualization Environment) prototypes according to the specification of the visualization goals expressed mainly with the Wehrend matrix (S. Wehrend \u0026amp; C. Lewis, 1990). This paper extends this approach in order to develop a system named GADGET/IV, which is intended to provide the users with an environment for semi-automatic design of information visualization (IV) applications. To this end, a novel goal-oriented taxonomy of IV techniques is presented. Also, an initial design of the system architecture and user assistance flow is described. The usefulness of the GADGET/IV system is illustrated with example problems of Web site access frequency analysis."}, {"color": "gray", "id": 101, "label": 101, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 101 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2000.885097\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Pak Chung Wong;W. Cowley;H. Foote;E. Jurrus;J. Thomas; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visualizing sequential patterns for text mining; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: A sequential pattern in data mining is a finite series of elements such as A/spl rarr/B/spl rarr/C/spl rarr/D where A, B, C, and D are elements of the same domain. The mining of sequential patterns is designed to find patterns of discrete events that frequently happen in the same arrangement along a timeline. Like association and clustering, the mining of sequential patterns is among the most popular knowledge discovery techniques that apply statistical measures to extract useful information from large datasets. As out computers become more powerful, we are able to mine bigger datasets and obtain hundreds of thousands of sequential patterns in full detail. With this vast amount of data, we argue that neither data mining nor visualization by itself can manage the information and reflect the knowledge effectively. Subsequently, we apply visualization to augment data mining in a study of sequential patterns in large text corpora. The result shows that we can learn more and more quickly in an integrated visual data-mining environment."}, {"color": "gray", "id": 103, "label": 103, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 103 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2000.885102\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: I. Brewer;A.M. MacEachren;H. Abdo;J. Gundrum;G. Otto; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Collaborative geographic visualization: enabling shared understanding of environmental processes; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We describe a prototype same-time/different-place collaborative geovisualization environment. We outline an approach to understanding use and usability and present results of interviews with domain experts about the ways in which collaborative visualization might enable groups to work at a distance. One goal for our research is to design an effective and flexible system that can support group work on environmental science research mediated through dynamic geovisualization displays. We are addressing this goal using a four-step human-centered system design process, modeled on that proposed by (Gabbard et al., 1999) for development and evaluation of virtual environments. The steps they delineate are: user task analysis; expert guideline-based evaluation; formative user-centered evaluation; and summative comparative evaluation."}, {"color": "gray", "id": 106, "label": 106, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 106 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2000.885091\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: J. Stasko;E. Zhang; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Focus+context display and navigation techniques for enhancing radial, space-filling hierarchy visualizations; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Radial, space-filling visualizations can be useful for depicting information hierarchies, but they suffer from one major problem. As the hierarchy grows in size, many items become small, peripheral slices that are difficult to distinguish. We have developed three visualization/interaction techniques that provide flexible browsing of the display. The techniques allow viewers to examine the small items in detail while providing context within the entire information hierarchy. Additionally, smooth transitions between views help users maintain orientation within the complete information space."}, {"color": "gray", "id": 113, "label": 113, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 113 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2002.1173142\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: C. North;N. Conklin;V. Saini; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visualization schemas for flexible information visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Relational databases provide significant flexibility to organize, store, and manipulate an infinite variety of complex data collections. This flexibility is enabled by the concept of relational data schemas, which allow data owners to easily design custom databases according to their unique needs. However, user interfaces and information visualizations for accessing and utilizing databases have not kept pace with this level of flexibility. This paper introduces the concept of visualization schemas, based on the Snap-Together Visualization model, which are analogous to relational data schemas. Visualization schemas enable users to rapidly construct customized multiple-view visualizations for databases in a similarly flexible fashion without programming. Since the design of appropriate visualizations for a given database depends on the data schema, visualization schemas are a natural analogy to the data schema concept."}, {"color": "gray", "id": 115, "label": 115, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 115 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2002.1173144\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: D.A. Keim;S.C. North;C. Panse;J. Schneidewind; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Efficient cartogram generation: a comparison; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Cartograms are a well-known technique for showing geography-related statistical information, such as population demographics and epidemiological data. The basic idea is to distort a map by resizing its regions according to a statistical parameter, but in a way that keeps the map recognizable. We deal with the problem of making continuous cartograms that strictly retain the topology of the input mesh. We compare two algorithms to solve the continuous cartogram problem. The first one uses an iterative relocation of the vertices based on scanlines. The second one is based on the Gridfit technique, which uses pixel-based distortion based on a quadtree-like data structure."}, {"color": "gray", "id": 116, "label": 116, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 116 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2002.1173145\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: C. Olston;J.D. Mackinlay; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visualizing data with bounded uncertainty; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Visualization is a powerful way to facilitate data analysis, but it is crucial that visualization systems explicitly convey the presence, nature, and degree of uncertainty to users. Otherwise, there is a danger that data will be falsely interpreted, potentially leading to inaccurate conclusions. A common method for denoting uncertainty is to use error bars or similar techniques designed to convey the degree of statistical uncertainty. While uncertainty can often be modeled statistically, a second form of uncertainty, bounded uncertainty, can also arise that has very different properties than statistical uncertainty. Error bars should not be used for bounded uncertainty because they do not convey the correct properties, so a different technique should be used instead. We describe a technique for conveying bounded uncertainty in visualizations and show how it can be applied systematically to common displays of abstract charts and graphs. Interestingly, it is not always possible to show the exact degree of uncertainty, and in some cases it can only be displayed approximately."}, {"color": "gray", "id": 120, "label": 120, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 120 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2002.1173149\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: K. Matkovic;H. Hauser;R. Sainitzer;M.E. Groller; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Process visualization with levels of detail; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We demonstrate how we apply information visualization techniques to process monitoring. Virtual instruments are enhanced using history encoding instruments are capable of displaying the current value and the value from the near past. Multi-instruments are capable of displaying several data sources simultaneously. Levels of detail for virtual instruments are introduced where the screen area is inversely proportional to the information amount displayed. Furthermore the monitoring system is enhanced by using: 3D anchoring attachment of instruments to positions on a 3D model, collision avoidance a physically based spring model prevents instruments from overlapping, and focus+context rendering - giving the user a possibility to examine particular instruments in detail without loosing the context information."}, {"color": "gray", "id": 121, "label": 121, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 121 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2002.1173150\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: N. Amenta;J. Klingner; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Case study: visualizing sets of evolutionary trees; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We describe a visualization tool which allows a biologist to explore a large set of hypothetical evolutionary trees. Interacting with such a dataset allows the biologist to identify distinct hypotheses about how different species or organisms evolved, which would not have been clear from traditional analyses. Our system integrates a point-set visualization of the distribution of hypothetical trees with detail views of an individual tree, or of a consensus tree summarizing a subset of trees. Efficient algorithms were required for the key tasks of computing distances between trees, finding consensus trees, and laying out the point-set visualization."}, {"color": "gray", "id": 124, "label": 124, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 124 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2002.1173153\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: F. van Ham;J.J. van Wijk; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Beamtrees: compact visualization of large hierarchies; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Beamtrees are a new method for the visualization of large hierarchical data sets. Nodes are shown as stacked circular beams, such that both the hierarchical structure as well as the size of nodes are depicted. The dimensions of beams are calculated using a variation of the treemap algorithm. A small user study indicated that beamtrees are significantly more effective than nested treemaps and cushion treemaps for the extraction of global hierarchical information."}, {"color": "gray", "id": 126, "label": 126, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 126 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2002.1173155\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: M. Wattenberg; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Arc diagrams: visualizing structure in strings; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: This paper introduces a new visualization method, the arc diagram, which is capable of representing complex patterns of repetition in string data. Arc diagrams improve over previous methods such as dotplots because they scale efficiently for strings that contain many instances of the same subsequence. This paper describes design and implementation issues related to arc diagrams and shows how they may be applied to visualize such diverse data as music, text, and compiled code."}, {"color": "gray", "id": 127, "label": 127, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 127 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2002.1173156\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: J.-D. Fekete;C. Plaisant; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Interactive information visualization of a million items; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Existing information visualization techniques are usually limited to the display of a few thousand items. This article describes new interactive techniques capable of handling a million items (effectively visible and manageable on screen). We evaluate the use of hardware-based techniques available with newer graphics cards, as well as new animation techniques and non-standard graphical features such as stereovision and overlap count. These techniques have been applied to two popular information visualizations: treemaps and scatter plot diagrams; but are generic enough to be applied to other 2D representations as well."}, {"color": "gray", "id": 129, "label": 129, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 129 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2002.1173158\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: N. Conklin;S. Prabhakar;C. North; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Multiple foci drill-down through tuple and attribute aggregation polyarchies in tabular data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Information analysis often involves decomposing data into sub-groups to allow for comparison and identification of relationships. Breakdown Visualization provides a mechanism to support this analysis through user guided drill-down of polyarchical metadata. This metadata describes multiple hierarchical structures for organizing tuple aggregations and table attributes. This structure is seen in financial data, organizational structures, sport statistics, and other domains. A spreadsheet format enables comparison of visualizations at any level of the hierarchy. Breakdown Visualization allows users to drill-down a single hierarchy then pivot into another hierarchy within the same view. It utilizes a fix and move technique that allows users to select multiple foci for drill-down."}, {"color": "gray", "id": 130, "label": 130, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 130 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2002.1173159\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Yehuda Koren;L. Carmel;D. Harel; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: ACE: a fast multiscale eigenvectors computation for drawing huge graphs; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present an extremely fast graph drawing algorithm for very large graphs, which we term ACE (for Algebraic multigrid Computation of Eigenvectors). ACE exhibits an improvement of something like two orders of magnitude over the fastest algorithms we are aware of; it draws graphs of millions of nodes in less than a minute. ACE finds an optimal drawing by minimizing a quadratic energy function. The minimization problem is expressed as a generalized eigenvalue problem, which is rapidly solved using a novel algebraic multigrid technique. The same generalized eigenvalue problem seems to come up also in other fields, hence ACE appears to be applicable outside of graph drawing too."}, {"color": "gray", "id": 132, "label": 132, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 132 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2002.1173161\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: A. Morrison;G. Ross;M. Chalmers; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: A hybrid layout algorithm for sub-quadratic multidimensional scaling; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Many clustering and layout techniques have been used for structuring and visualising complex data. This paper is inspired by a number of such contemporary techniques and presents a novel hybrid approach based upon stochastic sampling, interpolation and spring models. We use Chalmers\u0027 1996 O(N/sup 2/) spring model as a benchmark when evaluating our technique, comparing layout quality and run times using data sets of synthetic and real data. Our algorithm runs in O(N/spl radic/N) and executes significantly faster than Chalmers\u0027 1996 algorithm, whilst producing superior layouts. In reducing complexity and run time, we allow the visualisation of data sets of previously infeasible size. Our results indicate that our method is a solid foundation for interactive and visual exploration of data."}, {"color": "gray", "id": 142, "label": 142, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 142 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2003.1249009\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: T.J. Jankun-Kelly;Kwan-Liu Ma; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: MoireGraphs: radial focus+context visualization and interaction for graphs with visual nodes; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Graph and tree visualization techniques enable interactive exploration of complex relations while communicating topology. However, most existing techniques have not been designed for situations where visual information such as images is also present at each node and must be displayed. This paper presents MoireGraphs to address this need. MoireGraphs combine a new focus+context radial graph layout with a suite of interaction techniques (focus strength changing, radial rotation, level highlighting, secondary foci, animated transitions and node information) to assist in the exploration of graphs with visual nodes. The method is scalable to hundreds of displayed visual nodes."}, {"color": "gray", "id": 147, "label": 147, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 147 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2003.1249014\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Pak Chung Wong;H. Foote;D. Adams;W. Cowley;J. Thomas; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Dynamic visualization of transient data streams; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We introduce two dynamic visualization techniques using multidimensional scaling to analyze transient data streams such as newswires and remote sensing imagery. While the time-sensitive nature of these data streams requires immediate attention in many applications, the unpredictable and unbounded characteristics of this information can potentially overwhelm many scaling algorithms that require a full re-computation for every update. We present an adaptive visualization technique based on data stratification to ingest stream information adaptively when influx rate exceeds processing rate. We also describe an incremental visualization technique based on data fusion to project new information directly onto a visualization subspace spanned by the singular vectors of the previously processed neighboring data. The ultimate goal is to leverage the value of legacy and new information and minimize re-processing of the entire dataset in full resolution. We demonstrate these dynamic visualization results using a newswire corpus and a remote sensing imagery sequence."}, {"color": "gray", "id": 151, "label": 151, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 151 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2003.1249018\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: M. Trutschl;G. Grinstein;U. Cvek; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Intelligently resolving point occlusion; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Large and high-dimensional data sets mapped to low-dimensional visualizations often result in perceptual ambiguities. One such ambiguity is overlap or occlusion that occurs when the number of records exceeds the number of unique locations in the presentation or when there exist two or more records that map to the same location. To lessen the affect of occlusion, non-standard visual attributes (i.e. shading and/or transparency) are applied, or such records may be remapped to a corresponding jittered location. The resulting mapping efficiently portrays the crowding of records but fails to provide the insight into the relationship between the neighboring records. We introduce a new interactive technique that intelligibly organizes overlapped points, a neural network-based smart jittering algorithm. We demonstrate this technique on a scatter plot, the most widely used visualization. The algorithm can be applied to other one, two, and multi-dimensional visualizations which represent data as points, including 3-dimensional scatter plots, RadViz, polar coordinates."}, {"color": "gray", "id": 152, "label": 152, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 152 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2003.1249019\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: M. Derthick;M.G. Christel;A.G. Hauptmann;H.D. Wactlar; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Constant density displays using diversity sampling; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The Informedia Digital Video Library user interface summarizes query results with a collage of representative keyframes. We present a user study in which keyframe occlusion caused difficulties. To use the screen space most efficiently to display images, both occlusion and wasted whitespace should be minimized. Thus optimal choices will tend toward constant density displays. However, previous constant density algorithms are based on global density, which leads to occlusion and empty space if the density is not uniform. We introduce an algorithm that considers the layout of individual objects and avoids occlusion altogether. Efficiency concerns are important for dynamic summaries of the Informedia Digital Video Library, which has hundreds of thousands of shots. Posting multiple queries that take into account parameters of the visualization as well as the original query reduces the amount of work required. This greedy algorithm is then compared to an optimal one. The approach is also applicable to visualizations containing complex graphical objects other than images, such as text, icons, or trees."}, {"color": "gray", "id": 155, "label": 155, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 155 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2003.1249022\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Sunghee Kim;H. Hagh-Shenas;V. Interrante; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Conveying shape with texture: an experimental investigation of the impact of texture type on shape categorization judgments; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: As visualization researchers, we are interested in gaining a better understanding of how to effectively use texture to facilitate shape perception. If we could design the ideal texture pattern to apply to an arbitrary smoothly curving shape to be most accurately and effectively perceived, what would the characteristics of that texture pattern be? In this paper we describe the results of a comprehensive controlled observer experiment intended to yield insight into that question. Here, we report the results of a new study comparing the relative accuracy of observers\u0027 judgments of shape type (elliptical, cylindrical, hyperbolic or flat) and shape orientation (convex, concave, both, or neither) for local views of boundary masked quadric surface patches under six different principal direction texture pattern conditions plus two texture conditions (an isotropic pattern and a non-principal direction oriented anisotropic pattern), under both perspective and orthographic projection conditions and from both head-on and oblique viewpoints. Our results confirm the hypothesis that accurate shape perception is facilitated to a statistically significantly greater extent by some principal direction texture patterns than by others. Specifically, we found that, for both views, under conditions of perspective projection, participants more often correctly identified the shape category and the shape orientation when the surface was textured with the pattern that contained oriented energy along both the first and second principal directions only than in the case of any other texture condition. Patterns containing markings following only one of the principal directions, or containing information along other directions in addition to the principal directions yielded poorer performance overall."}, {"color": "gray", "id": 157, "label": 157, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 157 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2003.1249024\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Hong Chen; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Compound brushing; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: This paper proposes a conceptual model called compound brushing for modeling the brushing techniques used in dynamic data visualization. In this approach, brushing techniques are modeled as higraphs with five types of basic entities: data, selection, device, renderer, and transformation. Using this model, a flexible visual programming tool is designed not only to configure/control various common types of brushing techniques currently used in dynamic data visualization, but also to investigate new brushing techniques."}, {"color": "gray", "id": 158, "label": 158, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 158 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2003.1249025\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: N. Elmqvist;P. Tsigas; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Causality visualization using animated growing polygons; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present Growing Polygons, a novel visualization technique for the graphical representation of causal relations and information flow in a system of interacting processes. Using this method, individual processes are displayed as partitioned polygons with color-coded segments showing dependencies to other processes. The entire visualization is also animated to communicate the dynamic execution of the system to the user. The results from a comparative user study of the method show that the Growing Polygons technique is significantly more efficient than the traditional Hasse diagram visualization for analysis tasks related to deducing information flow in a system for both small and large executions. Furthermore, our findings indicate that the correctness when solving causality tasks is significantly improved using our method. In addition, the subjective ratings of the users rank the method as superior in all regards, including usability, efficiency, and enjoyability."}, {"color": "gray", "id": 160, "label": 160, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 160 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2003.1249027\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: C. Csallner;M. Handte;O. Lehmann;J. Stasko; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: FundExplorer: supporting the diversification of mutual fund portfolios using context treemaps; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: An equity mutual fund is a financial instrument that invests in a set of stocks. Any two different funds may partially invest in some of the same stocks, thus overlap is common. Portfolio diversification aims at spreading an investment over many different stocks in search of greater returns. Helping people with portfolio diversification is challenging because it requires informing them about both their current portfolio of stocks held through funds and the other stocks in the market not invested in yet. Current stock/fund visualization systems either waste screen real estate and visualization of all data points. We have developed a system called FundExplorer that implements a distorted treemap to visualize both the amount of money invested in a person\u0027s fund portfolio and the context of remaining market stocks. The FundExplorer system enables people to interactively explore diversification possibilities with their portfolios."}, {"color": "gray", "id": 161, "label": 161, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 161 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2003.1249028\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: B. Kerr; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Thread Arcs: an email thread visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: This paper describes Thread Arcs, a novel interactive visualization technique designed to help people use threads found in email. Thread Arcs combine the chronology of messages with the branching tree structure of a conversational thread in a mixed-model visualization by Venolia and Neustaedter (2003) that is stable and compact. By quickly scanning and interacting with Thread Arcs, people can see various attributes of conversations and find relevant messages in them easily. We tested this technique against other visualization techniques with users\u0027 own email in a functional prototype email client. Thread Arcs proved an excellent match for the types of threads found in users\u0027 email for the qualities users wanted in small-scale visualizations."}, {"color": "gray", "id": 166, "label": 166, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 166 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2004.1\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: M. Ghoniem;J.-D. Fekete;P. Castagliola; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: A Comparison of the Readability of Graphs Using Node-Link and Matrix-Based Representations; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In this paper, we describe a taxonomy of generic graph related tasks and an evaluation aiming at assessing the readability of two representations of graphs: matrix-based representations and node-link diagrams. This evaluation bears on seven generic tasks and leads to important recommendations with regard to the representation of graphs according to their size and density. For instance, we show that when graphs are bigger than twenty vertices, the matrix-based visualization performs better than node-link diagrams on most tasks. Only path finding is consistently in favor of node-link diagrams throughout the evaluation"}, {"color": "gray", "id": 168, "label": 168, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 168 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2004.11\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: L. Berry;T. Munzner; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: BinX: Dynamic Exploration of Time Series Datasets Across Aggregation Levels; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Many fields of study produce time series datasets, and both the size and number of theses datasets are increasing rapidly due to the improvement of data accumulation methods such as small, cheap sensors and routine logging of events. Humans often fail to comprehend the structure of a long time series dataset because of the overwhelming amount of data and the range of different time scales at which there may be meaningful patterns. BinX is an interactive tool that provides dynamic visualization and manipulation of long time series datasets. The dataset is visualized through user controlled aggregation, augmented by various information visualization techniques."}, {"color": "gray", "id": 169, "label": 169, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 169 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2004.12\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: C. Weaver; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Building Highly-Coordinated Visualizations in Improvise; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Improvise is a fully-implemented system in which users build and browse multiview visualizations interactively using a simple shared-object coordination mechanism coupled with a flexible, expression-based visual abstraction language. By coupling visual abstraction with coordination, users gain precise control over how navigation and selection in the visualization affects the appearance of data in individual views. As a result, it is practical to build visualizations with more views and richer coordination in Improvise than in other visualization systems. Building and browsing activities are integrated in a single, live user interface that lets users alter visualizations quickly and incrementally during data exploration"}, {"color": "gray", "id": 174, "label": 174, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 174 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2004.18\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Y. Frishman;Ayellet Tal; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Dynamic Drawing of Clustered Graphs; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: This paper presents an algorithm for drawing a sequence of graphs that contain an inherent grouping of their vertex set into clusters. It differs from previous work on dynamic graph drawing in the emphasis that is put on maintaining the clustered structure of the graph during incremental layout. The algorithm works online and allows arbitrary modifications to the graph. It is generic and can be implemented using a wide range of static force-directed graph layout tools. The paper introduces several metrics for measuring layout quality of dynamic clustered graphs. The performance of our algorithm is analyzed using these metrics. The algorithm has been successfully applied to visualizing mobile object software"}, {"color": "gray", "id": 180, "label": 180, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 180 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2004.25\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: L. Voinea;A. Telea;J.J. van Wijk; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: EZEL: a Visual Tool for Performance Assessment of Peer-to-Peer File-Sharing Network; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In this paper we present EZEL, a visual tool we developed for the performance assessment of peer-to-peer file-sharing networks. We start by identifying the relevant data transferred in this kind of networks and the main performance assessment questions. Then we describe the visualization of data from two different points of view. First we take servers as focal points and we introduce a new technique, faded cushioning, which allows visualizing the same data from different perspectives. Secondly, we present the viewpoint of files, and we expose the correlations with the server stance via a special scatter plot. Finally, we discuss how our tool, based on the described techniques, is effective in the performance assessment of peer-to-peer file-sharing networks"}, {"color": "gray", "id": 182, "label": 182, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 182 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2004.27\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: T. Kapler;W. Wright; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: GeoTime Information Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Analyzing observations over time and geography is a common task but typically requires multiple, separate tools. The objective of our research has been to develop a method to visualize, and work with, the spatial interconnectedness of information over time and geography within a single, highly interactive 3D view. A novel visualization technique for displaying and tracking events, objects and activities within a combined temporal and geospatial display has been developed. This technique has been implemented as a demonstratable prototype called GeoTime in order to determine potential utility. Initial evaluations have been with military users. However, we believe the concept is applicable to a variety of government and business analysis tasks"}, {"color": "gray", "id": 184, "label": 184, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 184 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2004.29\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: D. Cluxton;S.G. Eick;Jie Yun; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Hypothesis Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We have constructed an information visualization tool for understanding complex arguments. The tool enables analysts to construct structured arguments using judicial proof techniques, associate evidence with hypotheses, and set evidence parameters such as relevance and credibility. Users manipulate the hypotheses and their associated inference networks using visualization techniques. Our tool integrates concepts from structured argumentation, analysis of competing hypotheses, and hypothesis scoring with information visualization. It presents new metaphors for visualizing and manipulating structured arguments."}, {"color": "gray", "id": 191, "label": 191, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 191 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2004.43\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: F. van Ham;J.J. van Wijk; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Interactive Visualization of Small World Graphs; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Many real world graphs have small world characteristics, that is, they have a small diameter compared to the number of nodes and exhibit a local cluster structure. Examples are social networks, software structures, bibliographic references and biological neural nets. Their high connectivity makes both finding a pleasing layout and a suitable clustering hard. In this paper we present a method to create scalable, interactive visualizations of small world graphs, allowing the user to inspect local clusters while maintaining a global overview of the entire structure. The visualization method uses a combination of both semantical and geometrical distortions, while the layout is generated by a spring embedder algorithm using recently developed force model. We use a cross referenced database of 500 artists as a running example"}, {"color": "gray", "id": 192, "label": 192, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 192 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2004.44\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: S. Card; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Keynote Address: From Information Visualization to Sensemaking: Connecting the Mind\u0027s Eye to the Mind\u0027s Muscle; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Provides an abstract of the keynote presentation and a brief professional biography of the presenter. The complete presentation was not made available for publication as part of the conference proceedings."}, {"color": "gray", "id": 196, "label": 196, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 196 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2004.48\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Tzu-Wei Hsu;L. Inman;D. McColgin;K. Stamper; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: MonkEllipse: Visualizing the History of Information Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In this paper, we describe the process and result of creating a visualization to capture the past 10 years of history in the field of Information Visualization, as part of the annual InfoVis Conference Contest. We began with an XML file containing data provided by the contest organizers, scrubbed and augmented the data, and created a database to hold the information. We designed a visualization and implemented it using Flash MX 2004 Professional with ActionScript 2.0, PHP, and PostgreSQL. The resulting visualization provides an overview of the field of Information Visualization, and allows users to see the connections between areas of the field, particular researchers, and documents."}, {"color": "gray", "id": 197, "label": 197, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 197 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2004.49\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: S.G. Kobourov;K. Wampler; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Non-Euclidean Spring Embedders; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present a method by which force-directed algorithms for graph layouts can be generalized to calculate the layout of a graph in an arbitrary Riemannian geometry. The method relies on extending the Euclidean notions of distance, angle, and force-interactions to smooth nonEuclidean geometries via projections to and from appropriately chosen tangent spaces. In particular, we formally describe the calculations needed to extend such algorithms to hyperbolic and spherical geometries"}, {"color": "gray", "id": 200, "label": 200, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 200 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2004.53\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: S. Carpendale;A. Agarawala; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: PhylloTrees: Harnessing Nature\u0027s Phyllotactic Patterns for Tree Layout; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We explore the use of nature\u2019s phyllotactic patterns to inform the layout of hierarchical data. These naturally occurring patterns provide a non-overlapping, optimal packing when the total number of nodes is not known a priori. We present a family of expandable tree layouts based on these patterns."}, {"color": "gray", "id": 201, "label": 201, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 201 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2004.56\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: A. Spoerri; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: RankSpiral: Toward Enhancing Search Results Visualizations; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: This paper addresses the problem of how to enable users to visually explore and compare large sets of documents that have been retrieved by different search engines or queries. The Rank-Spiral enables users to rapidly scan large numbers of documents and their titles in a single screen. It uses a spiral mapping that maximizes information density and minimizes occlusions. It solves the labeling problem by exploiting the structure of the special spiral mapping used. Focus+Context interactions enable users to examine document clusters or groupings in more detail."}, {"color": "gray", "id": 205, "label": 205, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 205 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2004.6\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: E. Darling;C. Newbern;N. Kalghatgi;A. Burgman;K. Recktenwald; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: An Experimental Investigation of Magnification Lens Offset and Its Impact on Imagery Analysis; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: A digital lens is a user interface mechanism that is a potential solution to information mangement problems. We investigated the use of digital lensing applied to imagery analysis. Participants completed three different types of tasks (locate, follow, and compare) using a magnification lens with three different degrees of offset (aligned, adjacent, and docked) over a high-resolution aerial photo. Although no lens offset mode was significantly better than another, most participants preferred the adjacent mode for the locate and compare tasks, and the docked mode for the follow tasks. This paper describes the results of a user study of magnification lenses and provides new insights into preferences of and interactions with digital lensing."}, {"color": "gray", "id": 208, "label": 208, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 208 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2004.64\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: J.-D. Fekete; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: The InfoVis Toolkit; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: This article presents the InfoVis toolkit, designed to support the creation, extension and integration of advanced 2D information visualization components into interactive Java swing applications. The InfoVis toolkit provides specific data structures to achieve a fast action/feedback loop required by dynamic queries. It comes with a large set of components such as range sliders and tailored control panels required to control and configure the visualizations. These components are integrated into a coherent framework that simplifies the management of rich data structures and the design and extension of visualizations. Supported data structures currently include tables, trees and graphs. Supported visualizations include scatter plots, time series, parallel coordinates, treemaps, icicle trees, node-link diagrams for trees and graphs and adjacency matrices for graphs. All visualizations can use fisheye lenses and dynamic labeling. The InfoVis toolkit supports hardware acceleration when available through Agile2D, an implementation of the Java graphics API based on OpenGL, achieving speedups of 10 to 200 times. The article also shows how new visualizations can be added and extended to become components, enriching visualizations as well as general applications"}, {"color": "gray", "id": 210, "label": 210, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 210 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2004.66\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: E. Gansner;Y. Koren;S. North; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Topological Fisheye Views for Visualizing Large Graphs; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Graph drawing is a basic visualization tool. For graphs of up to hundreds of nodes and edges, there are many effective techniques available. At greater scale, data density and occlusion problems often negate its effectiveness. Conventional pan-and-zoom, and multiscale and geometric fisheye views are not fully satisfactory solutions to this problem. As an alternative, we describe a topological zooming method. It is based on the precomputation of a hierarchy of coarsened graphs, which are combined on the fly into renderings with the level of detail dependent on the distance from one or more foci. We also discuss a related distortion method that allows our technique to achieve constant information density displays"}, {"color": "gray", "id": 211, "label": 211, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 211 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2004.67\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: D.P. Groth;B.W. Murphy; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Tracking User Interactions Within Visualizations; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present a model and prototype system for tracking user interactions within a visualization. The history of the interactions are exposed to the user in a way that supports non-linear navigation of the visualization space. The interactions can be augmented with annotations, which, together with the interactions, can be shared with other users and applied to other data in a seamless way. The techniques constitute a novel approach for documenting information provenance."}, {"color": "gray", "id": 214, "label": 214, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 214 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2004.7\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: G. Gainant;D. Auber; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: ARNA: Interactive Comparison and Alignment of RNA Secondary Structure; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: ARNA is an interactive visualization system that supports comparison and alignment of RNA secondary structure. We present a new approach to RNA alignment that exploits the complex structure of the Smith-Waterman local distance matrix, allowing people to explore the space of possible partial alignments to discover a good global solution. The modular software architecture separates the user interface from computation, allowing the possibility of incorporating different alignment algorithms into the same framework."}, {"color": "gray", "id": 217, "label": 217, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 217 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2004.72\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: T.A. Keahey;K.C. Cox; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: VIM: A Framework for Intelligence Analysis; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Intelligence analysts receive thousands of facts from a variety of sources. In addition to the bare details of the fact \u2014 a particular person, for example \u2014 each fact may have provenance, reliability, weight, and other attributes. Each fact may also be associated with other facts, e.g. that one person met another at a particular location. The analyst\u2019s task is to examine a huge collection of such loosely-structured facts, and try to \"connect the dots\" to perceive the underlying and unknown causes \u2014 and their possible future courses. We have designed and implemented a Java platform called VIM to support intelligence analysts in their work."}, {"color": "gray", "id": 219, "label": 219, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 219 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2004.74\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: M.J. Mohammadi-Aragh;T.J. Jankun-Kelly; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visualizing and Interacting with Multi-Tree Hierarchical Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: This work focuses on visualizing highly cyclic hierarchical data. A user interface is discussed and its interaction is illustrated using a recipe database example. This example showcases a database with multiple categories for each recipe (database entry)."}, {"color": "gray", "id": 221, "label": 221, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 221 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2004.76\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: D. Surendran;S. Levy; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visualizing High Dimensional Datasets Using Partiview; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: A standard method of visualizing high-dimensional data is reducing its dimensionality to two or three using some algorithm, and then creating a scatterplot with data represented by labelled and/or colored dots. Two problems with this approach are (1) dots do not represent data well, (2) reducing to just three dimensions does not make full use of several dimensionality-reduction algorithms. We demonstrate how Partiview can be used to solve these problems, in the context of handwriting recognition and image retrieval."}, {"color": "gray", "id": 222, "label": 222, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 222 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2004.77\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: A. Ahmed;T. Dwyer;C. Murray;Le Song;Ying Xin Wu; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: WilmaScope Graph Visualisation; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Our visualisation of the IEEE InfoVis citation network is based on 3D graph visualisation techniques. To make effective use of the third dimension we use a layered approach, constraining nodes to lie on parallel planes depending on parameters such as year of publication or link degree. Within the parallel planes nodes are arranged using a fast force-directed layout method. A number of clusters representing different research areas were identified using a self organising map approach."}, {"color": "gray", "id": 225, "label": 225, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 225 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2005.1532123\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: G. Zotti;M.E. Groller; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: A sky dome visualisation for identification of astronomical orientations; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: It has long been known that ancient temples were frequently oriented along the cardinal directions or to certain points along the horizon where Sun or Moon rise or set on special days of the year. In the last decades, archaeologists have found evidence of even older building structures buried in the soil, with doorways that also appear to have distinct orientations. This paper presents a novel diagram combining archaeological maps with a folded-apart, flattened view of the whole sky, showing the local horizon and the daily paths of Sun, Moon and brighter stars. By use of this diagram, interesting groupings of astronomical orientation directions, e.g. to certain Sunrise and Sunset points could be identified, which were evidently used to mark certain days of the year. Orientations to a few significant stars very likely indicated the beginning of the agricultural year in the middle neolithic period"}, {"color": "gray", "id": 226, "label": 226, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 226 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2005.1532124\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: M.J. McGuffin;R. Balakrishnan; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Interactive visualization of genealogical graphs; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The general problem of visualizing \"family trees\", or genealogical graphs, in 2D, is considered. A graph theoretic analysis is given, which identifies why genealogical graphs can be difficult to draw. This motivates some novel graphical representations, including one based on a dual tree, a subgraph formed by the union of two trees. Dual trees can be drawn in various styles, including an indented outline style, and allow users to browse general multitrees in addition to genealogical graphs, by transitioning between different dual tree views. A software prototype for such browsing is described, that supports smoothly animated transitions, automatic camera framing, rotation of subtrees, and a novel interaction technique for expanding or collapsing subtrees to any depth with a single mouse drag"}, {"color": "gray", "id": 229, "label": 229, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 229 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2005.1532127\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: J. Slack;K. Hildebrand;T. Munzner; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: PRISAD: a partitioned rendering infrastructure for scalable accordion drawing; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present PRISAD, the first generic rendering infrastructure for information visualization applications that use the accordion drawing technique: rubber sheet navigation with guaranteed visibility for marked areas of interest. Our new rendering algorithms are based on the partitioning of screen space, which allows us to handle dense dataset regions correctly. The algorithms in previous work led to incorrect visual representations because of overculling, and to inefficiencies due to overdrawing multiple items in the same region. Our pixel based drawing infrastructure guarantees correctness by eliminating overculling, and improves rendering performance with tight bounds on overdrawing. PRITree and PRISeq are applications built on PRISAD, with the feature sets of TreeJuxtaposer and SequenceJuxtaposer, respectively. We describe our PRITree and PRISeq dataset traversal algorithms, which are used for efficient rendering, culling, and layout of datasets within the PRISAD framework. We also discuss PRITree node marking techniques, which offer order-of-magnitude improvements to both memory and time performance versus previous range storage and retrieval techniques. Our PRITree implementation features a five fold increase in rendering speed for nontrivial tree structures, and also reduces memory requirements in some real world datasets by up to eight times, so we are able to handle trees of several million nodes. PRISeq renders fifteen times faster and handles datasets twenty times larger than previous work."}, {"color": "gray", "id": 230, "label": 230, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 230 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2005.1532128\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: M. Balzer;O. Deussen; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Voronoi treemaps; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Treemaps are a well known method for the visualization of attributed hierarchical data. Previously proposed treemap layout algorithms are limited to rectangular shapes, which cause problems with the aspect ratio of the rectangles as well as with identifying the visualized hierarchical structure. The approach of Voronoi treemaps presented in this paper eliminates these problems through enabling subdivisions of and in polygons. Additionally, this allows for creating treemap visualizations within areas of arbitrary shape, such as triangles and circles, thereby enabling a more flexible adaptation of treemaps for a wider range of applications."}, {"color": "gray", "id": 232, "label": 232, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 232 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2005.1532130\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: T. Dwyer;Y. Koren; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Dig-CoLa: directed graph layout through constrained energy minimization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We describe a new method for visualization of directed graphs. The method combines constraint programming techniques with a high performance force directed placement (FDP) algorithm so that the directed nature of the graph is highlighted while useful properties of FDP - such as emphasis of symmetries and preservation of proximity relations - are retained. Our algorithm automatically identifies those parts of the digraph that contain hierarchical information and draws them accordingly. Additionally, those parts that do not contain hierarchy are drawn at the same quality expected from a nonhierarchical, undirected layout algorithm. An interesting application of our algorithm is directional multidimensional scaling (DMDS). DMDS deals with low dimensional embedding of multivariate data where we want to emphasize the overall flow in the data (e.g. chronological progress) along one of the axes."}, {"color": "gray", "id": 234, "label": 234, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 234 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2005.1532132\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Kang Shi;Pourang Irani;B. Li; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: An evaluation of content browsing techniques for hierarchical space-filling visualizations; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Space-filling visualizations, such as the TreeMap, are well suited for displaying the properties of nodes in hierarchies. To browse the contents of the hierarchy, the primary mode of interaction is by drilling down through many successive layers. In this paper we introduce a distortion algorithm based on fisheye and continuous zooming techniques for browsing data in the TreeMap representation. The motivation behind the distortion approach is for assisting users to rapidly browse information displayed in the TreeMap without opening successive layers of the hierarchy. Two experiments were conducted to evaluate the new approach. In the first experiment (N=20) the distortion approach is compared to the drill down method. Results show that subjects are quicker and more accurate in locating targets of interest using the distortion method. The second experiment (N=12) evaluates the effectiveness of the two approaches in a task requiring context, we define as the context browsing task. The results show that subjects are quicker and more accurate in locating targets with the distortion technique in the context browsing task."}, {"color": "gray", "id": 235, "label": 235, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 235 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2005.1532133\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: E.G. Hetzler;V.L. Crow;D.A. Payne;A.E. Turner; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Turning the bucket of text into a pipe; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Many visual analysis tools operate on a fixed set of data. However, professional information analysts follow issues over a period of time and need to be able to easily add new documents to an ongoing exploration. Some analysts handle documents in a moving window of time, with new documents constantly added and old ones aging out. This paper describes both the user interaction and the technical implementation approach for a visual analysis system designed to support constantly evolving text collections."}, {"color": "gray", "id": 237, "label": 237, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 237 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2005.1532135\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: U. Brandes;D. Fleischer;J. Lerner; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Highlighting conflict dynamics in event data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present a method for visual summary of bilateral conflict structures embodied in event data. Such data consists of actors linked by time stamped events, and may be extracted from various sources such as news reports and dossiers. When analyzing political events, it is of particular importance to be able to recognize conflicts and actors involved in them. By projecting actors into a conflict space, we are able to highlight the main opponents in a series of tens of thousands of events, and provide a graphic overview of the conflict structure. Moreover, our method allows for smooth animation of the dynamics of a conflict."}, {"color": "gray", "id": 238, "label": 238, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 238 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2005.1532136\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: R. Amar;J. Eagan;J. Stasko; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Low-level components of analytic activity in information visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Existing system level taxonomies of visualization tasks are geared more towards the design of particular representations than the facilitation of user analytic activity. We present a set of ten low level analysis tasks that largely capture people\u0027s activities while employing information visualization tools for understanding data. To help develop these tasks, we collected nearly 200 sample questions from students about how they would analyze five particular data sets from different domains. The questions, while not being totally comprehensive, illustrated the sheer variety of analytic questions typically posed by users when employing information visualization systems. We hope that the presented set of tasks is useful for information visualization system designers as a kind of common substrate to discuss the relative analytic capabilities of the systems. Further, the tasks may provide a form of checklist for system designers."}, {"color": "gray", "id": 243, "label": 243, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 243 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2005.1532141\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: E. Fanea;S. Carpendale;T. Isenberg; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: An interactive 3D integration of parallel coordinates and star glyphs; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Parallel coordinates are a powerful method for visualizing multidimensional data but, when applied to large data sets, they become cluttered and difficult to read. Star glyphs, on the other hand, can be used to display either the attributes of a data item or the values across all items for a single attribute. Star glyphs may readily provide a quick impression; however, since the full data set require multiple glyphs, overall readings are more difficult. We present parallel glyphs, an interactive integration of the visual representations of parallel coordinates and star glyphs that utilizes the advantages of both representations to offset the disadvantages they have separately. We discuss the role of uniform and stepped colour scales in the visual comparison of non-adjacent items and star glyphs. Parallel glyphs provide capabilities for focus-in-context exploration using two types of lenses and interactions specific to the 3D space."}, {"color": "gray", "id": 244, "label": 244, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 244 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2005.1532142\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: L. Wilkinson;A. Anand;R. Grossman; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Graph-theoretic scagnostics; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We introduce Tukey and Tukey scagnostics and develop graph-theoretic methods for implementing their procedure on large datasets."}, {"color": "gray", "id": 245, "label": 245, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 245 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2005.1532143\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: C. Weaver; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visualizing coordination in situ; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Exploratory visualization environments allow users to build and browse coordinated multiview visualizations interactively. As the number of views and amount of coordination increases, conceptualizing coordination structure becomes more and more important for successful data exploration. Integrated metavisualization is exploratory visualization of coordination and other interactive structure directly inside a visualization\u0027s own user interface. This paper presents a model of integrated metavisualization, describes the problem of capturing dynamic interface structure as visualizable data, and outlines three general approaches to integration. Metavisualization has been implemented in improvise, using views, lenses, and embedding to reveal the dynamic structure of its own highly coordinated visualizations."}, {"color": "gray", "id": 246, "label": 246, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 246 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2005.1532144\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: T. Saito;H.N. Miyamura;M. Yamamoto;H. Saito;Y. Hoshiya;T. Kaseda; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Two-tone pseudo coloring: compact visualization for one-dimensional data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: A new pseudo coloring technique for large scale one-dimensional datasets is proposed. For visualization of a large scale dataset, user interaction is indispensable for selecting focus areas in the dataset. However, excessive switching of the visualized image makes it difficult for the user to recognize overview/ detail and detail/ detail relationships. The goal of this research is to develop techniques for visualizing details as precisely as possible in overview display. In this paper, visualization of a one-dimensional but very large dataset is considered. The proposed method is based on pseudo coloring, however, each scalar value corresponds to two discrete colors. By painting with two colors at each value, users can read out the value precisely. This method has many advantages: it requires little image space for visualization; both the overview and details of the dataset are visible in one image without distortion; and implementation is very simple. Several application examples, such as meteorological observation data and train convenience evaluation data, show the effectiveness of the method."}, {"color": "gray", "id": 247, "label": 247, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 247 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2005.1532145\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: M. Wattenberg; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: A note on space-filling visualizations and space-filling curves; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: A recent line of treemap research has focused on layout algorithms that optimize properties such as stability, preservation of ordering information, and aspect ratio of rectangles. No ideal treemap layout algorithm has been found, and so it is natural to explore layouts that produce nonrectangular regions. This note describes a connection between space-filling visualizations and the mathematics of space-filling curves, and uses that connection to characterize a family of layout algorithms which produce nonrectangular regions but enjoy geometric continuity under changes to the data and legibility even for highly unbalanced trees."}, {"color": "gray", "id": 250, "label": 250, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 250 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2005.1532148\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: M.C. Hao;Umeshwar Dayal;D.A. Keim;T. Schreck; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Importance-driven visualization layouts for large time series data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Time series are an important type of data with applications in virtually every aspect of the real world. Often a large number of time series have to be monitored and analyzed in parallel. Sets of time series may show intrinsic hierarchical relationships and varying degrees of importance among the individual time series. Effective techniques for visually analyzing large sets of time series should encode the relative importance and hierarchical ordering of the time series data by size and position, and should also provide a high degree of regularity in order to support comparability by the analyst. In this paper, we present a framework for visualizing large sets of time series. Based on the notion of inter time series importance relationships, we define a set of objective functions that space-filling layout schemes for time series data should obey. We develop an efficient algorithm addressing the identified problems by generating layouts that reflect hierarchy and importance based relationships in a regular layout with favorable aspect ratios. We apply our technique to a number of real world data sets including sales and stock data, and we compare our technique with an aspect ratio aware variant of the well known TreeMap algorithm. The examples show the advantages and practical usefulness of our layout algorithm."}, {"color": "gray", "id": 251, "label": 251, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 251 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2005.1532149\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Poonam Shanbhag;P. Rheingans;M. desJardins; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Temporal visualization of planning polygons for efficient partitioning of geo-spatial data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Partitioning of geo-spatial data for efficient allocation of resources such as schools and emergency health care services is driven by a need to provide better and more effective services. Partitioning of spatial data is a complex process that depends on numerous factors such as population, costs incurred in deploying or utilizing resources and target capacity of a resource. Moreover, complex data such as population distributions are dynamic i.e. they may change over time. Simple animation may not effectively show temporal changes in spatial data. We propose the use of three temporal visualization techniques -wedges, rings and time slices - to display the nature of change in temporal data in a single view. Along with maximizing resource utilization and minimizing utilization costs, a partition should also ensure the long term effectiveness of the plan. We use multi-attribute visualization techniques to highlight the strengths and identify the weaknesses of a partition. Comparative visualization techniques allow multiple partitions to be viewed simultaneously. Users can make informed decisions about how to partition geo spatial data by using a combination of our techniques for multi-attribute visualization, temporal visualization and comparative visualization."}, {"color": "gray", "id": 252, "label": 252, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 252 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2005.1532150\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Doantam Phan;Ling Xiao;R. Yeh;P. Hanrahan; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Flow map layout; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Cartographers have long used flow maps to show the movement of objects from one location to another, such as the number of people in a migration, the amount of goods being traded, or the number of packets in a network. The advantage of flow maps is that they reduce visual clutter by merging edges. Most flow maps are drawn by hand and there are few computer algorithms available. We present a method for generating flow maps using hierarchical clustering given a set of nodes, positions, and flow data between the nodes. Our techniques are inspired by graph layout algorithms that minimize edge crossings and distort node positions while maintaining their relative position to one another. We demonstrate our technique by producing flow maps for network traffic, census data, and trade data."}, {"color": "gray", "id": 256, "label": 256, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 256 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2006.120\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: James Abello;Frank Van Ham;Neeraj Krishnan; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: ASK-graphView: a large scale graph visualization system; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We describe ASK-GraphView, a node-link-based graph visualization system that allows clustering and interactive navigation of large graphs, ranging in size up to 16 million edges. The system uses a scalable architecture and a series of increasingly sophisticated clustering algorithms to construct a hierarchy on an arbitrary, weighted undirected input graph. By lowering the interactivity requirements we can scale to substantially bigger graphs. The user is allowed to navigate this hierarchy in a top down manner by interactively expanding individual clusters. ASK-GraphView also provides facilities for filtering and coloring, annotation and cluster labeling"}, {"color": "gray", "id": 260, "label": 260, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 260 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2006.138\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Geoffrey Ellis;Alan Dix; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Enabling Automatic Clutter Reduction in Parallel Coordinate Plots; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We have previously shown that random sampling is an effective clutter reduction technique and that a sampling lens can facilitate focus+context viewing of particular regions. This demands an efficient method of estimating the overlap or occlusion of large numbers of intersecting lines in order to automatically adjust the sampling rate within the lens. This paper proposes several ways for measuring occlusion in parallel coordinate plots. An empirical study into the accuracy and efficiency of the occlusion measures show that a probabilistic approach combined with a \u0027binning\u0027 technique is very fast and yet approaches the accuracy of the more expensive \u0027true\u0027 complete measurement"}, {"color": "gray", "id": 262, "label": 262, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 262 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2006.147\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Danny Holten; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Hierarchical Edge Bundles: Visualization of Adjacency Relations in Hierarchical Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: A compound graph is a frequently encountered type of data set. Relations are given between items, and a hierarchy is defined on the items as well. We present a new method for visualizing such compound graphs. Our approach is based on visually bundling the adjacency edges, i.e., non-hierarchical edges, together. We realize this as follows. We assume that the hierarchy is shown via a standard tree visualization method. Next, we bend each adjacency edge, modeled as a B-spline curve, toward the polyline defined by the path via the inclusion edges from one node to another. This hierarchical bundling reduces visual clutter and also visualizes implicit adjacency edges between parent nodes that are the result of explicit adjacency edges between their respective child nodes. Furthermore, hierarchical edge bundling is a generic method which can be used in conjunction with existing tree visualization techniques. We illustrate our technique by providing example visualizations and discuss the results based on an informal evaluation provided by potential users of such visualizations"}, {"color": "gray", "id": 263, "label": 263, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 263 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2006.156\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Tim Dwyer;Yehuda Koren;Kim Marriott; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: IPSep-CoLa: An Incremental Procedure for Separation Constraint Layout of Graphs; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We extend the popular force-directed approach to network (or graph) layout to allow separation constraints, which enforce a minimum horizontal or vertical separation between selected pairs of nodes. This simple class of linear constraints is expressive enough to satisfy a wide variety of application-specific layout requirements, including: layout of directed graphs to better show flow; layout with non-overlapping node labels; and layout of graphs with grouped nodes (called clusters). In the stress majorization force-directed layout process, separation constraints can be treated as a quadratic programming problem. We give an incremental algorithm based on gradient projection for efficiently solving this problem. The algorithm is considerably faster than using generic constraint optimization techniques and is comparable in speed to unconstrained stress majorization. We demonstrate the utility of our technique with sample data from a number of practical applications including gene-activation networks, terrorist networks and visualization of high-dimensional data."}, {"color": "gray", "id": 268, "label": 268, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 268 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2006.177\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Daniel Archambault;Tamara Munzner;David Auber; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Smashing Peacocks Further: Drawing Quasi-Trees from Biconnected Components; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Quasi-trees, namely graphs with tree-like structure, appear in many application domains, including bioinformatics and computer networks. Our new SPF approach exploits the structure of these graphs with a two-level approach to drawing, where the graph is decomposed into a tree of biconnected components. The low-level biconnected components are drawn with a force-directed approach that uses a spanning tree skeleton as a starting point for the layout. The higher-level structure of the graph is a true tree with meta-nodes of variable size that contain each biconnected component. That tree is drawn with a new area-aware variant of a tree drawing algorithm that handles high-degree nodes gracefully, at the cost of allowing edge-node overlaps. SPF performs an order of magnitude faster than the best previous approaches, while producing drawings of commensurate or improved quality."}, {"color": "gray", "id": 281, "label": 281, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 281 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2006.261416\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jean Scholtz; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Beyond Usability: Evaluation Aspects of Visual Analytic Environments; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: A new field of research, visual analytics, has been introduced. This has been defined as \"the science of analytical reasoning facilitated by interactive visual interfaces\" (Thomas and Cook, 2005). Visual analytic environments, therefore, support analytical reasoning using visual representations and interactions, with data representations and transformation capabilities, to support production, presentation, and dissemination. As researchers begin to develop visual analytic environments, it is advantageous to develop metrics and methodologies to help researchers measure the progress of their work and understand the impact their work has on the users who work in such environments. This paper presents five areas or aspects of visual analytic environments that should be considered as metrics and methodologies for evaluation are developed. Evaluation aspects need to include usability, but it is necessary to go beyond basic usability. The areas of situation awareness, collaboration, interaction, creativity, and utility are proposed as the five evaluation areas for initial consideration. The steps that need to be undertaken to develop systematic evaluation methodologies and metrics for visual analytic environments are outlined"}, {"color": "gray", "id": 284, "label": 284, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 284 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2006.261420\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Georges Grinstein;Theresa O\u0027Connell;Sharon Laskowski;Catherine Plaisant;Jean Scholtz;Mark Whiting; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: VAST 2006 Contest - A Tale of Alderwood; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Visual analytics experts realize that one effective way to push the field forward and to develop metrics for measuring the performance of various visual analytics components is to hold an annual competition. The first visual analytics science and technology (VAST) contest was held in conjunction with the 2006 IEEE VAST Symposium. The competition entailed the identification of possible political shenanigans in the fictitious town of Alderwood. A synthetic data set was made available as well as tasks. We summarize how we prepared and advertised the contest, developed some initial metrics for evaluation, and selected the winners. The winners were invited to participate at an additional live competition at the symposium to provide them with feedback from senior analysts"}, {"color": "gray", "id": 285, "label": 285, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 285 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2006.261421\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jerry Alan Fails;Amy Karlson;Layla Shahamat;Ben Shneiderman; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: A Visual Interface for Multivariate Temporal Data: Finding Patterns of Events across Multiple Histories; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Finding patterns of events over time is important in searching patient histories, Web logs, news stories, and criminal activities. This paper presents PatternFinder, an integrated interface for query and result-set visualization for search and discovery of temporal patterns within multivariate and categorical data sets. We define temporal patterns as sequences of events with inter-event time spans. PatternFinder allows users to specify the attributes of events and time spans to produce powerful pattern queries that are difficult to express with other formalisms. We characterize the range of queries PatternFinder supports as users vary the specificity at which events and time spans are defined. Pattern Finder\u0027s query capabilities together with coupled ball-and-chain and tabular visualizations enable users to effectively query, explore and analyze event patterns both within and across data entities (e.g. patient histories, terrorist groups, Web logs, etc.)"}, {"color": "gray", "id": 289, "label": 289, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 289 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2006.261425\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jing Yang;Jianping Fan;Daniel Hubball;Yuli Gao;Hangzai Luo;William Ribarsky;Matthew Ward; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Semantic Image Browser: Bridging Information Visualization with Automated Intelligent Image Analysis; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Browsing and retrieving images from large image collections are becoming common and important activities. Semantic image analysis techniques, which automatically detect high level semantic contents of images for annotation, are promising solutions toward this problem. However, few efforts have been made to convey the annotation results to users in an intuitive manner to enable effective image browsing and retrieval. There is also a lack of methods to monitor and evaluate the automatic image analysis algorithms due to the high dimensional nature of image data, features, and contents. In this paper, we propose a novel, scalable semantic image browser by applying existing information visualization techniques to semantic image analysis. This browser not only allows users to effectively browse and search in large image databases according to the semantic content of images, but also allows analysts to evaluate their annotation process through interactive visual exploration. The major visualization components of this browser are multi-dimensional scaling (MDS) based image layout, the value and relation (VaR) display that allows effective high dimensional visualization without dimension reduction, and a rich set of interaction tools such as search by sample images and content relationship detection. Our preliminary user study showed that the browser was easy to use and understand, and effective in supporting image browsing and retrieval tasks"}, {"color": "gray", "id": 291, "label": 291, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 291 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2006.261427\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Pascale Proulx;Sumeet Tandon;Adam Bodnar;David Schroh;Robert Harper;William Wright; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Avian Flu Case Study with nSpace and GeoTime; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: GeoTime and nSpace are new analysis tools that provide innovative visual analytic capabilities. This paper uses an epidemiology analysis scenario to illustrate and discuss these new investigative methods and techniques. In addition, this case study is an exploration and demonstration of the analytical synergy achieved by combining GeoTime\u0027s geo-temporal analysis capabilities, with the rapid information triage, scanning and sense-making provided by nSpace. A fictional analyst works through the scenario from the initial brainstorming through to a final collaboration and report. With the efficient knowledge acquisition and insights into large amounts of documents, there is more time for the analyst to reason about the problem and imagine ways to mitigate threats. The use of both nSpace and GeoTime initiated a synergistic exchange of ideas, where hypotheses generated in either software tool could be cross-referenced, refuted, and supported by the other tool"}, {"color": "gray", "id": 300, "label": 300, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 300 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2006.261436\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Ling Xiao;John Gerth;Pat Hanrahan; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Enhancing Visual Analysis of Network Traffic Using a Knowledge Representation; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: This paper presents a network traffic analysis system that couples visual analysis with a declarative knowledge representation. The system supports multiple iterations of the sense-making loop of analytic reasoning by allowing users to save discoveries as they are found and to reuse them in future iterations. We show how the knowledge representation can be used to improve both the visual representations and the basic analytical tasks of filtering and changing level of detail. We describe how the system can be used to produce models of network patterns, and show results from classifying one day of network traffic in our laboratory"}, {"color": "gray", "id": 303, "label": 303, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 303 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2006.261439\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Susan E. Brennan;Klaus Mueller;Greg Zelinsky;IV Ramakrishnan;David S. Warren;Arie Kaufman; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Toward a Multi-Analyst, Collaborative Framework for Visual Analytics; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We describe a framework for the display of complex, multidimensional data, designed to facilitate exploration, analysis, and collaboration among multiple analysts. This framework aims to support human collaboration by making it easier to share representations, to translate from one point of view to another, to explain arguments, to update conclusions when underlying assumptions change, and to justify or account for decisions or actions. Multidimensional visualization techniques are used with interactive, context-sensitive, and tunable graphs. Visual representations are flexibly generated using a knowledge representation scheme based on annotated logic; this enables not only tracking and fusing different viewpoints, but also unpacking them. Fusing representations supports the creation of multidimensional meta-displays as well as the translation or mapping from one point of view to another. At the same time, analysts also need to be able to unpack one another\u0027s complex chains of reasoning, especially if they have reached different conclusions, and to determine the implications, if any, when underlying assumptions or evidence turn out to be false. The framework enables us to support a variety of scenarios as well as to systematically generate and test experimental hypotheses about the impact of different kinds of visual representations upon interactive collaboration by teams of distributed analysts"}, {"color": "gray", "id": 305, "label": 305, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 305 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2006.261451\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Sameep Mehta;Srinivasan Parthasarathy;Raghu Machiraju; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visual Exploration of Spatio-temporal Relationships for Scientific Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Spatio-temporal relationships among features extracted from temporally-varying scientific datasets can provide useful information about the evolution of an individual feature and its interactions with other features. However, extracting such useful relationships without user guidance is cumbersome and often an error prone process. In this paper, we present a visual analysis system that interactively discovers such relationships from the trajectories of derived features. We describe analysis algorithms to derive various spatial and spatio-temporal relationships. A visual interface is presented using which the user can interactively select spatial and temporal extents to guide the knowledge discovery process. We show the usefulness of our proposed algorithms on datasets originating from computational fluid dynamics. We also demonstrate how the derived relationships can help in explaining the occurrence of critical events like merging and bifurcation of the vortices"}, {"color": "gray", "id": 306, "label": 306, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 306 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2006.261452\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Roberto Theron; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visual Analytics of Paleoceanographic Conditions; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Decade scale oceanic phenomena like El Nino are correlated with weather anomalies all over the globe. Only by understanding the events that produced the climatic conditions in the past will it be possible to forecast abrupt climate changes and prevent disastrous consequences for human beings and their environment. Paleoceanography research is a collaborative effort that requires the analysis of paleo time-series, which are obtained from a number of independent techniques and instruments and produced by a variety of different researchers and/or laboratories. The complexity of these phenomena that consist of massive, dynamic and often conflicting data can only be faced by means of analytical reasoning supported by a highly interactive visual interface. This paper presents an interactive visual analysis environment for paleoceanography that permits to gain insight into the paleodata and allow the control and steering of the analytical methods involved in the reconstruction of the climatic conditions of the past"}, {"color": "gray", "id": 317, "label": 317, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 317 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2007.70556\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Martin Graham;Jessie Kennedy; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Exploring Multiple Trees through DAG Representations; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present a directed acyclic graph visualisation designed to allow interaction with a set of multiple classification trees, specifically to find overlaps and differences between groups of trees and individual trees. The work is motivated by the need to find a representation for multiple trees that has the space-saving property of a general graph representation and the intuitive parent-child direction cues present in individual representation of trees. Using example taxonomic data sets, we describe augmentations to the common barycenter DAG layout method that reveal shared sets of child nodes between common parents in a clearer manner. Other interactions such as displaying the multiple ancestor paths of a node when it occurs in several trees, and revealing intersecting sibling sets within the context of a single DAG representation are also discussed."}, {"color": "gray", "id": 319, "label": 319, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 319 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2007.70561\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Danyel Fisher; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Hotmap: Looking at Geographic Attention; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Understanding how people use online maps allows data acquisition teams to concentrate their efforts on the portions of the map that are most seen by users. Online maps represent vast databases, and so it is insufficient to simply look at a list of the most-accessed URLs. Hotmap takes advantage of the design of a mapping system\u0027s imagery pyramid to superpose a heatmap of the log files over the original maps. Users\u0027 behavior within the system can be observed and interpreted. This paper discusses the imagery acquisition task that motivated Hotmap, and presents several examples of information that Hotmap makes visible. We discuss the design choices behind Hotmap, including logarithmic color schemes; low-saturation background images; and tuning images to explore both infrequently-viewed and frequently-viewed spaces."}, {"color": "gray", "id": 322, "label": 322, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 322 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2007.70574\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Remco Chang;Ginette Wessel;Robert Kosara;Eric Sauda;William Ribarsky; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Legible Cities: Focus-Dependent Multi-Resolution Visualization of Urban Relationships; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Numerous systems have been developed to display large collections of data for urban contexts; however, most have focused on layering of single dimensions of data and manual calculations to understand relationships within the urban environment. Furthermore, these systems often limit the user\u0027s perspectives on the data, thereby diminishing the user\u0027s spatial understanding of the viewing region. In this paper, we introduce a highly interactive urban visualization tool that provides intuitive understanding of the urban data. Our system utilizes an aggregation method that combines buildings and city blocks into legible clusters, thus providing continuous levels of abstraction while preserving the user\u0027s mental model of the city. In conjunction with a 3D view of the urban model, a separate but integrated information visualization view displays multiple disparate dimensions of the urban data, allowing the user to understand the urban environment both spatially and cognitively in one glance. For our evaluation, expert users from various backgrounds viewed a real city model with census data and confirmed that our system allowed them to gain more intuitive and deeper understanding of the urban model from different perspectives and levels of abstraction than existing commercial urban visualization systems."}, {"color": "gray", "id": 323, "label": 323, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 323 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2007.70577\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Fernanda B. Viegas;Martin Wattenberg;Frank van Ham;Jesse Kriss;Matt McKeon; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: ManyEyes: a Site for Visualization at Internet Scale; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We describe the design and deployment of Many Eyes, a public Web site where users may upload data, create interactive visualizations, and carry on discussions. The goal of the site is to support collaboration around visualizations at a large scale by fostering a social style of data analysis in which visualizations not only serve as a discovery tool for individuals but also as a medium to spur discussion among users. To support this goal, the site includes novel mechanisms for end-user creation of visualizations and asynchronous collaboration around those visualizations. In addition to describing these technologies, we provide a preliminary report on the activity of our users."}, {"color": "gray", "id": 328, "label": 328, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 328 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2007.70592\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Yi Mao;Joshua Dillon;Guy Lebanon; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Sequential Document Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Documents and other categorical valued time series are often characterized by the frequencies of short range sequential patterns such as n-grams. This representation converts sequential data of varying lengths to high dimensional histogram vectors which are easily modeled by standard statistical models. Unfortunately, the histogram representation ignores most of the medium and long range sequential dependencies making it unsuitable for visualizing sequential data. We present a novel framework for sequential visualization of discrete categorical time series based on the idea of local statistical modeling. The framework embeds categorical time series as smooth curves in the multinomial simplex summarizing the progression of sequential trends. We discuss several visualization techniques based on the above framework and demonstrate their usefulness for document visualization."}, {"color": "gray", "id": 330, "label": 330, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 330 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2007.70596\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Melanie Tory;David Sprague;Fuqu Wu;Wing Yan So;Tamara Munzner; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Spatialization Design: Comparing Points and Landscapes; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Spatializations represent non-spatial data using a spatial layout similar to a map. We present an experiment comparing different visual representations of spatialized data, to determine which representations are best for a non-trivial search and point estimation task. Primarily, we compare point-based displays to 2D and 3D information landscapes. We also compare a colour (hue) scale to a grey (lightness) scale. For the task we studied, point-based spatializations were far superior to landscapes, and 2D landscapes were superior to 3D landscapes. Little or no benefit was found for redundantly encoding data using colour or greyscale combined with landscape height. 3D landscapes with no colour scale (height-only) were particularly slow and inaccurate. A colour scale was found to be better than a greyscale for all display types, but a greyscale was helpful compared to height-only. These results suggest that point-based spatializations should be chosen over landscape representations, at least for tasks involving only point data itself rather than derived information about the data space."}, {"color": "gray", "id": 333, "label": 333, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 333 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2007.70623\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Haleh Hagh-Shenas;Sunghee Kim;Victoria Interrante;Christopher Healey; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Weaving Versus Blending: a quantitative assessment of the information carrying capacities of two alternative methods for conveying multivariate data with color.; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In many applications, it is important to understand the individual values of, and relationships between, multiple related scalar variables defined across a common domain. Several approaches have been proposed for representing data in these situations. In this paper we focus on strategies for the visualization of multivariate data that rely on color mixing. In particular, through a series of controlled observer experiments, we seek to establish a fundamental understanding of the information-carrying capacities of two alternative methods for encoding multivariate information using color: color blending and color weaving. We begin with a baseline experiment in which we assess participants\u0027 abilities to accurately read numerical data encoded in six different basic color scales defined in the L*a*b* color space. We then assess participants\u0027 abilities to read combinations of 2, 3, 4 and 6 different data values represented in a common region of the domain, encoded using either color blending or color weaving. In color blending a single mixed color is formed via linear combination of the individual values in L*a*b* space, and in color weaving the original individual colors are displayed side-by-side in a high frequency texture that fills the region. A third experiment was conducted to clarify some of the trends regarding the color contrast and its effect on the magnitude of the error that was observed in the second experiment. The results indicate that when the component colors are represented side-by-side in a high frequency texture, most participants\u0027 abilities to infer the values of individual components are significantly improved, relative to when the colors are blended. Participants\u0027 performance was significantly better with color weaving particularly when more than 2 colors were used, and even when the individual colors subtended only 3 minutes of visual angle in the texture. However, the information-carrying capacity of the color weaving approach has its limits. We found that participants\u0027 abilities to accurately interpret each of the individual components in a high frequency color texture typically falls off as the number of components increases from 4 to 6. We found no significant advantages, in either color blending or color weaving, to using color scales based on component hues thatare more widely separated in the L*a*b* color space. Furthermore, we found some indications that extra difficulties may arise when opponent hues are employed."}, {"color": "gray", "id": 341, "label": 341, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 341 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2007.4388996\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Stephen G. Eick;M. Andrew Eick;Jesse Fugitt;Brian Horst;Maxim Khailo;Russell A. Lankenau; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Thin Client Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We have developed a Web 2.0 thin client visualization framework called GeoBoosttrade. Our framework focuses on geospatial visualization and using scalable vector graphics (SVG), AJAX, RSS and GeoRSS we have built a complete thin client component set. Our component set provides a rich user experience that is completely browser based. It includes maps, standard business charts, graphs, and time-oriented components. The components are live, interactive, linked, and support real time collaboration."}, {"color": "gray", "id": 342, "label": 342, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 342 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2007.4388997\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Christopher D. Shaw;Gregory A. Dasch;Marina E. Eremeeva; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: IMAS: The Interactive Multigenomic Analysis System; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: This paper introduces a new Visual Analysis tool named IMAS (Interactive Multigenomic Analysis System), which combines common analysis tools such as Glimmer, BLAST, and Clustal-W into a unified Visual Analytic framework. IMAS displays the primary DNA sequence being analyzed by the biologist in a highly interactive, zoomable visual display. The user may analyze the sequence in a number of ways, and visualize these analyses in a coherent, sequence aligned form, with all related analysis products grouped together. This enables the user to rapidly perform analyses of DNA sequences without the need for tedious and error-prone cutting and pasting of sequence data from text files to and from web-based databases and data analysis services, as is now common practice."}, {"color": "gray", "id": 347, "label": 347, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 347 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2007.4389002\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Ana M. Cuadros;Fernando V. Paulovich;Rosane Minghim;Guilherme P. Telles; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Point Placement by Phylogenetic Trees and its Application to Visual Analysis of Document Collections; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The task of building effective representations to visualize and explore collections with moderate to large number of documents is hard. It depends on the evaluation of some distance measure among texts and also on the representation of such relationships in bi- dimensional spaces. In this paper we introduce an alternative approach for building visual maps of documents based on their content similarity, through reconstruction of phylogenetic trees. The tree is capable of representing relationships that allows the user to quickly recover information detected by the similarity metric. For a variety of text collections of different natures we show that we can achieve improved exploration capability and more clear visualization of relationships amongst documents."}, {"color": "gray", "id": 350, "label": 350, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 350 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2007.4389005\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Mohammad Ghoniem;Dongning Luo;Jing Yang;William Ribarsky; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: NewsLab: Exploratory Broadcast News Video Analysis; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In this paper, we introduce NewsLab, an exploratory visualization approach for the analysis of large scale broadcast news video collections containing many thousands of news stories over extended periods of time. A river metaphor is used to depict the thematic changes of the news over time. An interactive lens metaphor allows the playback of fine-grained video segments selected through the river overview. Multi-resolution navigation is supported via a hierarchical time structure as well as a hierarchical theme structure. Themes can be explored hierarchically according to their thematic structure, or in an unstructured fashion using various ranking criteria. A rich set of interactions such as filtering, drill-down/roll-up navigation, history animation, and keyword based search are also provided. Our case studies show how this set of tools can be used to find emerging topics in the news, compare different broadcasters, or mine the news for topics of interest."}, {"color": "gray", "id": 351, "label": 351, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 351 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2007.4389006\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: John Stasko;Carsten Gorg;Zhicheng Liu;Kanupriya Singhal; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Jigsaw: Supporting Investigative Analysis through Interactive Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Investigative analysts who work with collections of text documents connect embedded threads of evidence in order to formulate hypotheses about plans and activities of potential interest. As the number of documents and the corresponding number of concepts and entities within the documents grow larger, sense-making processes become more and more difficult for the analysts. We have developed a visual analytic system called Jigsaw that represents documents and their entities visually in order to help analysts examine reports more efficiently and develop theories about potential actions more quickly. Jigsaw provides multiple coordinated views of document entities with a special emphasis on visually illustrating connections between entities across the different documents."}, {"color": "gray", "id": 354, "label": 354, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 354 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2007.4389009\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Remco Chang;Mohammad Ghoniem;Robert Kosara;William Ribarsky;Jing Yang;Evan Suma;Caroline Ziemkiewicz;Daniel Kern;Agus Sudjianto; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: WireVis: Visualization of Categorical, Time-Varying Data From Financial Transactions; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Large financial institutions such as Bank of America handle hundreds of thousands of wire transactions per day. Although most transactions are legitimate, these institutions have legal and financial obligations in discovering those that are suspicious. With the methods of fraudulent activities ever changing, searching on predefined patterns is often insufficient in detecting previously undiscovered methods. In this paper, we present a set of coordinated visualizations based on identifying specific keywords within the wire transactions. The different views used in our system depict relationships among keywords and accounts over time. Furthermore, we introduce a search-by-example technique which extracts accounts that show similar transaction patterns. In collaboration with the Anti-Money Laundering division at Bank of America, we demonstrate that using our tool, investigators are able to detect accounts and transactions that exhibit suspicious behaviors."}, {"color": "gray", "id": 355, "label": 355, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 355 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2007.4389010\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Bongwon Suh;Ed H. Chi;Bryan A. Pendleton;Aniket Kittur; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Us vs. Them: Understanding Social Dynamics in Wikipedia with Revert Graph Visualizations; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Wikipedia is a wiki-based encyclopedia that has become one of the most popular collaborative on-line knowledge systems. As in any large collaborative system, as Wikipedia has grown, conflicts and coordination costs have increased dramatically. Visual analytic tools provide a mechanism for addressing these issues by enabling users to more quickly and effectively make sense of the status of a collaborative environment. In this paper we describe a model for identifying patterns of conflicts in Wikipedia articles. The model relies on users\u0027 editing history and the relationships between user edits, especially revisions that void previous edits, known as \"reverts\". Based on this model, we constructed Revert Graph, a tool that visualizes the overall conflict patterns between groups of users. It enables visual analysis of opinion groups and rapid interactive exploration of those relationships via detail drill- downs. We present user patterns and case studies that show the effectiveness of these techniques, and discuss how they could generalize to other systems."}, {"color": "gray", "id": 356, "label": 356, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 356 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2007.4389011\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jeffrey Heer;Maneesh Agrawala; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Design Considerations for Collaborative Visual Analytics; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Information visualization leverages the human visual system to support the process of sensemaking, in which information is collected, organized, and analyzed to generate knowledge and inform action. Though most research to date assumes a single-user focus on perceptual and cognitive processes, in practice, sensemaking is often a social process involving parallelization of effort, discussion, and consensus building. This suggests that to fully support sensemaking, interactive visualization should also support social interaction. However, the most appropriate collaboration mechanisms for supporting this interaction are not immediately clear. In this article, we present design considerations for asynchronous collaboration in visual analysis environments, highlighting issues of work parallelization, communication, and social organization. These considerations provide a guide for the design and evaluation of collaborative visualization systems."}, {"color": "gray", "id": 357, "label": 357, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 357 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2007.4389012\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Ulrik Brandes;Jurgen Lerner; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visual Analysis of Controversy in User-generated Encyclopedias; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Wikipedia is a large and rapidly growing Web-based collaborative authoring environment, where anyone on the Internet can create, modify, and delete pages about encyclopedic topics. A remarkable property of some Wikipedia pages is that they are written by up to thousands of authors who may have contradicting opinions. In this paper we show that a visual analysis of the \"who revises whom\"- network gives deep insight into controversies. We propose a set of analysis and visualization techniques that reveal the dominant authors of a page, the roles they play, and the alters they confront. Thereby we provide tools to understand how Wikipedia authors collaborate in the presence of controversy."}, {"color": "gray", "id": 360, "label": 360, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 360 (VAST)  - \u003ca href=\"http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=4389016\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Lynn Schwendiman;Jonathan McLean;Jonathan Larson; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: VAST 2007 Contest Interactive Poster: Data Analysis Using NdCore and REGGAE; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: ATS intelligent discovery analyzed the VAST 2007 contest data set using two of its proprietary applications, NdCore and REGGAE (relationship generating graph analysis engine). The paper describes these tools and how they were used to discover the contest\u0027s scenarios of wildlife law enforcement, endangered species issues, and ecoterrorism."}, {"color": "gray", "id": 361, "label": 361, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 361 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2007.4389017\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Carsten Gorg;Zhicheng Liu;Neel Parekh;Kanupriya Singhal;John Stasko; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visual Analytics with Jigsaw; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: This article briefly introduces the Jigsaw system and describes how we used it in analysis activities for the VAST \u002707 Contest. Jigsaw is a visual analytic system that provides multiple coordinated views to show connections between entities that are extracted from a collection of documents."}, {"color": "gray", "id": 362, "label": 362, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 362 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2007.4389018\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Lynn Chien;Annie Tat;William Wright; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Something\u0027s \"Fishy\" at Global Ways and Gill Breeders - Analysis with nSpace and GeoTime; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: GeoTime and nSpace are two interactive visual analytics tools that support the process of analyzing massive and complex datasets. The two tools were used to examine and interpret the 2007 VAST contest dataset. This poster paper describes how the capabilities of the tools were used to facilitate and expedite every stage of an analyst workflow."}, {"color": "gray", "id": 363, "label": 363, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 363 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2007.4389019\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Chi-Chun Pan;Anuj R. Jaiswal;Junyan Luo;Anthony Robinson; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: TextPlorer: An application supporting text analysis; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: TexPlorer is an integrated system for exploring and analyzing large amounts of text documents. The data processing modules of TexPlorer consist of named entity extraction, entity relation extraction, hierarchical clustering, and text summarization tools. Using a timeline tool, tree-view, table-view, and concept maps, TexPlorer provides an analytical interface for exploring a set of text documents from different perspectives and allows users to explore vast amount of text documents efficiently."}, {"color": "gray", "id": 365, "label": 365, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 365 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2007.4389021\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Yedendra B. Shrinivasan;Jarke J. van Wijk; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: VisPad: Integrating Visualization, Navigation and Synthesis; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present a new framework - VisPad - to support the user to revisit the visual exploration process, and to synthesize and disseminate information. It offers three integrated views. The data view allows the user to interactively explore the data. The navigation view captures the exploration process. It enables the user to revisit any particular state and reuse it. The knowledge view enables the user to record his/her findings and the relations between these findings."}, {"color": "gray", "id": 367, "label": 367, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 367 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2007.4389023\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jae Choi;Sang-joon Lee;Sarah Gigitashvilli;James Wilson; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Situation Awareness Tool for Global Argus; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present a visualization tool to enhance situation awareness for Global Argus, a system that tracks and detects indications and warnings of biological events in near real time. Because Global Argus generates massive amounts of data daily, its analysts often struggle to interpret the information. To overcome this problem, we have developed the Global Argus situation awareness tool (GASAT) using the InteleView/World Wind geographical information system. This tool allows users to visualize current and past events in a particular region, and thus to understand how events evolve over time. Combined with the other tools that we are developing, GASAT will contribute to enhanced situation awareness in the tracking and detection of biological events."}, {"color": "gray", "id": 368, "label": 368, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 368 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2007.4389024\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Palmyra Catravas; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Spectra transformed for model-testing and visual exploration; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The presence of highly tangled patterns in spectra and other serial data exacerbates the difficulty of performing visual comparison between a test model for a particular pattern and the data. The use of a simple map that plants peaks in the data directly onto their corresponding position in a residual plot with respect to a chosen test model not only retrieves the advantages of dynamic regression plotting, but in practical cases also causes patterns in the data to congregate in meaningful ways with respect to more than one reference curve in the plane. The technique is demonstrated on a polyphonic music signal."}, {"color": "gray", "id": 369, "label": 369, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 369 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2007.4389025\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Guoray Cai; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Formalizing Analytical Discourse in Visual Analytics; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: This paper presents a theory of analytical discourse and a formal model of the intentional structure of visual analytic reasoning process. Our model rests on the theory of collaborative discourse, and allows for cooperative human-machine communication in visual interactive dialogues. Using a sample discourse from a crisis management scenario, we demonstrated the utility of our theory in characterizing the discourse context and collaboration. In particular, we view analytical discourse as plans consisting of complex mental attitude towards analytical tasks and issues. Under this view, human reasoning and computational analysis become integral part of the collaborative plan that evolves through discourse."}, {"color": "gray", "id": 370, "label": 370, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 370 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2007.4389026\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Cecilia R. Aragon;Stephen J. Bailey;Sarah Poon;Karl J. Runge;Rollin C. Thomas; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Sunfall: A Collaborative Visual Analytics System for Astrophysics; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Computational and experimental sciences produce and collect ever- larger and complex datasets, often in large-scale, multi-institution projects. The inability to gain insight into complex scientific phenomena using current software tools is a bottleneck facing virtually all endeavors of science. In this paper, we introduce Sunfall, a collaborative visual analytics system developed for the Nearby Supernova Factory, an international astrophysics experiment and the largest data volume supernova search currently in operation. Sunfall utilizes novel interactive visualization and analysis techniques to facilitate deeper scientific insight into complex, noisy, high-dimensional, high-volume, time-critical data. The system combines novel image processing algorithms, statistical analysis, and machine learning with highly interactive visual interfaces to enable collaborative, user-driven scientific exploration of supernova image and spectral data. Sunfall is currently in operation at the Nearby Supernova Factory; it is the first visual analytics system in production use at a major astrophysics project."}, {"color": "gray", "id": 371, "label": 371, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 371 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2007.4389027\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Adel Ahmed;Xiaoyan Fu;Seok-Hee Hong;Quan Hoang Nguyen;Kai Xu; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visual Analysis of Dynamic Networks with Geological Clustering; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Many dynamic networks have associated geological information. Here we present two complementing visual analysis methods for such networks. The first one provides an overview with summerized information while the second one presents a more detailed view. The geological information is encoded in the network layout, which is designed to help maintain user\u0027s mental map. We also combined visualization with social network analysis to facilitate knowledge discovery, especially to understand network changes in the context overall evolution. Both methods are applied to the \"History of the FIFA World Cup Competition\" data set."}, {"color": "gray", "id": 372, "label": 372, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 372 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2007.4389028\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Daniel Ha;Minjung Kim;Andrew Wade;William O. Chao;Kevin Ho;Linda Kaastra;Brian Fisher;John Dill; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: From Tasks to Tools: A Field Study in Collaborative Visual Analytics; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: This poster presents an exploratory field study of a VAST 2007 contest entry. We applied cognitive task analysis (CTA), grounded theory (GT), and activity theory (AT), to analysis of field notes and interviews from participants. Our results are described in the context of activity theory and sensemaking, two theoretical perspectives that we have found to be particularly useful in understanding analytic tasks."}, {"color": "gray", "id": 373, "label": 373, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 373 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2007.4389030\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jim Thomas;Daniel Keim;Joe Kielman;Larry Rosenblum; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Outlook for Visual Analytics Research Funding; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Visual Analytics has become a rapidly growing field of study. It is also a field that is addressing very significant real world problems in homeland security, business analytics, emergency management, genetics and bioinformatics, investigative analysis, medical analytics, and other areas. For both these reasons, it is attracting new funding and will continue to do so in the future. Visual analytics has also become an international field, with significant research efforts in Canada, Europe, and Australia, as well as the U.S. There is significant new research funding in Canada and Germany with other efforts being discussed, including a major program sponsored by the European Union. The contributors to this panel are some of the primary thought leaders providing research funding or involved in setting up the funding apparatus. We have asked them to present their needs, funding programs, and expectations from the research community. They all come from different perspectives, different missions, and different expectations. They will present their views of the range of activity in both the U.S. and internationally and discuss what is coming. Come learn about these programs, initiatives, and plans, and how you can contribute."}, {"color": "gray", "id": 374, "label": 374, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 374 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2007.4389032\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Georges Grinstein;Catherine Plaisant;Sharon Laskowski;Theresa O\u0027Connell;Jean Scholtz;Mark Whiting; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: VAST 2007 Contest - Blue Iguanodon; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Visual analytics experts realize that one effective way to push the field forward and to develop metrics for measuring the performance of various visual analytics components is to hold an annual competition. The second visual analytics science and technology (VAST) contest was held in conjunction with the 2007 IEEE VAST symposium. In this contest participants were to use visual analytic tools to explore a large heterogeneous data collection to construct a scenario and find evidence buried in the data of illegal and terrorist activities that were occurring. A synthetic data set was made available as well as tasks. In this paper we describe some of the advances we have made from the first competition held in 2006."}, {"color": "gray", "id": 375, "label": 375, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 375 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2007.4389033\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Lynn Chien;Annie Tat;Thomas Kapler;Patricia Enns;Winniefried Kuan;William Wright; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: VAST 2007 Contest - Analysis with nSpace and GeoTime; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: GeoTime and nSpace are two interactive visual analytics tools that support the process of analyzing massive and complex datasets. The two tools were used to examine and interpret the 2007 VAST contest dataset. This paper describes how the capabilities of the tools were used to facilitate and expedite every stage of the analysis."}, {"color": "gray", "id": 376, "label": 376, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 376 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2007.4389034\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Carsten Gorg;Zhicheng Liu;Neel Parekh;Kanupriya Singhal;John Stasko; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Jigsaw meets Blue Iguanodon - The VAST 2007 Contest; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: This article describes our use of the Jigsaw system in working on the VAST 2007 contest. Jigsaw provides multiple views of a document collection and the individual entities within those documents, with a particular focus on exposing connections between entities. We describe how we refined the identified entities in order to better facilitate Jigsaw\u0027s use and how the different views helped us to uncover key parts of the underlying plot."}, {"color": "gray", "id": 377, "label": 377, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 377 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2007.4389036\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Patricia Crossno;Brian Wylie;Andrew Wilson;John Greenfield;Eric Stanton;Timothy Shead;Lisa Ice;Kenneth Moreland;Jeffrey Baumes;Berk Geveci; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Intelligence Analysis Using Titan; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The open source Titan informatics toolkit project, which extends the visualization toolkit (VTK) to include information visualization capabilities, is being developed by Sandia National Laboratories in collaboration with Kitware. The VAST Contest provided us with an opportunity to explore various ideas for constructing an analysis tool, while allowing us to exercise our architecture in the solution of a complex problem. As amateur analysts, we found the experience both enlightening and fun."}, {"color": "gray", "id": 378, "label": 378, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 378 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2007.4389037\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Chi-Chun Pan;Anuj R. Jaiswal;Junyan Luo;Anthony Robinson;Prasenjit Mitra;Alan M. MacEachren;Ian Turton; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: VAST 2007 Contest TexPlorer; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: TexPlorer is an integrated system for exploring and analyzing vast amount of text documents. The data processing modules of TexPlorer consist of named entity extraction, entity relation extraction, hierarchical clustering, and text summarization tools. Using time line tool, tree-view, table-view, and concept maps, TexPlorer provides visualizations from different aspects and allows analysts to explore vast amount of text documents efficiently."}, {"color": "gray", "id": 379, "label": 379, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 379 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2007.4389038\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Lynn Schwendiman;Jonathan McLean;Jonathan Larson; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: VAST 2007 Contest Data Analysis Using NdCore and REGGAE; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: ATS Intelligent Discovery analyzed the VAST 2007 contest data set using two of its proprietary applications, NdCore and REGGAE (Relationship Generating Graph Analysis Engine). The paper describes these tools and how they were used to discover the contest\u0027s scenarios of wildlife law enforcement, endangered species issues, and ecoterrorism."}, {"color": "gray", "id": 383, "label": 383, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 383 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2008.121\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Zhicheng Liu;Nancy Nersessian;John Stasko; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Distributed Cognition as a Theoretical Framework for Information Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Even though information visualization (InfoVis) research has matured in recent years, it is generally acknowledged that the field still lacks supporting, encompassing theories. In this paper, we argue that the distributed cognition framework can be used to substantiate the theoretical foundation of InfoVis. We highlight fundamental assumptions and theoretical constructs of the distributed cognition approach, based on the cognitive science literature and a real life scenario. We then discuss how the distributed cognition framework can have an impact on the research directions and methodologies we take as InfoVis researchers. Our contributions are as follows. First, we highlight the view that cognition is more an emergent property of interaction than a property of the human mind. Second, we argue that a reductionist approach to study the abstract properties of isolated human minds may not be useful in informing InfoVis design. Finally we propose to make cognition an explicit research agenda, and discuss the implications on how we perform evaluation and theory building."}, {"color": "gray", "id": 388, "label": 388, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 388 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2008.135\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Weiwei Cui;Hong Zhou;Huamin Qu;Pak Chung Wong;Xiaoming Li; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Geometry-Based Edge Clustering for Graph Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Graphs have been widely used to model relationships among data. For large graphs, excessive edge crossings make the display visually cluttered and thus difficult to explore. In this paper, we propose a novel geometry-based edge-clustering framework that can group edges into bundles to reduce the overall edge crossings. Our method uses a control mesh to guide the edge-clustering process; edge bundles can be formed by forcing all edges to pass through some control points on the mesh. The control mesh can be generated at different levels of detail either manually or automatically based on underlying graph patterns. Users can further interact with the edge-clustering results through several advanced visualization techniques such as color and opacity enhancement. Compared with other edge-clustering methods, our approach is intuitive, flexible, and efficient. The experiments on some large graphs demonstrate the effectiveness of our method."}, {"color": "gray", "id": 390, "label": 390, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 390 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2008.138\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Fernando V. Paulovich;Rosane Minghim; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: HiPP: A Novel Hierarchical Point Placement Strategy and its Application to the Exploration of Document Collections; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Point placement strategies aim at mapping data points represented in higher dimensions to bi-dimensional spaces and are frequently used to visualize relationships amongst data instances. They have been valuable tools for analysis and exploration of data sets of various kinds. Many conventional techniques, however, do not behave well when the number of dimensions is high, such as in the case of documents collections. Later approaches handle that shortcoming, but may cause too much clutter to allow flexible exploration to take place. In this work we present a novel hierarchical point placement technique that is capable of dealing with these problems. While good grouping and separation of data with high similarity is maintained without increasing computation cost, its hierarchical structure lends itself both to exploration in various levels of detail and to handling data in subsets, improving analysis capability and also allowing manipulation of larger data sets."}, {"color": "gray", "id": 393, "label": 393, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 393 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2008.149\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Thomas Butkiewicz;Wenwen Dou;Zachary Wartell;William Ribarsky;Remco Chang; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Multi-Focused Geospatial Analysis Using Probes; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Traditional geospatial information visualizations often present views that restrict the user to a single perspective. When zoomed out, local trends and anomalies become suppressed and lost; when zoomed in for local inspection, spatial awareness and comparison between regions become limited. In our model, coordinated visualizations are integrated within individual probe interfaces, which depict the local data in user-defined regions-of-interest. Our probe concept can be incorporated into a variety of geospatial visualizations to empower users with the ability to observe, coordinate, and compare data across multiple local regions. It is especially useful when dealing with complex simulations or analyses where behavior in various localities differs from other localities and from the system as a whole. We illustrate the effectiveness of our technique over traditional interfaces by incorporating it within three existing geospatial visualization systems: an agent-based social simulation, a census data exploration tool, and an 3D GIS environment for analyzing urban change over time. In each case, the probe-based interaction enhances spatial awareness, improves inspection and comparison capabilities, expands the range of scopes, and facilitates collaboration among multiple users."}, {"color": "gray", "id": 399, "label": 399, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 399 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2008.165\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jo Wood;Jason Dykes; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Spatially Ordered Treemaps; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Existing treemap layout algorithms suffer to some extent from poor or inconsistent mappings between data order and visual ordering in their representation, reducing their cognitive plausibility. While attempts have been made to quantify this mismatch, and algorithms proposed to minimize inconsistency, solutions provided tend to concentrate on one-dimensional ordering. We propose extensions to the existing squarified layout algorithm that exploit the two-dimensional arrangement of treemap nodes more effectively. Our proposed spatial squarified layout algorithm provides a more consistent arrangement of nodes while maintaining low aspect ratios. It is suitable for the arrangement of data with a geographic component and can be used to create tessellated cartograms for geovisualization. Locational consistency is measured and visualized and a number of layout algorithms are compared. CIELab color space and displacement vector overlays are used to assess and emphasize the spatial layout of treemap nodes. A case study involving locations of tagged photographs in the Flickr database is described."}, {"color": "gray", "id": 402, "label": 402, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 402 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2008.172\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Martin Wattenberg;Fernanda B. Vi\u00e9gas; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: The Word Tree, an Interactive Visual Concordance; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We introduce the Word Tree, a new visualization and information-retrieval technique aimed at text documents. A Word Tree is a graphical version of the traditional \"keyword-in-context\" method, and enables rapid querying and exploration of bodies of text. In this paper we describe the design of the technique, along with some of the technical issues that arise in its implementation. In addition, we discuss the results of several months of public deployment of word trees on Many Eyes, which provides a window onto the ways in which users obtain value from the visualization."}, {"color": "gray", "id": 403, "label": 403, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 403 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2008.175\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Marian D\u00f6rk;Sheelagh Carpendale;Christopher Collins;Carey Williamson; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: VisGets: Coordinated Visualizations for Web-based Information Exploration and Discovery; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In common Web-based search interfaces, it can be difficult to formulate queries that simultaneously combine temporal, spatial, and topical data filters. We investigate how coordinated visualizations can enhance search and exploration of information on the World Wide Web by easing the formulation of these types of queries. Drawing from visual information seeking and exploratory search, we introduce VisGets - interactive query visualizations of Web-based information that operate with online information within a Web browser. VisGets provide the information seeker with visual overviews of Web resources and offer a way to visually filter the data. Our goal is to facilitate the construction of dynamic search queries that combine filters from more than one data dimension. We present a prototype information exploration system featuring three linked VisGets (temporal, spatial, and topical), and used it to visually explore news items from online RSS feeds."}, {"color": "gray", "id": 404, "label": 404, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 404 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2008.178\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Bryan Chan;Leslie Wu;Justin Talbot;Mike Cammarano;Pat Hanrahan; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Vispedia: Interactive Visual Exploration of Wikipedia Data via Search-Based Integration; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Wikipedia is an example of the collaborative, semi-structured data sets emerging on the Web. These data sets have large, non-uniform schema that require costly data integration into structured tables before visualization can begin. We present Vispedia, a Web-based visualization system that reduces the cost of this data integration. Users can browse Wikipedia, select an interesting data table, then use a search interface to discover, integrate, and visualize additional columns of data drawn from multiple Wikipedia articles. This interaction is supported by a fast path search algorithm over DBpedia, a semantic graph extracted from Wikipedia\u0027s hyperlink structure. Vispedia can also export the augmented data tables produced for use in traditional visualization systems. We believe that these techniques begin to address the \"long tail\" of visualization by allowing a wider audience to visualize a broader class of data. We evaluated this system in a first-use formative lab study. Study participants were able to quickly create effective visualizations for a diverse set of domains, performing data integration as needed."}, {"color": "gray", "id": 405, "label": 405, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 405 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2008.181\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Paul Kidwell;Guy Lebanon;William Cleveland; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visualizing Incomplete and Partially Ranked Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Ranking data, which result from m raters ranking n items, are difficult to visualize due to their discrete algebraic structure, and the computational difficulties associated with them when n is large. This problem becomes worse when raters provide tied rankings or not all items are ranked. We develop an approach for the visualization of ranking data for large n which is intuitive, easy to use, and computationally efficient. The approach overcomes the structural and computational difficulties by utilizing a natural measure of dissimilarity for raters, and projecting the raters into a low dimensional vector space where they are viewed. The visualization techniques are demonstrated using voting data, jokes, and movie preferences."}, {"color": "gray", "id": 406, "label": 406, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 406 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2008.185\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Mario Romero;Jay Summet;John Stasko;Gregory Abowd; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Viz-A-Vis: Toward Visualizing Video through Computer Vision; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In the established procedural model of information visualization, the first operation is to transform raw data into data tables. The transforms typically include abstractions that aggregate and segment relevant data and are usually defined by a human, user or programmer. The theme of this paper is that for video, data transforms should be supported by low level computer vision. High level reasoning still resides in the human analyst, while part of the low level perception is handled by the computer. To illustrate this approach, we present Viz-A-Vis, an overhead video capture and access system for activity analysis in natural settings over variable periods of time. Overhead video provides rich opportunities for long-term behavioral and occupancy analysis, but it poses considerable challenges. We present initial steps addressing two challenges. First, overhead video generates overwhelmingly large volumes of video impractical to analyze manually. Second, automatic video analysis remains an open problem for computer vision."}, {"color": "gray", "id": 408, "label": 408, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 408 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2008.4677350\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Tobias Schreck;Jurgen Bernard;Tatiana Tekusova;Jorn Kohlhammer; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visual cluster analysis of trajectory data with interactive Kohonen Maps; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Visual-interactive cluster analysis provides valuable tools for effectively analyzing large and complex data sets. Due to desirable properties and an inherent predisposition for visualization, the Kohonen Feature Map (or self-organizing map, or SOM) algorithm is among the most popular and widely used visual clustering techniques. However, the unsupervised nature of the algorithm may be disadvantageous in certain applications. Depending on initialization and data characteristics, cluster maps (cluster layouts) may emerge that do not comply with user preferences, expectations, or the application context. Considering SOM-based analysis of trajectory data, we propose a comprehensive visual-interactive monitoring and control framework extending the basic SOM algorithm. The framework implements the general Visual Analytics idea to effectively combine automatic data analysis with human expert supervision. It provides simple, yet effective facilities for visually monitoring and interactively controlling the trajectory clustering process at arbitrary levels of detail. The approach allows the user to leverage existing domain knowledge and user preferences, arriving at improved cluster maps. We apply the framework on a trajectory clustering problem, demonstrating its potential in combining both unsupervised (machine) and supervised (human expert) processing, in producing appropriate cluster results."}, {"color": "gray", "id": 411, "label": 411, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 411 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2008.4677353\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Cecilia R. Aragon;Sarah S. Poon;Gregory S. Aldering;Rollin C. Thomas;Robert Quimby; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Using visual analytics to maintain situation awareness in astrophysics; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present a novel collaborative visual analytics application for cognitively overloaded users in the astrophysics domain. The system was developed for scientists needing to analyze heterogeneous, complex data under time pressure, and then make predictions and time-critical decisions rapidly and correctly under a constant influx of changing data. The Sunfall Data Taking system utilizes several novel visualization and analysis techniques to enable a team of geographically distributed domain specialists to effectively and remotely maneuver a custom-built instrument under challenging operational conditions. Sunfall Data Taking has been in use for over eighteen months by a major international astrophysics collaboration (the largest data volume supernova search currently in operation), and has substantially improved the operational efficiency of its users. We describe the system design process by an interdisciplinary team, the system architecture, and the results of an informal usability evaluation of the production system by domain experts in the context of Endsleypsilas three levels of situation awareness."}, {"color": "gray", "id": 415, "label": 415, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 415 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2008.4677357\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Sye-Min Chan;Ling Xiao;John Gerth;Pat Hanrahan; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Maintaining interactivity while exploring massive time series; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The speed of data retrieval qualitatively affects how analysts visually explore and analyze their data. To ensure smooth interactions in massive time series datasets, one needs to address the challenges of computing \u0026lt;i\u0026gt;ad\u0026lt;/i\u0026gt; \u0026lt;i\u0026gt;hoc\u0026lt;/i\u0026gt; queries, distributing query load, and hiding system latency. In this paper, we present ATLAS, a visualization tool for temporal data that addresses these issues using a combination of high performance database technology, predictive caching, and level of detail management. We demonstrate ATLAS using commodity hardware on a network traffic dataset of more than a billion records."}, {"color": "gray", "id": 419, "label": 419, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 419 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2008.4677361\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Tera Marie Green;William Ribarsky;Brian Fisher; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visual analytics for complex concepts using a human cognition model; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: As the information being visualized and the process of understanding that information both become increasingly complex, it is necessary to develop new visualization approaches that facilitate the flow of human reasoning. In this paper, we endeavor to push visualization design a step beyond current user models by discussing a modeling framework of human ldquohigher cognition.rdquo Based on this cognition model, we present design guidelines for the development of visual interfaces designed to maximize the complementary cognitive strengths of both human and computer. Some of these principles are already being reflected in the better visual analytics designs, while others have not yet been applied or fully applied. But none of the guidelines have explained the deeper rationale that the model provides. Lastly, we discuss and assess these visual analytics guidelines through the evaluation of several visualization examples."}, {"color": "gray", "id": 421, "label": 421, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 421 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2008.4677363\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Anya Savikhin;Ross Maciejewski;David S. Ebert; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Applied visual analytics for economic decision-making; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: This paper introduces the application of visual analytics techniques as a novel approach for improving economic decision making. Particularly, we focus on two known problems where subjectspsila behavior consistently deviates from the optimal, the Winnerpsilas and Loserpsilas Curse. According to economists, subjects fail to recognize the profit-maximizing decision strategy in both the Winnerpsilas and Loserpsilas curse because they are unable to properly consider all the available information. As such, we have created a visual analytics tool to aid subjects in decision making under the Acquiring a Company framework common in many economic experiments. We demonstrate the added value of visual analytics in the decision making process through a series of user studies comparing standard visualization methods with interactive visual analytics techniques. Our work presents not only a basis for development and evaluation of economic visual analytic research, but also empirical evidence demonstrating the added value of applying visual analytics to general decision making tasks."}, {"color": "gray", "id": 424, "label": 424, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 424 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2008.4677366\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: William A. Pike;Joe Bruce;Bob Baddeley;Daniel Best;Lyndsey Franklin;Richard May;Douglas M. Rice;Rick Riensche;Katarina Younkin; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: The Scalable Reasoning System: Lightweight visualization for distributed analytics; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: A central challenge in visual analytics is the creation of accessible, widely distributable analysis applications that bring the benefits of visual discovery to as broad a user base as possible. Moreover, to support the role of visualization in the knowledge creation process, it is advantageous to allow users to describe the reasoning strategies they employ while interacting with analytic environments. We introduce an application suite called the scalable reasoning system (SRS), which provides Web-based and mobile interfaces for visual analysis. The service-oriented analytic framework that underlies SRS provides a platform for deploying pervasive visual analytic environments across an enterprise. SRS represents a ldquolightweightrdquo approach to visual analytics whereby thin client analytic applications can be rapidly deployed in a platform-agnostic fashion. Client applications support multiple coordinated views while giving analysts the ability to record evidence, assumptions, hypotheses and other reasoning artifacts. We describe the capabilities of SRS in the context of a real-world deployment at a regional law enforcement organization."}, {"color": "gray", "id": 428, "label": 428, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 428 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2008.4677370\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Chris Weaver; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Multidimensional visual analysis using cross-filtered views; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Analysis of multidimensional data often requires careful examination of relationships across dimensions. Coordinated multiple view approaches have become commonplace in visual analysis tools because they directly support expression of complex multidimensional queries using simple interactions. However, generating such tools remains difficult because of the need to map domain-specific data structures and semantics into the idiosyncratic combinations of interdependent data and visual abstractions needed to reveal particular patterns and distributions in cross-dimensional relationships. This paper describes: (1) a method for interactively expressing sequences of multidimensional set queries by cross-filtering data values across pairs of views, and (2) design strategies for constructing coordinated multiple view interfaces for cross-filtered visual analysis of multidimensional data sets. Using examples of cross-filtered visualizations of data from several different domains, we describe how cross-filtering can be modularized and reused across designs, flexibly customized with respect to data types across multiple dimensions, and incorporated into more wide-ranging multiple view designs. The demonstrated analytic utility of these examples suggest that cross-filtering is a suitable design pattern for instantiation in a wide variety of visual analysis tools."}, {"color": "gray", "id": 433, "label": 433, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 433 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2008.4677376\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Ye Zhao;Jamal Alsakran;Xinlei Zhao; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visual analysis for mutual fund performance; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Mutual funds are one of the most important investment instruments available. However, choosing among mutual funds is not an easy task because they vary in many different dimensions, such as asset size, turnover and fee structure, and these characteristics may affect fund returns. It is thus important to understand the relation between fund performance and these properties. In this work, we use a new visual analytical tool, the density-based distribution map, to assist in this task. By visualizing various important fund characteristics from a real-world database of the US stock funds, our new visual representations greatly help understand the relation between fund characteristics and returns."}, {"color": "gray", "id": 434, "label": 434, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 434 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2008.4677377\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Victor Pascual-Cid; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: An information visualisation system for the understanding of web data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Internet has become one of the best communication and marketing tools. Hence, designing well-structured Web sites with the information or products that users look for is a crucial mission. For this reason, understanding Web data is a decisive task to assure the success of a Website. In that sense, data mining techniques provide many metrics and statistics useful to automatically discover the structure, contents and usage of a site. This research aims at proving the usefulness of a set of information visualisation techniques in order to analyse Web data, using a visual Web mining tool that allows the combination, coordination and exploration of visualisations to get insight on Web data. The tool, named WET, provides a set of visual metaphors that represent the structure of the Websites where Web metrics are overlaid."}, {"color": "gray", "id": 435, "label": 435, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 435 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2008.4677378\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Yedendra B. Shrinivasan;Jarke J. van Wijk; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Supporting exploration awareness for visual analytics; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: While exploring data using information visualization, analysts try to make sense of the data, build cases, and present them to others. However, if the exploration is long or done in multiple sessions, it can be hard for analysts to remember all interesting visualizations and the relationships among them they have seen. Often, they will see the same or similar visualizations, and are unable to recall when, why and how they have seen something similar. Recalling and retrieving interesting visualizations are important tasks for the analysis processes such as problem solving, reasoning, and conceptualization. In this paper, we argue that offering support for thinking based on past analysis processes is important, and present a solution for this."}, {"color": "gray", "id": 436, "label": 436, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 436 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2008.4677379\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Alex Godwin;Remco Chang;Robert Kosara;William Ribarsky; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Interactive poster: Visual data mining of unevenly-spaced event sequences; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present a process for the exploration and analysis of large databases of events. A typical database is characterized by the sequential actions of a number of individual entities. These entities can be compared by their similarities in sequence and changes in sequence over time. The correlation of two sequences can provide important clues as to the possibility of a connection between the responsible entities, but an analyst might not be able to specify the type of connection sought prior to examination. Our process incorporates extensive automated calculation and data mining but permits diversity of analysis by providing visualization of results at multiple levels, taking advantage of human intuition and visual processing to generate avenues of inquiry."}, {"color": "gray", "id": 437, "label": 437, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 437 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2008.4677380\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Mark Giereth;Harald Bosch;Thomas Ertl; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: A 3D treemap approach for analyzing the classificatory distribution in patent portfolios; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Due to the complexity of the patent domain and the huge amount of data, advanced interactive visual techniques are needed to support the analysis of large patent collections and portfolios. In this paper we present a new approach for visualizing the classificatory distribution of patent collections among the International Patent Classification (IPC) - todaypsilas most important internationally agreed patent classification system with about 70.000 categories. Our approach is based on an interactive three-dimensional treemap overlaid with adjacency edge bundles."}, {"color": "gray", "id": 439, "label": 439, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 439 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2008.4677383\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Georges Grinstein;Catherine Plaisant;Sharon Laskowski;Theresa O\u0027Connell;Jean Scholtz;Mark Whiting; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: VAST 2008 Challenge: Introducing mini-challenges; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Visual analytics experts realize that one effective way to push the field forward and to develop metrics for measuring the performance of various visual analytics components is to hold an annual competition. The VAST 2008 Challenge is the third year that such a competition was held in conjunction with the IEEE Visual Analytics Science and Technology (VAST) symposium. The authors restructured the contest format used in 2006 and 2007 to reduce the barriers to participation and offered four mini-challenges and a Grand Challenge. Mini Challenge participants were to use visual analytic tools to explore one of four heterogeneous data collections to analyze specific activities of a fictitious, controversial movement. Questions asked in the Grand Challenge required the participants to synthesize data from all four data sets. In this paper we give a brief overview of the data sets, the tasks, the participation, the judging, and the results."}, {"color": "gray", "id": 440, "label": 440, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 440 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2008.4677384\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Donald Pellegrino;Chi-Chun Pan;Anthony Robinson;Michael Stryker;Junyan Luo;Chris Weaver;Prasenjit Mitra;Chaomei Chen;Ian Turton;Alan MacEachren; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Grand challenge award: Data integration visualization and collaboration in the VAST 2008 Challenge; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The VAST 2008 Challenge consisted of four heterogeneous synthetic data sets each organized into separate mini-challenges. The Grand Challenge required integrating the raw data from these four data sets as well as integrating results and findings from team members working on specific mini-challenges. Modeling the problem with a semantic network provided a means for integrating both the raw data and the subjective findings."}, {"color": "gray", "id": 441, "label": 441, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 441 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2008.4677385\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Lynn Chien;Annie Tat;Pascale Proulx;Adeel Khamisa;William Wright; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Grand challenge award 2008: Support for diverse analytic techniques - nSpace2 and GeoTime visual analytics; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: GeoTime and nSpace2 are interactive visual analytics tools that were used to examine and interpret all four of the 2008 VAST Challenge datasets. GeoTime excels in visualizing event patterns in time and space, or in time and any abstract landscape, while nSpace2 is a web-based analytical tool designed to support every step of the analytical process. nSpace2 is an integrating analytic environment. This paper highlights the VAST analytical experience with these tools that contributed to the success of these tools and this team for the third consecutive year."}, {"color": "gray", "id": 443, "label": 443, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 443 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2008.4677387\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: R. Miklin;T. Lipic;Z. Konyha;M. Beric;W. Freiler;K. Matkovic;D. Gracanin; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Migrant boat mini challenge award: Simple and effective integrated display geo-temporal analysis of migrant boats; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We provide a description of the tools and techniques used in our analysis of the VAST 2008 Challenge dealing with mass movement of persons departing Isla Del Sue.no on boats for the United States during 2005-2007. We used visual analytics to explore migration patterns, characterize the choice and evolution of landing sites, characterize the geographical patterns of interdictions and determine the successful landing rate. Our ComVis tool, in connection with some helper applications and Google Earth, allowed us to explore geo-temporal characteristics of the data set and answer the challenge questions. The ComVis project file captures the visual analysis context and facilitates better collaboration among team members."}, {"color": "gray", "id": 444, "label": 444, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 444 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2008.4677388\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Natalia Andrienko;Gennady Andrienko; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Evacuation trace Mini Challenge award: Tool integration analysis of movements with Geospatial Visual Analytics Toolkit; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The Geospatial Visual Analytics Toolkit intended for exploratory analysis of spatial and spatio-temporal data has been recently enriched with specific visual and computational techniques supporting analysis of data about movement. We applied these and other techniques to the data and tasks of Mini Challenge 4, where it was necessary to analyze tracks of moving people.CR Categories and Subject Descriptors: H.1.2 [User/Machine Systems]: Human information processing - Visual Analytics; 1.6.9 [Visualization]: information visualization."}, {"color": "gray", "id": 445, "label": 445, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 445 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2008.4677389\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Qi Ye;Tian Zhu;Deyong Hu;Bin Wu;Nan Du;Bai Wang; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Cell phone mini challenge award: Social network accuracy - exploring temporal communication in mobile call graphs; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In the mobile call mini challenge of VAST 2008 contest, we explored the temporal communication patterns of Catalano/Vidro social network which is reflected in the mobile call data. We focus on detecting the hierarchy of the social network and try to get the important actors in it. We present our tools and methods in this summary. By using the visual analytic approaches, we can find out not only the temporal communication patterns in the social network but also the hierarchy of it."}, {"color": "gray", "id": 447, "label": 447, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 447 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2008.4677391\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Carlos D. Correa;Tarik Crnovrsanin;Christopher Muelder;Zeqian Shen;Ryan Armstrong;James Shearer;Kwan-Liu Ma; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Cell phone mini challenge award: Intuitive social network graphs visual analytics of cell phone data using mobivis and ontovis; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: MobiVis is a visual analytics tools to aid in the process of processing and understanding complex relational data, such as social networks. At the core of these tools is the ability to filter complex networks structurally and semantically, which helps us discover clusters and patterns in the organization of social networks. Semantic filtering is obtained via an ontology graph, based on another visual analytics tool, called OntoVis. In this summary, we describe how these tools where used to analyze one of the mini-challenges of the 2008 VAST challenge."}, {"color": "gray", "id": 448, "label": 448, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 448 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2008.4677392\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Adam Perer; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Using SocialAction to uncover structure in social networks over time; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: I describe how SocialAction was used to find insights in an evolving social structure VAST Challenge 2008psilas Mini-Challenge 3. This analysis and SocialAction were given the award, ldquoCell Phone Mini Challenge Award: Time Visualizations of Cell Phone Activityrdquo."}, {"color": "gray", "id": 449, "label": 449, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 449 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2008.4677393\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Michael Farrugia;Aaron Quigley; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Cell phone Mini Challenge: Node-link animation award animating multivariate dynamic social networks; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: This article describes the visualization tool developed for analysing a dynamic social network of phone calls, for the VAST 2008 mini challenge. The tool was designed to highlight temporal changes in the network, by animating different network visual representations. We also explain how animating these network representations, helped to identify key events in the mini challenge problem scenario. Finally, we make some suggestions for future research and development in the area."}, {"color": "gray", "id": 450, "label": 450, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 450 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2008.4677394\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Benjamin Holland;Lisa Kuchy;Jason Dalton; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Migrant boat mini challenge award: Analysis summary a geo-temporal analysis of the migrant boat dataset; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The SPADAC team used various visual analytics tools and methods to find geo-temporal patterns of migration from a Caribbean island from 2005-2007. In this paper, we describe the tools and methods used in the analysis. These methods included generating temporal variograms, dendrograms, and proportionally weighted migration maps, using tools such as the R statistical software package and Signature Analysttrade. We found that there is a significant positive space-time correlation with the boat encounters (especially the landings), with a migratory shift further away from the point of departure over time."}, {"color": "gray", "id": 452, "label": 452, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 452 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2008.4677396\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Edward Swing; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Award: Efficient toolkit integration solving the cell phone calls challenge with the Prajna Project; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The Prajna Project is a Java toolkit designed to provide various capabilities for visualization, knowledge representation, geographic displays, semantic reasoning, and data fusion. Rather than attempt to recreate the significant capabilities provided in other tools, Prajna instead provides software bridges to incorporate other toolkits where appropriate. This challenge required the development of a custom application for visual analysis. By applying the utilities within the Prajna project, I developed a robust and diverse set of capabilities to solve the analytical challenge."}, {"color": "gray", "id": 459, "label": 459, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 459 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2009.122\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Christopher Collins;Gerald Penn;Sheelagh Carpendale; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Bubble Sets: Revealing Set Relations with Isocontours over Existing Visualizations; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: While many data sets contain multiple relationships, depicting more than one data relationship within a single visualization is challenging. We introduce Bubble Sets as a visualization technique for data that has both a primary data relation with a semantically significant spatial organization and a significant set membership relation in which members of the same set are not necessarily adjacent in the primary layout. In order to maintain the spatial rights of the primary data relation, we avoid layout adjustment techniques that improve set cluster continuity and density. Instead, we use a continuous, possibly concave, isocontour to delineate set membership, without disrupting the primary layout. Optimizations minimize cluster overlap and provide for calculation of the isocontours at interactive speeds. Case studies show how this technique can be used to indicate multiple sets on a variety of common visualizations."}, {"color": "gray", "id": 465, "label": 465, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 465 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2009.139\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Hendrik Strobelt;Daniela Oelke;Christian Rohrdantz;Andreas Stoffel;Daniel A. Keim;Oliver Deussen; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Document Cards: A Top Trumps Visualization for Documents; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Finding suitable, less space consuming views for a document\u0027s main content is crucial to provide convenient access to large document collections on display devices of different size. We present a novel compact visualization which represents the document\u0027s key semantic as a mixture of images and important key terms, similar to cards in a top trumps game. The key terms are extracted using an advanced text mining approach based on a fully automatic document structure extraction. The images and their captions are extracted using a graphical heuristic and the captions are used for a semi-semantic image weighting. Furthermore, we use the image color histogram for classification and show at least one representative from each non-empty image class. The approach is demonstrated for the IEEE InfoVis publications of a complete year. The method can easily be applied to other publication collections and sets of documents which contain images."}, {"color": "gray", "id": 467, "label": 467, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 467 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2009.143\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Diansheng Guo; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Flow Mapping and Multivariate Visualization of Large Spatial Interaction Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Spatial interactions (or flows), such as population migration and disease spread, naturally form a weighted location-to-location network (graph). Such geographically embedded networks (graphs) are usually very large. For example, the county-to-county migration data in the U.S. has thousands of counties and about a million migration paths. Moreover, many variables are associated with each flow, such as the number of migrants for different age groups, income levels, and occupations. It is a challenging task to visualize such data and discover network structures, multivariate relations, and their geographic patterns simultaneously. This paper addresses these challenges by developing an integrated interactive visualization framework that consists three coupled components: (1) a spatially constrained graph partitioning method that can construct a hierarchy of geographical regions (communities), where there are more flows or connections within regions than across regions; (2) a multivariate clustering and visualization method to detect and present multivariate patterns in the aggregated region-to-region flows; and (3) a highly interactive flow mapping component to map both flow and multivariate patterns in the geographic space, at different hierarchical levels. The proposed approach can process relatively large data sets and effectively discover and visualize major flow structures and multivariate relations at the same time. User interactions are supported to facilitate the understanding of both an overview and detailed patterns."}, {"color": "gray", "id": 474, "label": 474, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 474 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2009.165\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Frank van Ham;Martin Wattenberg;Fernanda B. Viegas; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Mapping Text with Phrase Nets; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present a new technique, the phrase net, for generating visual overviews of unstructured text. A phrase net displays a graph whose nodes are words and whose edges indicate that two words are linked by a user-specified relation. These relations may be defined either at the syntactic or lexical level; different relations often produce very different perspectives on the same text. Taken together, these perspectives often provide an illuminating visual overview of the key concepts and relations in a document or set of documents."}, {"color": "gray", "id": 476, "label": 476, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 476 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2009.171\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Fernanda B. Viegas;Martin Wattenberg;Jonathan Feinberg; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Participatory Visualization with Wordle; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We discuss the design and usage of ldquoWordle,rdquo a Web-based tool for visualizing text. Wordle creates tag-cloud-like displays that give careful attention to typography, color, and composition. We describe the algorithms used to balance various aesthetic criteria and create the distinctive Wordle layouts. We then present the results of a study of Wordle usage, based both on spontaneous behaviour observed in the wild, and on a large-scale survey of Wordle users. The results suggest that Wordles have become a kind of medium of expression, and that a ldquoparticipatory culturerdquo has arisen around them."}, {"color": "gray", "id": 478, "label": 478, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 478 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2009.176\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Edward Clarkson;Krishna Desai;James Foley; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: ResultMaps: Visualization for Search Interfaces; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Hierarchical representations are common in digital repositories, yet are not always fully leveraged in their online search interfaces. This work describes ResultMaps, which use hierarchical treemap representations with query string-driven digital library search engines. We describe two lab experiments, which find that ResultsMap users yield significantly better results over a control condition on some subjective measures, and we find evidence that ResultMaps have ancillary benefits via increased understanding of some aspects of repository content. The ResultMap system and experiments contribute an understanding of the benefits-direct and indirect-of the ResultMap approach to repository search visualization."}, {"color": "gray", "id": 480, "label": 480, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 480 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2009.180\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Zhicheng Liu;John Stasko;Timothy Sullivan; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: SellTrend: Inter-Attribute Visual Analysis of Temporal Transaction Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present a case study of our experience designing SellTrend, a visualization system for analyzing airline travel purchase requests. The relevant transaction data can be characterized as multi-variate temporal and categorical event sequences, and the chief problem addressed is how to help company analysts identify complex combinations of transaction attributes that contribute to failed purchase requests. SellTrend combines a diverse set of techniques ranging from time series visualization to faceted browsing and historical trend analysis in order to help analysts make sense of the data. We believe that the combination of views and interaction capabilities in SellTrend provides an innovative approach to this problem and to other similar types of multivariate, temporally driven transaction data analysis. Initial feedback from company analysts confirms the utility and benefits of the system."}, {"color": "gray", "id": 483, "label": 483, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 483 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2009.183\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Michael Douma;Grzegorz Ligierko;Ovidiu Ancuta;Pavel Gritsai;Sean Liu; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: SpicyNodes: Radial Layout Authoring for the General Public; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Trees and graphs are relevant to many online tasks such as visualizing social networks, product catalogs, educational portals, digital libraries, the semantic web, concept maps and personalized information management. SpicyNodes is an information-visualization technology that builds upon existing research on radial tree layouts and graph structures. Users can browse a tree, clicking from node to node, as well as successively viewing a node, immediately related nodes and the path back to the ldquohomerdquo nodes. SpicyNodes\u0027 layout algorithms maintain balanced layouts using a hybrid mixture of a geometric layout (a succession of spanning radial trees) and force-directed layouts to minimize overlapping nodes, plus several other improvements over prior art. It provides XML-based API and GUI authoring tools. The goal of the SpicyNodes project is to implement familiar principles of radial maps and focus+context with an attractive and inviting look and feel in an open system that is accessible to virtually any Internet user."}, {"color": "gray", "id": 490, "label": 490, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 490 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2009.5332481\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Edward Swing; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Merging visual analysis with automated reasoning: Using Prajna to solve the traffic challenge; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The Internet traffic challenge required the development of a custom application to analyze internet traffic patterns coupled with building access records. To solve this challenge, the author applied the Prajna Project, an open-source Java toolkit designed to provide various capabilities for visualization, knowledge representation, semantic reasoning, and data fusion. By applying some of the capabilities of Prajna to this challenge, the author could quickly develop a custom application for visual analysis. The author determined that he could solve some of the analytical components of this challenge using automated reasoning techniques. Prajna includes interfaces to incorporate automated reasoners into visual applications. By blending the automated reasoning processes with visual analysis, the author could design a flexible, useful application to solve this challenge."}, {"color": "gray", "id": 491, "label": 491, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 491 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2009.5332485\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Alex Endert;Christopher Andrews;Glenn A. Fink;Chris North; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Professional analysts using a large, high-resolution display; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Professional cyber analysts were observed as they attempted to solve the VAST 2009 Traffic Mini Challenge using basic visualization tools and a large, high-resolution display. We discuss some of the lessons we learned about how analysts actually work and potential roles for visualization and large, high-resolution displays."}, {"color": "gray", "id": 495, "label": 495, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 495 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2009.5332595\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Krist Wongsuphasawat;Ben Shneiderman; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Finding comparable temporal categorical records: A similarity measure with an interactive visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: An increasing number of temporal categorical databases are being collected: Electronic Health Records in healthcare organizations, traffic incident logs in transportation systems, or student records in universities. Finding similar records within these large databases requires effective similarity measures that capture the searcher\u0027s intent. Many similarity measures exist for numerical time series, but temporal categorical records are different. We propose a temporal categorical similarity measure, the M\u0026amp;M (Match \u0026amp; Mismatch) measure, which is based on the concept of aligning records by sentinel events, then matching events between the target and the compared records. The M\u0026amp;M measure combines the time differences between pairs of events and the number of mismatches. To accom-modate customization of parameters in the M\u0026amp;M measure and results interpretation, we implemented Similan, an interactive search and visualization tool for temporal categorical records. A usability study with 8 participants demonstrated that Similan was easy to learn and enabled them to find similar records, but users had difficulty understanding the M\u0026amp;M measure. The usability study feedback, led to an improved version with a continuous timeline, which was tested in a pilot study with 5 participants."}, {"color": "gray", "id": 496, "label": 496, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 496 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2009.5332596\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Yi Han;Erich P. Stuntebeck;John T. Stasko;Gregory D. Abowd; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: A visual analytics system for radio frequency fingerprinting-based localization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Radio frequency (RF) fingerprinting-based techniques for localization are a promising approach for ubiquitous positioning systems, particularly indoors. By finding unique fingerprints of RF signals received at different locations within a predefined area beforehand, whenever a similar fingerprint is subsequently seen again, the localization system will be able to infer a user\u0027s current location. However, developers of these systems face the problem of finding reliable RF fingerprints that are unique enough and adequately stable over time. We present a visual analytics system that enables developers of these localization systems to visually gain insight on whether their collected datasets and chosen fingerprint features have the necessary properties to enable a reliable RF fingerprinting-based localization system. The system was evaluated by testing and debugging an existing localization system."}, {"color": "gray", "id": 500, "label": 500, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 500 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2009.5332629\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jaegul Choo;Shawn Bohn;Haesun Park; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Two-stage framework for visualization of clustered high dimensional data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In this paper, we discuss dimension reduction methods for 2D visualization of high dimensional clustered data. We propose a two-stage framework for visualizing such data based on dimension reduction methods. In the first stage, we obtain the reduced dimensional data by applying a supervised dimension reduction method such as linear discriminant analysis which preserves the original cluster structure in terms of its criteria. The resulting optimal reduced dimension depends on the optimization criteria and is often larger than 2. In the second stage, the dimension is further reduced to 2 for visualization purposes by another dimension reduction method such as principal component analysis. The role of the second-stage is to minimize the loss of information due to reducing the dimension all the way to 2. Using this framework, we propose several two-stage methods, and present their theoretical characteristics as well as experimental comparisons on both artificial and real-world text data sets."}, {"color": "gray", "id": 501, "label": 501, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 501 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2009.5333020\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Nazanin Kadivar;Victor Chen;Dustin Dunsmuir;Eric Lee;Cheryl Qian;John Dill;Christopher Shaw;Robert Woodbury; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Capturing and supporting the analysis process; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Visual analytics tools provide powerful visual representations in order to support the sense-making process. In this process, analysts typically iterate through sequences of steps many times, varying parameters each time. Few visual analytics tools support this process well, nor do they provide support for visualizing and understanding the analysis process itself. To help analysts understand, explore, reference, and reuse their analysis process, we present a visual analytics system named CzSaw (See-Saw) that provides an editable and re-playable history navigation channel in addition to multiple visual representations of document collections and the entities within them (in a manner inspired by Jigsaw). Conventional history navigation tools range from basic undo and redo to branching timelines of user actions. In CzSaw\u0027s approach to this, first, user interactions are translated into a script language that drives the underlying scripting-driven propagation system. The latter allows analysts to edit analysis steps, and ultimately to program them. Second, on this base, we build both a history view showing progress and alternative paths, and a dependency graph showing the underlying logic of the analysis and dependency relations among the results of each step. These tools result in a visual model of the sense-making process, providing a way for analysts to visualize their analysis process, to reinterpret the problem, explore alternative paths, extract analysis patterns from existing history, and reuse them with other related analyses."}, {"color": "gray", "id": 502, "label": 502, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 502 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2009.5333023\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Yedendra B. Shrinivasan;David Gotzy;Jie Lu; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Connecting the dots in visual analysis; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: During visual analysis, users must often connect insights discovered at various points of time. This process is often called ldquoconnecting the dots.rdquo When analysts interactively explore complex datasets over multiple sessions, they may uncover a large number of findings. As a result, it is often difficult for them to recall the past insights, views and concepts that are most relevant to their current line of inquiry. This challenge is even more difficult during collaborative analysis tasks where they need to find connections between their own discoveries and insights found by others. In this paper, we describe a context-based retrieval algorithm to identify notes, views and concepts from users\u0027 past analyses that are most relevant to a view or a note based on their line of inquiry. We then describe a related notes recommendation feature that surfaces the most relevant items to the user as they work based on this algorithm. We have implemented this recommendation feature in HARVEST, a Web based visual analytic system. We evaluate the related notes recommendation feature of HARVEST through a case study and discuss the implications of our approach."}, {"color": "gray", "id": 508, "label": 508, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 508 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2009.5333417\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Soujanya Vadapalli;Kamalakar Karlapalem; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: BEADS: High dimensional data cluster visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In this poster paper, we present BEADS, a high dimensional data cluster visualization by having a 2-D representation of shape and spread of the cluster. The Cluster Division component, the Bead Shape Identification and Cluster Shape Composition form the core of the system. BEADS visualization consists of a 2-D plot, standard 2-D shapes which are used as metaphors to represent corresponding high-dimensional shapes of beads. The final resulting images convey the relative placement of beads with respect to the cluster center, the shape of the beads. We give a textual summary of the beads and their 2-D placement on the Beads plot in tabular format along with the image."}, {"color": "gray", "id": 510, "label": 510, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 510 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2009.5333421\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Xiongfei Luo;Hongan Wang;Feng Tian;Wei Liu;Dongxing Teng;Guozhong Dai; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: ProcessLine: Visualizing time-series data in process industry; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In modern process industry, it is often difficult to analyze a manufacture process due to its numerous time-series data. Analysts wish to not only interpret the evolution of data over time in a working procedure, but also examine the changes in the whole production process through time. To meet such analytic requirements, we have developed ProcessLine, an interactive visualization tool for a large amount of time-series data in process industry. The data are displayed in a fisheye timeline. ProcessLine provides good overviews for the whole production process and details for the focused working procedure. A preliminary user study using beer industry production data has shown that the tool is effective."}, {"color": "gray", "id": 513, "label": 513, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 513 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2009.5333436\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: VinhTuan Thai;Siegfried Handschuh; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Reordered tilebars for visual text exploration; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The classic TileBars paradigm has been used to show distribution information of query terms in full-text documents. However, when the number of query terms becomes large, it is not an easy task for users to comprehend their distribution within certain parts of a document. In this paper, we present a novel approach to improve the visual presentation of TileBars, in which barycenter heuristic for bigraph crossing minimization is used to reorder TileBars elements. The reordered TileBars can be demonstrated to provide users with better focus and navigation while exploring text documents."}, {"color": "gray", "id": 515, "label": 515, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 515 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2009.5333438\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Aba-Sah Dadzie;Daniela Petrelli; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visual knowledge exploration and discovery from different points of view; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Complex scenario analysis requires the exploration of multiple hypotheses and supporting evidence for each argument posed. Knowledge-intensive organisations typically analyse large amounts of inter-related, heterogeneous data to retrieve the knowledge this contains and use it to support effective decision-making. We demonstrate the use of interactive graph visualisation to support hierarchical, task-driven, hypothesis investigation. The visual investigative analysis is guided by task and domain ontologies used to capture the structure of the investigation process and the experience gained and knowledge created in previous, related investigations."}, {"color": "gray", "id": 517, "label": 517, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 517 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2009.5333451\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jonathan Decker;Alex Godwin;Mark A. Livingston;Denise Royle; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: A scalable architecture for visual data exploration; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Intelligence analysts in the areas of defense and homeland security are now faced with the difficult problem of discerning the relevant details amidst massive data stores. We propose a component-based visualization architecture that is built specifically to encourage the flexible exploration of geospatial event databases. The proposed system is designed to deploy on a variety of display layouts, from a single laptop screen to a multi-monitor tiled-display. By utilizing a combination of parallel coordinates, principal components plots, and other data views, analysts may reduce the dimensionality of a data set to its most salient features. Of particular value to our target applications are understanding correlations between data layers, both within a single view and across multiple views. Our proposed system aims to address the limited scalability associated with coordinated multiple views (CMVs) through the implementation of an efficient core application which is extensible by the end-user."}, {"color": "gray", "id": 519, "label": 519, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 519 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2009.5333468\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Courtney C. Dornburg;Laura E. Matzen;Travis L. Bauer;Laura A. McNamara; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Working memory load as a novel tool for evaluating visual analytics; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The current visual analytics literature highlights design and evaluation processes that are highly variable and situation dependent, which raises at least two broad challenges. First, lack of a standardized evaluation criterion leads to costly re-designs for each task and specific user community. Second, this inadequacy in criterion validation raises significant uncertainty regarding visualization outputs and their related decisions, which may be especially troubling in high consequence environments like those of the intelligence community. As an attempt to standardize the ldquoapples and orangesrdquo of the extant situation, we propose the creation of standardized evaluation tools using general principles of human cognition. Theoretically, visual analytics enables the user to see information in a way that should attenuate the user\u0027s memory load and increase the user\u0027s task-available cognitive resources. By using general cognitive abilities like available working memory resources as our dependent measures, we propose to develop standardized evaluative capabilities that can be generalized across contexts, tasks, and user communities."}, {"color": "gray", "id": 521, "label": 521, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 521 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2009.5333472\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Gennady Andrienko;Natalia Andrienko;Peter Bak;Slava Kisilevich;Daniel Keim; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Analysis of community-contributed space- and time-referenced data (example of flickr and panoramio photos); \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Space- and time-referenced data published on the Web by general people can be viewed in a dual way: as independent spatio-temporal events and as trajectories of people in the geographical space. These two views suppose different approaches to the analysis, which can yield different kinds of valuable knowledge about places and about people. We define possible types of analysis tasks related to the two views of the data and present several analysis methods appropriate for these tasks. The methods are suited to large amounts of the data."}, {"color": "gray", "id": 522, "label": 522, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 522 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2009.5333474\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jean Scholtz; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Interactive poster: A proposal for sharing user requirements for visual analytic tools; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Although many in the community have advocated user-centered evaluations for visual analytic environments, a significant barrier exists. The users targeted by the visual analytics community (law enforcement personnel, professional information analysts, financial analysts, health care analysts, etc.) are often inaccessible to researchers. These analysts are extremely busy and their work environments and data are often classified or at least confidential. Furthermore, their tasks often last weeks or even months. It is simply not feasible to do such long-term observations to understand their jobs. How then can we hope to gather enough information about the diverse user populations to understand their needs? Some researchers, including the author, have been successful in getting access to specific end-users. A reasonable approach, therefore, would be to find a way to share user information. This work outlines a proposal for developing a handbook of user profiles for use by researchers, developers, and evaluators."}, {"color": "gray", "id": 526, "label": 526, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 526 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2009.5333893\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Tatiana von Landesberger;Melanie Gorner;Tobias Schreck; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visual analysis of graphs with multiple connected components; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In this paper, we present a system for the interactive visualization and exploration of graphs with many weakly connected components. The visualization of large graphs has recently received much research attention. However, specific systems for visual analysis of graph data sets consisting of many components are rare. In our approach, we rely on graph clustering using an extensive set of topology descriptors. Specifically, we use the self-organizing-map algorithm in conjunction with a user-adaptable combination of graph features for clustering of graphs. It offers insight into the overall structure of the data set. The clustering output is presented in a grid containing clusters of the connected components of the input graph. Interactive feature selection and task-tailored data views allow the exploration of the whole graph space. The system provides also tools for assessment and display of cluster quality. We demonstrate the usefulness of our system by application to a shareholder network analysis problem based on a large real-world data set. While so far our approach is applied to weighted directed graphs only, it can be used for various graph types."}, {"color": "gray", "id": 527, "label": 527, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 527 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2009.5333895\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Robert Kincaid;Kurt Dejgaard; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: MassVis: Visual analysis of protein complexes using mass spectrometry; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Protein complexes are formed when two or more proteins non-covalently interact to form a larger three dimensional structure with specific biological function. Understanding the composition of such complexes is vital to understanding cell biology at the molecular level. MassVis is a visual analysis tool designed to assist the interpretation of data from a new workflow for detecting the composition of such protein complexes in biological samples. The data generated by the laboratory workflow naturally lends itself to a scatter plot visualization. However, characteristics of this data give rise to some unique aspects not typical of a standard scatter plot. We are able to take the output from tandem mass spectrometry and render the data in such a way that it mimics more traditional two-dimensional gel techniques and at the same time reveals the correlated behavior indicative of protein complexes. By computationally measuring these correlated patterns in the data, membership in putative complexes can be inferred. User interactions are provided to support both an interactive discovery mode as well as an unsupervised clustering of likely complexes. The specific analysis tasks led us to design a unique arrangement of item selection and coordinated detail views in order to simultaneously view different aspects of the selected item."}, {"color": "gray", "id": 528, "label": 528, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 528 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2009.5333911\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Janko Dietzsch;Julian Heinrich;Kay Nieselt;Dirk Bartz; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: SpRay: A visual analytics approach for gene expression data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present a new application, SpRay, designed for the visual exploration of gene expression data. It is based on an extension and adaption of parallel coordinates to support the visual exploration of large and high-dimensional datasets. In particular, we investigate the visual analysis of gene expression data as generated by micro-array experiments; We combine refined visual exploration with statistical methods to a visual analytics approach that proved to be particularly successful in this application domain. We will demonstrate the usefulness on several multidimensional gene expression datasets from different bioinformatics applications."}, {"color": "gray", "id": 529, "label": 529, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 529 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2009.5333917\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Boonthanome Nouanesengsy;Sang-Cheol Seok;Han-Wei Shen;Veronica J Vieland; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Using projection and 2D plots to visually reveal genetic mechanisms of complex human disorders; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Gene mapping is a statistical method used to localize human disease genes to particular regions of the human genome. When performing such analysis, a genetic likelihood space is generated and sampled, which results in a multidimensional scalar field. Researchers are interested in exploring this likelihood space through the use of visualization. Previous efforts at visualizing this space, though, were slow and cumbersome, only showing a small portion of the space at a time, thus requiring the user to keep a mental picture of several views. We have developed a new technique that displays much more data at once by projecting the multidimensional data into several 2D plots. One plot is created for each parameter that shows the change along that parameter. A radial projection is used to create another plot that provides an overview of the high dimensional surface from the perspective of a single point. Linking and brushing between all the plots are used to determine relationships between parameters. We demonstrate our techniques on real world autism data, showing how to visually examine features of the high dimensional space."}, {"color": "gray", "id": 532, "label": 532, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 532 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2009.5333946\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Thorsten Liebig;Olaf Noppens;Friedrich von Henke; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: VIScover: Visualizing, exploring, and analysing structured data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Today\u0027s challenging task in intelligent data processing is not to store large volumes of interlinked data but to visualize, explore, and understand its explicit or implicit relationships. Our solution to this is the VIScover system. VIScover combines semantic technologies with interactive exploration and visualization techniques able to analyze large volumes of structured data. We briefly describe our VIScover system and show its potential using the example of the VAST 2009 social network and geospatial data set."}, {"color": "gray", "id": 536, "label": 536, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 536 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2009.5333967\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Lorne Leonard; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: EAKOS: VAST 2009; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In this article, I describe the tools and techniques used to generate competing hypotheses for the VAST 2009 Flitter mini challenge. I will describe how I approached solving the social networks and the importance of the geospatial relationships to determine that ldquoSocial Structure Form Ardquo was the best matching social network."}, {"color": "gray", "id": 537, "label": 537, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 537 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2009.5333968\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Dora Erdos;Zsolt Fekete;Andras Lukacs; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visualized subgraph search; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present a visually supported search and browsing system for network-type data, especially a novel module for subgraph search with a GUI to define subgraphs for queries. We describe how this prototype was applied for the Vast Challenge 2009, Flitter Mini Challenge."}, {"color": "gray", "id": 540, "label": 540, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 540 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2009.5334426\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: David Allen;Tsai-Ching Lu;Dave Huber; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Detecting and analyzing relationships among anomalies; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The HRL anomaly analysis tool was developed as part of the IEEE VAST Challenge 2009. One of the tasks involved processing badge and network traffic in order to detect and identify a fictitious embassy employee suspected of leaking information. The tool is designed to assist an analyst in detecting, analyzing, and visualizing anomalies and their relationships. Two key visualizations in our submission present how we identified the suspicious traffic using network visualization and how subsequently we connected that activity to an employee using an alibi table."}, {"color": "gray", "id": 541, "label": 541, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 541 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2009.5334430\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Peter Bak;Christian Rohrdantz;Svenja Leifert;Christoph Granacher;Stefan Koch;Simon Butscher;Patrick Jungk;Daniel A. Keim; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Integrative visual analytics for suspicious behavior detection; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In the VAST Challenge 2009 suspicious behavior had to be detected applying visual analytics to heterogeneous data, such as network traffic, social network enriched with geo-spatial attributes, and finally video surveillance data. This paper describes some of the awarded parts from our solution entry."}, {"color": "gray", "id": 544, "label": 544, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 544 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2009.5334460\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jaegul Choo;Emily Fujimoto;Hanseung Lee;Pedro R. Walteros; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Timeline analysis of undercover activities VAST 2009 traffic mini challenge award: Good analytical technique; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Our visualization tool for the VAST 2009 traffic mini challenge, Timeliner, visualizes badge and network traffic data together in a single timeline. The two views of per-employee and per-day with various filtering interactions enable users to analyze easily employees activities at a particular moment of interest as well as their general daily patterns. Using Timeliner, we present several hypotheses for the task at hand and their validation processes, which reveals various aspects of the data."}, {"color": "gray", "id": 546, "label": 546, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 546 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2009.5334463\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Claudia Muller-Birn;Lukas Birn; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Combining iterative analytical reasoning and software development using the visualization language Processing; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Processing is a very powerful visualization language which combines software concepts with principles of visual form and interaction. Artists, designers and architects use it but it is also a very effective programming language in the area of visual analytics. In the following contribution Processing is utilized in order to visually analyze data provided by IEEE VAST 2009 Mini Challenge Badge and Network Traffic. The applied process is iterative and each stage of the analytical reasoning process is accompanied by customized software development. The visual model, the process and the technical solution will be briefly introduced."}, {"color": "gray", "id": 547, "label": 547, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 547 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2010.179\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Edward Segel;Jeffrey Heer; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Narrative Visualization: Telling Stories with Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Data visualization is regularly promoted for its ability to reveal stories within data, yet these \u201cdata stories\u201d differ in important ways from traditional forms of storytelling. Storytellers, especially online journalists, have increasingly been integrating visualizations into their narratives, in some cases allowing the visualization to function in place of a written story. In this paper, we systematically review the design space of this emerging class of visualizations. Drawing on case studies from news media to visualization research, we identify distinct genres of narrative visualization. We characterize these design differences, together with interactivity and messaging, in terms of the balance between the narrative flow intended by the author (imposed by graphical elements and the interface) and story discovery on the part of the reader (often through interactive exploration). Our framework suggests design strategies for narrative visualization, including promising under-explored approaches to journalistic storytelling and educational media."}, {"color": "gray", "id": 549, "label": 549, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 549 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2010.194\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Bongshin Lee;Nathalie Henry Riche;Amy K. Karlson;Sheelash Carpendale; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: SparkClouds: Visualizing Trends in Tag Clouds; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Tag clouds have proliferated over the web over the last decade. They provide a visual summary of a collection of texts by visually depicting the tag frequency by font size. In use, tag clouds can evolve as the associated data source changes over time. Interesting discussions around tag clouds often include a series of tag clouds and consider how they evolve over time. However, since tag clouds do not explicitly represent trends or support comparisons, the cognitive demands placed on the person for perceiving trends in multiple tag clouds are high. In this paper, we introduce SparkClouds, which integrate sparklines into a tag cloud to convey trends between multiple tag clouds. We present results from a controlled study that compares SparkClouds with two traditional trend visualizations-multiple line graphs and stacked bar charts-as well as Parallel Tag Clouds. Results show that SparkClouds\u0027 ability to show trends compares favourably to the alternative visualizations."}, {"color": "gray", "id": 552, "label": 552, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 552 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2010.162\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Waqas Javed;Bryan McDonnel;Niklas Elmqvist; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Graphical Perception of Multiple Time Series; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Line graphs have been the visualization of choice for temporal data ever since the days of William Playfair (1759-1823), but realistic temporal analysis tasks often include multiple simultaneous time series. In this work, we explore user performance for comparison, slope, and discrimination tasks for different line graph techniques involving multiple time series. Our results show that techniques that create separate charts for each time series--such as small multiples and horizon graphs--are generally more efficient for comparisons across time series with a large visual span. On the other hand, shared-space techniques--like standard line graphs--are typically more efficient for comparisons over smaller visual spans where the impact of overlap and clutter is reduced."}, {"color": "gray", "id": 555, "label": 555, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 555 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2010.154\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Nan Cao;Jimeng Sun;Yu-Ru Lin;David Gotz;Shixia Liu;Huamin Qu; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: FacetAtlas: Multifaceted Visualization for Rich Text Corpora; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Documents in rich text corpora usually contain multiple facets of information. For example, an article about a specific disease often consists of different facets such as symptom, treatment, cause, diagnosis, prognosis, and prevention. Thus, documents may have different relations based on different facets. Powerful search tools have been developed to help users locate lists of individual documents that are most related to specific keywords. However, there is a lack of effective analysis tools that reveal the multifaceted relations of documents within or cross the document clusters. In this paper, we present FacetAtlas, a multifaceted visualization technique for visually analyzing rich text corpora. FacetAtlas combines search technology with advanced visual analytical tools to convey both global and local patterns simultaneously. We describe several unique aspects of FacetAtlas, including (1) node cliques and multifaceted edges, (2) an optimized density map, and (3) automated opacity pattern enhancement for highlighting visual patterns, (4) interactive context switch between facets. In addition, we demonstrate the power of FacetAtlas through a case study that targets patient education in the health care domain. Our evaluation shows the benefits of this work, especially in support of complex multifaceted data analysis."}, {"color": "gray", "id": 557, "label": 557, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 557 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2010.184\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Aritra Dasgupta;Robert Kosara; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Pargnostics: Screen-Space Metrics for Parallel Coordinates; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Interactive visualization requires the translation of data into a screen space of limited resolution. While currently ignored by most visualization models, this translation entails a loss of information and the introduction of a number of artifacts that can be useful, (e.g., aggregation, structures) or distracting (e.g., over-plotting, clutter) for the analysis. This phenomenon is observed in parallel coordinates, where overlapping lines between adjacent axes form distinct patterns, representing the relation between variables they connect. However, even for a small number of dimensions, the challenge is to effectively convey the relationships for all combinations of dimensions. The size of the dataset and a large number of dimensions only add to the complexity of this problem. To address these issues, we propose Pargnostics, parallel coordinates diagnostics, a model based on screen-space metrics that quantify the different visual structures. Pargnostics metrics are calculated for pairs of axes and take into account the resolution of the display as well as potential axis inversions. Metrics include the number of line crossings, crossing angles, convergence, overplotting, etc. To construct a visualization view, the user can pick from a ranked display showing pairs of coordinate axes and the structures between them, or examine all possible combinations of axes at once in a matrix display. Picking the best axes layout is an NP-complete problem in general, but we provide a way of automatically optimizing the display according to the user\u0027s preferences based on our metrics and model."}, {"color": "gray", "id": 559, "label": 559, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 559 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2010.205\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Christophe Viau;Michael J. McGuffin;Yves Chiricota;Igor Jurisica; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: The FlowVizMenu and Parallel Scatterplot Matrix: Hybrid Multidimensional Visualizations for Network Exploration; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: A standard approach for visualizing multivariate networks is to use one or more multidimensional views (for example, scatterplots) for selecting nodes by various metrics, possibly coordinated with a node-link view of the network. In this paper, we present three novel approaches for achieving a tighter integration of these views through hybrid techniques for multidimensional visualization, graph selection and layout. First, we present the FlowVizMenu, a radial menu containing a scatterplot that can be popped up transiently and manipulated with rapid, fluid gestures to select and modify the axes of its scatterplot. Second, the FlowVizMenu can be used to steer an attribute-driven layout of the network, causing certain nodes of a node-link diagram to move toward their corresponding positions in a scatterplot while others can be positioned manually or by force-directed layout. Third, we describe a novel hybrid approach that combines a scatterplot matrix (SPLOM) and parallel coordinates called the Parallel Scatterplot Matrix (P-SPLOM), which can be used to visualize and select features within the network. We also describe a novel arrangement of scatterplots called the Scatterplot Staircase (SPLOS) that requires less space than a traditional scatterplot matrix. Initial user feedback is reported."}, {"color": "gray", "id": 560, "label": 560, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 560 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2010.144\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jeffrey Heer;Michael Bostock; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Declarative Language Design for Interactive Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We investigate the design of declarative, domain-specific languages for constructing interactive visualizations. By separating specification from execution, declarative languages can simplify development, enable unobtrusive optimization, and support retargeting across platforms. We describe the design of the Protovis specification language and its implementation within an object-oriented, statically-typed programming language (Java). We demonstrate how to support rich visualizations without requiring a toolkit-specific data model and extend Protovis to enable declarative specification of animated transitions. To support cross-platform deployment, we introduce rendering and event-handling infrastructures decoupled from the runtime platform, letting designers retarget visualization specifications (e.g., from desktop to mobile phone) with reduced effort. We also explore optimizations such as runtime compilation of visualization specifications, parallelized execution, and hardware-accelerated rendering. We present benchmark studies measuring the performance gains provided by these optimizations and compare performance to existing Java-based visualization tools, demonstrating scalability improvements exceeding an order of magnitude."}, {"color": "gray", "id": 562, "label": 562, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 562 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2010.159\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Anastasia Bezerianos;Pierre Dragicevic;Jean-Daniel Fekete;Juhee Bae;Ben Watson; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: GeneaQuilts: A System for Exploring Large Genealogies; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: GeneaQuilts is a new visualization technique for representing large genealogies of up to several thousand individuals. The visualization takes the form of a diagonally-filled matrix, where rows are individuals and columns are nuclear families. After identifying the major tasks performed in genealogical research and the limits of current software, we present an interactive genealogy exploration system based on GeneaQuilts. The system includes an overview, a timeline, search and filtering components, and a new interaction technique called Bring \u0026amp; Slide that allows fluid navigation in very large genealogies. We report on preliminary feedback from domain experts and show how our system supports a number of their tasks."}, {"color": "gray", "id": 565, "label": 565, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 565 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2010.176\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: David Feng;Lester Kwock;Yueh Lee;Russell Taylor; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Matching Visual Saliency to Confidence in Plots of Uncertain Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Conveying data uncertainty in visualizations is crucial for preventing viewers from drawing conclusions based on untrustworthy data points. This paper proposes a methodology for efficiently generating density plots of uncertain multivariate data sets that draws viewers to preattentively identify values of high certainty while not calling attention to uncertain values. We demonstrate how to augment scatter plots and parallel coordinates plots to incorporate statistically modeled uncertainty and show how to integrate them with existing multivariate analysis techniques, including outlier detection and interactive brushing. Computing high quality density plots can be expensive for large data sets, so we also describe a probabilistic plotting technique that summarizes the data without requiring explicit density plot computation. These techniques have been useful for identifying brain tumors in multivariate magnetic resonance spectroscopy data and we describe how to extend them to visualize ensemble data sets."}, {"color": "gray", "id": 567, "label": 567, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 567 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2010.193\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Robert Kincaid; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: SignalLens: Focus+Context Applied to Electronic Time Series; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Electronic test and measurement systems are becoming increasingly sophisticated in order to match the increased complexity and ultra-high speed of the devices under test. A key feature in many such instruments is a vastly increased capacity for storage of digital signals. Storage of 109 time points or more is now possible. At the same time, the typical screens on such measurement devices are relatively small. Therefore, these instruments can only render an extremely small fraction of the complete signal at any time. SignalLens uses a Focus+Context approach to provide a means of navigating to and inspecting low-level signal details in the context of the entire signal trace. This approach provides a compact visualization suitable for embedding into the small displays typically provided by electronic measurement instruments. We further augment this display with computed tracks which display time-aligned computed properties of the signal. By combining and filtering these computed tracks it is possible to easily and quickly find computationally detected features in the data which are often obscured by the visual compression required to render the large data sets on a small screen. Further, these tracks can be viewed in the context of the entire signal trace as well as visible high-level signal features. Several examples using real-world electronic measurement data are presented, which demonstrate typical use cases and the effectiveness of the design."}, {"color": "gray", "id": 573, "label": 573, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 573 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2010.216\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Tuan Pham;Rob Hess;Crystal Ju;Eugene Zhang;Ronald Metoyer; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visualization of Diversity in Large Multivariate Data Sets; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Understanding the diversity of a set of multivariate objects is an important problem in many domains, including ecology, college admissions, investing, machine learning, and others. However, to date, very little work has been done to help users achieve this kind of understanding. Visual representation is especially appealing for this task because it offers the potential to allow users to efficiently observe the objects of interest in a direct and holistic way. Thus, in this paper, we attempt to formalize the problem of visualizing the diversity of a large (more than 1000 objects), multivariate (more than 5 attributes) data set as one worth deeper investigation by the information visualization community. In doing so, we contribute a precise definition of diversity, a set of requirements for diversity visualizations based on this definition, and a formal user study design intended to evaluate the capacity of a visual representation for communicating diversity information. Our primary contribution, however, is a visual representation, called the Diversity Map, for visualizing diversity. An evaluation of the Diversity Map using our study design shows that users can judge elements of diversity consistently and as or more accurately than when using the only other representation specifically designed to visualize diversity."}, {"color": "gray", "id": 574, "label": 574, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 574 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2010.163\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Trevor O\u0027Brien;Anna Ritz;Benjamin Raphael;David Laidlaw; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Gremlin: An Interactive Visualization Model for Analyzing Genomic Rearrangements; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In this work we present, apply, and evaluate a novel, interactive visualization model for comparative analysis of structural variants and rearrangements in human and cancer genomes, with emphasis on data integration and uncertainty visualization. To support both global trend analysis and local feature detection, this model enables explorations continuously scaled from the high-level, complete genome perspective, down to the low-level, structural rearrangement view, while preserving global context at all times. We have implemented these techniques in Gremlin, a genomic rearrangement explorer with multi-scale, linked interactions, which we apply to four human cancer genome data sets for evaluation. Using an insight-based evaluation methodology, we compare Gremlin to Circos, the state-of-the-art in genomic rearrangement visualization, through a small user study with computational biologists working in rearrangement analysis. Results from user study evaluations demonstrate that this visualization model enables more total insights, more insights per minute, and more complex insights than the current state-of-the-art for visual analysis and exploration of genome rearrangements."}, {"color": "gray", "id": 580, "label": 580, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 580 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2010.217\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Stefan Janicke;Christian Heine;Marc Hellmuth;Peter F. Stadler;Gerik Scheuermann; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visualization of Graph Products; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Graphs are a versatile structure and abstraction for binary relationships between objects. To gain insight into such relationships, their corresponding graph can be visualized. In the past, many classes of graphs have been defined, e.g. trees, planar graphs, directed acyclic graphs, and visualization algorithms were proposed for these classes. Although many graphs may only be classified as \"general\" graphs, they can contain substructures that belong to a certain class. Archambault proposed the TopoLayout framework: rather than draw any arbitrary graph using one method, split the graph into components that are homogeneous with respect to one graph class and then draw each component with an algorithm best suited for this class. Graph products constitute a class that arises frequently in graph theory, but for which no visualization algorithm has been proposed until now. In this paper, we present an algorithm for drawing graph products and the aesthetic criterion graph product\u0027s drawings are subject to. We show that the popular High-Dimensional Embedder approach applied to cartesian products already respects this aestetic criterion, but has disadvantages. We also present how our method is integrated as a new component into the TopoLayout framework. Our implementation is used for further research of graph products in a biological context."}, {"color": "gray", "id": 581, "label": 581, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 581 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2010.180\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: authro Speckmann;Kevin Verbeek; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Necklace Maps; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Statistical data associated with geographic regions is nowadays globally available in large amounts and hence automated methods to visually display these data are in high demand. There are several well-established thematic map types for quantitative data on the ratio-scale associated with regions: choropleth maps, cartograms, and proportional symbol maps. However, all these maps suffer from limitations, especially if large data values are associated with small regions. To overcome these limitations, we propose a novel type of quantitative thematic map, the necklace map. In a necklace map, the regions of the underlying two-dimensional map are projected onto intervals on a one-dimensional curve (the necklace) that surrounds the map regions. Symbols are scaled such that their area corresponds to the data of their region and placed without overlap inside the corresponding interval on the necklace. Necklace maps appear clear and uncluttered and allow for comparatively large symbol sizes. They visualize data sets well which are not proportional to region sizes. The linear ordering of the symbols along the necklace facilitates an easy comparison of symbol sizes. One map can contain several nested or disjoint necklaces to visualize clustered data. The advantages of necklace maps come at a price: the association between a symbol and its region is weaker than with other types of maps. Interactivity can help to strengthen this association if necessary. We present an automated approach to generate necklace maps which allows the user to interactively control the final symbol placement. We validate our approach with experiments using various data sets and maps."}, {"color": "gray", "id": 582, "label": 582, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 582 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2010.5649831\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Justin Talbot;Pat Hanrahan; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Adapting Daniel and Wood\u0027s modeling approach to interactive visual analytics; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: This poster describes our progress in developing an interactive linear modeling system that supports the modeling approach described by Daniel and Wood. Our visual interface permits analysts to build sets of possible models and then creates appropriate visualizations to permit human-in-the-loop model comparison and selection."}, {"color": "gray", "id": 583, "label": 583, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 583 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2010.5649905\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Minoo Erfani Joorabchi;Ji-Dong Yim;Mona Erfani Joorabchi;Christopher D. Shaw; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Enron case study: Analysis of email behavior using EmailTime; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: This paper presents a case study with Enron email dataset to explore the behaviors of email users within different organizational positions. We defined email behavior as the email activity level of people regarding a series of measured metrics e.g. sent and received emails, numbers of email addresses, etc. These metrics were calculated through EmailTime, a visual analysis tool of email correspondence over the course of time. Results showed specific patterns in the email datasets of different organizational positions."}, {"color": "gray", "id": 587, "label": 587, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 587 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2010.5650251\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Maryam Nafari;Chris Weaver; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Poster: Translating cross-filtered queries into questions; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Complex combinations of coordinated multiple views are increasingly used to design tools for highly interactive visual exploration and analysis of multidimensional data. While complex coordination patterns provide substantial utility through expressive querying, they also exhibit usability problems for users when learning required interaction sequences, recalling past queries, and interpreting visual states. As visual analysis tools grow more sophisticated, there is a growing need to make them more understandable as well. Our long-term goal is to exploit natural language familiarity and literacy to directly facilitate individual and collaborative use of visual analysis tools. In this poster, we present work in progress on an automatically generated query-to-question user interface to translate interactive states during visual analysis into an accompanying visual log of formatted text. Our effort currently focuses on a symmetric and thus relatively simple coordination pattern: cross-filtered views. We describe our current thinking about query-to-question translation in a typical cross-filtered visualization of movies, people, and genres in the Internet Movie Database."}, {"color": "gray", "id": 588, "label": 588, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 588 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2010.5650766\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: M. C. Hao;M. Marwah;H. Janetzko;D. A. Keim;U. Dayal;R. Sharma;D. Patnaik;N. Ramakrishnan; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visual analysis of frequent patterns in large time series; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The detection of previously unknown, frequently occurring patterns in time series, often called motifs, has been recognized as an important task. To find these motifs, we use an advanced temporal data mining algorithm. Since our algorithm usually finds hundreds of motifs, we need to analyze and access the discovered motifs. For this purpose, we introduce three novel visual analytics methods: (1) motif layout, using colored rectangles for visualizing the occurrences and hierarchical relationships of motifs in a multivariate time series, (2) motif distortion, for enlarging or shrinking motifs as appropriate for easy analysis and (3) motif merging, to combine a number of identical adjacent motif instances without cluttering the display. We have applied and evaluated our methods using two real-world data sets: data center cooling and oil well production."}, {"color": "gray", "id": 591, "label": 591, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 591 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2010.5651192\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: J. Alex Godwin;Ryan M. Kilgore; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Conveying network features in geospatial battlespace displays; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Advanced battlespace network visualization techniques are required within the modern Air Operations Center (AOC) to improve cross-domain situation awareness and to support planning and decision-making. We present a visualization toolkit to address this need that supports the integration of network health and status information and meta-information with other traditional AOC information resources and activities across air, space, and cyber domains. Applications include the development of battlespace visualization technologies that will improve warfighters\u0027 decision-making response time and provide enhanced flexibility for mission planning by efficiently revealing affordances for leveraging, disrupting, or enhancing network connectivity."}, {"color": "gray", "id": 592, "label": 592, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 592 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2010.5651617\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Stephanie Dudzic;J. Alex Godwin;Ryan M. Kilgore; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visualization of temporal relationships within coordinated views; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In command and control (C2) environments, decision makers must rapidly understand and address key temporal relationships that exist between critical tasks as conditions fluctuate. However, traditional temporal displays, such as mission timelines, fail to support user understanding of and reasoning about critical relationships. We have developed visualization methods to compactly and effectively convey key temporal constraints. In this paper, we present examples of our visualization approach and describe how we are exploring interaction methods within an integrated visualization workspace to support user awareness of temporal constraints."}, {"color": "gray", "id": 593, "label": 593, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 593 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2010.5651676\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: J\u00fcrgen Bernard;Tatiana von Landesberger;Sebastian Bremm;Tobias Schreck; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Cluster correspondence views for enhanced analysis of SOM displays; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The Self-Organizing Map (SOM) algorithm is a popular and widely used cluster algorithm. Its constraint to organize clusters on a grid structure makes it very amenable to visualization. On the other hand, the grid constraint may lead to reduced cluster accuracy and reliability, compared to other clustering methods not implementing this restriction. We propose a visual cluster analysis system that allows to validate the output of the SOM algorithm by comparison with alternative clustering methods. Specifically, visual mappings overlaying alternative clustering results onto the SOM are proposed. We apply our system on an example data set, and outline main analytical use cases."}, {"color": "gray", "id": 594, "label": 594, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 594 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2010.5651694\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Wolfgang Berger;Harald Piringer; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Interactive visual analysis of multiobjective optimizations; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Optimization problems are typically addressed by purely automatic approaches. For multi-objective problems, however, a single best solution often does not exist. In this case, it is necessary to analyze trade-offs between many conflicting goals within a given application context. This poster describes an approach that tightly integrates automatic algorithms for multi-objective optimization and interactive multivariate visualizations. Ad-hoc selections support a flexible definition of input data for subsequent algorithms. These algorithms in turn represent their result as derived data attributes that can be assigned to visualizations or be used as a basis for further selections (e.g., to constrain the result set). This enables a guided search that still involves the knowledge of domain experts. We describe our approach in the context of multi-run simulation data from the application domain of car engine design."}, {"color": "gray", "id": 595, "label": 595, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 595 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2010.5652392\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Stephen Ingram;Tamara Munzner;Veronika Irvine;Melanie Tory;Steven Bergner;Torsten M\u00f6ller; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: DimStiller: Workflows for dimensional analysis and reduction; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: DimStiller is a system for dimensionality reduction and analysis. It frames the task of understanding and transforming input dimensions as a series of analysis steps where users transform data tables by chaining together different techniques, called operators, into pipelines of expressions. The individual operators have controls and views that are linked together based on the structure of the expression. Users interact with the operator controls to tune parameter choices, with immediate visual feedback guiding the exploration of local neighborhoods of the space of possible data tables. DimStiller also provides global guidance for navigating data-table space through expression templates called workflows, which permit re-use of common patterns of analysis."}, {"color": "gray", "id": 597, "label": 597, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 597 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2010.5652433\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Georgia Albuquerque;Martin Eisemann;Dirk J. Lehmann;Holger Theisel;Marcus Magnor; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Improving the visual analysis of high-dimensional datasets using quality measures; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Modern visualization methods are needed to cope with very high-dimensional data. Efficient visual analytical techniques are required to extract the information content in these data. The large number of possible projections for each method, which usually grow quadrat-ically or even exponentially with the number of dimensions, urges the necessity to employ automatic reduction techniques, automatic sorting or selecting the projections, based on their information-bearing content. Different quality measures have been successfully applied for several specified user tasks and established visualization techniques, like Scatterplots, Scatterplot Matrices or Parallel Coordinates. Many other popular visualization techniques exist, but due to the structural differences, the measures are not directly applicable to them and new approaches are needed. In this paper we propose new quality measures for three popular visualization methods: Radviz, Pixel-Oriented Displays and Table Lenses. Our experiments show that these measures efficiently guide the visual analysis task."}, {"color": "gray", "id": 598, "label": 598, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 598 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2010.5652443\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jaegul Choo;Hanseung Lee;Jaeyeon Kihm;Haesun Park; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: iVisClassifier: An interactive visual analytics system for classification based on supervised dimension reduction; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present an interactive visual analytics system for classification, iVisClassifier, based on a supervised dimension reduction method, linear discriminant analysis (LDA). Given high-dimensional data and associated cluster labels, LDA gives their reduced dimensional representation, which provides a good overview about the cluster structure. Instead of a single two- or three-dimensional scatter plot, iVisClassifier fully interacts with all the reduced dimensions obtained by LDA through parallel coordinates and a scatter plot. Furthermore, it significantly improves the interactivity and interpretability of LDA. LDA enables users to understand each of the reduced dimensions and how they influence the data by reconstructing the basis vector into the original data domain. By using heat maps, iVisClassifier gives an overview about the cluster relationship in terms of pairwise distances between cluster centroids both in the original space and in the reduced dimensional space. Equipped with these functionalities, iVisClassifier supports users\u0027 classification tasks in an efficient way. Using several facial image data, we show how the above analysis is performed."}, {"color": "gray", "id": 600, "label": 600, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 600 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2010.5652460\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Yu-Hsuan Chan;Carlos D. Correa;Kwan-Liu Ma; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Flow-based scatterplots for sensitivity analysis; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Visualization of multi-dimensional data is challenging due to the number of complex correlations that may be present in the data but that are difficult to be visually identified. One of the main causes for this problem is the inherent loss of information that occurs when high-dimensional data is projected into 2D or 3D. Although 2D scatterplots are ubiquitous due to their simplicity and familiarity, there are not a lot of variations on their basic metaphor. In this paper, we present a new way of visualizing multidimensional data using scatterplots. We extend 2D scatterplots using sensitivity coefficients to highlight local variation of one variable with respect to another. When applied to a scatterplot, these sensitivities can be understood as velocities, and the resulting visualization resembles a flow field. We also present a number of operations, based on flow-field analysis, that help users navigate, select and cluster points in an efficient manner. We show the flexibility and generality of this approach using a number of multidimensional data sets across different domains."}, {"color": "gray", "id": 601, "label": 601, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 601 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2010.5652467\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Zicheng Liao;Yizhou Yu;Baoquan Chen; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Anomaly detection in GPS data based on visual analytics; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Modern machine learning techniques provide robust approaches for data-driven modeling and critical information extraction, while human experts hold the advantage of possessing high-level intelligence and domain-specific expertise. We combine the power of the two for anomaly detection in GPS data by integrating them through a visualization and human-computer interaction interface. In this paper we introduce GPSvas (GPS Visual Analytics System), a system that detects anomalies in GPS data using the approach of visual analytics: a conditional random field (CRF) model is used as the machine learning component for anomaly detection in streaming GPS traces. A visualization component and an interactive user interface are built to visualize the data stream, display significant analysis results (i.e., anomalies or uncertain predications) and hidden information extracted by the anomaly detection model, which enable human experts to observe the real-time data behavior and gain insights into the data flow. Human experts further provide guidance to the machine learning model through the interaction tools; the learning model is then incrementally improved through an active learning procedure."}, {"color": "gray", "id": 602, "label": 602, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 602 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2010.5652478\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Gennady Andrienko;Natalia Andrienko;Martin Mladenov;Michael Mock;Christian P\u00f6litz; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Discovering bits of place histories from people\u0027s activity traces; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Events that happened in the past are important for understanding the ongoing processes, predicting future developments, and making informed decisions. Significant and/or interesting events tend to attract many people. Some people leave traces of their attendance in the form of computer-processable data, such as records in the databases of mobile phone operators or photos on photo sharing web sites. We developed a suite of visual analytics methods for reconstructing past events from these activity traces. Our tools combine geocomputations, interactive geovisualizations and statistical methods to enable integrated analysis of the spatial, temporal, and thematic components of the data, including numeric attributes and texts. We demonstrate the utility of our approach on two large real data sets, mobile phone calls in Milano during 9 days and flickr photos made on British Isles during 5 years."}, {"color": "gray", "id": 604, "label": 604, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 604 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2010.5652520\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Chris Weaver; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Multidimensional data dissection using attribute relationship graphs; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Visual exploration and analysis is a process of discovering and dissecting the abundant and complex attribute relationships that pervade multidimensional data. Recent research has identified and characterized patterns of multiple coordinated views, such as cross-filtered views, in which rapid sequences of simple interactions can be used to express queries on subsets of attribute values. In visualizations designed around these patterns, for the most part, distinct views serve to visually isolate each attribute from the others. Although the brush-and-click simplicity of visual isolation facilitates discovery of many-to-many relationships between attributes, dissecting these relationships into more fine-grained one-to-many relationships is interactively tedious and, worse, visually fragmented over prolonged sequences of queries. This paper describes: (1) a method for interactively dissecting multidimensional data by iteratively slicing and manipulating a multigraph representation of data values and value co-occurrences; and (2) design strategies for extending the construction of coordinated multiple view interfaces for dissection as well as discovery of attribute relationships in multidimensional data sets. Using examples from different domains, we describe how attribute relationship graphs can be combined with cross-filtered views, modularized for reuse across designs, and integrated into broader visual analysis tools. The exploratory and analytic utility of these examples suggests that an attribute relationship graph would be a useful addition to a wide variety of visual analysis tools."}, {"color": "gray", "id": 605, "label": 605, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 605 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2010.5652530\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Hartmut Ziegler;Marco Jenny;Tino Gruse;Daniel A. Keim; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visual market sector analysis for financial time series data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The massive amount of financial time series data that originates from the stock market generates large amounts of complex data of high interest. However, adequate solutions that can effectively handle the information in order to gain insight and to understand the market mechanisms are rare. In this paper, we present two techniques and applications that enable the user to interactively analyze large amounts of time series data in real-time in order to get insight into the development of assets, market sectors, countries, and the financial market as a whole. The first technique allows users to quickly analyze combinations of single assets, market sectors as well as countries, compare them to each other, and to visually discover the periods of time where market sectors and countries get into turbulence. The second application clusters a selection of large amounts of financial time series data according to their similarity, and analyzes the distribution of the assets among market sectors. This allows users to identify the characteristic graphs which are representative for the development of a particular market sector, and also to identify the assets which behave considerably differently compared to other assets in the same sector. Both applications allow the user to perform investigative exploration techniques and interactive visual analysis in real-time."}, {"color": "gray", "id": 606, "label": 606, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 606 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2010.5652532\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Shantanu H. Joshi;Ian Bowman;John Darrell Van Horn; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Large-scale neuroanatomical visualization using a manifold embedding approach; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present a unified framework for data processing, mining and interactive visualization of large-scale neuroanatomical databases. The input data is assumed to lie in a specific atlas space, or simply exist as a separate collection. Users can specify their own atlas for comparative analyses. The original data exist as MRI images in standard formats. It is uploaded to a remote server and processed offline by a parallelized pipeline workflow. This workflow transforms the data to represent it as both volumetric and triangular mesh cortical surfaces. We use multiresolution representations to scale complexity to data storage availability as well as graphical processing performance. Our workflow implements predefined metrics for clustering and classification, and data projection schemes to aid in visualization. Additionally the system provides a visual query interface for performing selection requests based on user-defined search criteria."}, {"color": "gray", "id": 609, "label": 609, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 609 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2010.5652885\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Yang Chen;Scott Barlowe;Jing Yang; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Click2Annotate: Automated Insight Externalization with rich semantics; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Insight Externalization (IE) refers to the process of capturing and recording the semantics of insights in decision making and problem solving. To reduce human effort, Automated Insight Externalization (AIE) is desired. Most existing IE approaches achieve automation by capturing events (e.g., clicks and key presses) or actions (e.g., panning and zooming). In this paper, we propose a novel AIE approach named Click2Annotate. It allows semi-automatic insight annotation that captures low-level analytics task results (e.g., clusters and outliers), which have higher semantic richness and abstraction levels than actions and events. Click2Annotate has two significant benefits. First, it reduces human effort required in IE and generates annotations easy to understand. Second, the rich semantic information encoded in the annotations enables various insight management activities, such as insight browsing and insight retrieval. We present a formal user study that proved this first benefit. We also illustrate the second benefit by presenting the novel insight management activities we developed based on Click2Annotate, namely scented insight browsing and faceted insight search."}, {"color": "gray", "id": 610, "label": 610, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 610 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2010.5652890\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jing Jin;Pedro Szekely; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Interactive querying of temporal data using a comic strip metaphor; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Finding patterns in temporal data is an important data analysis task in many domains. Static visualizations can help users easily see certain instances of patterns, but are not specially designed to support systematic analysis tasks, such as finding all instances of a pattern automatically. VizPattern is an interactive visual query environment that uses a comic strip metaphor to enable users to easily and quickly define and locate complex temporal patterns. Evaluations provide evidence that VizPattern is applicable in many domains, and that it enables a wide variety of users to answer questions about temporal data faster and with fewer errors than existing state-of-the-art visual analysis systems."}, {"color": "gray", "id": 613, "label": 613, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 613 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2010.5652910\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Zhicheng Liu;Bongshin Lee;Srikanth Kandula;Ratul Mahajan; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: NetClinic: Interactive visualization to enhance automated fault diagnosis in enterprise networks; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Diagnosing faults in an operational computer network is a frustrating, time-consuming exercise. Despite advances, automatic diagnostic tools are far from perfect: they occasionally miss the true culprit and are mostly only good at narrowing down the search to a few potential culprits. This uncertainty and the inability to extract useful sense from tool output renders most tools not usable to administrators. To bridge this gap, we present NetClinic, a visual analytics system that couples interactive visualization with an automated diagnostic tool for enterprise networks. It enables administrators to verify the output of the automatic analysis at different levels of detail and to move seamlessly across levels while retaining appropriate context. A qualitative user study shows that NetClinic users can accurately identify the culprit, even when it is not present in the suggestions made by the automated component. We also find that supporting a variety of sensemaking strategies is a key to the success of systems that enhance automated diagnosis."}, {"color": "gray", "id": 614, "label": 614, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 614 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2010.5652922\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Nicholas Diakopoulos;Mor Naaman;Funda Kivran-Swaine; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Diamonds in the rough: Social media visual analytics for journalistic inquiry; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Journalists increasingly turn to social media sources such as Facebook or Twitter to support their coverage of various news events. For large-scale events such as televised debates and speeches, the amount of content on social media can easily become overwhelming, yet still contain information that may aid and augment reporting via individual content items as well as via aggregate information from the crowd\u0027s response. In this work we present a visual analytic tool, Vox Civitas, designed to help journalists and media professionals extract news value from large-scale aggregations of social media content around broadcast events. We discuss the design of the tool, present the text analysis techniques used to enable the presentation, and provide details on the visual and interaction design. We provide an exploratory evaluation based on a user study in which journalists interacted with the system to explore and report on a dataset of over one hundred thousand twitter messages collected during the U.S. State of the Union presidential address in 2010."}, {"color": "gray", "id": 616, "label": 616, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 616 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2010.5652931\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Lei Shi;Furu Wei;Shixia Liu;Li Tan;Xiaoxiao Lian;Michelle X. Zhou; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Understanding text corpora with multiple facets; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Text visualization becomes an increasingly more important research topic as the need to understand massive-scale textual information is proven to be imperative for many people and businesses. However, it is still very challenging to design effective visual metaphors to represent large corpora of text due to the unstructured and high-dimensional nature of text. In this paper, we propose a data model that can be used to represent most of the text corpora. Such a data model contains four basic types of facets: time, category, content (unstructured), and structured facet. To understand the corpus with such a data model, we develop a hybrid visualization by combining the trend graph with tag-clouds. We encode the four types of data facets with four separate visual dimensions. To help people discover evolutionary and correlation patterns, we also develop several visual interaction methods that allow people to interactively analyze text by one or more facets. Finally, we present two case studies to demonstrate the effectiveness of our solution in support of multi-faceted visual analysis of text corpora."}, {"color": "gray", "id": 617, "label": 617, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 617 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2010.5652932\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Haeyong Chung;Seungwon Yang;Naveed Massjouni;Christopher Andrews;Rahul Kanna;Chris North; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: VizCept: Supporting synchronous collaboration for constructing visualizations in intelligence analysis; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In this paper, we present a new web-based visual analytics system, VizCept, which is designed to support fluid, collaborative analysis of large textual intelligence datasets. The main approach of the design is to combine individual workspace and shared visualization in an integrated environment. Collaborating analysts will be able to identify concepts and relationships from the dataset based on keyword searches in their own workspace and collaborate visually with other analysts using visualization tools such as a concept map view and a timeline view. The system allows analysts to parallelize the work by dividing initial sets of concepts, investigating them on their own workspace, and then integrating individual findings automatically on shared visualizations with support for interaction and personal graph layout in real time, in order to develop a unified plot. We highlight several design considerations that promote communication and analytic performance in small team synchronous collaboration. We report the result of a pair of case study applications including collaboration and communication methods, analysis strategies, and user behaviors under a competition setting in the same location at the same time. The results of these demonstrate the tool\u0027s effectiveness for synchronous collaborative construction and use of visualizations in intelligence data analysis."}, {"color": "gray", "id": 619, "label": 619, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 619 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2010.5652951\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Orland Hoeber;Garnett Wilson;Simon Harding;Ren\u00e9 Enguehard;Rodolphe Devillers; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visually representing geo-temporal differences; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Data sets that contain geospatial and temporal elements can be challenging to analyze. In particular, it can be difficult to determine how the data have changed over spatial and temporal ranges. In this poster, we present a visual approach for representing the pair-wise differences between geographically and temporally binned data. In addition to providing a novel method for visualizing such geo-temporal differences, GTdiff provides a high degree of interactivity that supports the exploration and analysis of the data."}, {"color": "gray", "id": 620, "label": 620, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 620 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2010.5652958\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Dong Hyun Jeong;Evan Suma;Thomas Butkiewicz;William Ribarsky;Remco Chang; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: A continuous analysis process between desktop and collaborative visual analytics environments; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Since its inception, the field of visual analytics has undergone tremendous growth in understanding how to create interactive visual tools to solve analytical problems. However, with few exceptions, most of these tools have been designed for single users in desktop environments. While often effective on their own, most single-user systems do not reflect the collaborative nature of solving real-world analytical tasks. Many intelligence analysts, for example, have been observed to switch repeatedly between working alone and collaborating with members of a small team. In this paper, we propose that a complete visual analytical system designed for solving real-world tasks ought to have two integrated components: a single-user desktop system and a mirroring system suitable for a collaborative environment."}, {"color": "gray", "id": 621, "label": 621, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 621 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2010.5652968\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Minoo Erfani Joorabchi;Ji-Dong Yim;Christopher D. Shaw; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: EmailTime: Visual analytics of emails; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Although the discovery and analysis of communication patterns in large and complex email datasets are difficult tasks, they can be a valuable source of information. This paper presents EmailTime\u0027s capabilities through several examples. EmailTime is a visual analysis of email correspondence patterns over the course of time that interactively portrays personal and interpersonal networks using the correspondence in the email dataset. We suggest that integrating both statistics and visualizations in order to display information about the email datasets may simplify its evaluation."}, {"color": "gray", "id": 622, "label": 622, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 622 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2010.5653580\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Gennady Andrienko;Natalia Andrienko; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Poster: Dynamic time transformation for interpreting clusters of trajectories with space-time cube; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We propose a set of techniques that support visual interpretation of trajectory clusters by transforming absolute time references into relative positions within temporal cycles or with respect to the starting and/or ending times of the trajectories. We demonstrate the work of the approach on a real data set about individual movement over one year."}, {"color": "gray", "id": 624, "label": 624, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 624 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2010.5653598\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Heather Richter Lipford;Felesia Stukes;Wenwen Dou;Matthew E. Hawkins;Remco Chang; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Helping users recall their reasoning process; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The final product of an analyst\u0027s investigation using a visualization is often a report of the discovered knowledge, as well as the methods employed and reasoning behind the discovery. We believe that analysts may have difficulty keeping track of their knowledge discovery process and will require tools to assist in accurately recovering their reasoning. We first report on a study examining analysts\u0027 recall of their strategies and methods, demonstrating their lack of memory of the path of knowledge discovery. We then explore whether a tool visualizing the steps of the visual analysis can aid users in recalling their reasoning process. The results of our second study indicate that visualizations of interaction logs can serve as an effective memory aid, allowing analysts to recall additional details of their strategies and decisions."}, {"color": "gray", "id": 626, "label": 626, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 626 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2010.5653822\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Eric E. Monson;Guangliang Chen;Rachael Brady;Mauro Maggioni; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Data representation and exploration with Geometric Wavelets; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Geometric Wavelets is a new multi-scale data representation technique which is useful for a variety of applications such as data compression, interpretation and anomaly detection. We have developed an interactive visualization with multiple linked views to help users quickly explore data sets and understand this novel construction. Currently the interface is being used by applied mathematicians to view results and gain new insights, speeding methods development."}, {"color": "gray", "id": 628, "label": 628, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 628 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2010.5654451\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Marielle Mokhtari;Eric Boivin;Denis Laurendeau;Maxime Girardin; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visual tools for dynamic analysis of complex situations; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: This paper presents an interactive interface synchronized with a simulation framework for exploring complex scenarios. This interface exploits visual analysis for facilitating the understanding of complex situation by human users."}, {"color": "gray", "id": 631, "label": 631, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 631 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2011.166\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Zhao Geng;ZhenMin Peng;Robert S.Laramee;Jonathan C. Roberts;Rick Walker; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Angular Histograms: Frequency-Based Visualizations for Large, High Dimensional Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Parallel coordinates is a popular and well-known multivariate data visualization technique. However, one of their inherent limitations has to do with the rendering of very large data sets. This often causes an overplotting problem and the goal of the visual information seeking mantra is hampered because of a cluttered overview and non-interactive update rates. In this paper, we propose two novel solutions, namely, angular histograms and attribute curves. These techniques are frequency-based approaches to large, high-dimensional data visualization. They are able to convey both the density of underlying polylines and their slopes. Angular histogram and attribute curves offer an intuitive way for the user to explore the clustering, linear correlations and outliers in large data sets without the over-plotting and clutter problems associated with traditional parallel coordinates. We demonstrate the results on a wide variety of data sets including real-world, high-dimensional biological data. Finally, we compare our methods with the other popular frequency-based algorithms."}, {"color": "gray", "id": 632, "label": 632, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 632 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2011.167\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Justin Talbot;John Gerth;Pat Hanrahan; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Arc Length-Based Aspect Ratio Selection; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The aspect ratio of a plot has a dramatic impact on our ability to perceive trends and patterns in the data. Previous approaches for automatically selecting the aspect ratio have been based on adjusting the orientations or angles of the line segments in the plot. In contrast, we recommend a simple, effective method for selecting the aspect ratio: minimize the arc length of the data curve while keeping the area of the plot constant. The approach is parameterization invariant, robust to a wide range of inputs, preserves visual symmetries in the data, and is a compromise between previously proposed techniques. Further, we demonstrate that it can be effectively used to select the aspect ratio of contour plots. We believe arc length should become the default aspect ratio selection method."}, {"color": "gray", "id": 633, "label": 633, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 633 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2011.169\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Ulrik Brandes;Bobo Nick; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Asymmetric Relations in Longitudinal Social Networks; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In modeling and analysis of longitudinal social networks, visual exploration is used in particular to complement and inform other methods. The most common graphical representations for this purpose appear to be animations and small multiples of intermediate states, depending on the type of media available. We present an alternative approach based on matrix representation of gestaltlines (a combination of Tufte\u0027s sparklines with glyphs based on gestalt theory). As a result, we obtain static, compact, yet data-rich diagrams that support specifically the exploration of evolving dyadic relations and persistent group structure, although at the expense of cross-sectional network views and indirect linkages."}, {"color": "gray", "id": 635, "label": 635, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 635 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2011.175\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jessica Hullman;Eytan Adar;Priti Shah; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Benefitting InfoVis with Visual Difficulties; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Many well-cited theories for visualization design state that a visual representation should be optimized for quick and immediate interpretation by a user. Distracting elements like decorative \"chartjunk\" or extraneous information are avoided so as not to slow comprehension. Yet several recent studies in visualization research provide evidence that non-efficient visual elements may benefit comprehension and recall on the part of users. Similarly, findings from studies related to learning from visual displays in various subfields of psychology suggest that introducing cognitive difficulties to visualization interaction can improve a user\u0027s understanding of important information. In this paper, we synthesize empirical results from cross-disciplinary research on visual information representations, providing a counterpoint to efficiency-based design theory with guidelines that describe how visual difficulties can be introduced to benefit comprehension and recall. We identify conditions under which the application of visual difficulties is appropriate based on underlying factors in visualization interaction like active processing and engagement. We characterize effective graph design as a trade-off between efficiency and learning difficulties in order to provide Information Visualization (InfoVis) researchers and practitioners with a framework for organizing explorations of graphs for which comprehension and recall are crucial. We identify implications of this view for the design and evaluation of information visualizations."}, {"color": "gray", "id": 641, "label": 641, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 641 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2011.185\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Michael Bostock;Vadim Ogievetsky;Jeffrey Heer; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: D\u00b3 Data-Driven Documents; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Data-Driven Documents (D3) is a novel representation-transparent approach to visualization for the web. Rather than hide the underlying scenegraph within a toolkit-specific abstraction, D3 enables direct inspection and manipulation of a native representation: the standard document object model (DOM). With D3, designers selectively bind input data to arbitrary document elements, applying dynamic transforms to both generate and modify content. We show how representational transparency improves expressiveness and better integrates with developer tools than prior approaches, while offering comparable notational efficiency and retaining powerful declarative components. Immediate evaluation of operators further simplifies debugging and allows iterative development. Additionally, we demonstrate how D3 transforms naturally enable animation and interaction with dramatic performance improvements over intermediate representations."}, {"color": "gray", "id": 643, "label": 643, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 643 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2011.187\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Juhee Bae;Benjamin Watson; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Developing and Evaluating Quilts for the Depiction of Large Layered Graphs; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Traditional layered graph depictions such as flow charts are in wide use. Yet as graphs grow more complex, these depictions can become difficult to understand. Quilts are matrix-based depictions for layered graphs designed to address this problem. In this research, we first improve Quilts by developing three design alternatives, and then compare the best of these alternatives to better-known node-link and matrix depictions. A primary weakness in Quilts is their depiction of skip links, links that do not simply connect to a succeeding layer. Therefore in our first study, we compare Quilts using color-only, text-only, and mixed (color and text) skip link depictions, finding that path finding with the color-only depiction is significantly slower and less accurate, and that in certain cases, the mixed depiction offers an advantage over the text-only depiction. In our second study, we compare Quilts using the mixed depiction to node-link diagrams and centered matrices. Overall results show that users can find paths through graphs significantly faster with Quilts (46.6 secs) than with node-link (58.3 secs) or matrix (71.2 secs) diagrams. This speed advantage is still greater in large graphs (e.g. in 200 node graphs, 55.4 secs vs. 71.1 secs for node-link and 84.2 secs for matrix depictions)."}, {"color": "gray", "id": 645, "label": 645, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 645 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2011.190\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: David Selassie;Brandon Heller;Jeffrey Heer; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Divided Edge Bundling for Directional Network Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The node-link diagram is an intuitive and venerable way to depict a graph. To reduce clutter and improve the readability of node-link views, Holten \u0026amp;amp; van Wijk\u0027s force-directed edge bundling employs a physical simulation to spatially group graph edges. While both useful and aesthetic, this technique has shortcomings: it bundles spatially proximal edges regardless of direction, weight, or graph connectivity. As a result, high-level directional edge patterns are obscured. We present divided edge bundling to tackle these shortcomings. By modifying the forces in the physical simulation, directional lanes appear as an emergent property of edge direction. By considering graph topology, we only bundle edges related by graph structure. Finally, we aggregate edge weights in bundles to enable more accurate visualization of total bundle weights. We compare visualizations created using our technique to standard force-directed edge bundling, matrix diagrams, and clustered graphs; we find that divided edge bundling leads to visualizations that are easier to interpret and reveal both familiar and previously obscured patterns."}, {"color": "gray", "id": 650, "label": 650, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 650 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2011.196\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Johnny Rodgers;Lyn Bartram; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Exploring Ambient and Artistic Visualization for Residential Energy Use Feedback; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Providing effective feedback on resource consumption in the home is a key challenge of environmental conservation efforts. One promising approach for providing feedback about residential energy consumption is the use of ambient and artistic visualizations. Pervasive computing technologies enable the integration of such feedback into the home in the form of distributed point-of-consumption feedback devices to support decision-making in everyday activities. However, introducing these devices into the home requires sensitivity to the domestic context. In this paper we describe three abstract visualizations and suggest four design requirements that this type of device must meet to be effective: pragmatic, aesthetic, ambient, and ecological. We report on the findings from a mixed methods user study that explores the viability of using ambient and artistic feedback in the home based on these requirements. Our findings suggest that this approach is a viable way to provide resource use feedback and that both the aesthetics of the representation and the context of use are important elements that must be considered in this design space."}, {"color": "gray", "id": 652, "label": 652, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 652 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2011.201\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jarry H.T. Claessen;Jarke J. van Wijk; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Flexible Linked Axes for Multivariate Data Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Multivariate data visualization is a classic topic, for which many solutions have been proposed, each with its own strengths and weaknesses. In standard solutions the structure of the visualization is fixed, we explore how to give the user more freedom to define visualizations. Our new approach is based on the usage of Flexible Linked Axes: The user is enabled to define a visualization by drawing and linking axes on a canvas. Each axis has an associated attribute and range, which can be adapted. Links between pairs of axes are used to show data in either scatter plot- or Parallel Coordinates Plot-style. Flexible Linked Axes enable users to define a wide variety of different visualizations. These include standard methods, such as scatter plot matrices, radar charts, and PCPs [11]; less well known approaches, such as Hyperboxes [1], TimeWheels [17], and many-to-many relational parallel coordinate displays [14]; and also custom visualizations, consisting of combinations of scatter plots and PCPs. Furthermore, our method allows users to define composite visualizations that automatically support brushing and linking. We have discussed our approach with ten prospective users, who found the concept easy to understand and highly promising."}, {"color": "gray", "id": 653, "label": 653, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 653 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2011.202\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Kevin Buchin;Bettina Speckmann;Kevin Verbeek; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Flow Map Layout via Spiral Trees; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Flow maps are thematic maps that visualize the movement of objects, such as people or goods, between geographic regions. One or more sources are connected to several targets by lines whose thickness corresponds to the amount of flow between a source and a target. Good flow maps reduce visual clutter by merging (bundling) lines smoothly and by avoiding self-intersections. Most flow maps are still drawn by hand and only few automated methods exist. Some of the known algorithms do not support edge-bundling and those that do, cannot guarantee crossing-free flows. We present a new algorithmic method that uses edge-bundling and computes crossing-free flows of high visual quality. Our method is based on so-called spiral trees, a novel type of Steiner tree which uses logarithmic spirals. Spiral trees naturally induce a clustering on the targets and smoothly bundle lines. Our flows can also avoid obstacles, such as map features, region outlines, or even the targets. We demonstrate our approach with extensive experiments."}, {"color": "gray", "id": 654, "label": 654, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 654 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2011.205\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Yu-Shuen Wang;Ming-Te Chi; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Focus+Context Metro Maps; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We introduce a focus+context method to visualize a complicated metro map of a modern city on a small displaying area. The context of our work is with regard the popularity of mobile devices. The best route to the destination, which can be obtained from the arrival time of trains, is highlighted. The stations on the route enjoy larger spaces, whereas the other stations are rendered smaller and closer to fit the whole map into a screen. To simplify the navigation and route planning for visitors, we formulate various map characteristics such as octilinear transportation lines and regular station distances into energy terms. We then solve for the optimal layout in a least squares sense. In addition, we label the names of stations that are on the route of a passenger according to human preferences, occlusions, and consistencies of label positions using the graph cuts method. Our system achieves real-time performance by being able to report instant information because of the carefully designed energy terms. We apply our method to layout a number of metro maps and show the results and timing statistics to demonstrate the feasibility of our technique."}, {"color": "gray", "id": 658, "label": 658, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 658 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2011.220\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Paulo Joia;Danilo Coimbra;Jose A. Cuminato;Fernando V. Paulovich;Luis G. Nonato; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Local Affine Multidimensional Projection; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Multidimensional projection techniques have experienced many improvements lately, mainly regarding computational times and accuracy. However, existing methods do not yet provide flexible enough mechanisms for visualization-oriented fully interactive applications. This work presents a new multidimensional projection technique designed to be more flexible and versatile than other methods. This novel approach, called Local Affine Multidimensional Projection (LAMP), relies on orthogonal mapping theory to build accurate local transformations that can be dynamically modified according to user knowledge. The accuracy, flexibility and computational efficiency of LAMP is confirmed by a comprehensive set of comparisons. LAMP\u0027s versatility is exploited in an application which seeks to correlate data that, in principle, has no connection as well as in visual exploration of textual documents."}, {"color": "gray", "id": 659, "label": 659, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 659 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2011.223\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Christophe Hurter;Alexandru Telea;Ozan Ersoy; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: MoleView: An Attribute and Structure-Based Semantic Lens for Large Element-Based Plots; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present MoleView, a novel technique for interactive exploration of multivariate relational data. Given a spatial embedding of the data, in terms of a scatter plot or graph layout, we propose a semantic lens which selects a specific spatial and attribute-related data range. The lens keeps the selected data in focus unchanged and continuously deforms the data out of the selection range in order to maintain the context around the focus. Specific deformations include distance-based repulsion of scatter plot points, deforming straight-line node-link graph drawings, and as varying the simplification degree of bundled edge graph layouts. Using a brushing-based technique, we further show the applicability of our semantic lens for scenarios requiring a complex selection of the zones of interest. Our technique is simple to implement and provides real-time performance on large datasets. We demonstrate our technique with actual data from air and road traffic control, medical imaging, and software comprehension applications."}, {"color": "gray", "id": 660, "label": 660, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 660 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2011.226\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Michael Burch;Corinna Vehlow;Fabian Beck;Stephan Diehl;Daniel Weiskopf; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Parallel Edge Splatting for Scalable Dynamic Graph Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present a novel dynamic graph visualization technique based on node-link diagrams. The graphs are drawn side-byside from left to right as a sequence of narrow stripes that are placed perpendicular to the horizontal time line. The hierarchically organized vertices of the graphs are arranged on vertical, parallel lines that bound the stripes; directed edges connect these vertices from left to right. To address massive overplotting of edges in huge graphs, we employ a splatting approach that transforms the edges to a pixel-based scalar field. This field represents the edge densities in a scalable way and is depicted by non-linear color mapping. The visualization method is complemented by interaction techniques that support data exploration by aggregation, filtering, brushing, and selective data zooming. Furthermore, we formalize graph patterns so that they can be interactively highlighted on demand. A case study on software releases explores the evolution of call graphs extracted from the JUnit open source software project. In a second application, we demonstrate the scalability of our approach by applying it to a bibliography dataset containing more than 1.5 million paper titles from 60 years of research history producing a vast amount of relations between title words."}, {"color": "gray", "id": 661, "label": 661, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 661 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2011.227\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Hadley Wickham;Heike Hofmann; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Product Plots; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We propose a new framework for visualising tables of counts, proportions and probabilities. We call our framework product plots, alluding to the computation of area as a product of height and width, and the statistical concept of generating a joint distribution from the product of conditional and marginal distributions. The framework, with extensions, is sufficient to encompass over 20 visualisations previously described in fields of statistical graphics and infovis, including bar charts, mosaic plots, treemaps, equal area plots and fluctuation diagrams."}, {"color": "gray", "id": 664, "label": 664, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 664 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2011.233\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Ozan Ersoy;Christophe Hurter;Fernando Paulovich;Gabriel Cantareiro;Alex Telea; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Skeleton-Based Edge Bundling for Graph Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In this paper, we present a novel approach for constructing bundled layouts of general graphs. As layout cues for bundles, we use medial axes, or skeletons, of edges which are similar in terms of position information. We combine edge clustering, distance fields, and 2D skeletonization to construct progressively bundled layouts for general graphs by iteratively attracting edges towards the centerlines of level sets of their distance fields. Apart from clustering, our entire pipeline is image-based with an efficient implementation in graphics hardware. Besides speed and implementation simplicity, our method allows explicit control of the emphasis on structure of the bundled layout, i.e. the creation of strongly branching (organic-like) or smooth bundles. We demonstrate our method on several large real-world graphs."}, {"color": "gray", "id": 669, "label": 669, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 669 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2011.250\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Alexander Lex;Hans-Jorg Schulz;Marc Streit;Christian Partl;Dieter Schmalstieg; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: VisBricks: Multiform Visualization of Large, Inhomogeneous Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Large volumes of real-world data often exhibit inhomogeneities: vertically in the form of correlated or independent dimensions and horizontally in the form of clustered or scattered data items. In essence, these inhomogeneities form the patterns in the data that researchers are trying to find and understand. Sophisticated statistical methods are available to reveal these patterns, however, the visualization of their outcomes is mostly still performed in a one-view-fits-all manner, In contrast, our novel visualization approach, VisBricks, acknowledges the inhomogeneity of the data and the need for different visualizations that suit the individual characteristics of the different data subsets. The overall visualization of the entire data set is patched together from smaller visualizations, there is one VisBrick for each cluster in each group of interdependent dimensions. Whereas the total impression of all VisBricks together gives a comprehensive high-level overview of the different groups of data, each VisBrick independently shows the details of the group of data it represents, State-of-the-art brushing and visual linking between all VisBricks furthermore allows the comparison of the groupings and the distribution of data items among them. In this paper, we introduce the VisBricks visualization concept, discuss its design rationale and implementation, and demonstrate its usefulness by applying it to a use case from the field of biomedicine."}, {"color": "gray", "id": 670, "label": 670, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 670 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2011.251\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jagoda Walny;Sheelagh Carpendale;Nathalie Henry Riche;Gina Venolia;Philip Fawcett; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visual Thinking In Action: Visualizations As Used On Whiteboards; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: While it is still most common for information visualization researchers to develop new visualizations from a data-or taskdriven perspective, there is growing interest in understanding the types of visualizations people create by themselves for personal use. As part of this recent direction, we have studied a large collection of whiteboards in a research institution, where people make active use of combinations of words, diagrams and various types of visuals to help them further their thought processes. Our goal is to arrive at a better understanding of the nature of visuals that are created spontaneously during brainstorming, thinking, communicating, and general problem solving on whiteboards. We use the qualitative approaches of open coding, interviewing, and affinity diagramming to explore the use of recognizable and novel visuals, and the interplay between visualization and diagrammatic elements with words, numbers and labels. We discuss the potential implications of our findings on information visualization design."}, {"color": "gray", "id": 675, "label": 675, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 675 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2011.6102438\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Youn-ah Kang;John Stasko; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Characterizing the intelligence analysis process: Informing visual analytics design through a longitudinal field study; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: While intelligence analysis has been a primary target domain for visual analytics system development, relatively little user and task analysis has been conducted within this area. Our research community\u0027s understanding of the work processes and practices of intelligence analysts is not deep enough to adequately address their needs. Without a better understanding of the analysts and their problems, we cannot build visual analytics systems that integrate well with their work processes and truly provide benefit to them. In order to close this knowledge gap, we conducted a longitudinal, observational field study of intelligence analysts in training within the intelligence program at Mercyhurst College. We observed three teams of analysts, each working on an intelligence problem for a ten-week period. Based upon study findings, we describe and characterize processes and methods of intelligence analysis that we observed, make clarifications regarding the processes and practices, and suggest design implications for visual analytics systems for intelligence analysis."}, {"color": "gray", "id": 677, "label": 677, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 677 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2011.6102440\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Zhicheng Liu;Shamkant B. Navathe;John T. Stasko; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Network-based visual analysis of tabular data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Tabular data are pervasive. Although tables often describe multivariate data without explicit network semantics, it may be advantageous to explore the data modeled as a graph or network for analysis. Even when a given table design conveys some static network semantics, analysts may want to look at multiple networks from different perspectives, at different levels of abstraction, and with different edge semantics. We present a system called Ploceus that offers a general approach for performing multi-dimensional and multi-level network-based visual analysis on multivariate tabular data. Powered by an underlying relational algebraic framework, Ploceus supports flexible construction and transformation of networks through a direct manipulation interface, and integrates dynamic network manipulation with visual exploration for a seamless analytic experience."}, {"color": "gray", "id": 678, "label": 678, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 678 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2011.6102441\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jeffrey Heer;Adam Perer; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Orion: A system for modeling, transformation and visualization of multidimensional heterogeneous networks; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The study of complex activities such as scientific production and software development often require modeling connections among heterogeneous entities including people, institutions and artifacts. Despite numerous advances in algorithms and visualization techniques for understanding such social networks, the process of constructing network models and performing exploratory analysis remains difficult and time-consuming. In this paper we present Orion, a system for interactive modeling, transformation and visualization of network data. Orion\u0027s interface enables the rapid manipulation of large graphs-including the specification of complex linking relationships-using simple drag-and-drop operations with desired node types. Orion maps these user interactions to statements in a declarative workflow language that incorporates both relational operators (e.g., selection, aggregation and joins) and network analytics (e.g., centrality measures). We demonstrate how these features enable analysts to flexibly construct and compare networks in domains such as online health communities, academic collaboration and distributed software development."}, {"color": "gray", "id": 682, "label": 682, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 682 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2011.6102446\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jean-Daniel Fekete;Pierre-Luc H\u00e9mery;Thomas Baudel;Jo Wood; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Obvious: A meta-toolkit to encapsulate information visualization toolkits - One toolkit to bind them all; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: This article describes \u201cObvious\u201d: a meta-toolkit that abstracts and encapsulates information visualization toolkits implemented in the Java language. It intends to unify their use and postpone the choice of which concrete toolkit(s) to use later-on in the development of visual analytics applications. We also report on the lessons we have learned when wrapping popular toolkits with Obvious, namely Prefuse, the InfoVis Toolkit, partly Improvise, JUNG and other data management libraries. We show several examples on the uses of Obvious, how the different toolkits can be combined, for instance sharing their data models. We also show how Weka and Rapid-Miner, two popular machine-learning toolkits, have been wrapped with Obvious and can be used directly with all the other wrapped toolkits. We expect Obvious to start a co-evolution process: Obvious is meant to evolve when more components of Information Visualization systems will become consensual. It is also designed to help information visualization systems adhere to the best practices to provide a higher level of interoperability and leverage the domain of visual analytics."}, {"color": "gray", "id": 683, "label": 683, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 683 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2011.6102447\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Yang Chen;Jamal Alsakran;Scott Barlowe;Jing Yang;Ye Zhao; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Supporting effective common ground construction in Asynchronous Collaborative Visual Analytics; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Asynchronous Collaborative Visual Analytics (ACVA) leverages group sensemaking by releasing the constraints on when, where, and who works collaboratively. A significant task to be addressed before ACVA can reach its full potential is effective common ground construction, namely the process in which users evaluate insights from individual work to develop a shared understanding of insights and collectively pool them. This is challenging due to the lack of instant communication and scale of collaboration in ACVA. We propose a novel visual analytics approach that automatically gathers, organizes, and summarizes insights to form common ground with reduced human effort. The rich set of visualization and interaction techniques provided in our approach allows users to effectively and flexibly control the common ground construction and review, explore, and compare insights in detail. A working prototype of the approach has been implemented. We have conducted a case study and a user study to demonstrate its effectiveness."}, {"color": "gray", "id": 686, "label": 686, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 686 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2011.6102450\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Zhenyu Guo;Matthew O. Ward;Elke A. Rundensteiner;Carolina Ruiz; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Pointwise local pattern exploration for sensitivity analysis; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Sensitivity analysis is a powerful method for discovering the significant factors that contribute to targets and understanding the interaction between variables in multivariate datasets. A number of sensitivity analysis methods fall into the class of local analysis, in which the sensitivity is defined as the partial derivatives of a target variable with respect to a group of independent variables. Incorporating sensitivity analysis in visual analytic tools is essential for multivariate phenomena analysis. However, most current multivariate visualization techniques do not allow users to explore local patterns individually for understanding the sensitivity from a pointwise view. In this paper, we present a novel pointwise local pattern exploration system for visual sensitivity analysis. Using this system, analysts are able to explore local patterns and the sensitivity at individual data points, which reveals the relationships between a focal point and its neighbors. During exploration, users are able to interactively change the derivative coefficients to perform sensitivity analysis based on different requirements as well as their domain knowledge. Each local pattern is assigned an outlier factor, so that users can quickly identify anomalous local patterns that do not conform with the global pattern. Users can also compare the local pattern with the global pattern both visually and statistically. Finally, the local pattern is integrated into the original attribute space using color mapping and jittering, which reveals the distribution of the partial derivatives. Case studies with real datasets are used to investigate the effectiveness of the visualizations and interactions."}, {"color": "gray", "id": 688, "label": 688, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 688 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2011.6102453\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Stef van den Elzen;Jarke J. van Wijk; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: BaobabView: Interactive construction and analysis of decision trees; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present a system for the interactive construction and analysis of decision trees that enables domain experts to bring in domain specific knowledge. We identify different user tasks and corresponding requirements, and develop a system incorporating a tight integration of visualization, interaction and algorithmic support. Domain experts are supported in growing, pruning, optimizing and analysing decision trees. Furthermore, we present a scalable decision tree visualization optimized for exploration. We show the effectiveness of our approach by applying the methods to two use cases. The first case illustrates the advantages of interactive construction, the second case demonstrates the effectiveness of analysis of decision trees and exploration of the structure of the data."}, {"color": "gray", "id": 689, "label": 689, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 689 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2011.6102454\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Gennady Andrienko;Natalia Andrienko;Christophe Hurter;Salvatore Rinzivillo;Stefan Wrobel; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: From movement tracks through events to places: Extracting and characterizing significant places from mobility data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We propose a visual analytics procedure for analyzing movement data, i.e., recorded tracks of moving objects. It is oriented to a class of problems where it is required to determine significant places on the basis of certain types of events occurring repeatedly in movement data. The procedure consists of four major steps: (1) event extraction from trajectories; (2) event clustering and extraction of relevant places; (3) spatio-temporal aggregation of events or trajectories; (4) analysis of the aggregated data. All steps are scalable with respect to the amount of the data under analysis. We demonstrate the use of the procedure by example of two real-world problems requiring analysis at different spatial scales."}, {"color": "gray", "id": 692, "label": 692, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 692 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2011.6102457\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Shehzad Afzal;Ross Maciejewski;David S. Ebert; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visual analytics decision support environment for epidemic modeling and response evaluation; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In modeling infectious diseases, scientists are studying the mechanisms by which diseases spread, predicting the future course of the outbreak, and evaluating strategies applied to control an epidemic. While recent work has focused on accurately modeling disease spread, less work has been performed in developing interactive decision support tools for analyzing the future course of the outbreak and evaluating potential disease mitigation strategies. The absence of such tools makes it difficult for researchers, analysts and public health officials to evaluate response measures within outbreak scenarios. As such, our research focuses on the development of an interactive decision support environment in which users can explore epidemic models and their impact. This environment provides a spatiotemporal view where users can interactively utilize mitigative response measures and observe the impact of their decision over time. Our system also provides users with a linked decision history visualization and navigation tool that support the simultaneous comparison of mortality and infection rates corresponding to different response measures at different points in time."}, {"color": "gray", "id": 693, "label": 693, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 693 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2011.6102458\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Lei Shi;Qi Liao;Yuan He;Rui Li;Aaron Striegel;Zhong Su; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: SAVE: Sensor anomaly visualization engine; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Diagnosing a large-scale sensor network is a crucial but challenging task. Particular challenges include the resource and bandwidth constraints on sensor nodes, the spatiotemporally dynamic network behaviors, and the lack of accurate models to understand such behaviors in a hostile environment. In this paper, we present the Sensor Anomaly Visualization Engine (SAVE), a system that fully leverages the power of both visualization and anomaly detection analytics to guide the user to quickly and accurately diagnose sensor network failures and faults. SAVE combines customized visualizations over separate sensor data facets as multiple coordinated views. Temporal expansion model, correlation graph and dynamic projection views are proposed to effectively interpret the topological, correlational and dimensional sensor data dynamics and their anomalies. Through a case study with real-world sensor network system and administrators, we demonstrate that SAVE is able to help better locate the system problem and further identify the root cause of major sensor network failure scenarios."}, {"color": "gray", "id": 695, "label": 695, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 695 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2011.6102460\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Abish Malik;Ross Maciejewski;Ben Maule;David S. Ebert; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: A visual analytics process for maritime resource allocation and risk assessment; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In this paper, we present our collaborative work with the U.S. Coast Guard\u0027s Ninth District and Atlantic Area Commands where we developed a visual analytics system to analyze historic response operations and assess the potential risks in the maritime environment associated with the hypothetical allocation of Coast Guard resources. The system includes linked views and interactive displays that enable the analysis of trends, patterns and anomalies among the U.S. Coast Guard search and rescue (SAR) operations and their associated sorties. Our system allows users to determine the potential change in risks associated with closing certain stations in terms of response time, potential lives and property lost and provides optimal direction as to the nearest available station. We provide maritime risk assessment tools that allow analysts to explore Coast Guard coverage for SAR operations and identify regions of high risk. The system also enables a thorough assessment of all SAR operations conducted by each Coast Guard station in the Great Lakes region. Our system demonstrates the effectiveness of visual analytics in analyzing risk within the maritime domain and is currently being used by analysts at the Coast Guard Atlantic Area."}, {"color": "gray", "id": 697, "label": 697, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 697 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2011.6102462\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Weijia Xu;Maria Esteva;Suyog Dutt Jain;Varun Jain; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Analysis of large digital collections with interactive visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: To make decisions about the long-term preservation and access of large digital collections, archivists gather information such as the collections\u0027 contents, their organizational structure, and their file format composition. To date, the process of analyzing a collection - from data gathering to exploratory analysis and final conclusions - has largely been conducted using pen and paper methods. To help archivists analyze large-scale digital collections for archival purposes, we developed an interactive visual analytics application. The application narrows down different kinds of information about the collection, and presents them as meaningful data views. Multiple views and analysis features can be linked or unlinked on demand to enable researchers to compare and contrast different analyses, and to identify trends. We describe and present two user scenarios to show how the application allowed archivists to learn about a collection with accuracy, facilitated decision-making, and helped them arrive at conclusions."}, {"color": "gray", "id": 698, "label": 698, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 698 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2011.6102463\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Xiaoyu Wang;Wenwen Dou;Thomas Butkiewicz;Eric A. Bier;William Ribarsky; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: A two-stage framework for designing visual analytics system in organizational environments; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: A perennially interesting research topic in the field of visual analytics is how to effectively develop systems that support organizational users\u0027 decision-making and reasoning processes. The problem is, however, most domain analytical practices generally vary from organization to organization. This leads to diverse designs of visual analytics systems in incorporating domain analytical processes, making it difficult to generalize the success from one domain to another. Exacerbating this problem is the dearth of general models of analytical workflows available to enable such timely and effective designs. To alleviate these problems, we present a two-stage framework for informing the design of a visual analytics system. This design framework builds upon and extends current practices pertaining to analytical workflow and focuses, in particular, on incorporating both general domain analysis processes as well as individual\u0027s analytical activities. We illustrate both stages and their design components through examples, and hope this framework will be useful for designing future visual analytics systems. We validate the soundness of our framework with two visual analytics systems, namely Entity Workspace [8] and PatViz [37]."}, {"color": "gray", "id": 699, "label": 699, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 699 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2011.6102465\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Anushka Anand;Leland Wilkinson;Tuan Nhon Dang; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Using random projections to identify class-separating variables in high-dimensional spaces; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Projection Pursuit has been an effective method for finding interesting low-dimensional (usually 2D) projections in multidimensional spaces. Unfortunately, projection pursuit is not scalable to high-dimensional spaces. We introduce a novel method for approximating the results of projection pursuit to find class-separating views by using random projections. We build an analytic visualization platform based on this algorithm that is scalable to extremely large problems. Then, we discuss its extension to the recognition of other noteworthy configurations in high-dimensional spaces."}, {"color": "gray", "id": 703, "label": 703, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 703 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2011.6102469\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: R. Jordan Crouser;Jeremy G. Freeman;Remco Chang; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Exploring agent-based simulations using temporal graphs; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Agent-based simulation has become a key technique for modeling and simulating dynamic, complicated behaviors in social and behavioral sciences. Lacking the appropriate tools and support, it is difficult for social scientists to thoroughly analyze the results of these simulations. In this work, we capture the complex relationships between discrete simulation states by visualizing the data as a temporal graph. In collaboration with expert analysts, we identify two graph structures which capture important relationships between pivotal states in the simulation and their inevitable outcomes. Finally, we demonstrate the utility of these structures in the interactive analysis of a large-scale social science simulation of political power in present-day Thailand."}, {"color": "gray", "id": 711, "label": 711, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 711 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2011.6102477\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Victoria Lemieux;Barbara Endicott-Popovsky;Karl Eckler;Thomas Dang;Adam Jansen; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visualizing an information assurance risk taxonomy; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The researchers explore the intersections between Information Assurance and Risk using visual analysis of text mining operations. The methodological approach involves searching for and extracting for analysis those abstracts and keywords groupings that relate to risk within a defined subset of scientific research journals. This analysis is conducted through a triangulated study incorporating visualizations produced using both Starlight and In-Spire visual analysis software. The results are definitional, showing current attitudes within the Information Assurance research community towards risk management strategies, while simultaneously demonstrating the value of visual analysis processes when engaging in sense making of a large body of knowledge."}, {"color": "gray", "id": 713, "label": 713, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 713 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2011.6102479\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Iulian Peca;Haolin Zhi;Katerina Vrotsou;Natalia Andrienko;Gennady Andrienko; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: KD-photomap: Exploring photographs in space and time; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: KD-photomap is a web-based visual analytics system for browsing collections of geotagged Flickr photographs in search of interesting pictures, places, and events. Spatial filtering of the data is performed through zooming, moving or searching along the map. Temporal filtering is possible through defining time windows using interactive histograms and calendar controls. Information about the number and spatiotemporal distribution of photos captured in an explored area is continuously provided using various visual cues."}, {"color": "gray", "id": 716, "label": 716, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 716 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2011.6102482\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Scott D. Rothenberger;John E. Wenskovitch;G. Elisabeta Marai; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Pexel and heatmap visual analysis of multidimensional gun/homicide data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present a visual analysis tool for mining correlations in county-level, multidimensional gun/homicide data. The tool uses 2D pexels, heatmaps, linked-views, dynamic queries and details-on-demand to analyze annual county-level data on firearm homicide rates and gun availability, as well as various socio-demographic measures. A statistical significance filter was implemented as a visual means to validate exploratory hypotheses. Results from expert evaluations indicate that our methods outperform typical graphical techniques used by statisticians, such as bar graphs, scatterplots and residual plots, to show spatial and temporal relationships. Our visualization has the potential to convey the impact of gun availability on firearm homicides to the public health arena and the general public."}, {"color": "gray", "id": 717, "label": 717, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 717 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2011.6102485\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: N. B\u00e1nfi;L. Dud\u00e1s;Zs. Fekete;J. G\u00f6b\u00f6 l\u00f6s-Szab\u00f3;A. Luk\u00e1cs;\u00c1. Nagy;A. Szab\u00f3;Z. Szab\u00f3;G. Sz\u0171cs; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: City sentinel - VAST 2011 mini challenge 1 award: \"Outstanding integration of computational and visual methods\"; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present City Sentinel, an in-house built visual analytic software capable of handling a large collection of textual documents by combining diverse text mining and visualization tools. We applied this tool for the Vast Challenge 2011, Mini Challenge 1 over millions of tweet messages. We demonstrate how City Sentinel aided the analyst in retrieving the hidden information from the tweet messages to analyze and locate a hypothetical epidemic outbreak."}, {"color": "gray", "id": 718, "label": 718, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 718 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2011.6102486\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Kevin Boone;Edward Swing; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Mapping an epidemic outbreak: Effective analysis and presentation; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The microblog challenge presented an opportunity to use commercial software for visual analysis. An epidemic outbreak occurred in the city of Vastopolis, requiring visualizations of symptoms and their spread over time. Using these tools, analysts could successfully identify the outbreak\u0027s origin and pattern of dispersion. The maps used to analyze the data and present the results provided clear, easily understood representations, and presented a logical explanation of a complex progression of events."}, {"color": "gray", "id": 719, "label": 719, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 719 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2011.6102488\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Harald Bosch;Dennis Thom;Michael W\u00f6rner;Steffen Koch;Edwin P\u00fcttmann;Dominik J\u00e4ckle;Thomas Ertl; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: ScatterBlogs: Geo-spatial document analysis; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We presented Scatterblogs, a system for microblog analysis that seamlessly integrates search backend and visual frontend. It provides powerful, automatic algorithms for detecting spatio-temporal `anomalies\u0027 within blog entries as well as corresponding visual representations and interaction facilities for inspecting anomalies or exploiting them in further analytic steps. Apart from that, we consider the system\u0027s combinatoric facilities for building complex hypotheses from temporal, spatial, and content-related aspects an important feature. This was the key for creating a cross-checked analysis for MC1."}, {"color": "gray", "id": 720, "label": 720, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 720 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2011.6102489\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Llyr ap Cenydd;Rick Walker;Serban Pop;Helen Miles;Chris Hughes;William Teahan;Jonathan C. Roberts; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: epSpread - Storyboarding for visual analytics; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present epSpread, an analysis and storyboarding tool for geolocated microblogging data. Individual time points and ranges are analysed through queries, heatmaps, word clouds and streamgraphs. The underlying narrative is shown on a storyboard-style timeline for discussion, refinement and presentation. The tool was used to analyse data from the VAST Challenge 2011 Mini-Challenge 1, tracking the spread of an epidemic using microblogging data. In this article we describe how the tool was used to identify the origin and track the spread of the epidemic."}, {"color": "gray", "id": 723, "label": 723, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 723 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2011.6102492\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Lane Harrison;Wenwen Dou;Aidong Lu;William Ribarsky;Xiaoyu Wang; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Guiding security analysis through visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present a multiple views visualization for the security data in the VAST 2010 Mini Challenge 2. The visualization is used to monitor log event activity on the network log data included in the challenge. Interactions are provided that allow analysts to investigate suspicious activity and escalate events as needed. Additionally, a database application is used to allow SQL queries for more detailed investigation."}, {"color": "gray", "id": 724, "label": 724, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 724 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2011.6102493\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Walter Marcelo Lamagna; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: An integrated visualization on network events VAST 2011 mini challenge #2 award: \"Outstanding integrated overview display\"; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: To visualize security trends for the data set provided by the VAST 2011 Mini Challenge #2 a custom tool has been developed. Open source tools [1,2], web programming languages [4,7] and an open source database [3] has been used to work with the data and create a visualization for security log files containing network security trends. In this paper, the tools and methods used for the analysis are described. The methods include the log synchronization with different timezone and the development of heat maps and parallel coordinates charts. To develop the visualization, Processing and Canvas [4,7] was used."}, {"color": "gray", "id": 725, "label": 725, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 725 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2011.6102495\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Christopher Andrews;M. Shahriar Hossain;Samah Gad;Naren Ramakrishnan;Chris North; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Analyst\u0027s workspace: Protecting vastopolis; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Analyst\u0027s Workspace is a sensemaking environment designed specifically for use of large, high-resolution displays. It employs a spatial workspace to integrate foraging and synthesis activities into a unified process. In this paper we describe how Analyst\u0027s Workspace solved the VAST 2011 mini-challenge #3 and discuss some of the unique features of the environment."}, {"color": "gray", "id": 726, "label": 726, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 726 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2011.6102496\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Elizabeth Braunstein;Carsten G\u00f6rg;Zhicheng Liu;John Stasko; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Jigsaw to save vastopolis; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: This article describes our analytic process and experience of using the Jigsaw system in working on the VAST 2011 Mini Challenge 3. We describe how we extracted and worked with entities from the documents, and how Jigsaw\u0027s computational analysis capabilities and visualizations scaffolded the investigation. Based on our experiences, we discuss desirable features that would enhance the analytic power of Jigsaw."}, {"color": "gray", "id": 727, "label": 727, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 727 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2011.6102497\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Casey M. Canfield;David Sheffield; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Interactive data analysis with nSpace2(c); \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: nSpace2 is an innovative visual analytics tool that was the primary platform used to search, evaluate, and organize the data in the VAST 2011 Mini Challenge #3 dataset. nSpace2 is a web-based tool that is designed to facilitate the back-and-forth flow of the multiple steps of an analysis process, including search, data triage, organization, sense-making, and reporting. This paper describes how nSpace2 was used to assist every step of the analysis process for this VAST challenge."}, {"color": "gray", "id": 728, "label": 728, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 728 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2011.6102498\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Enrico Bertini;Christian Scheible;Tobias Schreck;Stephan Sellien;Florian Stoffel;Mark Tautzenberger;Matthias Zieker;Daniel A. Keim;Juri Buchm\u00fcller;Fabian Fischer;Stephan Huber;Thomas Lindemeier;Fabian Maa\u00df;Florian Mansmann;Thomas Ramm;Michael Regenscheit;Christian Rohrdantz; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visual analytics of terrorist activities related to epidemics; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The task of the VAST 2011 Grand Challenge was to investigate potential terrorist activities and their relation to the spread of an epidemic. Three different data sets were provided as part of three Mini Challenges (MCs). MC 1 was about analyzing geo-tagged microblogging (Twitter) messages to characterize the spread of an epidemic. MC 2 required analyzing threats to a computer network using a situational awareness approach. In MC 3 possible criminal and terrorist activities were to be analyzed based on a collection of news articles. To solve the Grand Challenge, insight from each of the individual MCs had to be integrated appropriately."}, {"color": "gray", "id": 729, "label": 729, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 729 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2012.186\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Lars K\u00fchne;Joachim Giesen;Zhiyuan Zhang;Sungsoo Ha;Klaus Mueller; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: A Data-Driven Approach to Hue-Preserving Color-Blending; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Color mapping and semitransparent layering play an important role in many visualization scenarios, such as information visualization and volume rendering. The combination of color and transparency is still dominated by standard alpha-compositing using the Porter-Duff over operator which can result in false colors with deceiving impact on the visualization. Other more advanced methods have also been proposed, but the problem is still far from being solved. Here we present an alternative to these existing methods specifically devised to avoid false colors and preserve visual depth ordering. Our approach is data driven and follows the recently formulated knowledge-assisted visualization (KAV) paradigm. Preference data, that have been gathered in web-based user surveys, are used to train a support-vector machine model for automatically predicting an optimized hue-preserving blending. We have applied the resulting model to both volume rendering and a specific information visualization technique, illustrative parallel coordinate plots. Comparative renderings show a significant improvement over previous approaches in the sense that false colors are completely removed and important properties such as depth ordering and blending vividness are better preserved. Due to the generality of the defined data-driven blending operator, it can be easily integrated also into other visualization frameworks."}, {"color": "gray", "id": 734, "label": 734, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 734 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2012.191\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Mike Sips;Patrick K\u00f6thur;Andrea Unger;Hans-Christian Hege;Doris Dransch; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: A Visual Analytics Approach to Multiscale Exploration of Environmental Time Series; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present a Visual Analytics approach that addresses the detection of interesting patterns in numerical time series, specifically from environmental sciences. Crucial for the detection of interesting temporal patterns are the time scale and the starting points one is looking at. Our approach makes no assumption about time scale and starting position of temporal patterns and consists of three main steps: an algorithm to compute statistical values for all possible time scales and starting positions of intervals, visual identification of potentially interesting patterns in a matrix visualization, and interactive exploration of detected patterns. We demonstrate the utility of this approach in two scientific scenarios and explain how it allowed scientists to gain new insight into the dynamics of environmental systems."}, {"color": "gray", "id": 735, "label": 735, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 735 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2012.192\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Bernhard Jenny; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Adaptive Composite Map Projections; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: All major web mapping services use the web Mercator projection. This is a poor choice for maps of the entire globe or areas of the size of continents or larger countries because the Mercator projection shows medium and higher latitudes with extreme areal distortion and provides an erroneous impression of distances and relative areas. The web Mercator projection is also not able to show the entire globe, as polar latitudes cannot be mapped. When selecting an alternative projection for information visualization, rivaling factors have to be taken into account, such as map scale, the geographic area shown, the map\u0027s height-to-width ratio, and the type of cartographic visualization. It is impossible for a single map projection to meet the requirements for all these factors. The proposed composite map projection combines several projections that are recommended in cartographic literature and seamlessly morphs map space as the user changes map scale or the geographic region displayed. The composite projection adapts the map\u0027s geometry to scale, to the map\u0027s height-to-width ratio, and to the central latitude of the displayed area by replacing projections and adjusting their parameters. The composite projection shows the entire globe including poles; it portrays continents or larger countries with less distortion (optionally without areal distortion); and it can morph to the web Mercator projection for maps showing small regions."}, {"color": "gray", "id": 736, "label": 736, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 736 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2012.193\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Martin Fink;Jan-Henrik Haunert;Andr\u00e9 Schulz;Joachim Spoerhase;Alexander Wolff; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Algorithms for Labeling Focus Regions; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In this paper, we investigate the problem of labeling point sites in focus regions of maps or diagrams. This problem occurs, for example, when the user of a mapping service wants to see the names of restaurants or other POIs in a crowded downtown area but keep the overview over a larger area. Our approach is to place the labels at the boundary of the focus region and connect each site with its label by a linear connection, which is called a leader. In this way, we move labels from the focus region to the less valuable context region surrounding it. In order to make the leader layout well readable, we present algorithms that rule out crossings between leaders and optimize other characteristics such as total leader length and distance between labels. This yields a new variant of the boundary labeling problem, which has been studied in the literature. Other than in traditional boundary labeling, where leaders are usually schematized polylines, we focus on leaders that are either straight-line segments or Bezier curves. Further, we present algorithms that, given the sites, find a position of the focus region that optimizes the above characteristics. We also consider a variant of the problem where we have more sites than space for labels. In this situation, we assume that the sites are prioritized by the user. Alternatively, we take a new facility-location perspective which yields a clustering of the sites. We label one representative of each cluster. If the user wishes, we apply our approach to the sites within a cluster, giving details on demand."}, {"color": "gray", "id": 738, "label": 738, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 738 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2012.195\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: R. Jordon Crouser;Remco Chang; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: An Affordance-Based Framework for Human Computation and Human-Computer Collaboration; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Visual Analytics is \u201cthe science of analytical reasoning facilitated by visual interactive interfaces\u201d [70]. The goal of this field is to develop tools and methodologies for approaching problems whose size and complexity render them intractable without the close coupling of both human and machine analysis. Researchers have explored this coupling in many venues: VAST, Vis, InfoVis, CHI, KDD, IUI, and more. While there have been myriad promising examples of human-computer collaboration, there exists no common language for comparing systems or describing the benefits afforded by designing for such collaboration. We argue that this area would benefit significantly from consensus about the design attributes that define and distinguish existing techniques. In this work, we have reviewed 1,271 papers from many of the top-ranking conferences in visual analytics, human-computer interaction, and visualization. From these, we have identified 49 papers that are representative of the study of human-computer collaborative problem-solving, and provide a thorough overview of the current state-of-the-art. Our analysis has uncovered key patterns of design hinging on humanand machine-intelligence affordances, and also indicates unexplored avenues in the study of this area. The results of this analysis provide a common framework for understanding these seemingly disparate branches of inquiry, which we hope will motivate future work in the field."}, {"color": "gray", "id": 741, "label": 741, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 741 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2012.198\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Wieland Reich;Gerik Scheuermann; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Analysis of Streamline Separation at Infinity Using Time-Discrete Markov Chains; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Existing methods for analyzing separation of streamlines are often restricted to a finite time or a local area. In our paper we introduce a new method that complements them by allowing an infinite-time-evaluation of steady planar vector fields. Our algorithm unifies combinatorial and probabilistic methods and introduces the concept of separation in time-discrete Markov-Chains. We compute particle distributions instead of the streamlines of single particles. We encode the flow into a map and then into a transition matrix for each time direction. Finally, we compare the results of our grid-independent algorithm to the popular Finite-Time-Lyapunov-Exponents and discuss the discrepancies."}, {"color": "gray", "id": 749, "label": 749, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 749 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2012.207\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Alexander Pilh\u00f6fer;Alexander Gribov;Antony Unwin; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Comparing Clusterings Using Bertin\u0027s Idea; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Classifying a set of objects into clusters can be done in numerous ways, producing different results. They can be visually compared using contingency tables [27], mosaicplots [13], fluctuation diagrams [15], tableplots [20] , (modified) parallel coordinates plots [28], Parallel Sets plots [18] or circos diagrams [19]. Unfortunately the interpretability of all these graphical displays decreases rapidly with the numbers of categories and clusterings. In his famous book A Semiology of Graphics [5] Bertin writes \u201cthe discovery of an ordered concept appears as the ultimate point in logical simplification since it permits reducing to a single instant the assimilation of series which previously required many instants of study\u201d. Or in more everyday language, if you use good orderings you can see results immediately that with other orderings might take a lot of effort. This is also related to the idea of effect ordering [12], that data should be organised to reflect the effect you want to observe. This paper presents an efficient algorithm based on Bertin\u0027s idea and concepts related to Kendall\u0027s t [17], which finds informative joint orders for two or more nominal classification variables. We also show how these orderings improve the various displays and how groups of corresponding categories can be detected using a top-down partitioning algorithm. Different clusterings based on data on the environmental performance of cars sold in Germany are used for illustration. All presented methods are available in the R package extracat which is used to compute the optimized orderings for the example dataset."}, {"color": "gray", "id": 750, "label": 750, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 750 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2012.208\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Kasper Dinkla;Michel A. Westenberg;Jarke J. van Wijk; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Compressed Adjacency Matrices: Untangling Gene Regulatory Networks; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present a novel technique-Compressed Adjacency Matrices-for visualizing gene regulatory networks. These directed networks have strong structural characteristics: out-degrees with a scale-free distribution, in-degrees bound by a low maximum, and few and small cycles. Standard visualization techniques, such as node-link diagrams and adjacency matrices, are impeded by these network characteristics. The scale-free distribution of out-degrees causes a high number of intersecting edges in node-link diagrams. Adjacency matrices become space-inefficient due to the low in-degrees and the resulting sparse network. Compressed adjacency matrices, however, exploit these structural characteristics. By cutting open and rearranging an adjacency matrix, we achieve a compact and neatly-arranged visualization. Compressed adjacency matrices allow for easy detection of subnetworks with a specific structure, so-called motifs, which provide important knowledge about gene regulatory networks to domain experts. We summarize motifs commonly referred to in the literature, and relate them to network analysis tasks common to the visualization domain. We show that a user can easily find the important motifs in compressed adjacency matrices, and that this is hard in standard adjacency matrix and node-link diagrams. We also demonstrate that interaction techniques for standard adjacency matrices can be used for our compressed variant. These techniques include rearrangement clustering, highlighting, and filtering."}, {"color": "gray", "id": 751, "label": 751, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 751 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2012.209\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Attila Gyulassy;Peer-Timo Bremer;Valerio Pascucci; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Computing Morse-Smale Complexes with Accurate Geometry; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Topological techniques have proven highly successful in analyzing and visualizing scientific data. As a result, significant efforts have been made to compute structures like the Morse-Smale complex as robustly and efficiently as possible. However, the resulting algorithms, while topologically consistent, often produce incorrect connectivity as well as poor geometry. These problems may compromise or even invalidate any subsequent analysis. Moreover, such techniques may fail to improve even when the resolution of the domain mesh is increased, thus producing potentially incorrect results even for highly resolved functions. To address these problems we introduce two new algorithms: (i) a randomized algorithm to compute the discrete gradient of a scalar field that converges under refinement; and (ii) a deterministic variant which directly computes accurate geometry and thus correct connectivity of the MS complex. The first algorithm converges in the sense that on average it produces the correct result and its standard deviation approaches zero with increasing mesh resolution. The second algorithm uses two ordered traversals of the function to integrate the probabilities of the first to extract correct (near optimal) geometry and connectivity. We present an extensive empirical study using both synthetic and real-world data and demonstrates the advantages of our algorithms in comparison with several popular approaches."}, {"color": "gray", "id": 752, "label": 752, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 752 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2012.210\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Krishna Chaitanya Gurijala;Lei Wang;Arie Kaufman; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Cumulative Heat Diffusion Using Volume Gradient Operator for Volume Analysis; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We introduce a simple, yet powerful method called the Cumulative Heat Diffusion for shape-based volume analysis, while drastically reducing the computational cost compared to conventional heat diffusion. Unlike the conventional heat diffusion process, where the diffusion is carried out by considering each node separately as the source, we simultaneously consider all the voxels as sources and carry out the diffusion, hence the term cumulative heat diffusion. In addition, we introduce a new operator that is used in the evaluation of cumulative heat diffusion called the Volume Gradient Operator (VGO). VGO is a combination of the LBO and a data-driven operator which is a function of the half gradient. The half gradient is the absolute value of the difference between the voxel intensities. The VGO by its definition captures the local shape information and is used to assign the initial heat values. Furthermore, VGO is also used as the weighting parameter for the heat diffusion process. We demonstrate that our approach can robustly extract shape-based features and thus forms the basis for an improved classification and exploration of features based on shape."}, {"color": "gray", "id": 753, "label": 753, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 753 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2012.211\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Harald Obermaier;Kenneth I. Joy; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Derived Metric Tensors for Flow Surface Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Integral flow surfaces constitute a widely used flow visualization tool due to their capability to convey important flow information such as fluid transport, mixing, and domain segmentation. Current flow surface rendering techniques limit their expressiveness, however, by focusing virtually exclusively on displacement visualization, visually neglecting the more complex notion of deformation such as shearing and stretching that is central to the field of continuum mechanics. To incorporate this information into the flow surface visualization and analysis process, we derive a metric tensor field that encodes local surface deformations as induced by the velocity gradient of the underlying flow field. We demonstrate how properties of the resulting metric tensor field are capable of enhancing present surface visualization and generation methods and develop novel surface querying, sampling, and visualization techniques. The provided results show how this step towards unifying classic flow visualization and more advanced concepts from continuum mechanics enables more detailed and improved flow analysis."}, {"color": "gray", "id": 754, "label": 754, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 754 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2012.212\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Yuzuru Tanahashi;Kwan-Liu Ma; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Design Considerations for Optimizing Storyline Visualizations; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Storyline visualization is a technique used to depict the temporal dynamics of social interactions. This visualization technique was first introduced as a hand-drawn illustration in XKCD\u0027s \u201cMovie Narrative Charts\u201d [21]. If properly constructed, the visualization can convey both global trends and local interactions in the data. However, previous methods for automating storyline visualizations are overly simple, failing to achieve some of the essential principles practiced by professional illustrators. This paper presents a set of design considerations for generating aesthetically pleasing and legible storyline visualizations. Our layout algorithm is based on evolutionary computation, allowing us to effectively incorporate multiple objective functions. We show that the resulting visualizations have significantly improved aesthetics and legibility compared to existing techniques."}, {"color": "gray", "id": 755, "label": 755, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 755 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2012.213\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Michael Sedlmair;Miriah Meyer;Tamara Munzner; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Design Study Methodology: Reflections from the Trenches and the Stacks; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Design studies are an increasingly popular form of problem-driven visualization research, yet there is little guidance available about how to do them effectively. In this paper we reflect on our combined experience of conducting twenty-one design studies, as well as reading and reviewing many more, and on an extensive literature review of other field work methods and methodologies. Based on this foundation we provide definitions, propose a methodological framework, and provide practical guidance for conducting design studies. We define a design study as a project in which visualization researchers analyze a specific real-world problem faced by domain experts, design a visualization system that supports solving this problem, validate the design, and reflect about lessons learned in order to refine visualization design guidelines. We characterize two axes - a task clarity axis from fuzzy to crisp and an information location axis from the domain expert\u0027s head to the computer - and use these axes to reason about design study contributions, their suitability, and uniqueness from other approaches. The proposed methodological framework consists of 9 stages: learn, winnow, cast, discover, design, implement, deploy, reflect, and write. For each stage we provide practical guidance and outline potential pitfalls. We also conducted an extensive literature survey of related methodological approaches that involve a significant amount of qualitative field work, and compare design study methodology to that of ethnography, grounded theory, and action research."}, {"color": "gray", "id": 758, "label": 758, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 758 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2012.216\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jian Chen;Haipeng Cai;Alexander P. Auchus;David H. Laidlaw; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Effects of Stereo and Screen Size on the Legibility of Three-Dimensional Streamtube Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We report the impact of display characteristics (stereo and size) on task performance in diffusion magnetic resonance imaging (DMRI) in a user study with 12 participants. The hypotheses were that (1) adding stereo and increasing display size would improve task accuracy and reduce completion time, and (2) the greater the complexity of a spatial task, the greater the benefits of an improved display. Thus we expected to see greater performance gains when detailed visual reasoning was required. Participants used dense streamtube visualizations to perform five representative tasks: (1) determine the higher average fractional anisotropy (FA) values between two regions, (2) find the endpoints of fiber tracts, (3) name a bundle, (4) mark a brain lesion, and (5) judge if tracts belong to the same bundle. Contrary to our hypotheses, we found the task completion time was not improved by the use of the larger display and that performance accuracy was hurt rather than helped by the introduction of stereo in our study with dense DMRI data. Bigger was not always better. Thus cautious should be taken when selecting displays for scientific visualization applications. We explored the results further using the body-scale unit and subjective size and stereo experiences."}, {"color": "gray", "id": 759, "label": 759, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 759 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2012.217\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Lingyun Yu;Konstantinos Efstathiou;Petra Isenberg;Tobias Isenberg; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Efficient Structure-Aware Selection Techniques for 3D Point Cloud Visualizations with 2DOF Input; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Data selection is a fundamental task in visualization because it serves as a pre-requisite to many follow-up interactions. Efficient spatial selection in 3D point cloud datasets consisting of thousands or millions of particles can be particularly challenging. We present two new techniques, TeddySelection and CloudLasso, that support the selection of subsets in large particle 3D datasets in an interactive and visually intuitive manner. Specifically, we describe how to spatially select a subset of a 3D particle cloud by simply encircling the target particles on screen using either the mouse or direct-touch input. Based on the drawn lasso, our techniques automatically determine a bounding selection surface around the encircled particles based on their density. This kind of selection technique can be applied to particle datasets in several application domains. TeddySelection and CloudLasso reduce, and in some cases even eliminate, the need for complex multi-step selection processes involving Boolean operations. This was confirmed in a formal, controlled user study in which we compared the more flexible CloudLasso technique to the standard cylinder-based selection technique. This study showed that the former is consistently more efficient than the latter - in several cases the CloudLasso selection time was half that of the corresponding cylinder-based selection."}, {"color": "gray", "id": 767, "label": 767, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 767 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2012.225\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Krist Wongsuphasawat;David Gotz; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Exploring Flow, Factors, and Outcomes of Temporal Event Sequences with the Outflow Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Event sequence data is common in many domains, ranging from electronic medical records (EMRs) to sports events. Moreover, such sequences often result in measurable outcomes (e.g., life or death, win or loss). Collections of event sequences can be aggregated together to form event progression pathways. These pathways can then be connected with outcomes to model how alternative chains of events may lead to different results. This paper describes the Outflow visualization technique, designed to (1) aggregate multiple event sequences, (2) display the aggregate pathways through different event states with timing and cardinality, (3) summarize the pathways\u0027 corresponding outcomes, and (4) allow users to explore external factors that correlate with specific pathway state transitions. Results from a user study with twelve participants show that users were able to learn how to use Outflow easily with limited training and perform a range of tasks both accurately and rapidly."}, {"color": "gray", "id": 768, "label": 768, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 768 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2012.226\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jian Zhao;Fanny Chevalier;Christopher Collins;Ravin Balakrishnan; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Facilitating Discourse Analysis with Interactive Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: A discourse parser is a natural language processing system which can represent the organization of a document based on a rhetorical structure tree-one of the key data structures enabling applications such as text summarization, question answering and dialogue generation. Computational linguistics researchers currently rely on manually exploring and comparing the discourse structures to get intuitions for improving parsing algorithms. In this paper, we present DAViewer, an interactive visualization system for assisting computational linguistics researchers to explore, compare, evaluate and annotate the results of discourse parsers. An iterative user-centered design process with domain experts was conducted in the development of DAViewer. We report the results of an informal formative study of the system to better understand how the proposed visualization and interaction techniques are used in the real research environment."}, {"color": "gray", "id": 777, "label": 777, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 777 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2012.236\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Xiaoru Yuan;Limei Che;Yifan Hu;Xin Zhang; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Intelligent Graph Layout Using Many Users\u0027 Input; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In this paper, we propose a new strategy for graph drawing utilizing layouts of many sub-graphs supplied by a large group of people in a crowd sourcing manner. We developed an algorithm based on Laplacian constrained distance embedding to merge subgraphs submitted by different users, while attempting to maintain the topological information of the individual input layouts. To facilitate collection of layouts from many people, a light-weight interactive system has been designed to enable convenient dynamic viewing, modification and traversing between layouts. Compared with other existing graph layout algorithms, our approach can achieve more aesthetic and meaningful layouts with high user preference."}, {"color": "gray", "id": 779, "label": 779, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 779 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2012.238\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Michael Zinsmaier;Ulrik Brandes;Oliver Deussen;Hendrik Strobelt; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Interactive Level-of-Detail Rendering of Large Graphs; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We propose a technique that allows straight-line graph drawings to be rendered interactively with adjustable level of detail. The approach consists of a novel combination of edge cumulation with density-based node aggregation and is designed to exploit common graphics hardware for speed. It operates directly on graph data and does not require precomputed hierarchies or meshes. As proof of concept, we present an implementation that scales to graphs with millions of nodes and edges, and discuss several example applications."}, {"color": "gray", "id": 783, "label": 783, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 783 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2012.243\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Benjamin Schindler;Raphael Fuchs;Stefan Barp;J\u00fcrgen Waser;Armin Pobitzer;Robert Carnecky;Kre\u0161imir Matkovi\u0107;Ronald Peikert; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Lagrangian Coherent Structures for Design Analysis of Revolving Doors; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Room air flow and air exchange are important aspects for the design of energy-efficient buildings. As a result, simulations are increasingly used prior to construction to achieve an energy-efficient design. We present a visual analysis of air flow generated at building entrances, which uses a combination of revolving doors and air curtains. The resulting flow pattern is challenging because of two interacting flow patterns: On the one hand, the revolving door acts as a pump, on the other hand, the air curtain creates a layer of uniformly moving warm air between the interior of the building and the revolving door. Lagrangian coherent structures (LCS), which by definition are flow barriers, are the method of choice for visualizing the separation and recirculation behavior of warm and cold air flow. The extraction of LCS is based on the finite-time Lyapunov exponent (FTLE) and makes use of a ridge definition which is consistent with the concept of weak LCS. Both FTLE computation and ridge extraction are done in a robust and efficient way by making use of the fast Fourier transform for computing scale-space derivatives."}, {"color": "gray", "id": 788, "label": 788, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 788 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2012.250\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Arlind Nocaj;Ulrik Brandes; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Organizing Search Results with a Reference Map; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We propose a method to highlight query hits in hierarchically clustered collections of interrelated items such as digital libraries or knowledge bases. The method is based on the idea that organizing search results similarly to their arrangement on a fixed reference map facilitates orientation and assessment by preserving a user\u0027s mental map. Here, the reference map is built from an MDS layout of the items in a Voronoi treemap representing their hierarchical clustering, and we use techniques from dynamic graph layout to align query results with the map. The approach is illustrated on an archive of newspaper articles."}, {"color": "gray", "id": 789, "label": 789, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 789 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2012.251\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Anastasia Bezerianos;Petra Isenberg; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Perception of Visual Variables on Tiled Wall-Sized Displays for Information Visualization Applications; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present the results of two user studies on the perception of visual variables on tiled high-resolution wall-sized displays. We contribute an understanding of, and indicators predicting how, large variations in viewing distances and viewing angles affect the accurate perception of angles, areas, and lengths. Our work, thus, helps visualization researchers with design considerations on how to create effective visualizations for these spaces. The first study showed that perception accuracy was impacted most when viewers were close to the wall but differently for each variable (Angle, Area, Length). Our second study examined the effect of perception when participants could move freely compared to when they had a static viewpoint. We found that a far but static viewpoint was as accurate but less time consuming than one that included free motion. Based on our findings, we recommend encouraging viewers to stand further back from the display when conducting perception estimation tasks. If tasks need to be conducted close to the wall display, important information should be placed directly in front of the viewer or above, and viewers should be provided with an estimation of the distortion effects predicted by our work-or encouraged to physically navigate the wall in specific ways to reduce judgement error."}, {"color": "gray", "id": 791, "label": 791, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 791 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2012.253\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Conglei Shi;Weiwei Cui;Shixia Liu;Panpan Xu;Wei Chen;Huamin Qu; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: RankExplorer: Visualization of Ranking Changes in Large Time Series Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: For many applications involving time series data, people are often interested in the changes of item values over time as well as their ranking changes. For example, people search many words via search engines like Google and Bing every day. Analysts are interested in both the absolute searching number for each word as well as their relative rankings. Both sets of statistics may change over time. For very large time series data with thousands of items, how to visually present ranking changes is an interesting challenge. In this paper, we propose RankExplorer, a novel visualization method based on ThemeRiver to reveal the ranking changes. Our method consists of four major components: 1) a segmentation method which partitions a large set of time series curves into a manageable number of ranking categories; 2) an extended ThemeRiver view with embedded color bars and changing glyphs to show the evolution of aggregation values related to each ranking category over time as well as the content changes in each ranking category; 3) a trend curve to show the degree of ranking changes over time; 4) rich user interactions to support interactive exploration of ranking changes. We have applied our method to some real time series data and the case studies demonstrate that our method can reveal the underlying patterns related to ranking changes which might otherwise be obscured in traditional visualizations."}, {"color": "gray", "id": 797, "label": 797, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 797 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2012.260\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Alex Endert;Patrick Fiaux;Chris North; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Semantic Interaction for Sensemaking: Inferring Analytical Reasoning for Model Steering; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Visual analytic tools aim to support the cognitively demanding task of sensemaking. Their success often depends on the ability to leverage capabilities of mathematical models, visualization, and human intuition through flexible, usable, and expressive interactions. Spatially clustering data is one effective metaphor for users to explore similarity and relationships between information, adjusting the weighting of dimensions or characteristics of the dataset to observe the change in the spatial layout. Semantic interaction is an approach to user interaction in such spatializations that couples these parametric modifications of the clustering model with users\u0027 analytic operations on the data (e.g., direct document movement in the spatialization, highlighting text, search, etc.). In this paper, we present results of a user study exploring the ability of semantic interaction in a visual analytic prototype, ForceSPIRE, to support sensemaking. We found that semantic interaction captures the analytical reasoning of the user through keyword weighting, and aids the user in co-creating a spatialization based on the user\u0027s reasoning and intuition."}, {"color": "gray", "id": 801, "label": 801, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 801 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2012.264\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Shehzad Afzal;Ross Maciejewski;Yun Jang;Niklas Elmqvist;David S. Ebert; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Spatial Text Visualization Using Automatic Typographic Maps; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present a method for automatically building typographic maps that merge text and spatial data into a visual representation where text alone forms the graphical features. We further show how to use this approach to visualize spatial data such as traffic density, crime rate, or demographic data. The technique accepts a vector representation of a geographic map and spatializes the textual labels in the space onto polylines and polygons based on user-defined visual attributes and constraints. Our sample implementation runs as a Web service, spatializing shape files from the OpenStreetMap project into typographic maps for any region."}, {"color": "gray", "id": 802, "label": 802, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 802 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2012.265\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Christian Tominski;Heidrun Schumann;Gennady Andrienko;Natalia Andrienko; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Stacking-Based Visualization of Trajectory Attribute Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Visualizing trajectory attribute data is challenging because it involves showing the trajectories in their spatio-temporal context as well as the attribute values associated with the individual points of trajectories. Previous work on trajectory visualization addresses selected aspects of this problem, but not all of them. We present a novel approach to visualizing trajectory attribute data. Our solution covers space, time, and attribute values. Based on an analysis of relevant visualization tasks, we designed the visualization solution around the principle of stacking trajectory bands. The core of our approach is a hybrid 2D/3D display. A 2D map serves as a reference for the spatial context, and the trajectories are visualized as stacked 3D trajectory bands along which attribute values are encoded by color. Time is integrated through appropriate ordering of bands and through a dynamic query mechanism that feeds temporally aggregated information to a circular time display. An additional 2D time graph shows temporal information in full detail by stacking 2D trajectory bands. Our solution is equipped with analytical and interactive mechanisms for selecting and ordering of trajectories, and adjusting the color mapping, as well as coordinated highlighting and dedicated 3D navigation. We demonstrate the usefulness of our novel visualization by three examples related to radiation surveillance, traffic analysis, and maritime navigation. User feedback obtained in a small experiment indicates that our hybrid 2D/3D solution can be operated quite well."}, {"color": "gray", "id": 804, "label": 804, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 804 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2012.269\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Samer S. Barakat;Markus R\u00fctten;Xavier Tricoche; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Surface-Based Structure Analysis and Visualization for Multifield Time-Varying Datasets; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: This paper introduces a new feature analysis and visualization method for multifield datasets. Our approach applies a surface-centric model to characterize salient features and form an effective, schematic representation of the data. We propose a simple, geometrically motivated, multifield feature definition. This definition relies on an iterative algorithm that applies existing theory of skeleton derivation to fuse the structures from the constitutive fields into a coherent data description, while addressing noise and spurious details. This paper also presents a new method for non-rigid surface registration between the surfaces of consecutive time steps. This matching is used in conjunction with clustering to discover the interaction patterns between the different fields and their evolution over time. We document the unified visual analysis achieved by our method in the context of several multifield problems from large-scale time-varying simulations."}, {"color": "gray", "id": 807, "label": 807, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 807 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2012.273\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Margit Pohl;Michael Smuc;Eva Mayr; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: The User Puzzle---Explaining the Interaction with Visual Analytics Systems; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Visual analytics emphasizes the interplay between visualization, analytical procedures performed by computers and human perceptual and cognitive activities. Human reasoning is an important element in this context. There are several theories in psychology and HCI explaining open-ended and exploratory reasoning. Five of these theories (sensemaking theories, gestalt theories, distributed cognition, graph comprehension theories and skill-rule-knowledge models) are described in this paper. We discuss their relevance for visual analytics. In order to do this more systematically, we developed a schema of categories relevant for visual analytics research and evaluation. All these theories have strengths but also weaknesses in explaining interaction with visual analytics systems. A possibility to overcome the weaknesses would be to combine two or more of these theories."}, {"color": "gray", "id": 812, "label": 812, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 812 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2012.278\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Joerg Meyer;Glenn Taylor;Ben Torkian;Timothy C. Johnson;Ian Gorton;E. Wes Bethel;Jennifer L. Horsman;Susan S. Hubbard;Harinarayan Krishnan;Alexandru Romosan;Elizabeth H. Keating;Laura Monroe;Richard Strelitz;Phil Moore; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visual Data Analysis as an Integral Part of Environmental Management; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The U.S. Department of Energy\u0027s (DOE) Office of Environmental Management (DOE/EM) currently supports an effort to understand and predict the fate of nuclear contaminants and their transport in natural and engineered systems. Geologists, hydrologists, physicists and computer scientists are working together to create models of existing nuclear waste sites, to simulate their behavior and to extrapolate it into the future. We use visualization as an integral part in each step of this process. In the first step, visualization is used to verify model setup and to estimate critical parameters. High-performance computing simulations of contaminant transport produces massive amounts of data, which is then analyzed using visualization software specifically designed for parallel processing of large amounts of structured and unstructured data. Finally, simulation results are validated by comparing simulation results to measured current and historical field data. We describe in this article how visual analysis is used as an integral part of the decision-making process in the planning of ongoing and future treatment options for the contaminated nuclear waste sites. Lessons learned from visually analyzing our large-scale simulation runs will also have an impact on deciding on treatment measures for other contaminated sites."}, {"color": "gray", "id": 814, "label": 814, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 814 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2012.280\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Daniel Engel;Klaus Greff;Christoph Garth;Keith Bein;Anthony Wexler;Bernd Hamann;Hans Hagen; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visual Steering and Verification of Mass Spectrometry Data Factorization in Air Quality Research; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The study of aerosol composition for air quality research involves the analysis of high-dimensional single particle mass spectrometry data. We describe, apply, and evaluate a novel interactive visual framework for dimensionality reduction of such data. Our framework is based on non-negative matrix factorization with specifically defined regularization terms that aid in resolving mass spectrum ambiguity. Thereby, visualization assumes a key role in providing insight into and allowing to actively control a heretofore elusive data processing step, and thus enabling rapid analysis meaningful to domain scientists. In extending existing black box schemes, we explore design choices for visualizing, interacting with, and steering the factorization process to produce physically meaningful results. A domain-expert evaluation of our system performed by the air quality research experts involved in this effort has shown that our method and prototype admits the finding of unambiguous and physically correct lower-dimensional basis transformations of mass spectrometry data at significantly increased speed and a higher degree of ease."}, {"color": "gray", "id": 815, "label": 815, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 815 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2012.281\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Stephan Wenger;Marco Ament;Stefan Guthe;Dirk Lorenz;Andreas Tillmann;Daniel Weiskopf;Marcus Magnor; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visualization of Astronomical Nebulae via Distributed Multi-GPU Compressed Sensing Tomography; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The 3D visualization of astronomical nebulae is a challenging problem since only a single 2D projection is observable from our fixed vantage point on Earth. We attempt to generate plausible and realistic looking volumetric visualizations via a tomographic approach that exploits the spherical or axial symmetry prevalent in some relevant types of nebulae. Different types of symmetry can be implemented by using different randomized distributions of virtual cameras. Our approach is based on an iterative compressed sensing reconstruction algorithm that we extend with support for position-dependent volumetric regularization and linear equality constraints. We present a distributed multi-GPU implementation that is capable of reconstructing high-resolution datasets from arbitrary projections. Its robustness and scalability are demonstrated for astronomical imagery from the Hubble Space Telescope. The resulting volumetric data is visualized using direct volume rendering. Compared to previous approaches, our method preserves a much higher amount of detail and visual variety in the 3D visualization, especially for objects with only approximate symmetry."}, {"color": "gray", "id": 818, "label": 818, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 818 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2012.284\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Steffen Frey;Filip Sadlo;Thomas Ertl; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visualization of Temporal Similarity in field Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: This paper presents a visualization approach for detecting and exploring similarity in the temporal variation of field data. We provide an interactive technique for extracting correlations from similarity matrices which capture temporal similarity of univariate functions. We make use of the concept to extract periodic and quasiperiodic behavior at single (spatial) points as well as similarity between different locations within a field and also between different data sets. The obtained correlations are utilized for visual exploration of both temporal and spatial relationships in terms of temporal similarity. Our entire pipeline offers visual interaction and inspection, allowing for the flexibility that in particular time-dependent data analysis techniques require. We demonstrate the utility and versatility of our approach by applying our implementation to data from both simulation and measurement."}, {"color": "gray", "id": 820, "label": 820, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 820 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2012.286\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Aaditya G. Landge;Joshua A. Levine;Abhinav Bhatele;Katherine E. Isaacs;Todd Gamblin;Martin Schulz;Steve H. Langer;Peer-Timo Bremer;Valerio Pascucci; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visualizing Network Traffic to Understand the Performance of Massively Parallel Simulations; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The performance of massively parallel applications is often heavily impacted by the cost of communication among compute nodes. However, determining how to best use the network is a formidable task, made challenging by the ever increasing size and complexity of modern supercomputers. This paper applies visualization techniques to aid parallel application developers in understanding the network activity by enabling a detailed exploration of the flow of packets through the hardware interconnect. In order to visualize this large and complex data, we employ two linked views of the hardware network. The first is a 2D view, that represents the network structure as one of several simplified planar projections. This view is designed to allow a user to easily identify trends and patterns in the network traffic. The second is a 3D view that augments the 2D view by preserving the physical network topology and providing a context that is familiar to the application developers. Using the massively parallel multi-physics code pF3D as a case study, we demonstrate that our tool provides valuable insight that we use to explain and optimize pF3D\u0027s performance on an IBM Blue Gene/P system."}, {"color": "gray", "id": 821, "label": 821, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 821 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2012.287\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: David Duke;Hamish Carr;Aaron Knoll;Nicolas Schunck;Hai Ah Nam;Andrzej Staszczak; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visualizing Nuclear Scission through a Multifield Extension of Topological Analysis; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In nuclear science, density functional theory (DFT) is a powerful tool to model the complex interactions within the atomic nucleus, and is the primary theoretical approach used by physicists seeking a better understanding of fission. However DFT simulations result in complex multivariate datasets in which it is difficult to locate the crucial `scission\u0027 point at which one nucleus fragments into two, and to identify the precursors to scission. The Joint Contour Net (JCN) has recently been proposed as a new data structure for the topological analysis of multivariate scalar fields, analogous to the contour tree for univariate fields. This paper reports the analysis of DFT simulations using the JCN, the first application of the JCN technique to real data. It makes three contributions to visualization: (i) a set of practical methods for visualizing the JCN, (ii) new insight into the detection of nuclear scission, and (iii) an analysis of aesthetic criteria to drive further work on representing the JCN."}, {"color": "gray", "id": 822, "label": 822, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 822 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2012.288\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: David Trimm;Penny Rheingans;Marie desJardins; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visualizing Student Histories Using Clustering and Composition; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: While intuitive time-series visualizations exist for common datasets, student course history data is difficult to represent using traditional visualization techniques due its concurrent nature. A visual composition process is developed and applied to reveal trends across various groupings. By working closely with educators, analytic strategies and techniques are developed to leverage the visualization composition to reveal unknown trends in the data. Furthermore, clustering algorithms are developed to group common course-grade histories for further analysis. Lastly, variations of the composition process are implemented to reveal subtle differences in the underlying data. These analytic tools and techniques enabled educators to confirm expected trends and to discover new ones."}, {"color": "gray", "id": 825, "label": 825, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 825 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2012.6400484\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Magdalena Jankowska;Vlado Ke\u0161elj;Evangelos Milios; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Relative N-gram signatures: Document visualization at the level of character N-grams; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The Common N-Gram (CNG) classifier is a text classification algorithm based on the comparison of frequencies of character n-grams (strings of characters of length n) that are the most common in the considered documents and classes of documents. We present a text analytic visualization system that employs the CNG approach for text classification and uses the differences in frequency values of common n-grams in order to visually compare documents at the sub-word level. The visualization method provides both an insight into n-gram characteristics of documents or classes of documents and a visual interpretation of the workings of the CNG classifier."}, {"color": "gray", "id": 826, "label": 826, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 826 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2012.6400485\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Wenwen Dou;Xiaoyu Wang;Drew Skau;William Ribarsky;Michelle X. Zhou; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: LeadLine: Interactive visual analysis of text data through event identification and exploration; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Text data such as online news and microblogs bear valuable insights regarding important events and responses to such events. Events are inherently temporal, evolving over time. Existing visual text analysis systems have provided temporal views of changes based on topical themes extracted from text data. But few have associated topical themes with events that cause the changes. In this paper, we propose an interactive visual analytics system, LeadLine, to automatically identify meaningful events in news and social media data and support exploration of the events. To characterize events, LeadLine integrates topic modeling, event detection, and named entity recognition techniques to automatically extract information regarding the investigative 4 Ws: who, what, when, and where for each event. To further support analysis of the text corpora through events, LeadLine allows users to interactively examine meaningful events using the 4 Ws to develop an understanding of how and why. Through representing large-scale text corpora in the form of meaningful events, LeadLine provides a concise summary of the corpora. LeadLine also supports the construction of simple narratives through the exploration of events. To demonstrate the efficacy of LeadLine in identifying events and supporting exploration, two case studies were conducted using news and social media data."}, {"color": "gray", "id": 830, "label": 830, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 830 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2012.6400489\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Elisa Portes dos Santos Amorim;Emilio Vital Brazil;Joel Daniels;Paulo Joia;Luis Gustavo Nonato;Mario Costa Sousa; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: iLAMP: Exploring high-dimensional spacing through backward multidimensional projection; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Ever improving computing power and technological advances are greatly augmenting data collection and scientific observation. This has directly contributed to increased data complexity and dimensionality, motivating research of exploration techniques for multidimensional data. Consequently, a recent influx of work dedicated to techniques and tools that aid in understanding multidimensional datasets can be observed in many research fields, including biology, engineering, physics and scientific computing. While the effectiveness of existing techniques to analyze the structure and relationships of multidimensional data varies greatly, few techniques provide flexible mechanisms to simultaneously visualize and actively explore high-dimensional spaces. In this paper, we present an inverse linear affine multidimensional projection, coined iLAMP, that enables a novel interactive exploration technique for multidimensional data. iLAMP operates in reverse to traditional projection methods by mapping low-dimensional information into a high-dimensional space. This allows users to extrapolate instances of a multidimensional dataset while exploring a projection of the data to the planar domain. We present experimental results that validate iLAMP, measuring the quality and coherence of the extrapolated data; as well as demonstrate the utility of iLAMP to hypothesize the unexplored regions of a high-dimensional space."}, {"color": "gray", "id": 831, "label": 831, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 831 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2012.6400490\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Anushka Anand;Leland Wilkinson;Tuan Nhon Dang; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visual pattern discovery using random projections; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: An essential element of exploratory data analysis is the use of revealing low-dimensional projections of high-dimensional data. Projection Pursuit has been an effective method for finding interesting low-dimensional projections of multidimensional spaces by optimizing a score function called a projection pursuit index. However, the technique is not scalable to high-dimensional spaces. Here, we introduce a novel method for discovering noteworthy views of high-dimensional data spaces by using binning and random projections. We define score functions, akin to projection pursuit indices, that characterize visual patterns of the low-dimensional projections that constitute feature subspaces. We also describe an analytic, multivariate visualization platform based on this algorithm that is scalable to extremely large problems."}, {"color": "gray", "id": 832, "label": 832, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 832 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2012.6400491\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Abish Malik;Ross Maciejewski;Niklas Elmqvist;Yun Jang;David S. Ebert;Whitney Huang; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: A correlative analysis process in a visual analytics environment; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Finding patterns and trends in spatial and temporal datasets has been a long studied problem in statistics and different domains of science. This paper presents a visual analytics approach for the interactive exploration and analysis of spatiotemporal correlations among multivariate datasets. Our approach enables users to discover correlations and explore potentially causal or predictive links at different spatiotemporal aggregation levels among the datasets, and allows them to understand the underlying statistical foundations that precede the analysis. Our technique utilizes the Pearson\u0027s product-moment correlation coefficient and factors in the lead or lag between different datasets to detect trends and periodic patterns amongst them."}, {"color": "gray", "id": 836, "label": 836, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 836 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2012.6400530\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Ravikiran Vadlapudi;Maryam Siahbani;Anoop Sarkar;John Dill; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: LensingWikipedia: Parsing text for the interactive visualization of human history; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Extracting information from text is challenging. Most current practices treat text as a bag of words or word clusters, ignoring valuable linguistic information. Leveraging this linguistic information, we propose a novel approach to visualize textual information. The novelty lies in using state-of-the-art Natural Language Processing (NLP) tools to automatically annotate text which provides a basis for new and powerful interactive visualizations. Using NLP tools, we built a web-based interactive visual browser for human history articles from Wikipedia."}, {"color": "gray", "id": 838, "label": 838, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 838 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2012.6400532\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jay Takle;Deborah Silver;Katrin Heitmann; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: A case study: Tracking and visualizing the evolution of dark matter halos and groups of satellite halos in cosmology simulations; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In this poster, we track the evolution of cosmic structures and higher level host structures in cosmological simulation as they interact with each other. The structures found in these simulations are made up of groups of dark matter tracer particles called satellite halos and groups of satellite halos called host halos. We implement a multilevel tracking model to track dark matter tracer particles, satellite halos and host halos to understand their behaviour and show how the different structures are formed over time. We also represent the evolution of halos in the form of merger trees for detailed analysis by cosmologists."}, {"color": "gray", "id": 846, "label": 846, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 846 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2012.6400540\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Lane Harrison;Remco Chang;Aidong Lu; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Exploring the impact of emotion on visual judgement; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Existing research suggests that individual personality differences can influence performance with visualizations. In addition to stable traits such as locus of control, research in psychology has found that temporary changes in affect (emotion) can significantly impact individual performance on cognitive tasks. We examine the relationship between fundamental visual judgement tasks and affect through a crowdsourced user study that combines affective-priming techniques from psychology with longstanding graphical perception experiments. Our results suggest that affective-priming can significantly influence accuracy in visual judgements, and that some chart types may be more affected than others."}, {"color": "gray", "id": 848, "label": 848, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 848 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2012.6400542\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Hua Guo;Diem Tran;David H. Laidlaw; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Incorporating GOMS analysis into the design of an EEG data visual analysis tool; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In this paper, we present a case study where we incorporate GOMS (Goals, Operators, Methods, and Selectors) [2] task analysis into the design process of a visual analysis tool. We performed GOMS analysis on an Electroencephalography (EEG) analyst\u0027s current data analysis strategy to identify important user tasks and unnecessary user actions in his current workflow. We then designed an EEG data visual analysis tool based on the GOMS analysis result. Evaluation results show that the tool we have developed, EEGVis, allows the user to analyze EEG data with reduced subjective cognitive load, faster speed and increased confidence in the analysis quality. The positive evaluation results suggest that our design process demonstrates an effective application of GOMS analysis to discover opportunities for designing better tools to support the user\u0027s visual analysis process."}, {"color": "gray", "id": 849, "label": 849, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 849 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2012.6400543\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Tera Marie Green;Brian Fisher; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Using translational science in visual analytics; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We introduce translational science, a research discipline from medicine, and show how adapting it for visual analytics can improve the design and evaluation of visual analytics interfaces. Translational science \u201ctranslates\u201d knowledge from the lab to the real-world to \u201cground truth\u201d by incorporating a 3 phase program of research. Phase 1 \u0026amp; 2 include protocols for research in the lab and field and Phase 3 focuses on dissemination and documentation. We discuss these phases and how they may be applied to visual analytics research."}, {"color": "gray", "id": 854, "label": 854, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 854 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2012.6400548\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Ian Bowman;Shantanu H. Joshi;Vaughan Greer;John Darrell Van Horn; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Feature-similarity visualization of MRI cortical surface data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present an analytics-based framework for simultaneous visualization of large surface data collections arising in clinical neuroimaging studies. Termed Informatics Visualization for Neuroimaging (INVIZIAN), this framework allows the visualization of both cortical surfaces characteristics and feature relatedness in unison. It also uses dimension reduction methods to derive new coordinate systems using a Jensen-Shannon divergence metric for positioning cortical surfaces in a metric space such that the proximity in location is proportional to neuroanatomical similarity. Feature data such as thickness and volume are colored on the cortical surfaces and used to display both subject-specific feature values and global trends within the population. Additionally, a query-based framework allows the neuroscience researcher to investigate probable correlations between neuroanatomical and subject patient attribute values such as age and diagnosis."}, {"color": "gray", "id": 855, "label": 855, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 855 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2012.6400549\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Michael Behrisch;James Davey;Tobias Schreck;Daniel Keim;J\u00f6rn Kohlhammer; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Matrix-based visual correlation analysis on large timeseries data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In recent years, the quantity of time series data generated in a wide variety of domains grown consistently. Thus, it is difficult for analysts to process and understand this overwhelming amount of data. In the specific case of time series data another problem arises: time series can be highly interrelated. This problem becomes even more challenging when a set of parameters influences the progression of a time series. However, while most visual analysis techniques support the analysis of short time periods, e.g. one day or one week, they fail to visualize large-scale time series, ranging over one year or more. In our approach we present a time series matrix visualization that tackles this problem. Its primary advantages are that it scales to a large number of time series with different start and end points and allows for the visual comparison / correlation analysis of a set of influencing factors. To evaluate our approach, we applied our technique to a real-world data set, showing the impact of local weather conditions on the efficiency of photovoltaic power plants."}, {"color": "gray", "id": 857, "label": 857, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 857 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2012.6400551\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Marco Angelini;Nicola Ferro;Guido Granato;Guiseppe Santucci;Gianmaria Silvello; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Information retrieval failure analysis: Visual analytics as a support for interactive \"what-if\" investigation; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: This poster provides an analytical model for examining performances of IR systems, based on the discounted cumulative gain family of metrics, and visualization for interacting and exploring the performances of the system under examination. Moreover, we propose machine learning approach to learn the ranking model of the examined system in order to be able to conduct a \u201cwhat-if\u201d analysis and visually explore what can happen if you adopt a given solution before having to actually implement it."}, {"color": "gray", "id": 859, "label": 859, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 859 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2012.6400553\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: T. von Landesberger;Sebastian Bremm;Natalia Andrienko;Gennady Andrienko;M\u00e1ria Teku\u0161ov\u00e1; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visual analytics methods for categoric spatio-temporal data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We focus on visual analysis of space- and time-referenced categorical data, which describe possible states of spatial (geographical) objects or locations and their changes over time. The analysis of these data is difficult as there are only limited possibilities to analyze the three aspects (location, time and category) simultaneously. We present a new approach which interactively combines (a) visualization of categorical changes over time; (b) various spatial data displays; (c) computational techniques for task-oriented selection of time steps. They provide an expressive visualization with regard to either the overall evolution over time or unusual changes. We apply our approach on two use cases demonstrating its usefulness for a wide variety of tasks. We analyze data from movement tracking and meteorologic areas. Using our approach, expected events could be detected and new insights were gained."}, {"color": "gray", "id": 860, "label": 860, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 860 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2012.6400554\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Leishi Zhang;Andreas Stoffel;Michael Behrisch;Sebastian Mittelstadt;Tobias Schreck;Ren\u00e9 Pompl;Stefan Weber;Holger Last;Daniel Keim; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visual analytics for the big data era---A comparative review of state-of-the-art commercial systems; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Visual analytics (VA) system development started in academic research institutions where novel visualization techniques and open source toolkits were developed. Simultaneously, small software companies, sometimes spin-offs from academic research institutions, built solutions for specific application domains. In recent years we observed the following trend: some small VA companies grew exponentially; at the same time some big software vendors such as IBM and SAP started to acquire successful VA companies and integrated the acquired VA components into their existing frameworks. Generally the application domains of VA systems have broadened substantially. This phenomenon is driven by the generation of more and more data of high volume and complexity, which leads to an increasing demand for VA solutions from many application domains. In this paper we survey a selection of state-of-the-art commercial VA frameworks, complementary to an existing survey on open source VA tools. From the survey results we identify several improvement opportunities as future research directions."}, {"color": "gray", "id": 861, "label": 861, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 861 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2012.6400555\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Gabriel Mistelbauer;Arnold K\u00f6chl;Rudiger Schernthaner;Ivan Baclija;R\u00fcdiger Schernthaner;Stefan Bruckner;Milos Sramek;Meister Eduard Gr\u00f6ller; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Smart super views---A knowledge-assisted interface for medical visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Due to the ever growing volume of acquired data and information, users have to be constantly aware of the methods for their exploration and for interaction. Of these, not each might be applicable to the data at hand or might reveal the desired result. Owing to this, innovations may be used inappropriately and users may become skeptical. In this paper we propose a knowledge-assisted interface for medical visualization, which reduces the necessary effort to use new visualization methods, by providing only the most relevant ones in a smart way. Consequently, we are able to expand such a system with innovations without the users to worry about when, where, and especially how they may or should use them. We present an application of our system in the medical domain and give qualitative feedback from domain experts."}, {"color": "gray", "id": 862, "label": 862, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 862 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2012.6400556\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Harald Piringer;Matthias Buchetics;Rudolf Benedik; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: AlVis: Situation awareness in the surveillance of road tunnels; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In the surveillance of road tunnels, video data plays an important role for a detailed inspection and as an input to systems for an automated detection of incidents. In disaster scenarios like major accidents, however, the increased amount of detected incidents may lead to situations where human operators lose a sense of the overall meaning of that data, a problem commonly known as a lack of situation awareness. The primary contribution of this paper is a design study of AlVis, a system designed to increase situation awareness in the surveillance of road tunnels. The design of AlVis is based on a simplified tunnel model which enables an overview of the spatiotemporal development of scenarios in real-time. The visualization explicitly represents the present state, the history, and predictions of potential future developments. Concepts for situation-sensitive prioritization of information ensure scalability from normal operation to major disaster scenarios. The visualization enables an intuitive access to live and historic video for any point in time and space. We illustrate AlVis by means of a scenario and report qualitative feedback by tunnel experts and operators. This feedback suggests that AlVis is suitable to save time in recognizing dangerous situations and helps to maintain an overview in complex disaster scenarios."}, {"color": "gray", "id": 863, "label": 863, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 863 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2012.6400557\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Junghoon Chae;Dennis Thom;Harald Bosch;Yun Jang;Ross Maciejewski;David S. Ebert;Thomas Ertl; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Spatiotemporal social media analytics for abnormal event detection and examination using seasonal-trend decomposition; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Recent advances in technology have enabled social media services to support space-time indexed data, and internet users from all over the world have created a large volume of time-stamped, geo-located data. Such spatiotemporal data has immense value for increasing situational awareness of local events, providing insights for investigations and understanding the extent of incidents, their severity, and consequences, as well as their time-evolving nature. In analyzing social media data, researchers have mainly focused on finding temporal trends according to volume-based importance. Hence, a relatively small volume of relevant messages may easily be obscured by a huge data set indicating normal situations. In this paper, we present a visual analytics approach that provides users with scalable and interactive social media data analysis and visualization including the exploration and examination of abnormal topics and events within various social media data sources, such as Twitter, Flickr and YouTube. In order to find and understand abnormal events, the analyst can first extract major topics from a set of selected messages and rank them probabilistically using Latent Dirichlet Allocation. He can then apply seasonal trend decomposition together with traditional control chart methods to find unusual peaks and outliers within topic time series. Our case studies show that situational awareness can be improved by incorporating the anomaly and trend examination techniques into a highly interactive visual analysis process."}, {"color": "gray", "id": 864, "label": 864, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 864 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2012.6400558\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Liang Gou;Xiaolong Zhang;Airong Luo;Patricia F. Anderson; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: SocialNetSense: Supporting sensemaking of social and structural features in networks with interactive visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Increasingly, social network datasets contain social attribute information about actors and their relationship. Analyzing such network with social attributes requires making sense of not only its structural features, but also the relationship between social features in attributes and network structures. Existing social network analysis tools are usually weak in supporting complex analytical tasks involving both structural and social features, and often overlook users\u0027 needs for sensemaking tools that help to gather, synthesize, and organize information of these features. To address these challenges, we propose a sensemaking framework of social-network visual analytics in this paper. This framework considers both bottom-up processes, which are about constructing new understandings based on collected information, and top-down processes, which concern using prior knowledge to guide information collection, in analyzing social networks from both social and structural perspectives. The framework also emphasizes the externalization of sensemaking processes through interactive visualization. Guided by the framework, we develop a system, SocialNetSense, to support the sensemaking in visual analytics of social networks with social attributes. The example of using our system to analyze a scholar collaboration network shows that our approach can help users gain insight into social networks both structurally and socially, and enhance their process awareness in visual analytics."}, {"color": "gray", "id": 866, "label": 866, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 866 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2012.6400560\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Patrick Butler;Prithwish Chakraborty;Naren Ramakrishan; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: The Deshredder: A visual analytic approach to reconstructing shredded documents; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Reconstruction of shredded documents remains a significant challenge. Creating a better document reconstruction system enables not just recovery of information accidentally lost but also understanding our limitations against adversaries\u0027 attempts to gain access to information. Existing approaches to reconstructing shredded documents adopt either a predominantly manual (e.g., crowd-sourcing) or a near automatic approach. We describe Deshredder, a visual analytic approach that scales well and effectively incorporates user input to direct the reconstruction process. Deshredder represents shredded pieces as time series and uses nearest neighbor matching techniques that enable matching both the contours of shredded pieces as well as the content of shreds themselves. More importantly, Deshred-der\u0027s interface support visual analytics through user interaction with similarity matrices as well as higher level assembly through more complex stitching functions. We identify a functional task taxonomy leading to design considerations for constructing deshredding solutions, and describe how Deshredder applies to problems from the DARPA Shredder Challenge through expert evaluations."}, {"color": "gray", "id": 871, "label": 871, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 871 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.123\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Wei-Hsien Hsu;Yubo Zhang;Kwan-Liu Ma; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: A Multi-Criteria Approach to Camera Motion Design for Volume Data Animation; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present an integrated camera motion design and path generation system for building volume data animations. Creating animations is an essential task in presenting complex scientific visualizations. Existing visualization systems use an established animation function based on keyframes selected by the user. This approach is limited in providing the optimal in-between views of the data. Alternatively, computer graphics and virtual reality camera motion planning is frequently focused on collision free movement in a virtual walkthrough. For semi-transparent, fuzzy, or blobby volume data the collision free objective becomes insufficient. Here, we provide a set of essential criteria focused on computing camera paths to establish effective animations of volume data. Our dynamic multi-criteria solver coupled with a force-directed routing algorithm enables rapid generation of camera paths. Once users review the resulting animation and evaluate the camera motion, they are able to determine how each criterion impacts path generation. In this paper, we demonstrate how incorporating this animation approach with an interactive volume visualization system reduces the effort in creating context-aware and coherent animations. This frees the user to focus on visualization tasks with the objective of gaining additional insight from the volume data."}, {"color": "gray", "id": 872, "label": 872, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 872 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.124\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Matthew Brehmer;Tamara Munzner; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: A Multi-Level Typology of Abstract Visualization Tasks; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The considerable previous work characterizing visualization usage has focused on low-level tasks or interactions and high-level tasks, leaving a gap between them that is not addressed. This gap leads to a lack of distinction between the ends and means of a task, limiting the potential for rigorous analysis. We contribute a multi-level typology of visualization tasks to address this gap, distinguishing why and how a visualization task is performed, as well as what the task inputs and outputs are. Our typology allows complex tasks to be expressed as sequences of interdependent simpler tasks, resulting in concise and flexible descriptions for tasks of varying complexity and scope. It provides abstract rather than domain-specific descriptions of tasks, so that useful comparisons can be made between visualization systems targeted at different application domains. This descriptive power supports a level of analysis required for the generation of new designs, by guiding the translation of domain-specific problems into abstract tasks, and for the qualitative evaluation of visualization usage. We demonstrate the benefits of our approach in a detailed case study, comparing task descriptions from our typology to those derived from related work. We also discuss the similarities and differences between our typology and over two dozen extant classification systems and theoretical frameworks from the literatures of visualization, human-computer interaction, information retrieval, communications, and cartography."}, {"color": "gray", "id": 876, "label": 876, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 876 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.128\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Samer S. Barakat;Xavier Tricoche; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Adaptive Refinement of the Flow Map Using Sparse Samples; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present a new efficient and scalable method for the high quality reconstruction of the flow map from sparse samples. The flow map describes the transport of massless particles along the flow. As such, it is a fundamental concept in the analysis of transient flow phenomena and all so-called Lagrangian flow visualization techniques require its approximation. The flow map is generally obtained by integrating a dense 1D, 2D, or 3D set of particles across the domain of definition of the flow. Despite its embarrassingly parallel nature, this computation creates a performance bottleneck in the analysis of large-scale datasets that existing adaptive techniques alleviate only partially. Our iterative approximation method significantly improves upon the state of the art by precisely modeling the flow behavior around automatically detected geometric structures embedded in the flow, thus effectively restricting the sampling effort to interesting regions. Our data reconstruction is based on a modified version of Sibson\u0027s scattered data interpolation and allows us at each step to offer an intermediate dense approximation of the flow map and to seamlessly integrate regions that will be further refined in subsequent steps. We present a quantitative and qualitative evaluation of our method on different types of flow datasets and offer a detailed comparison with existing techniques."}, {"color": "gray", "id": 877, "label": 877, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 877 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.129\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Marco Ament;Filip Sadlo;Daniel Weiskopf; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Ambient Volume Scattering; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present ambient scattering as a preintegration method for scattering on mesoscopic scales in direct volume rendering. Far-range scattering effects usually provide negligible contributions to a given location due to the exponential attenuation with increasing distance. This motivates our approach to preintegrating multiple scattering within a finite spherical region around any given sample point. To this end, we solve the full light transport with a Monte-Carlo simulation within a set of spherical regions, where each region may have different material parameters regarding anisotropy and extinction. This precomputation is independent of the data set and the transfer function, and results in a small preintegration table. During rendering, the look-up table is accessed for each ray sample point with respect to the viewing direction, phase function, and material properties in the spherical neighborhood of the sample. Our rendering technique is efficient and versatile because it readily fits in existing ray marching algorithms and can be combined with local illumination and volumetric ambient occlusion. It provides interactive volumetric scattering and soft shadows, with interactive control of the transfer function, anisotropy parameter of the phase function, lighting conditions, and viewpoint. A GPU implementation demonstrates the benefits of ambient scattering for the visualization of different types of data sets, with respect to spatial perception, high-quality illumination, translucency, and rendering speed."}, {"color": "gray", "id": 880, "label": 880, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 880 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.132\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Rick Walker;Aiden Slingsby;Jason Dykes;Kai Xu;Jo Wood;Phong H. Nguyen;Derek Stephens;B.L. William Wong;Yongjun Zheng; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: An Extensible Framework for Provenance in Human Terrain Visual Analytics; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We describe and demonstrate an extensible framework that supports data exploration and provenance in the context of Human Terrain Analysis (HTA). Working closely with defence analysts we extract requirements and a list of features that characterise data analysed at the end of the HTA chain. From these, we select an appropriate non-classified data source with analogous features, and model it as a set of facets. We develop ProveML, an XML-based extension of the Open Provenance Model, using these facets and augment it with the structures necessary to record the provenance of data, analytical process and interpretations. Through an iterative process, we develop and refine a prototype system for Human Terrain Visual Analytics (HTVA), and demonstrate means of storing, browsing and recalling analytical provenance and process through analytic bookmarks in ProveML. We show how these bookmarks can be combined to form narratives that link back to the live data. Throughout the process, we demonstrate that through structured workshops, rapid prototyping and structured communication with intelligence analysts we are able to establish requirements, and design schema, techniques and tools that meet the requirements of the intelligence community. We use the needs and reactions of defence analysts in defining and steering the methods to validate the framework."}, {"color": "gray", "id": 883, "label": 883, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 883 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.135\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Xin Zhao;Zhengyu Su;Xianfeng David Gu;Arie Kaufman;Jian Sun;Jie Gao;Feng Luo; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Area-Preservation Mapping using Optimal Mass Transport; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present a novel area-preservation mapping/flattening method using the optimal mass transport technique, based on the Monge-Brenier theory. Our optimal transport map approach is rigorous and solid in theory, efficient and parallel in computation, yet general for various applications. By comparison with the conventional Monge-Kantorovich approach, our method reduces the number of variables from O(n\u0026lt;sup\u0026gt;2\u0026lt;/sup\u0026gt;) to O(n), and converts the optimal mass transport problem to a convex optimization problem, which can now be efficiently carried out by Newton\u0027s method. Furthermore, our framework includes the area weighting strategy that enables users to completely control and adjust the size of areas everywhere in an accurate and quantitative way. Our method significantly reduces the complexity of the problem, and improves the efficiency, flexibility and scalability during visualization. Our framework, by combining conformal mapping and optimal mass transport mapping, serves as a powerful tool for a broad range of applications in visualization and graphics, especially for medical imaging. We provide a variety of experimental results to demonstrate the efficiency, robustness and efficacy of our novel framework."}, {"color": "gray", "id": 884, "label": 884, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 884 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.137\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Eirik Bakke;David R. Karger;Robert C. Miller; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Automatic Layout of Structured Hierarchical Reports; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Domain-specific database applications tend to contain a sizable number of table-, form-, and report-style views that must each be designed and maintained by a software developer. A significant part of this job is the necessary tweaking of low-level presentation details such as label placements, text field dimensions, list or table styles, and so on. In this paper, we present a horizontally constrained layout management algorithm that automates the display of structured hierarchical data using the traditional visual idioms of hand-designed database UIs: tables, multi-column forms, and outline-style indented lists. We compare our system with pure outline and nested table layouts with respect to space efficiency and readability, the latter with an online user study on 27 subjects. Our layouts are 3.9 and 1.6 times more compact on average than outline layouts and horizontally unconstrained table layouts, respectively, and are as readable as table layouts even for large datasets."}, {"color": "gray", "id": 886, "label": 886, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 886 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.139\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Krishna Chaitanya Gurijala;Rui Shi;Wei Zeng;Xianfeng Gu;Arie Kaufman; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Colon Flattening Using Heat Diffusion Riemannian Metric; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We propose a new colon flattening algorithm that is efficient, shape-preserving, and robust to topological noise. Unlike previous approaches, which require a mandatory topological denoising to remove fake handles, our algorithm directly flattens the colon surface without any denoising. In our method, we replace the original Euclidean metric of the colon surface with a heat diffusion metric that is insensitive to topological noise. Using this heat diffusion metric, we then solve a Laplacian equation followed by an integration step to compute the final flattening. We demonstrate that our method is shape-preserving and the shape of the polyps are well preserved. The flattened colon also provides an efficient way to enhance the navigation and inspection in virtual colonoscopy. We further show how the existing colon registration pipeline is made more robust by using our colon flattening. We have tested our method on several colon wall surfaces and the experimental results demonstrate the robustness and the efficiency of our method."}, {"color": "gray", "id": 888, "label": 888, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 888 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.141\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Mathias Hummel;Harald Obermaier;Christoph Garth;Kenneth I. Joy; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Comparative Visual Analysis of Lagrangian Transport in CFD Ensembles; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Sets of simulation runs based on parameter and model variation, so-called ensembles, are increasingly used to model physical behaviors whose parameter space is too large or complex to be explored automatically. Visualization plays a key role in conveying important properties in ensembles, such as the degree to which members of the ensemble agree or disagree in their behavior. For ensembles of time-varying vector fields, there are numerous challenges for providing an expressive comparative visualization, among which is the requirement to relate the effect of individual flow divergence to joint transport characteristics of the ensemble. Yet, techniques developed for scalar ensembles are of little use in this context, as the notion of transport induced by a vector field cannot be modeled using such tools. We develop a Lagrangian framework for the comparison of flow fields in an ensemble. Our techniques evaluate individual and joint transport variance and introduce a classification space that facilitates incorporation of these properties into a common ensemble visualization. Variances of Lagrangian neighborhoods are computed using pathline integration and Principal Components Analysis. This allows for an inclusion of uncertainty measurements into the visualization and analysis approach. Our results demonstrate the usefulness and expressiveness of the presented method on several practical examples."}, {"color": "gray", "id": 890, "label": 890, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 890 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.143\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Ross T. Whitaker;Mahsa Mirzargar;Robert M. Kirby; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Contour Boxplots: A Method for Characterizing Uncertainty in Feature Sets from Simulation Ensembles; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Ensembles of numerical simulations are used in a variety of applications, such as meteorology or computational solid mechanics, in order to quantify the uncertainty or possible error in a model or simulation. Deriving robust statistics and visualizing the variability of an ensemble is a challenging task and is usually accomplished through direct visualization of ensemble members or by providing aggregate representations such as an average or pointwise probabilities. In many cases, the interesting quantities in a simulation are not dense fields, but are sets of features that are often represented as thresholds on physical or derived quantities. In this paper, we introduce a generalization of boxplots, called contour boxplots, for visualization and exploration of ensembles of contours or level sets of functions. Conventional boxplots have been widely used as an exploratory or communicative tool for data analysis, and they typically show the median, mean, confidence intervals, and outliers of a population. The proposed contour boxplots are a generalization of functional boxplots, which build on the notion of data depth. Data depth approximates the extent to which a particular sample is centrally located within its density function. This produces a center-outward ordering that gives rise to the statistical quantities that are essential to boxplots. Here we present a generalization of functional data depth to contours and demonstrate methods for displaying the resulting boxplots for two-dimensional simulation data in weather forecasting and computational fluid dynamics."}, {"color": "gray", "id": 891, "label": 891, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 891 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.144\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Hanqi Guo;Xiaoru Yuan;Jian Huang;Xiaomin Zhu; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Coupled Ensemble Flow Line Advection and Analysis; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Ensemble run simulations are becoming increasingly widespread. In this work, we couple particle advection with pathline analysis to visualize and reveal the differences among the flow fields of ensemble runs. Our method first constructs a variation field using a Lagrangian-based distance metric. The variation field characterizes the variation between vector fields of the ensemble runs, by extracting and visualizing the variation of pathlines within ensemble. Parallelism in a MapReduce style is leveraged to handle data processing and computing at scale. Using our prototype system, we demonstrate how scientists can effectively explore and investigate differences within ensemble simulations."}, {"color": "gray", "id": 893, "label": 893, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 893 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.146\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Bertjan Broeksema;Thomas Baudel;Alex Telea;Paolo Crisafulli; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Decision Exploration Lab: A Visual Analytics Solution for Decision Management; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present a visual analytics solution designed to address prevalent issues in the area of Operational Decision Management (ODM). In ODM, which has its roots in Artificial Intelligence (Expert Systems) and Management Science, it is increasingly important to align business decisions with business goals. In our work, we consider decision models (executable models of the business domain) as ontologies that describe the business domain, and production rules that describe the business logic of decisions to be made over this ontology. Executing a decision model produces an accumulation of decisions made over time for individual cases. We are interested, first, to get insight in the decision logic and the accumulated facts by themselves. Secondly and more importantly, we want to see how the accumulated facts reveal potential divergences between the reality as captured by the decision model, and the reality as captured by the executed decisions. We illustrate the motivation, added value for visual analytics, and our proposed solution and tooling through a business case from the car insurance industry."}, {"color": "gray", "id": 897, "label": 897, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 897 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.150\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Xiaoru Yuan;Donghao Ren;Zuchao Wang;Cong Guo; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Dimension Projection Matrix/Tree: Interactive Subspace Visual Exploration and Analysis of High Dimensional Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: For high-dimensional data, this work proposes two novel visual exploration methods to gain insights into the data aspect and the dimension aspect of the data. The first is a Dimension Projection Matrix, as an extension of a scatterplot matrix. In the matrix, each row or column represents a group of dimensions, and each cell shows a dimension projection (such as MDS) of the data with the corresponding dimensions. The second is a Dimension Projection Tree, where every node is either a dimension projection plot or a Dimension Projection Matrix. Nodes are connected with links and each child node in the tree covers a subset of the parent node\u0027s dimensions or a subset of the parent node\u0027s data items. While the tree nodes visualize the subspaces of dimensions or subsets of the data items under exploration, the matrix nodes enable cross-comparison between different combinations of subspaces. Both Dimension Projection Matrix and Dimension Project Tree can be constructed algorithmically through automation, or manually through user interaction. Our implementation enables interactions such as drilling down to explore different levels of the data, merging or splitting the subspaces to adjust the matrix, and applying brushing to select data clusters. Our method enables simultaneously exploring data correlation and dimension correlation for data with high dimensions."}, {"color": "gray", "id": 898, "label": 898, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 898 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.151\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Tim Dwyer;Nathalie Henry Riche;Kim Marriott;Christopher Mears; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Edge Compression Techniques for Visualization of Dense Directed Graphs; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We explore the effectiveness of visualizing dense directed graphs by replacing individual edges with edges connected to \u0027modules\u0027-or groups of nodes-such that the new edges imply aggregate connectivity. We only consider techniques that offer a lossless compression: that is, where the entire graph can still be read from the compressed version. The techniques considered are: a simple grouping of nodes with identical neighbor sets; Modular Decomposition which permits internal structure in modules and allows them to be nested; and Power Graph Analysis which further allows edges to cross module boundaries. These techniques all have the same goal-to compress the set of edges that need to be rendered to fully convey connectivity-but each successive relaxation of the module definition permits fewer edges to be drawn in the rendered graph. Each successive technique also, we hypothesize, requires a higher degree of mental effort to interpret. We test this hypothetical trade-off with two studies involving human participants. For Power Graph Analysis we propose a novel optimal technique based on constraint programming. This enables us to explore the parameter space for the technique more precisely than could be achieved with a heuristic. Although applicable to many domains, we are motivated by-and discuss in particular-the application to software dependency analysis."}, {"color": "gray", "id": 899, "label": 899, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 899 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.152\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Teng-Yok Lee;Han-Wei Shen; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Efficient Local Statistical Analysis via Integral Histograms with Discrete Wavelet Transform; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Histograms computed from local regions are commonly used in many visualization applications, and allowing the user to query histograms interactively in regions of arbitrary locations and sizes plays an important role in feature identification and tracking. Computing histograms in regions with arbitrary location and size, nevertheless, can be time consuming for large data sets since it involves expensive I/O and scan of data elements. To achieve both performance- and storage-efficient query of local histograms, we present a new algorithm called WaveletSAT, which utilizes integral histograms, an extension of the summed area tables (SAT), and discrete wavelet transform (DWT). Similar to SAT, an integral histogram is the histogram computed from the area between each grid point and the grid origin, which can be be pre-computed to support fast query. Nevertheless, because one histogram contains multiple bins, it will be very expensive to store one integral histogram at each grid point. To reduce the storage cost for large integral histograms, WaveletSAT treats the integral histograms of all grid points as multiple SATs, each of which can be converted into a sparse representation via DWT, allowing the reconstruction of axis-aligned region histograms of arbitrary sizes from a limited number of wavelet coefficients. Besides, we present an efficient wavelet transform algorithm for SATs that can operate on each grid point separately in logarithmic time complexity, which can be extended to parallel GPU-based implementation. With theoretical and empirical demonstration, we show that WaveletSAT can achieve fast preprocessing and smaller storage overhead than the conventional integral histogram approach with close query performance."}, {"color": "gray", "id": 903, "label": 903, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 903 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.156\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Maria-Elena Froese;Melanie Tory;Guy-Warwick Evans;Kedar Shrikhande; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Evaluation of Static and Dynamic Visualization Training Approaches for Users with Different Spatial Abilities; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Conflicting results are reported in the literature on whether dynamic visualizations are more effective than static visualizations for learning and mastering 3-D tasks, and only a few investigations have considered the influence of the spatial abilities of the learners. In a study with 117 participants, we compared the benefit of static vs. dynamic visualization training tools on learners with different spatial abilities performing a typical 3-D task (specifically, creating orthographic projections of a 3-D object). We measured the spatial abilities of the participants using the Mental Rotation Test (MRT) and classified participants into two groups (high and low abilities) to examine how the participants\u0027 abilities predicted change in performance after training with static versus dynamic training tools. Our results indicate that: 1) visualization training programs can help learners to improve 3-D task performance, 2) dynamic visualizations provide no advantages over static visualizations that show intermediate steps, 3) training programs are more beneficial for individuals with low spatial abilities than for individuals with high spatial abilities, and 4) training individuals with high spatial abilities using dynamic visualizations provides little benefit."}, {"color": "gray", "id": 904, "label": 904, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 904 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.157\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Michael Gleicher; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Explainers: Expert Explorations with Crafted Projections; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: This paper introduces an approach to exploration and discovery in high-dimensional data that incorporates a user\u0027s knowledge and questions to craft sets of projection functions meaningful to them. Unlike most prior work that defines projections based on their statistical properties, our approach creates projection functions that align with user-specified annotations. Therefore, the resulting derived dimensions represent concepts defined by the user\u0027s examples. These especially crafted projection functions, or explainers, can help find and explain relationships between the data variables and user-designated concepts. They can organize the data according to these concepts. Sets of explainers can provide multiple perspectives on the data. Our approach considers tradeoffs in choosing these projection functions, including their simplicity, expressive power, alignment with prior knowledge, and diversity. We provide techniques for creating collections of explainers. The methods, based on machine learning optimization frameworks, allow exploring the tradeoffs. We demonstrate our approach on model problems and applications in text analysis."}, {"color": "gray", "id": 905, "label": 905, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 905 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.158\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Julius Parulek;Andrea Brambilla; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Fast Blending Scheme for Molecular Surface Representation; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Representation of molecular surfaces is a well established way to study the interaction of molecules. The state-of-theart molecular representation is the SES model, which provides a detailed surface visualization. Nevertheless, it is computationally expensive, so the less accurate Gaussian model is traditionally preferred. We introduce a novel surface representation that resembles the SES and approaches the rendering performance of the Gaussian model. Our technique is based on the iterative blending of implicit functions and avoids any pre-computation. Additionally, we propose a GPU-based ray-casting algorithm that efficiently visualize our molecular representation. A qualitative and quantitative comparison of our model with respect to the Gaussian and SES models is presented. As showcased in the paper, our technique is a valid and appealing alternative to the Gaussian representation. This is especially relevant in all the applications where the cost of the SES is prohibitive."}, {"color": "gray", "id": 906, "label": 906, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 906 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.159\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Moritz Ehlke;Heiko Ramm;Hans Lamecker;Hans-Christian Hege;Stefan Zachow; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Fast Generation of Virtual X-ray Images for Reconstruction of 3D Anatomy; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We propose a novel GPU-based approach to render virtual X-ray projections of deformable tetrahedral meshes. These meshes represent the shape and the internal density distribution of a particular anatomical structure and are derived from statistical shape and intensity models (SSIMs). We apply our method to improve the geometric reconstruction of 3D anatomy (e.g. pelvic bone) from 2D X-ray images. For that purpose, shape and density of a tetrahedral mesh are varied and virtual X-ray projections are generated within an optimization process until the similarity between the computed virtual X-ray and the respective anatomy depicted in a given clinical X-ray is maximized. The OpenGL implementation presented in this work deforms and projects tetrahedral meshes of high resolution (200.000+ tetrahedra) at interactive rates. It generates virtual X-rays that accurately depict the density distribution of an anatomy of interest. Compared to existing methods that accumulate X-ray attenuation in deformable meshes, our novel approach significantly boosts the deformation/projection performance. The proposed projection algorithm scales better with respect to mesh resolution and complexity of the density distribution, and the combined deformation and projection on the GPU scales better with respect to the number of deformation parameters. The gain in performance allows for a larger number of cycles in the optimization process. Consequently, it reduces the risk of being stuck in a local optimum. We believe that our approach will improve treatments in orthopedics, where 3D anatomical information is essential."}, {"color": "gray", "id": 907, "label": 907, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 907 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.160\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jean-Fran\u00e7ois Im;Michael J. McGuffin;Rock Leung; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: GPLOM: The Generalized Plot Matrix for Visualizing Multidimensional Multivariate Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Scatterplot matrices (SPLOMs), parallel coordinates, and glyphs can all be used to visualize the multiple continuous variables (i.e., dependent variables or measures) in multidimensional multivariate data. However, these techniques are not well suited to visualizing many categorical variables (i.e., independent variables or dimensions). To visualize multiple categorical variables, \u0027hierarchical axes\u0027 that \u0027stack dimensions\u0027 have been used in systems like Polaris and Tableau. However, this approach does not scale well beyond a small number of categorical variables. Emerson et al. [8] extend the matrix paradigm of the SPLOM to simultaneously visualize several categorical and continuous variables, displaying many kinds of charts in the matrix depending on the kinds of variables involved. We propose a variant of their technique, called the Generalized Plot Matrix (GPLOM). The GPLOM restricts Emerson et al.\u0027s technique to only three kinds of charts (scatterplots for pairs of continuous variables, heatmaps for pairs of categorical variables, and barcharts for pairings of categorical and continuous variable), in an effort to make it easier to understand. At the same time, the GPLOM extends Emerson et al.\u0027s work by demonstrating interactive techniques suited to the matrix of charts. We discuss the visual design and interactive features of our GPLOM prototype, including a textual search feature allowing users to quickly locate values or variables by name. We also present a user study that compared performance with Tableau and our GPLOM prototype, that found that GPLOM is significantly faster in certain cases, and not significantly slower in other cases."}, {"color": "gray", "id": 908, "label": 908, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 908 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.161\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Adrian Maries;Nathan Mays;MeganOlson Hunt;Kim F. Wong;William Layton;Robert Boudreau;Caterina Rosano;G. Elisabeta Marai; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: GRACE: A Visual Comparison Framework for Integrated Spatial and Non-Spatial Geriatric Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present the design of a novel framework for the visual integration, comparison, and exploration of correlations in spatial and non-spatial geriatric research data. These data are in general high-dimensional and span both the spatial, volumetric domain - through magnetic resonance imaging volumes - and the non-spatial domain, through variables such as age, gender, or walking speed. The visual analysis framework blends medical imaging, mathematical analysis and interactive visualization techniques, and includes the adaptation of Sparse Partial Least Squares and iterated Tikhonov Regularization algorithms to quantify potential neurologymobility connections. A linked-view design geared specifically at interactive visual comparison integrates spatial and abstract visual representations to enable the users to effectively generate and refine hypotheses in a large, multidimensional, and fragmented space. In addition to the domain analysis and design description, we demonstrate the usefulness of this approach on two case studies. Last, we report the lessons learned through the iterative design and evaluation of our approach, in particular those relevant to the design of comparative visualization of spatial and non-spatial data."}, {"color": "gray", "id": 913, "label": 913, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 913 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.167\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jian Zhao;Christopher Collins;Fanny Chevalier;Ravin Balakrishnan; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Interactive Exploration of Implicit and Explicit Relations in Faceted Datasets; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Many datasets, such as scientific literature collections, contain multiple heterogeneous facets which derive implicit relations, as well as explicit relational references between data items. The exploration of this data is challenging not only because of large data scales but also the complexity of resource structures and semantics. In this paper, we present PivotSlice, an interactive visualization technique which provides efficient faceted browsing as well as flexible capabilities to discover data relationships. With the metaphor of direct manipulation, PivotSlice allows the user to visually and logically construct a series of dynamic queries over the data, based on a multi-focus and multi-scale tabular view that subdivides the entire dataset into several meaningful parts with customized semantics. PivotSlice further facilitates the visual exploration and sensemaking process through features including live search and integration of online data, graphical interaction histories and smoothly animated visual state transitions. We evaluated PivotSlice through a qualitative lab study with university researchers and report the findings from our observations and interviews. We also demonstrate the effectiveness of PivotSlice using a scenario of exploring a repository of information visualization literature."}, {"color": "gray", "id": 915, "label": 915, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 915 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.169\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jan Kretschmer;Christian Godenschwager;Bernhard Preim;Marc Stamminger; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Interactive Patient-Specific Vascular Modeling with Sweep Surfaces; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The precise modeling of vascular structures plays a key role in medical imaging applications, such as diagnosis, therapy planning and blood flow simulations. For the simulation of blood flow in particular, high-precision models are required to produce accurate results. It is thus common practice to perform extensive manual data polishing on vascular segmentations prior to simulation. This usually involves a complex tool chain which is highly impractical for clinical on-site application. To close this gap in current blood flow simulation pipelines, we present a novel technique for interactive vascular modeling which is based on implicit sweep surfaces. Our method is able to generate and correct smooth high-quality models based on geometric centerline descriptions on the fly. It supports complex vascular free-form contours and consequently allows for an accurate and fast modeling of pathological structures such as aneurysms or stenoses. We extend the concept of implicit sweep surfaces to achieve increased robustness and applicability as required in the medical field. We finally compare our method to existing techniques and provide case studies that confirm its contribution to current simulation pipelines."}, {"color": "gray", "id": 917, "label": 917, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 917 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.172\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Yubo Zhang;Kwan-Liu Ma; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Lighting Design for Globally Illuminated Volume Rendering; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: With the evolution of graphics hardware, high quality global illumination becomes available for real-time volume rendering. Compared to local illumination, global illumination can produce realistic shading effects which are closer to real world scenes, and has proven useful for enhancing volume data visualization to enable better depth and shape perception. However, setting up optimal lighting could be a nontrivial task for average users. There were lighting design works for volume visualization but they did not consider global light transportation. In this paper, we present a lighting design method for volume visualization employing global illumination. The resulting system takes into account view and transfer-function dependent content of the volume data to automatically generate an optimized three-point lighting environment. Our method fully exploits the back light which is not used by previous volume visualization systems. By also including global shadow and multiple scattering, our lighting system can effectively enhance the depth and shape perception of volumetric features of interest. In addition, we propose an automatic tone mapping operator which recovers visual details from overexposed areas while maintaining sufficient contrast in the dark areas. We show that our method is effective for visualizing volume datasets with complex structures. The structural information is more clearly and correctly presented under the automatically generated light sources."}, {"color": "gray", "id": 923, "label": 923, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 923 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.180\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Rostislav Khlebnikov;Bernhard Kainz;Markus Steinberger;Dieter Schmalstieg; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Noise-Based Volume Rendering for the Visualization of Multivariate Volumetric Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Analysis of multivariate data is of great importance in many scientific disciplines. However, visualization of 3D spatially-fixed multivariate volumetric data is a very challenging task. In this paper we present a method that allows simultaneous real-time visualization of multivariate data. We redistribute the opacity within a voxel to improve the readability of the color defined by a regular transfer function, and to maintain the see-through capabilities of volume rendering. We use predictable procedural noise - random-phase Gabor noise - to generate a high-frequency redistribution pattern and construct an opacity mapping function, which allows to partition the available space among the displayed data attributes. This mapping function is appropriately filtered to avoid aliasing, while maintaining transparent regions. We show the usefulness of our approach on various data sets and with different example applications. Furthermore, we evaluate our method by comparing it to other visualization techniques in a controlled user study. Overall, the results of our study indicate that users are much more accurate in determining exact data values with our novel 3D volume visualization method. Significantly lower error rates for reading data values and high subjective ranking of our method imply that it has a high chance of being adopted for the purpose of visualization of multivariate 3D data."}, {"color": "gray", "id": 926, "label": 926, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 926 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.183\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Michael Gleicher;Michael Correll;Christine Nothelfer;Steven Franconeri; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Perception of Average Value in Multiclass Scatterplots; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The visual system can make highly efficient aggregate judgements about a set of objects, with speed roughly independent of the number of objects considered. While there is a rich literature on these mechanisms and their ramifications for visual summarization tasks, this prior work rarely considers more complex tasks requiring multiple judgements over long periods of time, and has not considered certain critical aggregation types, such as the localization of the mean value of a set of points. In this paper, we explore these questions using a common visualization task as a case study: relative mean value judgements within multi-class scatterplots. We describe how the perception literature provides a set of expected constraints on the task, and evaluate these predictions with a large-scale perceptual study with crowd-sourced participants. Judgements are no harder when each set contains more points, redundant and conflicting encodings, as well as additional sets, do not strongly affect performance, and judgements are harder when using less salient encodings. These results have concrete ramifications for the design of scatterplots."}, {"color": "gray", "id": 929, "label": 929, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 929 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.187\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Martin Fink;Jan-Henrik Haunert;Joachim Spoerhase;Alexander Wolff; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Selecting the Aspect Ratio of a Scatter Plot Based on Its Delaunay Triangulation; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Scatter plots are diagrams that visualize two-dimensional data as sets of points in the plane. They allow users to detect correlations and clusters in the data. Whether or not a user can accomplish these tasks highly depends on the aspect ratio selected for the plot, i.e., the ratio between the horizontal and the vertical extent of the diagram. We argue that an aspect ratio is good if the Delaunay triangulation of the scatter plot at this aspect ratio has some nice geometric property, e.g., a large minimum angle or a small total edge length. More precisely, we consider the following optimization problem. Given a set Q of points in the plane, find a scale factor s such that scaling the x-coordinates of the points in Q by s and the y-coordinates by 1=s yields a point set P(s) that optimizes a property of the Delaunay triangulation of P(s), over all choices of s. We present an algorithm that solves this problem efficiently and demonstrate its usefulness on real-world instances. Moreover, we discuss an empirical test in which we asked 64 participants to choose the aspect ratios of 18 scatter plots. We tested six different quality measures that our algorithm can optimize. In conclusion, minimizing the total edge length and minimizing what we call the \u0027uncompactness\u0027 of the triangles of the Delaunay triangulation yielded the aspect ratios that were most similar to those chosen by the participants in the test."}, {"color": "gray", "id": 937, "label": 937, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 937 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.196\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Shixia Liu;Yingcai Wu;Enxun Wei;Mengchen Liu;Yang Liu; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: StoryFlow: Tracking the Evolution of Stories; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Storyline visualizations, which are useful in many applications, aim to illustrate the dynamic relationships between entities in a story. However, the growing complexity and scalability of stories pose great challenges for existing approaches. In this paper, we propose an efficient optimization approach to generating an aesthetically appealing storyline visualization, which effectively handles the hierarchical relationships between entities over time. The approach formulates the storyline layout as a novel hybrid optimization approach that combines discrete and continuous optimization. The discrete method generates an initial layout through the ordering and alignment of entities, and the continuous method optimizes the initial layout to produce the optimal one. The efficient approach makes real-time interactions (e.g., bundling and straightening) possible, thus enabling users to better understand and track how the story evolves. Experiments and case studies are conducted to demonstrate the effectiveness and usefulness of the optimization approach."}, {"color": "gray", "id": 943, "label": 943, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 943 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.207\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Philip A. Legg;David H.S. Chung;Matthew L. Parry;Rhodri Bown;Mark W. Jones;Iwan W. Griffiths;Min Chen; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Transformation of an Uncertain Video Search Pipeline to a Sketch-Based Visual Analytics Loop; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Traditional sketch-based image or video search systems rely on machine learning concepts as their core technology. However, in many applications, machine learning alone is impractical since videos may not be semantically annotated sufficiently, there may be a lack of suitable training data, and the search requirements of the user may frequently change for different tasks. In this work, we develop a visual analytics systems that overcomes the shortcomings of the traditional approach. We make use of a sketch-based interface to enable users to specify search requirement in a flexible manner without depending on semantic annotation. We employ active machine learning to train different analytical models for different types of search requirements. We use visualization to facilitate knowledge discovery at the different stages of visual analytics. This includes visualizing the parameter space of the trained model, visualizing the search space to support interactive browsing, visualizing candidature search results to support rapid interaction for active learning while minimizing watching videos, and visualizing aggregated information of the search results. We demonstrate the system for searching spatiotemporal attributes from sports video to identify key instances of the team and player performance."}, {"color": "gray", "id": 944, "label": 944, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 944 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.208\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Tushar Athawale;Alireza Entezari; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Uncertainty Quantification in Linear Interpolation for Isosurface Extraction; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present a study of linear interpolation when applied to uncertain data. Linear interpolation is a key step for isosurface extraction algorithms, and the uncertainties in the data lead to non-linear variations in the geometry of the extracted isosurface. We present an approach for deriving the probability density function of a random variable modeling the positional uncertainty in the isosurface extraction. When the uncertainty is quantified by a uniform distribution, our approach provides a closed-form characterization of the mentioned random variable. This allows us to derive, in closed form, the expected value as well as the variance of the level-crossing position. While the former quantity is used for constructing a stable isosurface for uncertain data, the latter is used for visualizing the positional uncertainties in the expected isosurface level crossings on the underlying grid."}, {"color": "gray", "id": 945, "label": 945, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 945 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.209\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Rahul C. Basole;Trustin Clear;Mengdie Hu;Harshit Mehrotra;John Stasko; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Understanding Interfirm Relationships in Business Ecosystems with Interactive Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Business ecosystems are characterized by large, complex, and global networks of firms, often from many different market segments, all collaborating, partnering, and competing to create and deliver new products and services. Given the rapidly increasing scale, complexity, and rate of change of business ecosystems, as well as economic and competitive pressures, analysts are faced with the formidable task of quickly understanding the fundamental characteristics of these interfirm networks. Existing tools, however, are predominantly query- or list-centric with limited interactive, exploratory capabilities. Guided by a field study of corporate analysts, we have designed and implemented dotlink360, an interactive visualization system that provides capabilities to gain systemic insight into the compositional, temporal, and connective characteristics of business ecosystems. dotlink360 consists of novel, multiple connected views enabling the analyst to explore, discover, and understand interfirm networks for a focal firm, specific market segments or countries, and the entire business ecosystem. System evaluation by a small group of prototypical users shows supporting evidence of the benefits of our approach. This design study contributes to the relatively unexplored, but promising area of exploratory information visualization in market research and business strategy."}, {"color": "gray", "id": 947, "label": 947, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 947 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.211\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Neesha Kodagoda;Simon Attfield;B.L. William Wong;Chris Rooney;Sharmin Choudhury; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Using Interactive Visual Reasoning to Support Sense-Making: Implications for Design; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: This research aims to develop design guidelines for systems that support investigators and analysts in the exploration and assembly of evidence and inferences. We focus here on the problem of identifying candidate \u0027influencers\u0027 within a community of practice. To better understand this problem and its related cognitive and interaction needs, we conducted a user study using a system called INVISQUE (INteractive Visual Search and QUery Environment) loaded with content from the ACM Digital Library. INVISQUE supports search and manipulation of results over a freeform infinite \u0027canvas\u0027. The study focuses on the representations user create and their reasoning process. It also draws on some pre-established theories and frameworks related to sense-making and cognitive work in general, which we apply as a \u0027theoretical lenses\u0027 to consider findings and articulate solutions. Analysing the user-study data in the light of these provides some understanding of how the high-level problem of identifying key players within a domain can translate into lower-level questions and interactions. This, in turn, has informed our understanding of representation and functionality needs at a level of description which abstracts away from the specifics of the problem at hand to the class of problems of interest. We consider the study outcomes from the perspective of implications for design."}, {"color": "gray", "id": 948, "label": 948, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 948 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.212\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jaegul Choo;Changhyun Lee;Chandan K. Reddy;Haesun Park; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: UTOPIAN: User-Driven Topic Modeling Based on Interactive Nonnegative Matrix Factorization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Topic modeling has been widely used for analyzing text document collections. Recently, there have been significant advancements in various topic modeling techniques, particularly in the form of probabilistic graphical modeling. State-of-the-art techniques such as Latent Dirichlet Allocation (LDA) have been successfully applied in visual text analytics. However, most of the widely-used methods based on probabilistic modeling have drawbacks in terms of consistency from multiple runs and empirical convergence. Furthermore, due to the complicatedness in the formulation and the algorithm, LDA cannot easily incorporate various types of user feedback. To tackle this problem, we propose a reliable and flexible visual analytics system for topic modeling called UTOPIAN (User-driven Topic modeling based on Interactive Nonnegative Matrix Factorization). Centered around its semi-supervised formulation, UTOPIAN enables users to interact with the topic modeling method and steer the result in a user-driven manner. We demonstrate the capability of UTOPIAN via several usage scenarios with real-world document corpuses such as InfoVis/VAST paper data set and product review data sets."}, {"color": "gray", "id": 951, "label": 951, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 951 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.215\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Thomas Auzinger;Gabriel Mistelbauer;Ivan Baclija;R\u00fcdiger Schernthaner;Arnold K\u00f6chl;Michael Wimmer;M. Eduard Gr\u00f6ller;Stefan Bruckner; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Vessel Visualization using Curved Surface Reformation; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Visualizations of vascular structures are frequently used in radiological investigations to detect and analyze vascular diseases. Obstructions of the blood flow through a vessel are one of the main interests of physicians, and several methods have been proposed to aid the visual assessment of calcifications on vessel walls. Curved Planar Reformation (CPR) is a wide-spread method that is designed for peripheral arteries which exhibit one dominant direction. To analyze the lumen of arbitrarily oriented vessels, Centerline Reformation (CR) has been proposed. Both methods project the vascular structures into 2D image space in order to reconstruct the vessel lumen. In this paper, we propose Curved Surface Reformation (CSR), a technique that computes the vessel lumen fully in 3D. This offers high-quality interactive visualizations of vessel lumina and does not suffer from problems of earlier methods such as ambiguous visibility cues or premature discretization of centerline data. Our method maintains exact visibility information until the final query of the 3D lumina data. We also present feedback from several domain experts."}, {"color": "gray", "id": 954, "label": 954, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 954 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.221\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Panpan Xu;Yingcai Wu;Enxun Wei;Tai-Quan Peng;Shixia Liu;Jonathan J.H. Zhu;Huamin Qu; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visual Analysis of Topic Competition on Social Media; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: How do various topics compete for public attention when they are spreading on social media? What roles do opinion leaders play in the rise and fall of competitiveness of various topics? In this study, we propose an expanded topic competition model to characterize the competition for public attention on multiple topics promoted by various opinion leaders on social media. To allow an intuitive understanding of the estimated measures, we present a timeline visualization through a metaphoric interpretation of the results. The visual design features both topical and social aspects of the information diffusion process by compositing ThemeRiver with storyline style visualization. ThemeRiver shows the increase and decrease of competitiveness of each topic. Opinion leaders are drawn as threads that converge or diverge with regard to their roles in influencing the public agenda change over time. To validate the effectiveness of the visual analysis techniques, we report the insights gained on two collections of Tweets: the 2012 United States presidential election and the Occupy Wall Street movement."}, {"color": "gray", "id": 955, "label": 955, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 955 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.222\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Markus B\u00f6gl;Wolfgang Aigner;Peter Filzmoser;Tim Lammarsch;Silvia Miksch;Alexander Rind; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visual Analytics for Model Selection in Time Series Analysis; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Model selection in time series analysis is a challenging task for domain experts in many application areas such as epidemiology, economy, or environmental sciences. The methodology used for this task demands a close combination of human judgement and automated computation. However, statistical software tools do not adequately support this combination through interactive visual interfaces. We propose a Visual Analytics process to guide domain experts in this task. For this purpose, we developed the TiMoVA prototype that implements this process based on user stories and iterative expert feedback on user experience. The prototype was evaluated by usage scenarios with an example dataset from epidemiology and interviews with two external domain experts in statistics. The insights from the experts\u0027 feedback and the usage scenarios show that TiMoVA is able to support domain experts in model selection tasks through interactive visual interfaces with short feedback cycles."}, {"color": "gray", "id": 957, "label": 957, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 957 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.224\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Eli Packer;Peter Bak;Mikko Nikkil\u00e4;Valentin Polishchuk;Harold J. Ship; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visual Analytics for Spatial Clustering: Using a Heuristic Approach for Guided Exploration; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We propose a novel approach of distance-based spatial clustering and contribute a heuristic computation of input parameters for guiding users in the search of interesting cluster constellations. We thereby combine computational geometry with interactive visualization into one coherent framework. Our approach entails displaying the results of the heuristics to users, as shown in Figure 1, providing a setting from which to start the exploration and data analysis. Addition interaction capabilities are available containing visual feedback for exploring further clustering options and is able to cope with noise in the data. We evaluate, and show the benefits of our approach on a sophisticated artificial dataset and demonstrate its usefulness on real-world data."}, {"color": "gray", "id": 959, "label": 959, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 959 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.226\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Nivan Ferreira;Jorge Poco;Huy T. Vo;Juliana Freire;Cl\u00e1udio T. Silva; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visual Exploration of Big Spatio-Temporal Urban Data: A Study of New York City Taxi Trips; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: As increasing volumes of urban data are captured and become available, new opportunities arise for data-driven analysis that can lead to improvements in the lives of citizens through evidence-based decision making and policies. In this paper, we focus on a particularly important urban data set: taxi trips. Taxis are valuable sensors and information associated with taxi trips can provide unprecedented insight into many different aspects of city life, from economic activity and human behavior to mobility patterns. But analyzing these data presents many challenges. The data are complex, containing geographical and temporal components in addition to multiple variables associated with each trip. Consequently, it is hard to specify exploratory queries and to perform comparative analyses (e.g., compare different regions over time). This problem is compounded due to the size of the data-there are on average 500,000 taxi trips each day in NYC. We propose a new model that allows users to visually query taxi trips. Besides standard analytics queries, the model supports origin-destination queries that enable the study of mobility across the city. We show that this model is able to express a wide range of spatio-temporal queries, and it is also flexible in that not only can queries be composed but also different aggregations and visual representations can be applied, allowing users to explore and compare results. We have built a scalable system that implements this model which supports interactive response times; makes use of an adaptive level-of-detail rendering strategy to generate clutter-free visualization for large results; and shows hidden details to the users in a summary through the use of overlay heat maps. We present a series of case studies motivated by traffic engineers and economists that show how our model and system enable domain experts to perform tasks that were previously unattainable for them."}, {"color": "gray", "id": 961, "label": 961, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 961 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.228\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Zuchao Wang;Min Lu;Xiaoru Yuan;Junping Zhang;Huub van de Wetering; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visual Traffic Jam Analysis Based on Trajectory Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In this work, we present an interactive system for visual analysis of urban traffic congestion based on GPS trajectories. For these trajectories we develop strategies to extract and derive traffic jam information. After cleaning the trajectories, they are matched to a road network. Subsequently, traffic speed on each road segment is computed and traffic jam events are automatically detected. Spatially and temporally related events are concatenated in, so-called, traffic jam propagation graphs. These graphs form a high-level description of a traffic jam and its propagation in time and space. Our system provides multiple views for visually exploring and analyzing the traffic condition of a large city as a whole, on the level of propagation graphs, and on road segment level. Case studies with 24 days of taxi GPS trajectories collected in Beijing demonstrate the effectiveness of our system."}, {"color": "gray", "id": 962, "label": 962, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 962 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.229\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Andrzej Szymczak;Levente Sipeki; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visualization of Morse Connection Graphs for Topologically Rich 2D Vector fields; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Recent advances in vector field topologymake it possible to compute its multi-scale graph representations for autonomous 2D vector fields in a robust and efficient manner. One of these representations is a Morse Connection Graph (MCG), a directed graph whose nodes correspond to Morse sets, generalizing stationary points and periodic trajectories, and arcs - to trajectories connecting them. While being useful for simple vector fields, the MCG can be hard to comprehend for topologically rich vector fields, containing a large number of features. This paper describes a visual representation of the MCG, inspired by previous work on graph visualization. Our approach aims to preserve the spatial relationships between the MCG arcs and nodes and highlight the coherent behavior of connecting trajectories. Using simulations of ocean flow, we show that it can provide useful information on the flow structure. This paper focuses specifically on MCGs computed for piecewise constant (PC) vector fields. In particular, we describe extensions of the PC framework that make it more flexible and better suited for analysis of data on complex shaped domains with a boundary. We also describe a topology simplification scheme that makes our MCG visualizations less ambiguous. Despite the focus on the PC framework, our approach could also be applied to graph representations or topological skeletons computed using different methods."}, {"color": "gray", "id": 963, "label": 963, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 963 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.230\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Vahid Taimouri;Jing Hua; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visualization of Shape Motions in Shape Space; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Analysis of dynamic object deformations such as cardiac motion is of great importance, especially when there is a necessity to visualize and compare the deformation behavior across subjects. However, there is a lack of effective techniques for comparative visualization and assessment of a collection of motion data due to its 4-dimensional nature, i.e., timely varying three-dimensional shapes. From the geometric point of view, the motion change can be considered as a function defined on the 2D manifold of the surface. This paper presents a novel classification and visualization method based on a medial surface shape space, in which two novel shape descriptors are defined, for discriminating normal and abnormal human heart deformations as well as localizing the abnormal motion regions. In our medial surface shape space, the geodesic distance connecting two points in the space measures the similarity between their corresponding medial surfaces, which can quantify the similarity and disparity of the 3D heart motions. Furthermore, the novel descriptors can effectively localize the inconsistently deforming myopathic regions on the left ventricle. An easy visualization of heart motion sequences on the projected space allows users to distinguish the deformation differences. Our experimental results on both synthetic and real imaging data show that this method can automatically classify the healthy and myopathic subjects and accurately detect myopathic regions on the left ventricle, which outperforms other conventional cardiac diagnostic methods."}, {"color": "gray", "id": 964, "label": 964, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 964 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.231\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: JohnAlexis Guerra-G\u00f3mez;Michael L. Pack;Catherine Plaisant;Ben Shneiderman; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visualizing Change over Time Using Dynamic Hierarchies: TreeVersity2 and the StemView; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: To analyze data such as the US Federal Budget or characteristics of the student population of a University it is common to look for changes over time. This task can be made easier and more fruitful if the analysis is performed by grouping by attributes, such as by Agencies, Bureaus and Accounts for the Budget, or Ethnicity, Gender and Major in a University. We present TreeVersity2, a web based interactive data visualization tool that allows users to analyze change in datasets by creating dynamic hierarchies based on the data attributes. TreeVersity2 introduces a novel space filling visualization (StemView) to represent change in trees at multiple levels - not just at the leaf level. With this visualization users can explore absolute and relative changes, created and removed nodes, and each node\u0027s actual values, while maintaining the context of the tree. In addition, TreeVersity2 provides overviews of change over the entire time period, and a reporting tool that lists outliers in textual form, which helps users identify the major changes in the data without having to manually setup filters. We validated TreeVersity2 with 12 case studies with organizations as diverse as the National Cancer Institute, Federal Drug Administration, Department of Transportation, Office of the Bursar of the University of Maryland, or eBay. Our case studies demonstrated that TreeVersity2 is flexible enough to be used in different domains and provide useful insights for the data owners. A TreeVersity2 demo can be found at https://treeversity.cattlab.umd.edu."}, {"color": "gray", "id": 971, "label": 971, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 971 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346258\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Manuel Rubio-S\u00e1nchez;Alberto Sanchez; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Axis Calibration for Improving Data Attribute Estimation in Star Coordinates Plots; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Star coordinates is a well-known multivariate visualization method that produces linear dimensionality reduction mappings through a set of radial axes defined by vectors in an observable space. One of its main drawbacks concerns the difficulty to recover attributes of data samples accurately, which typically lie in the [0], [1] interval, given the locations of the low-dimensional embeddings and the vectors. In this paper we show that centering the data can considerably increase attribute estimation accuracy, where data values can be read off approximately by projecting embedded points onto calibrated (i.e., labeled) axes, similarly to classical statistical biplots. In addition, this idea can be coupled with a recently developed orthonormalization process on the axis vectors that prevents unnecessary distortions. We demonstrate that the combination of both approaches not only enhances the estimates, but also provides more faithful representations of the data."}, {"color": "gray", "id": 972, "label": 972, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 972 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346260\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Samuel Gratzl;Nils Gehlenborg;Alexander Lex;Hanspeter Pfister;Marc Streit; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Domino: Extracting, Comparing, and Manipulating Subsets Across Multiple Tabular Datasets; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Answering questions about complex issues often requires analysts to take into account information contained in multiple interconnected datasets. A common strategy in analyzing and visualizing large and heterogeneous data is dividing it into meaningful subsets. Interesting subsets can then be selected and the associated data and the relationships between the subsets visualized. However, neither the extraction and manipulation nor the comparison of subsets is well supported by state-of-the-art techniques. In this paper we present Domino, a novel multiform visualization technique for effectively representing subsets and the relationships between them. By providing comprehensive tools to arrange, combine, and extract subsets, Domino allows users to create both common visualization techniques and advanced visualizations tailored to specific use cases. In addition to the novel technique, we present an implementation that enables analysts to manage the wide range of options that our approach offers. Innovative interactive features such as placeholders and live previews support rapid creation of complex analysis setups. We introduce the technique and the implementation using a simple example and demonstrate scalability and effectiveness in a use case from the field of cancer genomics."}, {"color": "gray", "id": 973, "label": 973, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 973 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346265\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Cagatay Turkay;Aidan Slingsby;Helwig Hauser;Jo Wood;Jason Dykes; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Attribute Signatures: Dynamic Visual Summaries for Analyzing Multivariate Geographical Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The visual analysis of geographically referenced datasets with a large number of attributes is challenging due to the fact that the characteristics of the attributes are highly dependent upon the locations at which they are focussed, and the scale and time at which they are measured. Specialized interactive visual methods are required to help analysts in understanding the characteristics of the attributes when these multiple aspects are considered concurrently. Here, we develop attribute signatures-interactively crafted graphics that show the geographic variability of statistics of attributes through which the extent of dependency between the attributes and geography can be visually explored. We compute a number of statistical measures, which can also account for variations in time and scale, and use them as a basis for our visualizations. We then employ different graphical configurations to show and compare both continuous and discrete variation of location and scale. Our methods allow variation in multiple statistical summaries of multiple attributes to be considered concurrently and geographically, as evidenced by examples in which the census geography of London and the wider UK are explored."}, {"color": "gray", "id": 974, "label": 974, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 974 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346271\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Diansheng Guo;Xi Zhu; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Origin-Destination Flow Data Smoothing and Mapping; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: This paper presents a new approach to flow mapping that extracts inherent patterns from massive geographic mobility data and constructs effective visual representations of the data for the understanding of complex flow trends. This approach involves a new method for origin-destination flow density estimation and a new method for flow map generalization, which together can remove spurious data variance, normalize flows with control population, and detect high-level patterns that are not discernable with existing approaches. The approach achieves three main objectives in addressing the challenges for analyzing and mapping massive flow data. First, it removes the effect of size differences among spatial units via kernel-based density estimation, which produces a measurement of flow volume between each pair of origin and destination. Second, it extracts major flow patterns in massive flow data through a new flow sampling method, which filters out duplicate information in the smoothed flows. Third, it enables effective flow mapping and allows intuitive perception of flow patterns among origins and destinations without bundling or altering flow paths. The approach can work with both point-based flow data (such as taxi trips with GPS locations) and area-based flow data (such as county-to-county migration). Moreover, the approach can be used to detect and compare flow patterns at different scales or in relatively sparse flow datasets, such as migration for each age group. We evaluate and demonstrate the new approach with case studies of U.S. migration data and experiments with synthetic data."}, {"color": "gray", "id": 975, "label": 975, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 975 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346274\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Arthur van Goethem;Andreas Reimer;Bettina Speckmann;Jo Wood; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Stenomaps: Shorthand for shapes; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We address some of the challenges in representing spatial data with a novel form of geometric abstraction-the stenomap. The stenomap comprises a series of smoothly curving linear glyphs that each represent both the boundary and the area of a polygon. We present an efficient algorithm to automatically generate these open, C\u0026lt;sup\u0026gt;1\u0026lt;/sup\u0026gt;-continuous splines from a set of input polygons. Feature points of the input polygons are detected using the medial axis to maintain important shape properties. We use dynamic programming to compute a planar non-intersecting spline representing each polygon\u0027s base shape. The results are stylised glyphs whose appearance may be parameterised and that offer new possibilities in the \u0027cartographic design space\u0027. We compare our glyphs with existing forms of geometric schematisation and discuss their relative merits and shortcomings. We describe several use cases including the depiction of uncertain model data in the form of hurricane track forecasting; minimal ink thematic mapping; and the depiction of continuous statistical data."}, {"color": "gray", "id": 977, "label": 977, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 977 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346277\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Martijn Tennekes;Edwin de Jonge; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Tree Colors: Color Schemes for Tree-Structured Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present a method to map tree structures to colors from the Hue-Chroma-Luminance color model, which is known for its well balanced perceptual properties. The Tree Colors method can be tuned with several parameters, whose effect on the resulting color schemes is discussed in detail. We provide a free and open source implementation with sensible parameter defaults. Categorical data are very common in statistical graphics, and often these categories form a classification tree. We evaluate applying Tree Colors to tree structured data with a survey on a large group of users from a national statistical institute. Our user study suggests that Tree Colors are useful, not only for improving node-link diagrams, but also for unveiling tree structure in non-hierarchical visualizations."}, {"color": "gray", "id": 978, "label": 978, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 978 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346279\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Charles Perin;Pierre Dragicevic;Jean-Daniel Fekete; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Revisiting Bertin Matrices: New Interactions for Crafting Tabular Visualizations; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present Bertifier, a web app for rapidly creating tabular visualizations from spreadsheets. Bertifier draws from Jacques Bertin\u0027s matrix analysis method, whose goal was to \u201csimplify without destroying\u201d by encoding cell values visually and grouping similar rows and columns. Although there were several attempts to bring this method to computers, no implementation exists today that is both exhaustive and accessible to a large audience. Bertifier remains faithful to Bertin\u0027s method while leveraging the power of today\u0027s interactive computers. Tables are formatted and manipulated through crossets, a new interaction technique for rapidly applying operations on rows and columns. We also introduce visual reordering, a semi-interactive reordering approach that lets users apply and tune automatic reordering algorithms in a WYSIWYG manner. Sessions with eight users from different backgrounds suggest that Bertifier has the potential to bring Bertin\u0027s method to a wider audience of both technical and non-technical users, and empower them with data analysis and communication tools that were so far only accessible to a handful of specialists.COMPUTER"}, {"color": "gray", "id": 979, "label": 979, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 979 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346291\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Donghao Ren;Tobias H\u00f6llerer;Xiaoru Yuan; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: iVisDesigner: Expressive Interactive Design of Information Visualizations; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present the design, implementation and evaluation of iVisDesigner, a web-based system that enables users to design information visualizations for complex datasets interactively, without the need for textual programming. Our system achieves high interactive expressiveness through conceptual modularity, covering a broad information visualization design space. iVisDesigner supports the interactive design of interactive visualizations, such as provisioning for responsive graph layouts and different types of brushing and linking interactions. We present the system design and implementation, exemplify it through a variety of illustrative visualization designs and discuss its limitations. A performance analysis and an informal user study are presented to evaluate the system."}, {"color": "gray", "id": 980, "label": 980, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 980 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346292\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Samuel Huron;Yvonne Jansen;Sheelagh Carpendale; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Constructing Visual Representations: Investigating the Use of Tangible Tokens; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The accessibility of infovis authoring tools to a wide audience has been identified as a major research challenge. A key task in the authoring process is the development of visual mappings. While the infovis community has long been deeply interested in finding effective visual mappings, comparatively little attention has been placed on how people construct visual mappings. In this paper, we present the results of a study designed to shed light on how people transform data into visual representations. We asked people to create, update and explain their own information visualizations using only tangible building blocks. We learned that all participants, most of whom had little experience in visualization authoring, were readily able to create and talk about their own visualizations. Based on our observations, we discuss participants\u0027 actions during the development of their visual representations and during their analytic activities. We conclude by suggesting implications for tool design to enable broader support for infovis authoring."}, {"color": "gray", "id": 985, "label": 985, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 985 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346312\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Ali K. Al-Awami;Johanna Beyer;Hendrik Strobelt;Narayanan Kasthuri;Jeff W. Lichtman;Hanspeter Pfister;Markus Hadwiger; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: NeuroLines: A Subway Map Metaphor for Visualizing Nanoscale Neuronal Connectivity; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present NeuroLines, a novel visualization technique designed for scalable detailed analysis of neuronal connectivity at the nanoscale level. The topology of 3D brain tissue data is abstracted into a multi-scale, relative distance-preserving subway map visualization that allows domain scientists to conduct an interactive analysis of neurons and their connectivity. Nanoscale connectomics aims at reverse-engineering the wiring of the brain. Reconstructing and analyzing the detailed connectivity of neurons and neurites (axons, dendrites) will be crucial for understanding the brain and its development and diseases. However, the enormous scale and complexity of nanoscale neuronal connectivity pose big challenges to existing visualization techniques in terms of scalability. NeuroLines offers a scalable visualization framework that can interactively render thousands of neurites, and that supports the detailed analysis of neuronal structures and their connectivity. We describe and analyze the design of NeuroLines based on two real-world use-cases of our collaborators in developmental neuroscience, and investigate its scalability to large-scale neuronal connectivity data."}, {"color": "gray", "id": 986, "label": 986, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 986 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346317\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Christian Schulte zu Berge;Maximilian Baust;Ankur Kapoor;Nassir Navab; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Predicate-Based Focus-and-Context Visualization for 3D Ultrasound; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Direct volume visualization techniques offer powerful insight into volumetric medical images and are part of the clinical routine for many applications. Up to now, however, their use is mostly limited to tomographic imaging modalities such as CT or MRI. With very few exceptions, such as fetal ultrasound, classic volume rendering using one-dimensional intensity-based transfer functions fails to yield satisfying results in case of ultrasound volumes. This is particularly due its gradient-like nature, a high amount of noise and speckle, and the fact that individual tissue types are rather characterized by a similar texture than by similar intensity values. Therefore, clinicians still prefer to look at 2D slices extracted from the ultrasound volume. In this work, we present an entirely novel approach to the classification and compositing stage of the volume rendering pipeline, specifically designed for use with ultrasonic images. We introduce point predicates as a generic formulation for integrating the evaluation of not only low-level information like local intensity or gradient, but also of high-level information, such as non-local image features or even anatomical models. Thus, we can successfully filter clinically relevant from non-relevant information. In order to effectively reduce the potentially high dimensionality of the predicate configuration space, we propose the predicate histogram as an intuitive user interface. This is augmented by a scribble technique to provide a comfortable metaphor for selecting predicates of interest. Assigning importance factors to the predicates allows for focus-and-context visualization that ensures to always show important (focus) regions of the data while maintaining as much context information as possible. Our method naturally integrates into standard ray casting algorithms and yields superior results in comparison to traditional methods in terms of visualizing a specific target anatomy in ultrasound volumes."}, {"color": "gray", "id": 988, "label": 988, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 988 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346319\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Steffen Frey;Filip Sadlo;Kwan-Liu Ma;Thomas Ertl; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Interactive Progressive Visualization with Space-Time Error Control; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present a novel scheme for progressive rendering in interactive visualization. Static settings with respect to a certain image quality or frame rate are inherently incapable of delivering both high frame rates for rapid changes and high image quality for detailed investigation. Our novel technique flexibly adapts by steering the visualization process in three major degrees of freedom: when to terminate the refinement of a frame in the background and start a new one, when to display a frame currently computed, and how much resources to consume. We base these decisions on the correlation of the errors due to insufficient sampling and response delay, which we estimate separately using fast yet expressive heuristics. To automate the configuration of the steering behavior, we employ offline video quality analysis. We provide an efficient implementation of our scheme for the application of volume raycasting, featuring integrated GPU-accelerated image reconstruction and error estimation. Our implementation performs an integral handling of the changes due to camera transforms, transfer function adaptations, as well as the progression of the data to in time. Finally, the overall technique is evaluated with an expert study."}, {"color": "gray", "id": 989, "label": 989, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 989 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346320\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Justin Talbot;Vidya Setlur;Anushka Anand; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Four Experiments on the Perception of Bar Charts; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Bar charts are one of the most common visualization types. In a classic graphical perception paper, Cleveland \u0026amp;amp; McGill studied how different bar chart designs impact the accuracy with which viewers can complete simple perceptual tasks. They found that people perform substantially worse on stacked bar charts than on aligned bar charts, and that comparisons between adjacent bars are more accurate than between widely separated bars. However, the study did not explore why these differences occur. In this paper, we describe a series of follow-up experiments to further explore and explain their results. While our results generally confirm Cleveland \u0026amp;amp; McGill\u0027s ranking of various bar chart configurations, we provide additional insight into the bar chart reading task and the sources of participants\u0027 errors. We use our results to propose new hypotheses on the perception of bar charts."}, {"color": "gray", "id": 993, "label": 993, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 993 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346324\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Ronell Sicat;Jens Kr\u00fcger;Torsten M\u00f6ller;Markus Hadwiger; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Sparse PDF Volumes for Consistent Multi-Resolution Volume Rendering; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: This paper presents a new multi-resolution volume representation called sparse pdf volumes, which enables consistent multi-resolution volume rendering based on probability density functions (pdfs) of voxel neighborhoods. These pdfs are defined in the 4D domain jointly comprising the 3D volume and its 1D intensity range. Crucially, the computation of sparse pdf volumes exploits data coherence in 4D, resulting in a sparse representation with surprisingly low storage requirements. At run time, we dynamically apply transfer functions to the pdfs using simple and fast convolutions. Whereas standard low-pass filtering and down-sampling incur visible differences between resolution levels, the use of pdfs facilitates consistent results independent of the resolution level used. We describe the efficient out-of-core computation of large-scale sparse pdf volumes, using a novel iterative simplification procedure of a mixture of 4D Gaussians. Finally, our data structure is optimized to facilitate interactive multi-resolution volume rendering on GPUs."}, {"color": "gray", "id": 995, "label": 995, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 995 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346331\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Sean McKenna;Dominika Mazur;James Agutter;Miriah Meyer; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Design Activity Framework for Visualization Design; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: An important aspect in visualization design is the connection between what a designer does and the decisions the designer makes. Existing design process models, however, do not explicitly link back to models for visualization design decisions. We bridge this gap by introducing the design activity framework, a process model that explicitly connects to the nested model, a well-known visualization design decision model. The framework includes four overlapping activities that characterize the design process, with each activity explicating outcomes related to the nested model. Additionally, we describe and characterize a list of exemplar methods and how they overlap among these activities. The design activity framework is the result of reflective discussions from a collaboration on a visualization redesign project, the details of which we describe to ground the framework in a real-world design process. Lastly, from this redesign project we provide several research outcomes in the domain of cybersecurity, including an extended data abstraction and rich opportunities for future visualization research."}, {"color": "gray", "id": 996, "label": 996, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 996 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346332\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Dilip Mathew Thomas;Vijay Natarajan; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Multiscale Symmetry Detection in Scalar Fields by Clustering Contours; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The complexity in visualizing volumetric data often limits the scope of direct exploration of scalar fields. Isocontour extraction is a popular method for exploring scalar fields because of its simplicity in presenting features in the data. In this paper, we present a novel representation of contours with the aim of studying the similarity relationship between the contours. The representation maps contours to points in a high-dimensional transformation-invariant descriptor space. We leverage the power of this representation to design a clustering based algorithm for detecting symmetric regions in a scalar field. Symmetry detection is a challenging problem because it demands both segmentation of the data and identification of transformation invariant segments. While the former task can be addressed using topological analysis of scalar fields, the latter requires geometry based solutions. Our approach combines the two by utilizing the contour tree for segmenting the data and the descriptor space for determining transformation invariance. We discuss two applications, query driven exploration and asymmetry visualization, that demonstrate the effectiveness of the approach."}, {"color": "gray", "id": 997, "label": 997, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 997 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346333\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Marco Ament;Filip Sadlo;Carsten Dachsbacher;Daniel Weiskopf; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Low-Pass Filtered Volumetric Shadows; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present a novel and efficient method to compute volumetric soft shadows for interactive direct volume visualization to improve the perception of spatial depth. By direct control of the softness of volumetric shadows, disturbing visual patterns due to hard shadows can be avoided and users can adapt the illumination to their personal and application-specific requirements. We compute the shadowing of a point in the data set by employing spatial filtering of the optical depth over a finite area patch pointing toward each light source. Conceptually, the area patch spans a volumetric region that is sampled with shadow rays; afterward, the resulting optical depth values are convolved with a low-pass filter on the patch. In the numerical computation, however, to avoid expensive shadow ray marching, we show how to align and set up summed area tables for both directional and point light sources. Once computed, the summed area tables enable efficient evaluation of soft shadows for each point in constant time without shadow ray marching and the softness of the shadows can be controlled interactively. We integrated our method in a GPU-based volume renderer with ray casting from the camera, which offers interactive control of the transfer function, light source positions, and viewpoint, for both static and time-dependent data sets. Our results demonstrate the benefit of soft shadows for visualization to achieve user-controlled illumination with many-point lighting setups for improved perception combined with high rendering speed."}, {"color": "gray", "id": 1006, "label": 1006, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1006 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346412\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Tao Ju;Minxin Cheng;Xu Wang;Ye Duan; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: A Robust Parity Test for Extracting Parallel Vectors in 3D; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Parallel vectors (PV), the loci where two vector fields are parallel, are commonly used to represent curvilinear features in 3D for data visualization. Methods for extracting PV usually operate on a 3D grid and start with detecting seed points on a cell face. We propose, to the best of our knowledge, the first provably correct test that determines the parity of the number of PV points on a cell face. The test only needs to sample along the face boundary and works for any choice of the two vector fields. A discretization of the test is described, validated, and compared with existing tests that are also based on boundary sampling. The test can guide PV-extraction algorithms to ensure closed curves wherever the input fields are continuous, which we exemplify in extracting ridges and valleys of scalar functions."}, {"color": "gray", "id": 1007, "label": 1007, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1007 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346415\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Tobias G\u00fcnther;Holger Theisel; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Vortex Cores of Inertial Particles; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The cores of massless, swirling particle motion are an indicator for vortex-like behavior in vector fields and to this end, a number of coreline extractors have been proposed in the literature. Though, many practical applications go beyond the study of the vector field. Instead, engineers seek to understand the behavior of inertial particles moving therein, for instance in sediment transport, helicopter brownout and pulverized coal combustion. In this paper, we present two strategies for the extraction of the corelines that inertial particles swirl around, which depend on particle density, particle diameter, fluid viscosity and gravity. The first is to deduce the local swirling behavior from the autonomous inertial motion ODE, which eventually reduces to a parallel vectors operation. For the second strategy, we use a particle density estimation to locate inertial attractors. With this, we are able to extract the cores of swirling inertial particle motion for both steady and unsteady 3D vector fields. We demonstrate our techniques in a number of benchmark data sets, and elaborate on the relation to traditional massless corelines."}, {"color": "gray", "id": 1008, "label": 1008, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1008 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346416\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Fan Hong;Chufan Lai;Hanqi Guo;Enya Shen;Xiaoru Yuan;Sikun Li; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: FLDA: Latent Dirichlet Allocation Based Unsteady Flow Analysis; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In this paper, we present a novel feature extraction approach called FLDA for unsteady flow fields based on Latent Dirichlet allocation (LDA) model. Analogous to topic modeling in text analysis, in our approach, pathlines and features in a given flow field are defined as documents and words respectively. Flow topics are then extracted based on Latent Dirichlet allocation. Different from other feature extraction methods, our approach clusters pathlines with probabilistic assignment, and aggregates features to meaningful topics at the same time. We build a prototype system to support exploration of unsteady flow field with our proposed LDA-based method. Interactive techniques are also developed to explore the extracted topics and to gain insight from the data. We conduct case studies to demonstrate the effectiveness of our proposed approach."}, {"color": "gray", "id": 1009, "label": 1009, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1009 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346418\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Hanqi Guo;Jiang Zhang;Richen Liu;Lu Liu;Xiaoru Yuan;Jian Huang;Xiangfei Meng;Jingshan Pan; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Advection-Based Sparse Data Management for Visualizing Unsteady Flow; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: When computing integral curves and integral surfaces for large-scale unsteady flow fields, a major bottleneck is the widening gap between data access demands and the available bandwidth (both I/O and in-memory). In this work, we explore a novel advection-based scheme to manage flow field data for both efficiency and scalability. The key is to first partition flow field into blocklets (e.g. cells or very fine-grained blocks of cells), and then (pre)fetch and manage blocklets on-demand using a parallel key-value store. The benefits are (1) greatly increasing the scale of local-range analysis (e.g. source-destination queries, streak surface generation) that can fit within any given limit of hardware resources; (2) improving memory and I/O bandwidth-efficiencies as well as the scalability of naive task-parallel particle advection. We demonstrate our method using a prototype system that works on workstation and also in supercomputing environments. Results show significantly reduced I/O overhead compared to accessing raw flow data, and also high scalability on a supercomputer for a variety of applications."}, {"color": "gray", "id": 1014, "label": 1014, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1014 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346424\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Fanny Chevalier;Pierre Dragicevic;Steven Franconeri; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: The Not-so-Staggering Effect of Staggered Animated Transitions on Visual Tracking; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Interactive visual applications often rely on animation to transition from one display state to another. There are multiple animation techniques to choose from, and it is not always clear which should produce the best visual correspondences between display elements. One major factor is whether the animation relies on staggering-an incremental delay in start times across the moving elements. It has been suggested that staggering may reduce occlusion, while also reducing display complexity and producing less overwhelming animations, though no empirical evidence has demonstrated these advantages. Work in perceptual psychology does show that reducing occlusion, and reducing inter-object proximity (crowding) more generally, improves performance in multiple object tracking. We ran simulations confirming that staggering can in some cases reduce crowding in animated transitions involving dot clouds (as found in, e.g., animated 2D scatterplots). We empirically evaluated the effect of two staggering techniques on tracking tasks, focusing on cases that should most favour staggering. We found that introducing staggering has a negligible, or even negative, impact on multiple object tracking performance. The potential benefits of staggering may be outweighed by strong costs: a loss of common-motion grouping information about which objects travel in similar paths, and less predictability about when any specific object would begin to move. Staggering may be beneficial in some conditions, but they have yet to be demonstrated. The present results are a significant step toward a better understanding of animation pacing, and provide direction for further research."}, {"color": "gray", "id": 1015, "label": 1015, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1015 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346425\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Hui Zhang;Jianguang Weng;Guangchen Ruan; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visualizing 2-dimensional Manifolds with Curve Handles in 4D; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In this paper, we present a mathematical visualization paradigm for exploring curves embedded in 3D and surfaces in 4D mathematical world. The basic problem is that, 3D figures of 4D mathematical entities often twist, turn, and fold back on themselves, leaving important properties behind the surface sheets. We propose an interactive system to visualize the topological features of the original 4D surface by slicing its 3D figure into a series of feature diagram. A novel 4D visualization interface is designed to allow users to control 4D topological shapes via the collection of diagram handles using the established curve manipulation mechanism. Our system can support rich mathematical interaction of 4D mathematical objects which is very difficult with any existing approach. We further demonstrate the effectiveness of the proposed visualization tool using various experimental results and cases studies."}, {"color": "gray", "id": 1017, "label": 1017, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1017 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346428\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Rita Borgo;Joel Dearden;Mark W. Jones; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Order of Magnitude Markers: An Empirical Study on Large Magnitude Number Detection; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In this paper we introduce Order of Magnitude Markers (OOMMs) as a new technique for number representation. The motivation for this work is that many data sets require the depiction and comparison of numbers that have varying orders of magnitude. Existing techniques for representation use bar charts, plots and colour on linear or logarithmic scales. These all suffer from related problems. There is a limit to the dynamic range available for plotting numbers, and so the required dynamic range of the plot can exceed that of the depiction method. When that occurs, resolving, comparing and relating values across the display becomes problematical or even impossible for the user. With this in mind, we present an empirical study in which we compare logarithmic, linear, scale-stack bars and our new markers for 11 different stimuli grouped into 4 different tasks across all 8 marker types."}, {"color": "gray", "id": 1025, "label": 1025, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1025 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346442\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Gustavo Machado;Filip Sadlo;Thomas M\u00fcller;Thomas Ertl; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Escape Maps; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present a technique to visualize the streamline-based mapping between the boundary of a simply-connected subregion of arbitrary 3D vector fields. While the streamlines are seeded on one part of the boundary, the remaining part serves as escape border. Hence, the seeding part of the boundary represents a map of streamline behavior, indicating if streamlines reach the escape border or not. Since the resulting maps typically exhibit a very fine and complex structure and are thus not amenable to direct sampling, our approach instead aims at topologically consistent extraction of their boundary. We show that isocline surfaces of the projected vector field provide a robust basis for stream-surface-based extraction of these boundaries. The utility of our technique is demonstrated in the context of transport processes using vector field data from different domains."}, {"color": "gray", "id": 1030, "label": 1030, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1030 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346448\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Ismail Demir;Christian Dick;R\u00fcdiger Westermann; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Multi-Charts for Comparative 3D Ensemble Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: A comparative visualization of multiple volume data sets is challenging due to the inherent occlusion effects, yet it is important to effectively reveal uncertainties, correlations and reliable trends in 3D ensemble fields. In this paper we present bidirectional linking of multi-charts and volume visualization as a means to analyze visually 3D scalar ensemble fields at the data level. Multi-charts are an extension of conventional bar and line charts: They linearize the 3D data points along a space-filling curve and draw them as multiple charts in the same plot area. The bar charts encode statistical information on ensemble members, such as histograms and probability densities, and line charts are overlayed to allow comparing members against the ensemble. Alternative linearizations based on histogram similarities or ensemble variation allow clustering of spatial locations depending on data distribution. Multi-charts organize the data at multiple scales to quickly provide overviews and enable users to select regions exhibiting interesting behavior interactively. They are further put into a spatial context by allowing the user to brush or query value intervals and specific distributions, and to simultaneously visualize the corresponding spatial points via volume rendering. By providing a picking mechanism in 3D and instantly highlighting the corresponding data points in the chart, the user can go back and forth between the abstract and the 3D view to focus the analysis."}, {"color": "gray", "id": 1031, "label": 1031, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1031 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346449\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Harish Doraiswamy;Nivan Ferreira;Theodoros Damoulas;Juliana Freire;Cl\u00e1udio T. Silva; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Using Topological Analysis to Support Event-Guided Exploration in Urban Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The explosion in the volume of data about urban environments has opened up opportunities to inform both policy and administration and thereby help governments improve the lives of their citizens, increase the efficiency of public services, and reduce the environmental harms of development. However, cities are complex systems and exploring the data they generate is challenging. The interaction between the various components in a city creates complex dynamics where interesting facts occur at multiple scales, requiring users to inspect a large number of data slices over time and space. Manual exploration of these slices is ineffective, time consuming, and in many cases impractical. In this paper, we propose a technique that supports event-guided exploration of large, spatio-temporal urban data. We model the data as time-varying scalar functions and use computational topology to automatically identify events in different data slices. To handle a potentially large number of events, we develop an algorithm to group and index them, thus allowing users to interactively explore and query event patterns on the fly. A visual exploration interface helps guide users towards data slices that display interesting events and trends. We demonstrate the effectiveness of our technique on two different data sets from New York City (NYC): data about taxi trips and subway service. We also report on the feedback we received from analysts at different NYC agencies."}, {"color": "gray", "id": 1034, "label": 1034, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1034 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346454\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jaemin Jo;Jaeseok Huh;Jonghun Park;Bohyoung Kim;Jinwook Seo; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: LiveGantt: Interactively Visualizing a Large Manufacturing Schedule; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In this paper, we introduce LiveGantt as a novel interactive schedule visualization tool that helps users explore highly-concurrent large schedules from various perspectives. Although a Gantt chart is the most common approach to illustrate schedules, currently available Gantt chart visualization tools suffer from limited scalability and lack of interactions. LiveGantt is built with newly designed algorithms and interactions to improve conventional charts with better scalability, explorability, and reschedulability. It employs resource reordering and task aggregation to display the schedules in a scalable way. LiveGantt provides four coordinated views and filtering techniques to help users explore and interact with the schedules in more flexible ways. In addition, LiveGantt is equipped with an efficient rescheduler to allow users to instantaneously modify their schedules based on their scheduling experience in the fields. To assess the usefulness of the application of LiveGantt, we conducted a case study on manufacturing schedule data with four industrial engineering researchers. Participants not only grasped an overview of a schedule but also explored the schedule from multiple perspectives to make enhancements."}, {"color": "gray", "id": 1037, "label": 1037, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1037 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346457\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jiaxi Hu;Guangyu Jeff Zou;Jing Hua; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Volume-Preserving Mapping and Registration for Collective Data Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In order to visualize and analyze complex collective data, complicated geometric structure of each data is desired to be mapped onto a canonical domain to enable map-based visual exploration. This paper proposes a novel volume-preserving mapping and registration method which facilitates effective collective data visualization. Given two 3-manifolds with the same topology, there exists a mapping between them to preserve each local volume element. Starting from an initial mapping, a volume restoring diffeomorphic flow is constructed as a compressible flow based on the volume forms at the manifold. Such a flow yields equality of each local volume element between the original manifold and the target at its final state. Furthermore, the salient features can be used to register the manifold to a reference template by an incompressible flow guided by a divergence-free vector field within the manifold. The process can retain the equality of local volume elements while registering the manifold to a template at the same time. An efficient and practical algorithm is also presented to generate a volume-preserving mapping and a salient feature registration on discrete 3D volumes which are represented with tetrahedral meshes embedded in 3D space. This method can be applied to comparative analysis and visualization of volumetric medical imaging data across subjects. We demonstrate an example application in multimodal neuroimaging data analysis and collective data visualization."}, {"color": "gray", "id": 1038, "label": 1038, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1038 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346458\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Peter Lindstrom; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Fixed-Rate Compressed Floating-Point Arrays; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Current compression schemes for floating-point data commonly take fixed-precision values and compress them to a variable-length bit stream, complicating memory management and random access. We present a fixed-rate, near-lossless compression scheme that maps small blocks of 4\u0026lt;sup\u0026gt;d\u0026lt;/sup\u0026gt; values in d dimensions to a fixed, user-specified number of bits per block, thereby allowing read and write random access to compressed floating-point data at block granularity. Our approach is inspired by fixed-rate texture compression methods widely adopted in graphics hardware, but has been tailored to the high dynamic range and precision demands of scientific applications. Our compressor is based on a new, lifted, orthogonal block transform and embedded coding, allowing each per-block bit stream to be truncated at any point if desired, thus facilitating bit rate selection using a single compression scheme. To avoid compression or decompression upon every data access, we employ a software write-back cache of uncompressed blocks. Our compressor has been designed with computational simplicity and speed in mind to allow for the possibility of a hardware implementation, and uses only a small number of fixed-point arithmetic operations per compressed value. We demonstrate the viability and benefits of lossy compression in several applications, including visualization, quantitative data analysis, and numerical simulation."}, {"color": "gray", "id": 1039, "label": 1039, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1039 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346459\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Silvia Born;Simon H. S\u00fcndermann;Christoph Russ;Raoul Hopf;Carlos E. Ruiz;Volkmar Falk;Michael Gessat; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Stent Maps - Comparative Visualization for the Prediction of Adverse Events of Transcatheter Aortic Valve Implantations; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Transcatheter aortic valve implantation (TAVI) is a minimally-invasive method for the treatment of aortic valve stenosis in patients with high surgical risk. Despite the success of TAVI, side effects such as paravalvular leakages can occur postoperatively. The goal of this project is to quantitatively analyze the co-occurrence of this complication and several potential risk factors such as stent shape after implantation, implantation height, amount and distribution of calcifications, and contact forces between stent and surrounding structure. In this paper, we present a two-dimensional visualization (stent maps), which allows (1) to comprehensively display all these aspects from CT data and mechanical simulation results and (2) to compare different datasets to identify patterns that are typical for adverse effects. The area of a stent map represents the surface area of the implanted stent - virtually straightened and uncoiled. Several properties of interest, like radial forces or stent compression, are displayed in this stent map in a heatmap-like fashion. Important anatomical landmarks and calcifications are plotted to show their spatial relation to the stent and possible correlations with the color-coded parameters. To provide comparability, the maps of different patient datasets are spatially adjusted according to a corresponding anatomical landmark. Also, stent maps summarizing the characteristics of different populations (e.g. with or without side effects) can be generated. Up to this point several interesting patterns have been observed with our technique, which remained hidden when examining the raw CT data or 3D visualizations of the same data. One example are obvious radial force maxima between the right and non-coronary valve leaflet occurring mainly in cases without leakages. These observations confirm the usefulness of our approach and give starting points for new hypotheses and further analyses. Because of its reduced dimensionality, the stent map data is an appropriate input for statistical group evaluation and machine learning methods."}, {"color": "gray", "id": 1040, "label": 1040, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1040 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346481\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Dominik Sacha;Andreas Stoffel;Florian Stoffel;Bum Chul Kwon;Geoffrey Ellis;Daniel A. Keim; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Knowledge Generation Model for Visual Analytics; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Visual analytics enables us to analyze huge information spaces in order to support complex decision making and data exploration. Humans play a central role in generating knowledge from the snippets of evidence emerging from visual data analysis. Although prior research provides frameworks that generalize this process, their scope is often narrowly focused so they do not encompass different perspectives at different levels. This paper proposes a knowledge generation model for visual analytics that ties together these diverse frameworks, yet retains previously developed models (e.g., KDD process) to describe individual segments of the overall visual analytic processes. To test its utility, a real world visual analytics system is compared against the model, demonstrating that the knowledge generation process model provides a useful guideline when developing and evaluating such systems. The model is used to effectively compare different data analysis systems. Furthermore, the model provides a common language and description of visual analytic processes, which can be used for communication between researchers. At the end, our model reflects areas of research that future researchers can embark on."}, {"color": "gray", "id": 1041, "label": 1041, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1041 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346482\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Josua Krause;Adam Perer;Enrico Bertini; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: INFUSE: Interactive Feature Selection for Predictive Modeling of High Dimensional Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Predictive modeling techniques are increasingly being used by data scientists to understand the probability of predicted outcomes. However, for data that is high-dimensional, a critical step in predictive modeling is determining which features should be included in the models. Feature selection algorithms are often used to remove non-informative features from models. However, there are many different classes of feature selection algorithms. Deciding which one to use is problematic as the algorithmic output is often not amenable to user interpretation. This limits the ability for users to utilize their domain expertise during the modeling process. To improve on this limitation, we developed INFUSE, a novel visual analytics system designed to help analysts understand how predictive features are being ranked across feature selection algorithms, cross-validation folds, and classifiers. We demonstrate how our system can lead to important insights in a case study involving clinical researchers predicting patient outcomes from electronic medical records."}, {"color": "gray", "id": 1043, "label": 1043, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1043 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346573\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Narges Mahyar;Melanie Tory; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Supporting Communication and Coordination in Collaborative Sensemaking; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: When people work together to analyze a data set, they need to organize their findings, hypotheses, and evidence, share that information with their collaborators, and coordinate activities amongst team members. Sharing externalizations (recorded information such as notes) could increase awareness and assist with team communication and coordination. However, we currently know little about how to provide tool support for this sort of sharing. We explore how linked common work (LCW) can be employed within a `collaborative thinking space\u0027, to facilitate synchronous collaborative sensemaking activities in Visual Analytics (VA). Collaborative thinking spaces provide an environment for analysts to record, organize, share and connect externalizations. Our tool, CLIP, extends earlier thinking spaces by integrating LCW features that reveal relationships between collaborators\u0027 findings. We conducted a user study comparing CLIP to a baseline version without LCW. Results demonstrated that LCW significantly improved analytic outcomes at a collaborative intelligence task. Groups using CLIP were also able to more effectively coordinate their work, and held more discussion of their findings and hypotheses. LCW enabled them to maintain awareness of each other\u0027s activities and findings and link those findings to their own work, preventing disruptive oral awareness notifications."}, {"color": "gray", "id": 1046, "label": 1046, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1046 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346578\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Thomas M\u00fchlbacher;Harald Piringer;Samuel Gratzl;Michael Sedlmair;Marc Streit; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Opening the Black Box: Strategies for Increased User Involvement in Existing Algorithm Implementations; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: An increasing number of interactive visualization tools stress the integration with computational software like MATLAB and R to access a variety of proven algorithms. In many cases, however, the algorithms are used as black boxes that run to completion in isolation which contradicts the needs of interactive data exploration. This paper structures, formalizes, and discusses possibilities to enable user involvement in ongoing computations. Based on a structured characterization of needs regarding intermediate feedback and control, the main contribution is a formalization and comparison of strategies for achieving user involvement for algorithms with different characteristics. In the context of integration, we describe considerations for implementing these strategies either as part of the visualization tool or as part of the algorithm, and we identify requirements and guidelines for the design of algorithmic APIs. To assess the practical applicability, we provide a survey of frequently used algorithm implementations within R regarding the fulfillment of these guidelines. While echoing previous calls for analysis modules which support data exploration more directly, we conclude that a range of pragmatic options for enabling user involvement in ongoing computations exists on both the visualization and algorithm side and should be used."}, {"color": "gray", "id": 1048, "label": 1048, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1048 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346594\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Haidong Chen;Wei Chen;Honghui Mei;Zhiqi Liu;Kun Zhou;Weifeng Chen;Wentao Gu;Kwan-Liu Ma; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visual Abstraction and Exploration of Multi-class Scatterplots; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Scatterplots are widely used to visualize scatter dataset for exploring outliers, clusters, local trends, and correlations. Depicting multi-class scattered points within a single scatterplot view, however, may suffer from heavy overdraw, making it inefficient for data analysis. This paper presents a new visual abstraction scheme that employs a hierarchical multi-class sampling technique to show a feature-preserving simplification. To enhance the density contrast, the colors of multiple classes are optimized by taking the multi-class point distributions into account. We design a visual exploration system that supports visual inspection and quantitative analysis from different perspectives. We have applied our system to several challenging datasets, and the results demonstrate the efficiency of our approach."}, {"color": "gray", "id": 1049, "label": 1049, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1049 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346626\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Michael Beham;Wolfgang Herzner;M. Eduard Gr\u00f6ller;Johannes Kehrer; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Cupid: Cluster-Based Exploration of Geometry Generators with Parallel Coordinates and Radial Trees; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Geometry generators are commonly used in video games and evaluation systems for computer vision to create geometric shapes such as terrains, vegetation or airplanes. The parameters of the generator are often sampled automatically which can lead to many similar or unwanted geometric shapes. In this paper, we propose a novel visual exploration approach that combines the abstract parameter space of the geometry generator with the resulting 3D shapes in a composite visualization. Similar geometric shapes are first grouped using hierarchical clustering and then nested within an illustrative parallel coordinates visualization. This helps the user to study the sensitivity of the generator with respect to its parameter space and to identify invalid parameter settings. Starting from a compact overview representation, the user can iteratively drill-down into local shape differences by clicking on the respective clusters. Additionally, a linked radial tree gives an overview of the cluster hierarchy and enables the user to manually split or merge clusters. We evaluate our approach by exploring the parameter space of a cup generator and provide feedback from domain experts."}, {"color": "gray", "id": 1053, "label": 1053, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1053 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346682\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: David Gotz;Harry Stavropoulos; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: DecisionFlow: Visual Analytics for High-Dimensional Temporal Event Sequence Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Temporal event sequence data is increasingly commonplace, with applications ranging from electronic medical records to financial transactions to social media activity. Previously developed techniques have focused on low-dimensional datasets (e.g., with less than 20 distinct event types). Real-world datasets are often far more complex. This paper describes DecisionFlow, a visual analysis technique designed to support the analysis of high-dimensional temporal event sequence data (e.g., thousands of event types). DecisionFlow combines a scalable and dynamic temporal event data structure with interactive multi-view visualizations and ad hoc statistical analytics. We provide a detailed review of our methods, and present the results from a 12-person user study. The study results demonstrate that DecisionFlow enables the quick and accurate completion of a range of sequence analysis tasks for datasets containing thousands of event types and millions of individual events."}, {"color": "gray", "id": 1056, "label": 1056, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1056 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346746\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Zuchao Wang;Tangzhi Ye;Min Lu;Xiaoru Yuan;Huamin Qu;Jacky Yuan;Qianliang Wu; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visual Exploration of Sparse Traffic Trajectory Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In this paper, we present a visual analysis system to explore sparse traffic trajectory data recorded by transportation cells. Such data contains the movements of nearly all moving vehicles on the major roads of a city. Therefore it is very suitable for macro-traffic analysis. However, the vehicle movements are recorded only when they pass through the cells. The exact tracks between two consecutive cells are unknown. To deal with such uncertainties, we first design a local animation, showing the vehicle movements only in the vicinity of cells. Besides, we ignore the micro-behaviors of individual vehicles, and focus on the macro-traffic patterns. We apply existing trajectory aggregation techniques to the dataset, studying cell status pattern and inter-cell flow pattern. Beyond that, we propose to study the correlation between these two patterns with dynamic graph visualization techniques. It allows us to check how traffic congestion on one cell is correlated with traffic flows on neighbouring links, and with route selection in its neighbourhood. Case studies show the effectiveness of our system."}, {"color": "gray", "id": 1057, "label": 1057, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1057 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346747\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Krishna Madhavan;Niklas Elmqvist;Mihaela Vorvoreanu;Xin Chen;Yuetling Wong;Hanjun Xian;Zhihua Dong;Aditya Johri; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: DIA2: Web-based Cyberinfrastructure for Visual Analysis of Funding Portfolios; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present a design study of the Deep Insights Anywhere, Anytime (DIA2) platform, a web-based visual analytics system that allows program managers and academic staff at the U.S. National Science Foundation to search, view, and analyze their research funding portfolio. The goal of this system is to facilitate users\u0027 understanding of both past and currently active research awards in order to make more informed decisions of their future funding. This user group is characterized by high domain expertise yet not necessarily high literacy in visualization and visual analytics-they are essentially casual experts-and thus require careful visual and information design, including adhering to user experience standards, providing a self-instructive interface, and progressively refining visualizations to minimize complexity. We discuss the challenges of designing a system for casual experts and highlight how we addressed this issue by modeling the organizational structure and workflows of the NSF within our system. We discuss each stage of the design process, starting with formative interviews, prototypes, and finally live deployments and evaluation with stakeholders."}, {"color": "gray", "id": 1063, "label": 1063, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1063 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346893\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Wei Zeng;Chi-Wing Fu;Stefan M\u00fcller Arisona;Alexander Erath;Huamin Qu; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visualizing Mobility of Public Transportation System; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Public transportation systems (PTSs) play an important role in modern cities, providing shared/massive transportation services that are essential for the general public. However, due to their increasing complexity, designing effective methods to visualize and explore PTS is highly challenging. Most existing techniques employ network visualization methods and focus on showing the network topology across stops while ignoring various mobility-related factors such as riding time, transfer time, waiting time, and round-the-clock patterns. This work aims to visualize and explore passenger mobility in a PTS with a family of analytical tasks based on inputs from transportation researchers. After exploring different design alternatives, we come up with an integrated solution with three visualization modules: isochrone map view for geographical information, isotime flow map view for effective temporal information comparison and manipulation, and OD-pair journey view for detailed visual analysis of mobility factors along routes between specific origin-destination pairs. The isotime flow map linearizes a flow map into a parallel isoline representation, maximizing the visualization of mobility information along the horizontal time axis while presenting clear and smooth pathways from origin to destinations. Moreover, we devise several interactive visual query methods for users to easily explore the dynamics of PTS mobility over space and time. Lastly, we also construct a PTS mobility model from millions of real passenger trajectories, and evaluate our visualization techniques with assorted case studies with the transportation researchers."}, {"color": "gray", "id": 1067, "label": 1067, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1067 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346913\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Cong Xie;Wei Chen;Xinxin Huang;Yueqi Hu;Scott Barlowe;Jing Yang; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: VAET: A Visual Analytics Approach for E-Transactions Time-Series; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Previous studies on E-transaction time-series have mainly focused on finding temporal trends of transaction behavior. Interesting transactions that are time-stamped and situation-relevant may easily be obscured in a large amount of information. This paper proposes a visual analytics system, Visual Analysis of E-transaction Time-Series (VAET), that allows the analysts to interactively explore large transaction datasets for insights about time-varying transactions. With a set of analyst-determined training samples, VAET automatically estimates the saliency of each transaction in a large time-series using a probabilistic decision tree learner. It provides an effective time-of-saliency (TOS) map where the analysts can explore a large number of transactions at different time granularities. Interesting transactions are further encoded with KnotLines, a compact visual representation that captures both the temporal variations and the contextual connection of transactions. The analysts can thus explore, select, and investigate knotlines of interest. A case study and user study with a real E-transactions dataset (26 million records) demonstrate the effectiveness of VAET."}, {"color": "gray", "id": 1068, "label": 1068, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1068 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346919\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Guodao Sun;Yingcai Wu;Shixia Liu;Tai-Quan Peng;Jonathan J. H. Zhu;Ronghua Liang; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: EvoRiver: Visual Analysis of Topic Coopetition on Social Media; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Cooperation and competition (jointly called \u201ccoopetition\u201d) are two modes of interactions among a set of concurrent topics on social media. How do topics cooperate or compete with each other to gain public attention? Which topics tend to cooperate or compete with one another? Who plays the key role in coopetition-related interactions? We answer these intricate questions by proposing a visual analytics system that facilitates the in-depth analysis of topic coopetition on social media. We model the complex interactions among topics as a combination of carry-over, coopetition recruitment, and coopetition distraction effects. This model provides a close functional approximation of the coopetition process by depicting how different groups of influential users (i.e., \u201ctopic leaders\u201d) affect coopetition. We also design EvoRiver, a time-based visualization, that allows users to explore coopetition-related interactions and to detect dynamically evolving patterns, as well as their major causes. We test our model and demonstrate the usefulness of our system based on two Twitter data sets (social topics data and business topics data)."}, {"color": "gray", "id": 1070, "label": 1070, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1070 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346922\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jian Zhao;Nan Cao;Zhen Wen;Yale Song;Yu-Ru Lin;Christopher Collins; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: #FluxFlow: Visual Analysis of Anomalous Information Spreading on Social Media; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present FluxFlow, an interactive visual analysis system for revealing and analyzing anomalous information spreading in social media. Everyday, millions of messages are created, commented, and shared by people on social media websites, such as Twitter and Facebook. This provides valuable data for researchers and practitioners in many application domains, such as marketing, to inform decision-making. Distilling valuable social signals from the huge crowd\u0027s messages, however, is challenging, due to the heterogeneous and dynamic crowd behaviors. The challenge is rooted in data analysts\u0027 capability of discerning the anomalous information behaviors, such as the spreading of rumors or misinformation, from the rest that are more conventional patterns, such as popular topics and newsworthy events, in a timely fashion. FluxFlow incorporates advanced machine learning algorithms to detect anomalies, and offers a set of novel visualization designs for presenting the detected threads for deeper analysis. We evaluated FluxFlow with real datasets containing the Twitter feeds captured during significant events such as Hurricane Sandy. Through quantitative measurements of the algorithmic performance and qualitative interviews with domain experts, the results show that the back-end anomaly detection model is effective in identifying anomalous retweeting threads, and its front-end interactive visualizations are intuitive and useful for analysts to discover insights in data and comprehend the underlying analytical model."}, {"color": "gray", "id": 1073, "label": 1073, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1073 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346978\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: \u00c7a\u011fatay Demiralp;Michael S. Bernstein;Jeffrey Heer; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Learning Perceptual Kernels for Visualization Design; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Visualization design can benefit from careful consideration of perception, as different assignments of visual encoding variables such as color, shape and size affect how viewers interpret data. In this work, we introduce perceptual kernels: distance matrices derived from aggregate perceptual judgments. Perceptual kernels represent perceptual differences between and within visual variables in a reusable form that is directly applicable to visualization evaluation and automated design. We report results from crowd-sourced experiments to estimate kernels for color, shape, size and combinations thereof. We analyze kernels estimated using five different judgment types-including Likert ratings among pairs, ordinal triplet comparisons, and manual spatial arrangement-and compare them to existing perceptual models. We derive recommendations for collecting perceptual similarities, and then demonstrate how the resulting kernels can be applied to automate visualization design decisions."}, {"color": "gray", "id": 1075, "label": 1075, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1075 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346983\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Connor C. Gramazio;Karen B. Schloss;David H. Laidlaw; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: The relation between visualization size, grouping, and user performance; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In this paper we make the following contributions: (1) we describe how the grouping, quantity, and size of visual marks affects search time based on the results from two experiments; (2) we report how search performance relates to self-reported difficulty in finding the target for different display types; and (3) we present design guidelines based on our findings to facilitate the design of effective visualizations. Both Experiment 1 and 2 asked participants to search for a unique target in colored visualizations to test how the grouping, quantity, and size of marks affects user performance. In Experiment 1, the target square was embedded in a grid of squares and in Experiment 2 the target was a point in a scatterplot. Search performance was faster when colors were spatially grouped than when they were randomly arranged. The quantity of marks had little effect on search time for grouped displays (\u201cpop-out\u201d), but increasing the quantity of marks slowed reaction time for random displays. Regardless of color layout (grouped vs. random), response times were slowest for the smallest mark size and decreased as mark size increased to a point, after which response times plateaued. In addition to these two experiments we also include potential application areas, as well as results from a small case study where we report preliminary findings that size may affect how users infer how visualizations should be used. We conclude with a list of design guidelines that focus on how to best create visualizations based on grouping, quantity, and size of visual marks."}, {"color": "gray", "id": 1078, "label": 1078, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1078 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2352952\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jarke J. van Wijk; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visualization of Regular Maps: The Chase Continues; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: A regular map is a symmetric tiling of a closed surface, in the sense that all faces, vertices, and edges are topologically indistinguishable. Platonic solids are prime examples, but also for surfaces with higher genus such regular maps exist. We present a new method to visualize regular maps. Space models are produced by matching regular maps with target shapes in the hyperbolic plane. The approach is an extension of our earlier work. Here a wider variety of target shapes is considered, obtained by duplicating spherical and toroidal regular maps, merging triangles, punching holes, and gluing the edges. The method produces about 45 new examples, including the genus 7 Hurwitz surface."}, {"color": "gray", "id": 1083, "label": 1083, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1083 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2014.7042479\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Tarik Crnovrsanin;Chris Muelder;Kwan-Liu Ma; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: A System for Visual Analysis of Radio Signal Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Analysis of radio transmissions is vital for military defense as it provides valuable information about enemy communication and infrastructure. One challenge to the data analysis task is that there are far too many signals for analysts to go through by hand. Even typical signal meta data (such as frequency band, duration, and geographic location) can be overwhelming. In this paper, we present a system for exploring and analyzing such radio signal meta-data. Our system incorporates several visual representations for signal data, designed for readability and ease of comparison, as well as novel algorithms for extracting and classifying consistent signal patterns. We demonstrate the effectiveness of our system using data collected from real missions with an airborne sensor platform."}, {"color": "gray", "id": 1085, "label": 1085, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1085 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2014.7042481\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Miguel Nunes;Benjamin Rowland;Matthias Schlachter;Sol\u00e9akh\u00e9na Ken;Kresimir Matkovic;Anne Laprie;Katja B\u00fchler; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: An Integrated Visual Analysis System for Fusing MR Spectroscopy and Multi-Modal Radiology Imaging; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: For cancers such as glioblastoma multiforme, there is an increasing interest in defining \"biological target volumes\" (BTV), high tumour-burden regions which may be targeted with dose boosts in radiotherapy. The definition of a BTV requires insight into tumour characteristics going beyond conventionally defined radiological abnormalities and anatomical features. Molecular and biochemical imaging techniques, like positron emission tomography, the use of Magnetic Resonance (MR) Imaging contrast agents or MR Spectroscopy deliver this information and support BTV delineation. MR Spectroscopy Imaging (MRSI) is the only non-invasive technique in this list. Studies with MRSI have shown that voxels with certain metabolic signatures are more susceptible to predict the site of relapse. Nevertheless, the discovery of complex relationships between a high number of different metabolites, anatomical, molecular and functional features is an ongoing topic of research - still lacking appropriate tools supporting a smooth workflow by providing data integration and fusion of MRSI data with other imaging modalities. We present a solution bridging this gap which gives fast and flexible access to all data at once. By integrating a customized visualization of the multi-modal and multi-variate image data with a highly flexible visual analytics (VA) framework, it is for the first time possible to interactively fuse, visualize and explore user defined metabolite relations derived from MRSI in combination with markers delivered by other imaging modalities. Real-world medical cases demonstrate the utility of our solution. By making MRSI data available both in a VA tool and in a multi-modal visualization renderer we can combine insights from each side to arrive at a superior BTV delineation. We also report feedback from domain experts indicating significant positive impact in how this work can improve the understanding of MRSI data and its integration into radiotherapy planning."}, {"color": "gray", "id": 1088, "label": 1088, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1088 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2014.7042484\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Sungahnn Ko;Shehzad Afzal;Simon Walton;Yang Yang;Junghoon Chae;Abish Malik;Yun Jang;Min Chen;David Ebert; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Analyzing High-dimensional Multivariate Network Links with Integrated Anomaly Detection, Highlighting and Exploration; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: This paper focuses on the integration of a family of visual analytics techniques for analyzing high-dimensional, multivariate network data that features spatial and temporal information, network connections, and a variety of other categorical and numerical data types. Such data types are commonly encountered in transportation, shipping, and logistics industries. Due to the scale and complexity of the data, it is essential to integrate techniques for data analysis, visualization, and exploration. We present new visual representations, Petal and Thread, to effectively present many-to-many network data including multi-attribute vectors. In addition, we deploy an information-theoretic model for anomaly detection across varying dimensions, displaying highlighted anomalies in a visually consistent manner, as well as supporting a managed process of exploration. Lastly, we evaluate the proposed methodology through data exploration and an empirical study."}, {"color": "gray", "id": 1094, "label": 1094, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1094 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2014.7042490\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Wenchao Wu;Yixian Zheng;Huamin Qu;Wei Chen;Eduard Gr\u00f6ller;Lionel M. Ni; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: BoundarySeer: Visual Analysis of 2D Boundary Changes; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Boundary changes exist ubiquitously in our daily life. From the Antarctic ozone hole to the land desertification, and from the territory of a country to the area within one-hour reach from a downtown location, boundaries change over time. With a large number of time-varying boundaries recorded, people often need to analyze the changes, detect their similarities or differences, and find out spatial and temporal patterns of the evolution for various applications. In this paper, we present a comprehensive visual analytics system, BoundarySeer, to help users gain insight into the changes of boundaries. Our system consists of four major viewers: 1) a global viewer to show boundary groups based on their similarity and the distribution of boundary attributes such as smoothness and perimeter; 2) a region viewer to display the regions encircled by the boundaries and how they are affected by boundary changes; 3) a trend viewer to reveal the temporal patterns in the boundary evolution and potential spatio-temporal correlations; 4) a directional change viewer to encode movements of boundary segments in different directions. Quantitative analyses of boundaries (e.g., similarity measurement and adaptive clustering) and intuitive visualizations (e.g., density map and ThemeRiver) are integrated into these viewers, which enable users to explore boundary changes from different aspects and at different scales. Case studies with two real-world datasets have been carried out to demonstrate the effectiveness of our system."}, {"color": "gray", "id": 1095, "label": 1095, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1095 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2014.7042491\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Johanna Schmidt;Reinhold Preiner;Thomas Auzinger;Michael Wimmer;M. Eduard Gr\u00f6ller;Stefan Bruckner; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: YMCA - Your Mesh Comparison Application; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Polygonal meshes can be created in several different ways. In this paper we focus on the reconstruction of meshes from point clouds, which are sets of points in 3D. Several algorithms that tackle this task already exist, but they have different benefits and drawbacks, which leads to a large number of possible reconstruction results (i.e., meshes). The evaluation of those techniques requires extensive comparisons between different meshes which is up to now done by either placing images of rendered meshes side-by-side, or by encoding differences by heat maps. A major drawback of both approaches is that they do not scale well with the number of meshes. This paper introduces a new comparative visual analysis technique for 3D meshes which enables the simultaneous comparison of several meshes and allows for the interactive exploration of their differences. Our approach gives an overview of the differences of the input meshes in a 2D view. By selecting certain areas of interest, the user can switch to a 3D representation and explore the spatial differences in detail. To inspect local variations, we provide a magic lens tool in 3D. The location and size of the lens provide further information on the variations of the reconstructions in the selected area. With our comparative visualization approach, differences between several mesh reconstruction algorithms can be easily localized and inspected."}, {"color": "gray", "id": 1096, "label": 1096, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1096 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2014.7042492\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Lauren Bradel;Chris North;Leanna House;Scotland Leman; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Multi-Model Semantic Interaction for Text Analytics; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Semantic interaction offers an intuitive communication mechanism between human users and complex statistical models. By shielding the users from manipulating model parameters, they focus instead on directly manipulating the spatialization, thus remaining in their cognitive zone. However, this technique is not inherently scalable past hundreds of text documents. To remedy this, we present the concept of multi-model semantic interaction, where semantic interactions can be used to steer multiple models at multiple levels of data scale, enabling users to tackle larger data problems. We also present an updated visualization pipeline model for generalized multi-model semantic interaction. To demonstrate multi-model semantic interaction, we introduce StarSPIRE, a visual text analytics prototype that transforms user interactions on documents into both small-scale display layout updates as well as large-scale relevancy-based document selection."}, {"color": "gray", "id": 1099, "label": 1099, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1099 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2014.7042495\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Yafeng Lu;Robert Kr\u00fcger;Dennis Thom;Feng Wang;Steffen Koch;Thomas Ertl;Ross Maciejewski; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Integrating Predictive Analytics and Social Media; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: A key analytical task across many domains is model building and exploration for predictive analysis. Data is collected, parsed and analyzed for relationships, and features are selected and mapped to estimate the response of a system under exploration. As social media data has grown more abundant, data can be captured that may potentially represent behavioral patterns in society. In turn, this unstructured social media data can be parsed and integrated as a key factor for predictive intelligence. In this paper, we present a framework for the development of predictive models utilizing social media data. We combine feature selection mechanisms, similarity comparisons and model cross-validation through a variety of interactive visualizations to support analysts in model building and prediction. In order to explore how predictions might be performed in such a framework, we present results from a user study focusing on social media data as a predictor for movie box-office success."}, {"color": "gray", "id": 1107, "label": 1107, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1107 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/SciVis.2015.7429491\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Valentin Zobel;Markus Stommel;Gerik Scheuermann; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Feature-Based Tensor Field Visualization for Fiber Reinforced Polymers; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Virtual testing is an integral part of modern product development in mechanical engineering. Numerical structure simulations allow the computation of local stresses which are given as tensor fields. For homogeneous materials, the tensor information is usually reduced to a scalar field like the von Mises stress. A material-dependent threshold defines the material failure answering the key question of engineers. This leads to a rather simple feature-based visualisation. For composite materials like short fiber reinforced polymers, the situation is much more complex. The material property is determined by the fiber distribution at every position, often described as fiber orientation tensor field. Essentially, the material\u0027s ability to cope with stress becomes anisotropic and inhomogeneous. We show how to combine the stress field and the fiber orientation field in such cases, leading to a feature-based visualization of tensor fields for composite materials. The resulting features inform the engineer about potential improvements in the product development."}, {"color": "gray", "id": 1108, "label": 1108, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1108 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/SciVis.2015.7429492\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Ingo Wald;Aaron Knoll;Gregory P. Johnson;Will Usher;Valerio Pascucci;Michael E. Papka; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: CPU Ray Tracing Large Particle Data with Balanced P-k-d Trees; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present a novel approach to rendering large particle data sets from molecular dynamics, astrophysics and other sources. We employ a new data structure adapted from the original balanced k-d tree, which allows for representation of data with trivial or no overhead. In the OSPRay visualization framework, we have developed an efficient CPU algorithm for traversing, classifying and ray tracing these data. Our approach is able to render up to billions of particles on a typical workstation, purely on the CPU, without any approximations or level-of-detail techniques, and optionally with attribute-based color mapping, dynamic range query, and advanced lighting models such as ambient occlusion and path tracing."}, {"color": "gray", "id": 1110, "label": 1110, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1110 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/SciVis.2015.7429502\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Najmeh Abedzadeh; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Correlation analysis in multidimensional multivariate time-varying datasets; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: One of the most vital challenges for weather forecasters is the correlation between two geographical phenomena that are distributed continuously in multidimensional multivariate time-varying datasets. In this research, we have visualized the correlation between Pressure and Temperature in the climate datasets. Pearson correlation is used in this study to measure the major linear relationship between two variables in the dataset. Using glyphs in the spatial location, we highlighted the significant association between variables. Based on the positive or negative slope of correlation lines, we can conclude how much they are correlated. The principal of this research is visualizing the local trend of variables versus each other in multidimensional multivariate time-varying datasets, which needs to be visualized with their spatial locations in meteorological datasets. Using glyphs, not only can we visualize the correlation between two variables in the coordinate system, but we can also discern whether any of these variables is separately increasing or decreasing. Moreover, we can visualize the background color as another variable and see the correlation lines around of a particular zone such as storm area."}, {"color": "gray", "id": 1114, "label": 1114, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1114 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/SciVis.2015.7429506\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Mathias Goldau;Andr\u00e9 Reichenbach;Mario Hlawitschka; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visualizing crossing probabilistic tracts; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Diffusion weighted magnetic resonance imaging (dMRI) together with tractography algorithms allow to probe for principal white matter tracts in the living human brain. Specifically, probabilistic tractography quantifies the existence of physical connections to a given seed region as a 3D scalar map of confidence scores. Fiber-Stippling is a visualization for probabilistic tracts that effectively communicates the diffusion pattern, connectivity score, and anatomical context. Unfortunately, it cannot handle multiple diffusion orientations per voxel, which exist in high angular resolution diffusion imaging (HARDI) data. Such data is needed to resolve tracts in complex configurations, such as crossings. In this work, we suggest a visualization based on Fiber-Stippling but sensible to multiple diffusion orientations from HARDI-based diffusion models. With such a technique, it is now possible to visualize probabilistic tracts from HARDI-based tractography algorithms. This implies that tract crossings may now be visualized as crossing stipples, which is an essential step towards an accurate visualization of the neuroanatomy, as crossing tracts are widespread phenomena in the brain."}, {"color": "gray", "id": 1116, "label": 1116, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1116 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/SciVis.2015.7429508\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Mohammad Imrul Jubair;Usman Alim;Niklas Roeber;John Clyne;Ali Mahdavi-Amiri;Faramarz Samavati; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Multiresolution visualization of digital earth data via hexagonal box-spline wavelets; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Multiresolution analysis is an important tool for exploring large-scale data sets. Such analysis provides facilities to visualize data at different levels of detail while providing the advantages of efficient data compression and transmission. In this work, an approach is presented to apply multiresolution analysis to digital Earth data where each resolution describes data at a specific level of detail. Geospatial data at a fine level is taken as the input and a hierarchy of approximation and detail coefficients is built by applying a hexagonal discrete wavelet transform. Multiresolution filters are designed for hexagonal cells based on the three directional linear box spline which is natively supported by modern GPUs."}, {"color": "gray", "id": 1118, "label": 1118, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1118 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/SciVis.2015.7429510\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Richen Liu;Hanqi Guo;Xiaoru Yuan; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: A bottom-up scheme for user-defined feature exploration in vector field ensembles; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Most of the existing approaches to visualize vector field ensembles are achieved by visualizing the uncertainty of individual variables from different simulation runs. However, the comparison of the derived feature or user-defined feature, such as the vortex in ensemble flow is also of vital significance since they often make more sense according to the domain knowledge. In this work, we present a framework to extract user-defined feature from different simulation runs. Specially, we use a bottom-up searching scheme to help to extract vortex with a user-defined shape, and further compute the geometry information including the size, and the geo-spatial location of the extracted vortex. Finally we design some linked views to compare the feature between different runs."}, {"color": "gray", "id": 1124, "label": 1124, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1124 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2466838\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Hanqi Guo;Carolyn L. Phillips;Tom Peterka;Dmitry Karpeyev;Andreas Glatz; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Extracting, Tracking, and Visualizing Magnetic Flux Vortices in 3D Complex-Valued Superconductor Simulation Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We propose a method for the vortex extraction and tracking of superconducting magnetic flux vortices for both structured and unstructured mesh data. In the Ginzburg-Landau theory, magnetic flux vortices are well-defined features in a complex-valued order parameter field, and their dynamics determine electromagnetic properties in type-II superconductors. Our method represents each vortex line (a 1D curve embedded in 3D space) as a connected graph extracted from the discretized field in both space and time. For a time-varying discrete dataset, our vortex extraction and tracking method is as accurate as the data discretization. We then apply 3D visualization and 2D event diagrams to the extraction and tracking results to help scientists understand vortex dynamics and macroscale superconductor behavior in greater detail than previously possible."}, {"color": "gray", "id": 1125, "label": 1125, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1125 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2466971\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Matthew Brehmer;Jocelyn Ng;Kevin Tate;Tamara Munzner; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Matches, Mismatches, and Methods: Multiple-View Workflows for Energy Portfolio Analysis; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The energy performance of large building portfolios is challenging to analyze and monitor, as current analysis tools are not scalable or they present derived and aggregated data at too coarse of a level. We conducted a visualization design study, beginning with a thorough work domain analysis and a characterization of data and task abstractions. We describe generalizable visual encoding design choices for time-oriented data framed in terms of matches and mismatches, as well as considerations for workflow design. Our designs address several research questions pertaining to scalability, view coordination, and the inappropriateness of line charts for derived and aggregated data due to a combination of data semantics and domain convention. We also present guidelines relating to familiarity and trust, as well as methodological considerations for visualization design studies. Our designs were adopted by our collaborators and incorporated into the design of an energy analysis software application that will be deployed to tens of thousands of energy workers in their client base."}, {"color": "gray", "id": 1127, "label": 1127, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1127 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467031\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Amin Abbasloo;Vitalis Wiens;Max Hermann;Thomas Schultz; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visualizing Tensor Normal Distributions at Multiple Levels of Detail; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Despite the widely recognized importance of symmetric second order tensor fields in medicine and engineering, the visualization of data uncertainty in tensor fields is still in its infancy. A recently proposed tensorial normal distribution, involving a fourth order covariance tensor, provides a mathematical description of how different aspects of the tensor field, such as trace, anisotropy, or orientation, vary and covary at each point. However, this wealth of information is far too rich for a human analyst to take in at a single glance, and no suitable visualization tools are available. We propose a novel approach that facilitates visual analysis of tensor covariance at multiple levels of detail. We start with a visual abstraction that uses slice views and direct volume rendering to indicate large-scale changes in the covariance structure, and locations with high overall variance. We then provide tools for interactive exploration, making it possible to drill down into different types of variability, such as in shape or orientation. Finally, we allow the analyst to focus on specific locations of the field, and provide tensor glyph animations and overlays that intuitively depict confidence intervals at those points. Our system is demonstrated by investigating the effects of measurement noise on diffusion tensor MRI, and by analyzing two ensembles of stress tensor fields from solid mechanics."}, {"color": "gray", "id": 1128, "label": 1128, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1128 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467035\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Aur\u00e9lie Coh\u00e9;Bastien Liutkus;Gilles Bailly;James Eagan;Eric Lecolinet; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: SchemeLens: A Content-Aware Vector-Based Fisheye Technique for Navigating Large Systems Diagrams; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: System schematics, such as those used for electrical or hydraulic systems, can be large and complex. Fisheye techniques can help navigate such large documents by maintaining the context around a focus region, but the distortion introduced by traditional fisheye techniques can impair the readability of the diagram. We present SchemeLens, a vector-based, topology-aware fisheye technique which aims to maintain the readability of the diagram. Vector-based scaling reduces distortion to components, but distorts layout. We present several strategies to reduce this distortion by using the structure of the topology, including orthogonality and alignment, and a model of user intention to foster smooth and predictable navigation. We evaluate this approach through two user studies: Results show that (1) SchemeLens is 16-27% faster than both round and rectangular flat-top fisheye lenses at finding and identifying a target along one or several paths in a network diagram; (2) augmenting SchemeLens with a model of user intentions aids in learning the network topology."}, {"color": "gray", "id": 1135, "label": 1135, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1135 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467194\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Wenchao Wu;Jiayi Xu;Haipeng Zeng;Yixian Zheng;Huamin Qu;Bing Ni;Mingxuan Yuan;Lionel M. Ni; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: TelCoVis: Visual Exploration of Co-occurrence in Urban Human Mobility Based on Telco Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Understanding co-occurrence in urban human mobility (i.e. people from two regions visit an urban place during the same time span) is of great value in a variety of applications, such as urban planning, business intelligence, social behavior analysis, as well as containing contagious diseases. In recent years, the widespread use of mobile phones brings an unprecedented opportunity to capture large-scale and fine-grained data to study co-occurrence in human mobility. However, due to the lack of systematic and efficient methods, it is challenging for analysts to carry out in-depth analyses and extract valuable information. In this paper, we present TelCoVis, an interactive visual analytics system, which helps analysts leverage their domain knowledge to gain insight into the co-occurrence in urban human mobility based on telco data. Our system integrates visualization techniques with new designs and combines them in a novel way to enhance analysts\u0027 perception for a comprehensive exploration. In addition, we propose to study the correlations in co-occurrence (i.e. people from multiple regions visit different places during the same time span) by means of biclustering techniques that allow analysts to better explore coordinated relationships among different regions and identify interesting patterns. The case studies based on a real-world dataset and interviews with domain experts have demonstrated the effectiveness of our system in gaining insights into co-occurrence and facilitating various analytical tasks."}, {"color": "gray", "id": 1137, "label": 1137, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1137 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467196\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Nan Cao;Conglei Shi;Sabrina Lin;Jie Lu;Yu-Ru Lin;Ching-Yung Lin; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: TargetVue: Visual Analysis of Anomalous User Behaviors in Online Communication Systems; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Users with anomalous behaviors in online communication systems (e.g. email and social medial platforms) are potential threats to society. Automated anomaly detection based on advanced machine learning techniques has been developed to combat this issue; challenges remain, though, due to the difficulty of obtaining proper ground truth for model training and evaluation. Therefore, substantial human judgment on the automated analysis results is often required to better adjust the performance of anomaly detection. Unfortunately, techniques that allow users to understand the analysis results more efficiently, to make a confident judgment about anomalies, and to explore data in their context, are still lacking. In this paper, we propose a novel visual analysis system, TargetVue, which detects anomalous users via an unsupervised learning model and visualizes the behaviors of suspicious users in behavior-rich context through novel visualization designs and multiple coordinated contextual views. Particularly, TargetVue incorporates three new ego-centric glyphs to visually summarize a user\u0027s behaviors which effectively present the user\u0027s communication activities, features, and social interactions. An efficient layout method is proposed to place these glyphs on a triangle grid, which captures similarities among users and facilitates comparisons of behaviors of different users. We demonstrate the power of TargetVue through its application in a social bot detection challenge using Twitter data, a case study based on email records, and an interview with expert users. Our evaluation shows that TargetVue is beneficial to the detection of users with anomalous communication behaviors."}, {"color": "gray", "id": 1143, "label": 1143, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1143 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467203\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Steffen Oeltze-Jafra;Juan R. Cebral;G\u00e1bor Janiga;Bernhard Preim; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Cluster Analysis of Vortical Flow in Simulations of Cerebral Aneurysm Hemodynamics; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Computational fluid dynamic (CFD) simulations of blood flow provide new insights into the hemodynamics of vascular pathologies such as cerebral aneurysms. Understanding the relations between hemodynamics and aneurysm initiation, progression, and risk of rupture is crucial in diagnosis and treatment. Recent studies link the existence of vortices in the blood flow pattern to aneurysm rupture and report observations of embedded vortices - a larger vortex encloses a smaller one flowing in the opposite direction - whose implications are unclear. We present a clustering-based approach for the visual analysis of vortical flow in simulated cerebral aneurysm hemodynamics. We show how embedded vortices develop at saddle-node bifurcations on vortex core lines and convey the participating flow at full manifestation of the vortex by a fast and smart grouping of streamlines and the visualization of group representatives. The grouping result may be refined based on spectral clustering generating a more detailed visualization of the flow pattern, especially further off the core lines. We aim at supporting CFD engineers researching the biological implications of embedded vortices."}, {"color": "gray", "id": 1144, "label": 1144, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1144 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467204\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Florian Ferstl;Kai B\u00fcrger;R\u00fcdiger Westermann; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Streamline Variability Plots for Characterizing the Uncertainty in Vector Field Ensembles; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present a new method to visualize from an ensemble of flow fields the statistical properties of streamlines passing through a selected location. We use principal component analysis to transform the set of streamlines into a low-dimensional Euclidean space. In this space the streamlines are clustered into major trends, and each cluster is in turn approximated by a multivariate Gaussian distribution. This yields a probabilistic mixture model for the streamline distribution, from which confidence regions can be derived in which the streamlines are most likely to reside. This is achieved by transforming the Gaussian random distributions from the low-dimensional Euclidean space into a streamline distribution that follows the statistical model, and by visualizing confidence regions in this distribution via iso-contours. We further make use of the principal component representation to introduce a new concept of streamline-median, based on existing median concepts in multidimensional Euclidean spaces. We demonstrate the potential of our method in a number of real-world examples, and we compare our results to alternative clustering approaches for particle trajectories as well as curve boxplots."}, {"color": "gray", "id": 1145, "label": 1145, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1145 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467251\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Vahan Yoghourdjian;Tim Dwyer;Graeme Gange;Steve Kieffer;Karsten Klein;Kim Marriott; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: High-Quality Ultra-Compact Grid Layout of Grouped Networks; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Prior research into network layout has focused on fast heuristic techniques for layout of large networks, or complex multi-stage pipelines for higher quality layout of small graphs. Improvements to these pipeline techniques, especially for orthogonal-style layout, are difficult and practical results have been slight in recent years. Yet, as discussed in this paper, there remain significant issues in the quality of the layouts produced by these techniques, even for quite small networks. This is especially true when layout with additional grouping constraints is required. The first contribution of this paper is to investigate an ultra-compact, grid-like network layout aesthetic that is motivated by the grid arrangements that are used almost universally by designers in typographical layout. Since the time when these heuristic and pipeline-based graph-layout methods were conceived, generic technologies (MIP, CP and SAT) for solving combinatorial and mixed-integer optimization problems have improved massively. The second contribution of this paper is to reassess whether these techniques can be used for high-quality layout of small graphs. While they are fast enough for graphs of up to 50 nodes we found these methods do not scale up. Our third contribution is a large-neighborhood search meta-heuristic approach that is scalable to larger networks."}, {"color": "gray", "id": 1146, "label": 1146, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1146 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467271\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jonathan C. Roberts;Chris Headleand;Panagiotis D. Ritsos; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Sketching Designs Using the Five Design-Sheet Methodology; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Sketching designs has been shown to be a useful way of planning and considering alternative solutions. The use of lo-fidelity prototyping, especially paper-based sketching, can save time, money and converge to better solutions more quickly. However, this design process is often viewed to be too informal. Consequently users do not know how to manage their thoughts and ideas (to first think divergently, to then finally converge on a suitable solution). We present the Five Design Sheet (FdS) methodology. The methodology enables users to create information visualization interfaces through lo-fidelity methods. Users sketch and plan their ideas, helping them express different possibilities, think through these ideas to consider their potential effectiveness as solutions to the task (sheet 1); they create three principle designs (sheets 2,3 and 4); before converging on a final realization design that can then be implemented (sheet 5). In this article, we present (i) a review of the use of sketching as a planning method for visualization and the benefits of sketching, (ii) a detailed description of the Five Design Sheet (FdS) methodology, and (iii) an evaluation of the FdS using the System Usability Scale, along with a case-study of its use in industry and experience of its use in teaching."}, {"color": "gray", "id": 1148, "label": 1148, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1148 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467292\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Zhongjie Wang;Hans-Peter Seidel;Tino Weinkauf; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Multi-field Pattern Matching based on Sparse Feature Sampling; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present an approach to pattern matching in 3D multi-field scalar data. Existing pattern matching algorithms work on single scalar or vector fields only, yet many numerical simulations output multi-field data where only a joint analysis of multiple fields describes the underlying phenomenon fully. Our method takes this into account by bundling information from multiple fields into the description of a pattern. First, we extract a sparse set of features for each 3D scalar field using the 3D SIFT algorithm (Scale-Invariant Feature Transform). This allows for a memory-saving description of prominent features in the data with invariance to translation, rotation, and scaling. Second, the user defines a pattern as a set of SIFT features in multiple fields by e.g. brushing a region of interest. Third, we locate and rank matching patterns in the entire data set. Experiments show that our algorithm is efficient in terms of required memory and computational efforts."}, {"color": "gray", "id": 1153, "label": 1153, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1153 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467323\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Anushka Anand;Justin Talbot; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Automatic Selection of Partitioning Variables for Small Multiple Displays; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Effective small multiple displays are created by partitioning a visualization on variables that reveal interesting conditional structure in the data. We propose a method that automatically ranks partitioning variables, allowing analysts to focus on the most promising small multiple displays. Our approach is based on a randomized, non-parametric permutation test, which allows us to handle a wide range of quality measures for visual patterns defined on many different visualization types, while discounting spurious patterns. We demonstrate the effectiveness of our approach on scatterplots of real-world, multidimensional datasets."}, {"color": "gray", "id": 1155, "label": 1155, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1155 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467325\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Mona Hosseinkhani Loorak;Charles Perin;Noreen Kamal;Michael Hill;Sheelagh Carpendale; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: TimeSpan: Using Visualization to Explore Temporal Multi-dimensional Data of Stroke Patients; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present TimeSpan, an exploratory visualization tool designed to gain a better understanding of the temporal aspects of the stroke treatment process. Working with stroke experts, we seek to provide a tool to help improve outcomes for stroke victims. Time is of critical importance in the treatment of acute ischemic stroke patients. Every minute that the artery stays blocked, an estimated 1.9 million neurons and 12 km of myelinated axons are destroyed. Consequently, there is a critical need for efficiency of stroke treatment processes. Optimizing time to treatment requires a deep understanding of interval times. Stroke health care professionals must analyze the impact of procedures, events, and patient attributes on time-ultimately, to save lives and improve quality of life after stroke. First, we interviewed eight domain experts, and closely collaborated with two of them to inform the design of TimeSpan. We classify the analytical tasks which a visualization tool should support and extract design goals from the interviews and field observations. Based on these tasks and the understanding gained from the collaboration, we designed TimeSpan, a web-based tool for exploring multi-dimensional and temporal stroke data. We describe how TimeSpan incorporates factors from stacked bar graphs, line charts, histograms, and a matrix visualization to create an interactive hybrid view of temporal data. From feedback collected from domain experts in a focus group session, we reflect on the lessons we learned from abstracting the tasks and iteratively designing TimeSpan."}, {"color": "gray", "id": 1158, "label": 1158, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1158 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467412\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Kenneth Weiss;Peter Lindstrom; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Adaptive Multilinear Tensor Product Wavelets; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Many foundational visualization techniques including isosurfacing, direct volume rendering and texture mapping rely on piecewise multilinear interpolation over the cells of a mesh. However, there has not been much focus within the visualization community on techniques that efficiently generate and encode globally continuous functions defined by the union of multilinear cells. Wavelets provide a rich context for analyzing and processing complicated datasets. In this paper, we exploit adaptive regular refinement as a means of representing and evaluating functions described by a subset of their nonzero wavelet coefficients. We analyze the dependencies involved in the wavelet transform and describe how to generate and represent the coarsest adaptive mesh with nodal function values such that the inverse wavelet transform is exactly reproduced via simple interpolation (subdivision) over the mesh elements. This allows for an adaptive, sparse representation of the function with on-demand evaluation at any point in the domain. We focus on the popular wavelets formed by tensor products of linear B-splines, resulting in an adaptive, nonconforming but crack-free quadtree (2D) or octree (3D) mesh that allows reproducing globally continuous functions via multilinear interpolation over its cells."}, {"color": "gray", "id": 1159, "label": 1159, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1159 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467413\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Joseph Marino;Arie Kaufman; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Planar Visualization of Treelike Structures; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present a novel method to create planar visualizations of treelike structures (e.g., blood vessels and airway trees) where the shape of the object is well preserved, allowing for easy recognition by users familiar with the structures. Based on the extracted skeleton within the treelike object, a radial planar embedding is first obtained such that there are no self-intersections of the skeleton which would have resulted in occlusions in the final view. An optimization procedure which adjusts the angular positions of the skeleton nodes is then used to reconstruct the shape as closely as possible to the original, according to a specified view plane, which thus preserves the global geometric context of the object. Using this shape recovered embedded skeleton, the object surface is then flattened to the plane without occlusions using harmonic mapping. The boundary of the mesh is adjusted during the flattening step to account for regions where the mesh is stretched over concavities. This parameterized surface can then be used either as a map for guidance during endoluminal navigation or directly for interrogation and decision making. Depth cues are provided with a grayscale border to aid in shape understanding. Examples are presented using bronchial trees, cranial and lower limb blood vessels, and upper aorta datasets, and the results are evaluated quantitatively and with a user study."}, {"color": "gray", "id": 1160, "label": 1160, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1160 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467431\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Xiaotong Liu;Han-Wei Shen; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Association Analysis for Visual Exploration of Multivariate Scientific Data Sets; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The heterogeneity and complexity of multivariate characteristics poses a unique challenge to visual exploration of multivariate scientific data sets, as it requires investigating the usually hidden associations between different variables and specific scalar values to understand the data\u0027s multi-faceted properties. In this paper, we present a novel association analysis method that guides visual exploration of scalar-level associations in the multivariate context. We model the directional interactions between scalars of different variables as information flows based on association rules. We introduce the concepts of informativeness and uniqueness to describe how information flows between scalars of different variables and how they are associated with each other in the multivariate domain. Based on scalar-level associations represented by a probabilistic association graph, we propose the Multi-Scalar Informativeness-Uniqueness (MSIU) algorithm to evaluate the informativeness and uniqueness of scalars. We present an exploration framework with multiple interactive views to explore the scalars of interest with confident associations in the multivariate spatial domain, and provide guidelines for visual exploration using our framework. We demonstrate the effectiveness and usefulness of our approach through case studies using three representative multivariate scientific data sets."}, {"color": "gray", "id": 1161, "label": 1161, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1161 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467432\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Attila Gyulassy;Aaron Knoll;Kah Chun Lau;Bei Wang;Peer-Timo Bremer;Michael E. Papka;Larry A. Curtiss;Valerio Pascucci; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Interstitial and Interlayer Ion Diffusion Geometry Extraction in Graphitic Nanosphere Battery Materials; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Large-scale molecular dynamics (MD) simulations are commonly used for simulating the synthesis and ion diffusion of battery materials. A good battery anode material is determined by its capacity to store ion or other diffusers. However, modeling of ion diffusion dynamics and transport properties at large length and long time scales would be impossible with current MD codes. To analyze the fundamental properties of these materials, therefore, we turn to geometric and topological analysis of their structure. In this paper, we apply a novel technique inspired by discrete Morse theory to the Delaunay triangulation of the simulated geometry of a thermally annealed carbon nanosphere. We utilize our computed structures to drive further geometric analysis to extract the interstitial diffusion structure as a single mesh. Our results provide a new approach to analyze the geometry of the simulated carbon nanosphere, and new insights into the role of carbon defect size and distribution in determining the charge capacity and charge dynamics of these carbon based battery materials."}, {"color": "gray", "id": 1163, "label": 1163, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1163 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467434\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jan By\u0161ka;Mathieu Le Muzic;M. Eduard Gr\u00f6ller;Ivan Viola;Barbora Kozl\u00edkov\u00e1; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: AnimoAminoMiner: Exploration of Protein Tunnels and their Properties in Molecular Dynamics; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In this paper we propose a novel method for the interactive exploration of protein tunnels. The basic principle of our approach is that we entirely abstract from the 3D/4D space the simulated phenomenon is embedded in. A complex 3D structure and its curvature information is represented only by a straightened tunnel centerline and its width profile. This representation focuses on a key aspect of the studied geometry and frees up graphical estate to key chemical and physical properties represented by surrounding amino acids. The method shows the detailed tunnel profile and its temporal aggregation. The profile is interactively linked with a visual overview of all amino acids which are lining the tunnel over time. In this overview, each amino acid is represented by a set of colored lines depicting the spatial and temporal impact of the amino acid on the corresponding tunnel. This representation clearly shows the importance of amino acids with respect to selected criteria. It helps the biochemists to select the candidate amino acids for mutation which changes the protein function in a desired way. The AnimoAminoMiner was designed in close cooperation with domain experts. Its usefulness is documented by their feedback and a case study, which are included."}, {"color": "gray", "id": 1165, "label": 1165, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1165 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467436\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Soumya Dutta;Han-Wei Shen; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Distribution Driven Extraction and Tracking of Features for Time-varying Data Analysis; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Effective analysis of features in time-varying data is essential in numerous scientific applications. Feature extraction and tracking are two important tasks scientists rely upon to get insights about the dynamic nature of the large scale time-varying data. However, often the complexity of the scientific phenomena only allows scientists to vaguely define their feature of interest. Furthermore, such features can have varying motion patterns and dynamic evolution over time. As a result, automatic extraction and tracking of features becomes a non-trivial task. In this work, we investigate these issues and propose a distribution driven approach which allows us to construct novel algorithms for reliable feature extraction and tracking with high confidence in the absence of accurate feature definition. We exploit two key properties of an object, motion and similarity to the target feature, and fuse the information gained from them to generate a robust feature-aware classification field at every time step. Tracking of features is done using such classified fields which enhances the accuracy and robustness of the proposed algorithm. The efficacy of our method is demonstrated by successfully applying it on several scientific data sets containing a wide range of dynamic time-varying features."}, {"color": "gray", "id": 1167, "label": 1167, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1167 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467449\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Gordon Kindlmann;Charisee Chiw;Nicholas Seltzer;Lamont Samuels;John Reppy; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Diderot: a Domain-Specific Language for Portable Parallel Scientific Visualization and Image Analysis; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Many algorithms for scientific visualization and image analysis are rooted in the world of continuous scalar, vector, and tensor fields, but are programmed in low-level languages and libraries that obscure their mathematical foundations. Diderot is a parallel domain-specific language that is designed to bridge this semantic gap by providing the programmer with a high-level, mathematical programming notation that allows direct expression of mathematical concepts in code. Furthermore, Diderot provides parallel performance that takes advantage of modern multicore processors and GPUs. The high-level notation allows a concise and natural expression of the algorithms and the parallelism allows efficient execution on real-world datasets."}, {"color": "gray", "id": 1172, "label": 1172, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1172 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467551\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Eric D. Ragan;Alex Endert;Jibonananda Sanyal;Jian Chen; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Characterizing Provenance in Visualization and Data Analysis: An Organizational Framework of Provenance Types and Purposes; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: While the primary goal of visual analytics research is to improve the quality of insights and findings, a substantial amount of research in provenance has focused on the history of changes and advances throughout the analysis process. The term, provenance, has been used in a variety of ways to describe different types of records and histories related to visualization. The existing body of provenance research has grown to a point where the consolidation of design knowledge requires cross-referencing a variety of projects and studies spanning multiple domain areas. We present an organizational framework of the different types of provenance information and purposes for why they are desired in the field of visual analytics. Our organization is intended to serve as a framework to help researchers specify types of provenance and coordinate design knowledge across projects. We also discuss the relationships between these factors and the methods used to capture provenance information. In addition, our organization can be used to guide the selection of evaluation methodology and the comparison of study outcomes in provenance research."}, {"color": "gray", "id": 1174, "label": 1174, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1174 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467553\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Dominik J\u00e4ckle;Fabian Fischer;Tobias Schreck;Daniel A. Keim; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Temporal MDS Plots for Analysis of Multivariate Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Multivariate time series data can be found in many application domains. Examples include data from computer networks, healthcare, social networks, or financial markets. Often, patterns in such data evolve over time among multiple dimensions and are hard to detect. Dimensionality reduction methods such as PCA and MDS allow analysis and visualization of multivariate data, but per se do not provide means to explore multivariate patterns over time. We propose Temporal Multidimensional Scaling (TMDS), a novel visualization technique that computes temporal one-dimensional MDS plots for multivariate data which evolve over time. Using a sliding window approach, MDS is computed for each data window separately, and the results are plotted sequentially along the time axis, taking care of plot alignment. Our TMDS plots enable visual identification of patterns based on multidimensional similarity of the data evolving over time. We demonstrate the usefulness of our approach in the field of network security and show in two case studies how users can iteratively explore the data to identify previously unknown, temporally evolving patterns."}, {"color": "gray", "id": 1179, "label": 1179, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1179 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467611\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Phong H. Nguyen;Kai Xu;Ashley Wheat;B.L. William Wong;Simon Attfield;Bob Fields; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: SensePath: Understanding the Sensemaking Process Through Analytic Provenance; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Sensemaking is described as the process of comprehension, finding meaning and gaining insight from information, producing new knowledge and informing further action. Understanding the sensemaking process allows building effective visual analytics tools to make sense of large and complex datasets. Currently, it is often a manual and time-consuming undertaking to comprehend this: researchers collect observation data, transcribe screen capture videos and think-aloud recordings, identify recurring patterns, and eventually abstract the sensemaking process into a general model. In this paper, we propose a general approach to facilitate such a qualitative analysis process, and introduce a prototype, SensePath, to demonstrate the application of this approach with a focus on browser-based online sensemaking. The approach is based on a study of a number of qualitative research sessions including observations of users performing sensemaking tasks and post hoc analyses to uncover their sensemaking processes. Based on the study results and a follow-up participatory design session with HCI researchers, we decided to focus on the transcription and coding stages of thematic analysis. SensePath automatically captures user\u0027s sensemaking actions, i.e., analytic provenance, and provides multi-linked views to support their further analysis. A number of other requirements elicited from the design session are also implemented in SensePath, such as easy integration with existing qualitative analysis workflow and non-intrusive for participants. The tool was used by an experienced HCI researcher to analyze two sensemaking sessions. The researcher found the tool intuitive and considerably reduced analysis time, allowing better understanding of the sensemaking process."}, {"color": "gray", "id": 1180, "label": 1180, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1180 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467612\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Thomas L\u00f6we;Emmy-Charlotte F\u00f6rster;Georgia Albuquerque;Jens-Peter Kreiss;Marcus Magnor; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visual Analytics for Development and Evaluation of Order Selection Criteria for Autoregressive Processes; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Order selection of autoregressive processes is an active research topic in time series analysis, and the development and evaluation of automatic order selection criteria remains a challenging task for domain experts. We propose a visual analytics approach, to guide the analysis and development of such criteria. A flexible synthetic model generator-combined with specialized responsive visualizations-allows comprehensive interactive evaluation. Our fast framework allows feedback-driven development and fine-tuning of new order selection criteria in real-time. We demonstrate the applicability of our approach in three use-cases for two general as well as a real-world example."}, {"color": "gray", "id": 1184, "label": 1184, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1184 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467619\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Siming Chen;Xiaoru Yuan;Zhenhuang Wang;Cong Guo;Jie Liang;Zuchao Wang;Xiaolong Luke Zhang;Jiawan Zhang; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Interactive Visual Discovering of Movement Patterns from Sparsely Sampled Geo-tagged Social Media Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Social media data with geotags can be used to track people\u0027s movements in their daily lives. By providing both rich text and movement information, visual analysis on social media data can be both interesting and challenging. In contrast to traditional movement data, the sparseness and irregularity of social media data increase the difficulty of extracting movement patterns. To facilitate the understanding of people\u0027s movements, we present an interactive visual analytics system to support the exploration of sparsely sampled trajectory data from social media. We propose a heuristic model to reduce the uncertainty caused by the nature of social media data. In the proposed system, users can filter and select reliable data from each derived movement category, based on the guidance of uncertainty model and interactive selection tools. By iteratively analyzing filtered movements, users can explore the semantics of movements, including the transportation methods, frequent visiting sequences and keyword descriptions. We provide two cases to demonstrate how our system can help users to explore the movement patterns."}, {"color": "gray", "id": 1187, "label": 1187, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1187 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467622\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Josua Krause;Adam Perer;Harry Stavropoulos; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Supporting Iterative Cohort Construction with Visual Temporal Queries; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Many researchers across diverse disciplines aim to analyze the behavior of cohorts whose behaviors are recorded in large event databases. However, extracting cohorts from databases is a difficult yet important step, often overlooked in many analytical solutions. This is especially true when researchers wish to restrict their cohorts to exhibit a particular temporal pattern of interest. In order to fill this gap, we designed COQUITO, a visual interface that assists users defining cohorts with temporal constraints. COQUITO was designed to be comprehensible to domain experts with no preknowledge of database queries and also to encourage exploration. We then demonstrate the utility of COQUITO via two case studies, involving medical and social media researchers."}, {"color": "gray", "id": 1194, "label": 1194, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1194 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467752\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Theresia Gschwandtnei;Markus B\u00f6gl;Paolo Federico;Silvia Miksch; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visual Encodings of Temporal Uncertainty: A Comparative User Study; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: A number of studies have investigated different ways of visualizing uncertainty. However, in the temporal dimension, it is still an open question how to best represent uncertainty, since the special characteristics of time require special visual encodings and may provoke different interpretations. Thus, we have conducted a comprehensive study comparing alternative visual encodings of intervals with uncertain start and end times: gradient plots, violin plots, accumulated probability plots, error bars, centered error bars, and ambiguation. Our results reveal significant differences in error rates and completion time for these different visualization types and different tasks. We recommend using ambiguation - using a lighter color value to represent uncertain regions - or error bars for judging durations and temporal bounds, and gradient plots - using fading color or transparency - for judging probability values."}, {"color": "gray", "id": 1199, "label": 1199, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1199 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467771\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Xiaoke Huang;Ye Zhao;Chao Ma;Jing Yang;Xinyue Ye;Chong Zhang; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: TrajGraph: A Graph-Based Visual Analytics Approach to Studying Urban Network Centralities Using Taxi Trajectory Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We propose TrajGraph, a new visual analytics method, for studying urban mobility patterns by integrating graph modeling and visual analysis with taxi trajectory data. A special graph is created to store and manifest real traffic information recorded by taxi trajectories over city streets. It conveys urban transportation dynamics which can be discovered by applying graph analysis algorithms. To support interactive, multiscale visual analytics, a graph partitioning algorithm is applied to create region-level graphs which have smaller size than the original street-level graph. Graph centralities, including Pagerank and betweenness, are computed to characterize the time-varying importance of different urban regions. The centralities are visualized by three coordinated views including a node-link graph view, a map view and a temporal information view. Users can interactively examine the importance of streets to discover and assess city traffic patterns. We have implemented a fully working prototype of this approach and evaluated it using massive taxi trajectories of Shenzhen, China. TrajGraph\u0027s capability in revealing the importance of city streets was evaluated by comparing the calculated centralities with the subjective evaluations from a group of drivers in Shenzhen. Feedback from a domain expert was collected. The effectiveness of the visual interface was evaluated through a formal user study. We also present several examples and a case study to demonstrate the usefulness of TrajGraph in urban transportation analysis."}, {"color": "gray", "id": 1200, "label": 1200, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1200 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467811\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Nina McCurdy;Julie Lein;Katharine Coles;Miriah Meyer; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Poemage: Visualizing the Sonic Topology of a Poem; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The digital humanities have experienced tremendous growth within the last decade, mostly in the context of developing computational tools that support what is called distant reading - collecting and analyzing huge amounts of textual data for synoptic evaluation. On the other end of the spectrum is a practice at the heart of the traditional humanities, close reading - the careful, in-depth analysis of a single text in order to extract, engage, and even generate as much productive meaning as possible. The true value of computation to close reading is still very much an open question. During a two-year design study, we explored this question with several poetry scholars, focusing on an investigation of sound and linguistic devices in poetry. The contributions of our design study include a problem characterization and data abstraction of the use of sound in poetry as well as Poemage, a visualization tool for interactively exploring the sonic topology of a poem. The design of Poemage is grounded in the evaluation of a series of technology probes we deployed to our poetry collaborators, and we validate the final design with several case studies that illustrate the disruptive impact technology can have on poetry scholarship. Finally, we also contribute a reflection on the challenges we faced conducting visualization research in literary studies."}, {"color": "gray", "id": 1203, "label": 1203, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1203 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467851\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Benjamin Bach;Conglei Shi;Nicolas Heulot;Tara Madhyastha;Tom Grabowski;Pierre Dragicevic; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Time Curves: Folding Time to Visualize Patterns of Temporal Evolution in Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We introduce time curves as a general approach for visualizing patterns of evolution in temporal data. Examples of such patterns include slow and regular progressions, large sudden changes, and reversals to previous states. These patterns can be of interest in a range of domains, such as collaborative document editing, dynamic network analysis, and video analysis. Time curves employ the metaphor of folding a timeline visualization into itself so as to bring similar time points close to each other. This metaphor can be applied to any dataset where a similarity metric between temporal snapshots can be defined, thus it is largely datatype-agnostic. We illustrate how time curves can visually reveal informative patterns in a range of different datasets."}, {"color": "gray", "id": 1205, "label": 1205, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1205 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467872\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Renata Georgia Raidou;Martin Eisemann;Marcel Breeuwer;Elmar Eisemann;Anna Vilanova; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Orientation-Enhanced Parallel Coordinate Plots; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Parallel Coordinate Plots (PCPs) is one of the most powerful techniques for the visualization of multivariate data. However, for large datasets, the representation suffers from clutter due to overplotting. In this case, discerning the underlying data information and selecting specific interesting patterns can become difficult. We propose a new and simple technique to improve the display of PCPs by emphasizing the underlying data structure. Our Orientation-enhanced Parallel Coordinate Plots (OPCPs) improve pattern and outlier discernibility by visually enhancing parts of each PCP polyline with respect to its slope. This enhancement also allows us to introduce a novel and efficient selection method, the Orientation-enhanced Brushing (O-Brushing). Our solution is particularly useful when multiple patterns are present or when the view on certain patterns is obstructed by noise. We present the results of our approach with several synthetic and real-world datasets. Finally, we conducted a user evaluation, which verifies the advantages of the OPCPs in terms of discernibility of information in complex data. It also confirms that O-Brushing eases the selection of data patterns in PCPs and reduces the amount of necessary user interactions compared to state-of-the-art brushing techniques."}, {"color": "gray", "id": 1208, "label": 1208, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1208 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467951\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Yvonne Jansen;Kasper Hornb\u00e6k; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: A Psychophysical Investigation of Size as a Physical Variable; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Physical visualizations, or data physicalizations, encode data in attributes of physical shapes. Despite a considerable body of work on visual variables, \u201cphysical variables\u201d remain poorly understood. One of them is physical size. A difficulty for solid elements is that \u201csize\u201d is ambiguous - it can refer to either length/diameter, surface, or volume. Thus, it is unclear for designers of physicalizations how to effectively encode quantities in physical size. To investigate, we ran an experiment where participants estimated ratios between quantities represented by solid bars and spheres. Our results suggest that solid bars are compared based on their length, consistent with previous findings for 2D and 3D bars on flat media. But for spheres, participants\u0027 estimates are rather proportional to their surface. Depending on the estimation method used, judgments are rather consistent across participants, thus the use of perceptually-optimized size scales seems possible. We conclude by discussing implications for the design of data physicalizations and the need for more empirical studies on physical variables."}, {"color": "gray", "id": 1210, "label": 1210, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1210 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467954\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: C. Papadopoulos;I. Gutenko;A. E. Kaufman; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: VEEVVIE: Visual Explorer for Empirical Visualization, VR and Interaction Experiments; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Empirical, hypothesis-driven, experimentation is at the heart of the scientific discovery process and has become commonplace in human-factors related fields. To enable the integration of visual analytics in such experiments, we introduce VEEVVIE, the Visual Explorer for Empirical Visualization, VR and Interaction Experiments. VEEVVIE is comprised of a back-end ontology which can model several experimental designs encountered in these fields. This formalization allows VEEVVIE to capture experimental data in a query-able form and makes it accessible through a front-end interface. This front-end offers several multi-dimensional visualization widgets with built-in filtering and highlighting functionality. VEEVVIE is also expandable to support custom experimental measurements and data types through a plug-in visualization widget architecture. We demonstrate VEEVVIE through several case studies of visual analysis, performed on the design and data collected during an experiment on the scalability of high-resolution, immersive, tiled-display walls."}, {"color": "gray", "id": 1211, "label": 1211, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1211 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467958\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Tushar Athawale;Elham Sakhaee;Alireza Entezari; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Isosurface Visualization of Data with Nonparametric Models for Uncertainty; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The problem of isosurface extraction in uncertain data is an important research problem and may be approached in two ways. One can extract statistics (e.g., mean) from uncertain data points and visualize the extracted field. Alternatively, data uncertainty, characterized by probability distributions, can be propagated through the isosurface extraction process. We analyze the impact of data uncertainty on topology and geometry extraction algorithms. A novel, edge-crossing probability based approach is proposed to predict underlying isosurface topology for uncertain data. We derive a probabilistic version of the midpoint decider that resolves ambiguities that arise in identifying topological configurations. Moreover, the probability density function characterizing positional uncertainty in isosurfaces is derived analytically for a broad class of nonparametric distributions. This analytic characterization can be used for efficient closed-form computation of the expected value and variation in geometry. Our experiments show the computational advantages of our analytic approach over Monte-Carlo sampling for characterizing positional uncertainty. We also show the advantage of modeling underlying error densities in a nonparametric statistical framework as opposed to a parametric statistical framework through our experiments on ensemble datasets and uncertain scalar fields."}, {"color": "gray", "id": 1212, "label": 1212, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1212 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467961\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Kai Lawonn;Sylvia Gla\u00dfer;Anna Vilanova;Bernhard Preim;Tobias Isenberg; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Occlusion-free Blood Flow Animation with Wall Thickness Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present the first visualization tool that combines pathlines from blood flow and wall thickness information. Our method uses illustrative techniques to provide occlusion-free visualization of the flow. We thus offer medical researchers an effective visual analysis tool for aneurysm treatment risk assessment. Such aneurysms bear a high risk of rupture and significant treatment-related risks. Therefore, to get a fully informed decision it is essential to both investigate the vessel morphology and the hemodynamic data. Ongoing research emphasizes the importance of analyzing the wall thickness in risk assessment. Our combination of blood flow visualization and wall thickness representation is a significant improvement for the exploration and analysis of aneurysms. As all presented information is spatially intertwined, occlusion problems occur. We solve these occlusion problems by dynamic cutaway surfaces. We combine this approach with a glyph-based blood flow representation and a visual mapping of wall thickness onto the vessel surface. We developed a GPU-based implementation of our visualizations which facilitates wall thickness analysis through real-time rendering and flexible interactive data exploration mechanisms. We designed our techniques in collaboration with domain experts, and we provide details about the evaluation of the technique and tool."}, {"color": "gray", "id": 1213, "label": 1213, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1213 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467962\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Thomas Butkiewicz;Andrew H. Stevens; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Effectiveness of Structured Textures on Dynamically Changing Terrain-like Surfaces; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Previous perceptual research and human factors studies have identified several effective methods for texturing 3D surfaces to ensure that their curvature is accurately perceived by viewers. However, most of these studies examined the application of these techniques to static surfaces. This paper explores the effectiveness of applying these techniques to dynamically changing surfaces. When these surfaces change shape, common texturing methods, such as grids and contours, induce a range of different motion cues, which can draw attention and provide information about the size, shape, and rate of change. A human factors study was conducted to evaluate the relative effectiveness of these methods when applied to dynamically changing pseudo-terrain surfaces. The results indicate that, while no technique is most effective for all cases, contour lines generally perform best, and that the pseudo-contour lines induced by banded color scales convey the same benefits."}, {"color": "gray", "id": 1214, "label": 1214, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1214 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467963\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Marco Ament;Carsten Dachsbacher; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Anisotropic Ambient Volume Shading; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present a novel method to compute anisotropic shading for direct volume rendering to improve the perception of the orientation and shape of surface-like structures. We determine the scale-aware anisotropy of a shading point by analyzing its ambient region. We sample adjacent points with similar scalar values to perform a principal component analysis by computing the eigenvectors and eigenvalues of the covariance matrix. In particular, we estimate the tangent directions, which serve as the tangent frame for anisotropic bidirectional reflectance distribution functions. Moreover, we exploit the ratio of the eigenvalues to measure the magnitude of the anisotropy at each shading point. Altogether, this allows us to model a data-driven, smooth transition from isotropic to strongly anisotropic volume shading. In this way, the shape of volumetric features can be enhanced significantly by aligning specular highlights along the principal direction of anisotropy. Our algorithm is independent of the transfer function, which allows us to compute all shading parameters once and store them with the data set. We integrated our method in a GPU-based volume renderer, which offers interactive control of the transfer function, light source positions, and viewpoint. Our results demonstrate the benefit of anisotropic shading for visualization to achieve data-driven local illumination for improved perception compared to isotropic shading."}, {"color": "gray", "id": 1216, "label": 1216, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1216 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467991\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Yafeng Lu;Michael Steptoe;Sarah Burke;Hong Wang;Jiun-Yi Tsai;Hasan Davulcu;Douglas Montgomery;Steven R. Corman;Ross Maciejewski; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Exploring Evolving Media Discourse Through Event Cueing; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Online news, microblogs and other media documents all contain valuable insight regarding events and responses to events. Underlying these documents is the concept of framing, a process in which communicators act (consciously or unconsciously) to construct a point of view that encourages facts to be interpreted by others in a particular manner. As media discourse evolves, how topics and documents are framed can undergo change, shifting the discussion to different viewpoints or rhetoric. What causes these shifts can be difficult to determine directly; however, by linking secondary datasets and enabling visual exploration, we can enhance the hypothesis generation process. In this paper, we present a visual analytics framework for event cueing using media data. As discourse develops over time, our framework applies a time series intervention model which tests to see if the level of framing is different before or after a given date. If the model indicates that the times before and after are statistically significantly different, this cues an analyst to explore related datasets to help enhance their understanding of what (if any) events may have triggered these changes in discourse. Our framework consists of entity extraction and sentiment analysis as lenses for data exploration and uses two different models for intervention analysis. To demonstrate the usage of our framework, we present a case study on exploring potential relationships between climate change framing and conflicts in Africa."}, {"color": "gray", "id": 1217, "label": 1217, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1217 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467992\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Paolo Simonetto;Daniel Archambault;Carlos Scheidegger; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: A Simple Approach for Boundary Improvement of Euler Diagrams; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: General methods for drawing Euler diagrams tend to generate irregular polygons. Yet, empirical evidence indicates that smoother contours make these diagrams easier to read. In this paper, we present a simple method to smooth the boundaries of any Euler diagram drawing. When refining the diagram, the method must ensure that set elements remain inside their appropriate boundaries and that no region is removed or created in the diagram. Our approach uses a force system that improves the diagram while at the same time ensuring its topological structure does not change. We demonstrate the effectiveness of the approach through case studies and quantitative evaluations."}, {"color": "gray", "id": 1218, "label": 1218, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1218 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2468011\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Johannes Sorger;Thomas Ortner;Christian Luksch;Michael Schw\u00e4rzler;Eduard Gr\u00f6ller;Harald Piringer; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: LiteVis: Integrated Visualization for Simulation-Based Decision Support in Lighting Design; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: State-of-the-art lighting design is based on physically accurate lighting simulations of scenes such as offices. The simulation results support lighting designers in the creation of lighting configurations, which must meet contradicting customer objectives regarding quality and price while conforming to industry standards. However, current tools for lighting design impede rapid feedback cycles. On the one side, they decouple analysis and simulation specification. On the other side, they lack capabilities for a detailed comparison of multiple configurations. The primary contribution of this paper is a design study of LiteVis, a system for efficient decision support in lighting design. LiteVis tightly integrates global illumination-based lighting simulation, a spatial representation of the scene, and non-spatial visualizations of parameters and result indicators. This enables an efficient iterative cycle of simulation parametrization and analysis. Specifically, a novel visualization supports decision making by ranking simulated lighting configurations with regard to a weight-based prioritization of objectives that considers both spatial and non-spatial characteristics. In the spatial domain, novel concepts support a detailed comparison of illumination scenarios. We demonstrate LiteVis using a real-world use case and report qualitative feedback of lighting designers. This feedback indicates that LiteVis successfully supports lighting designers to achieve key tasks more efficiently and with greater certainty."}, {"color": "gray", "id": 1221, "label": 1221, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1221 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2468091\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Kuno Kurzhals;Marcel Hlawatsch;Florian Heimerl;Michael Burch;Thomas Ertl;Daniel Weiskopf; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Gaze Stripes: Image-Based Visualization of Eye Tracking Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present a new visualization approach for displaying eye tracking data from multiple participants. We aim to show the spatio-temporal data of the gaze points in the context of the underlying image or video stimulus without occlusion. Our technique, denoted as gaze stripes, does not require the explicit definition of areas of interest but directly uses the image data around the gaze points, similar to thumbnails for images. A gaze stripe consists of a sequence of such gaze point images, oriented along a horizontal timeline. By displaying multiple aligned gaze stripes, it is possible to analyze and compare the viewing behavior of the participants over time. Since the analysis is carried out directly on the image data, expensive post-processing or manual annotation are not required. Therefore, not only patterns and outliers in the participants\u0027 scanpaths can be detected, but the context of the stimulus is available as well. Furthermore, our approach is especially well suited for dynamic stimuli due to the non-aggregated temporal mapping. Complementary views, i.e., markers, notes, screenshots, histograms, and results from automatic clustering, can be added to the visualization to display analysis results. We illustrate the usefulness of our technique on static and dynamic stimuli. Furthermore, we discuss the limitations and scalability of our approach in comparison to established visualization techniques."}, {"color": "gray", "id": 1222, "label": 1222, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1222 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2468093\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Lihua Hao;Christopher G. Healey;Steffen A. Bass; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Effective Visualization of Temporal Ensembles; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: An ensemble is a collection of related datasets, called members, built from a series of runs of a simulation or an experiment. Ensembles are large, temporal, multidimensional, and multivariate, making them difficult to analyze. Another important challenge is visualizing ensembles that vary both in space and time. Initial visualization techniques displayed ensembles with a small number of members, or presented an overview of an entire ensemble, but without potentially important details. Recently, researchers have suggested combining these two directions, allowing users to choose subsets of members to visualization. This manual selection process places the burden on the user to identify which members to explore. We first introduce a static ensemble visualization system that automatically helps users locate interesting subsets of members to visualize. We next extend the system to support analysis and visualization of temporal ensembles. We employ 3D shape comparison, cluster tree visualization, and glyph based visualization to represent different levels of detail within an ensemble. This strategy is used to provide two approaches for temporal ensemble analysis: (1) segment based ensemble analysis, to capture important shape transition time-steps, clusters groups of similar members, and identify common shape changes over time across multiple members; and (2) time-step based ensemble analysis, which assumes ensemble members are aligned in time by combining similar shapes at common time-steps. Both approaches enable users to interactively visualize and analyze a temporal ensemble from different perspectives at different levels of detail. We demonstrate our techniques on an ensemble studying matter transition from hadronic gas to quark-gluon plasma during gold-on-gold particle collisions."}, {"color": "gray", "id": 1223, "label": 1223, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1223 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2468111\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Tatiana von Landesberger;Felix Brodkorb;Philipp Roskosch;Natalia Andrienko;Gennady Andrienko;Andreas Kerren; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: MobilityGraphs: Visual Analysis of Mass Mobility Dynamics via Spatio-Temporal Graphs and Clustering; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Learning more about people mobility is an important task for official decision makers and urban planners. Mobility data sets characterize the variation of the presence of people in different places over time as well as movements (or flows) of people between the places. The analysis of mobility data is challenging due to the need to analyze and compare spatial situations (i.e., presence and flows of people at certain time moments) and to gain an understanding of the spatio-temporal changes (variations of situations over time). Traditional flow visualizations usually fail due to massive clutter. Modern approaches offer limited support for investigating the complex variation of the movements over longer time periods. We propose a visual analytics methodology that solves these issues by combined spatial and temporal simplifications. We have developed a graph-based method, called MobilityGraphs, which reveals movement patterns that were occluded in flow maps. Our method enables the visual representation of the spatio-temporal variation of movements for long time series of spatial situations originally containing a large number of intersecting flows. The interactive system supports data exploration from various perspectives and at various levels of detail by interactive setting of clustering parameters. The feasibility our approach was tested on aggregated mobility data derived from a set of geolocated Twitter posts within the Greater London city area and mobile phone call data records in Abidjan, Ivory Coast. We could show that MobilityGraphs support the identification of regular daily and weekly movement patterns of resident population."}, {"color": "gray", "id": 1224, "label": 1224, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1224 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2468151\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Yanhong Wu;Naveen Pitipornvivat;Jian Zhao;Sixiao Yang;Guowei Huang;Huamin Qu; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: egoSlider: Visual Analysis of Egocentric Network Evolution; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Ego-network, which represents relationships between a specific individual, i.e., the ego, and people connected to it, i.e., alters, is a critical target to study in social network analysis. Evolutionary patterns of ego-networks along time provide huge insights to many domains such as sociology, anthropology, and psychology. However, the analysis of dynamic ego-networks remains challenging due to its complicated time-varying graph structures, for example: alters come and leave, ties grow stronger and fade away, and alter communities merge and split. Most of the existing dynamic graph visualization techniques mainly focus on topological changes of the entire network, which is not adequate for egocentric analytical tasks. In this paper, we present egoSlider, a visual analysis system for exploring and comparing dynamic ego-networks. egoSlider provides a holistic picture of the data through multiple interactively coordinated views, revealing ego-network evolutionary patterns at three different layers: a macroscopic level for summarizing the entire ego-network data, a mesoscopic level for overviewing specific individuals\u0027 ego-network evolutions, and a microscopic level for displaying detailed temporal information of egos and their alters. We demonstrate the effectiveness of egoSlider with a usage scenario with the DBLP publication records. Also, a controlled user study indicates that in general egoSlider outperforms a baseline visualization of dynamic networks for completing egocentric analytical tasks."}, {"color": "gray", "id": 1226, "label": 1226, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1226 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2468292\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Sujin Jang;Niklas Elmqvist;Karthik Ramani; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: MotionFlow: Visual Abstraction and Aggregation of Sequential Patterns in Human Motion Tracking Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Pattern analysis of human motions, which is useful in many research areas, requires understanding and comparison of different styles of motion patterns. However, working with human motion tracking data to support such analysis poses great challenges. In this paper, we propose MotionFlow, a visual analytics system that provides an effective overview of various motion patterns based on an interactive flow visualization. This visualization formulates a motion sequence as transitions between static poses, and aggregates these sequences into a tree diagram to construct a set of motion patterns. The system also allows the users to directly reflect the context of data and their perception of pose similarities in generating representative pose states. We provide local and global controls over the partition-based clustering process. To support the users in organizing unstructured motion data into pattern groups, we designed a set of interactions that enables searching for similar motion sequences from the data, detailed exploration of data subsets, and creating and modifying the group of motion patterns. To evaluate the usability of MotionFlow, we conducted a user study with six researchers with expertise in gesture-based interaction design. They used MotionFlow to explore and organize unstructured motion tracking data. Results show that the researchers were able to easily learn how to use MotionFlow, and the system effectively supported their pattern analysis activities, including leveraging their perception and domain knowledge."}, {"color": "gray", "id": 1227, "label": 1227, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1227 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2469125\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Susan VanderPlas;Heike Hofmann; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Spatial Reasoning and Data Displays; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Graphics convey numerical information very efficiently, but rely on a different set of mental processes than tabular displays. Here, we present a study relating demographic characteristics and visual skills to perception of graphical lineups. We conclude that lineups are essentially a classification test in a visual domain, and that performance on the lineup protocol is associated with general aptitude, rather than specific tasks such as card rotation and spatial manipulation. We also examine the possibility that specific graphical tasks may be associated with certain visual skills and conclude that more research is necessary to understand which visual skills are required in order to understand certain plot types."}, {"color": "gray", "id": 1229, "label": 1229, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1229 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2015.7347625\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Kristin Cook;Nick Cramer;David Israel;Michael Wolverton;Joe Bruce;Russ Burtner;Alex Endert; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Mixed-initiative visual analytics using task-driven recommendations; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Visual data analysis is composed of a collection of cognitive actions and tasks to decompose, internalize, and recombine data to produce knowledge and insight. Visual analytic tools provide interactive visual interfaces to data to support discovery and sensemaking tasks, including forming hypotheses, asking questions, and evaluating and organizing evidence. Myriad analytic models can be incorporated into visual analytic systems at the cost of increasing complexity in the analytic discourse between user and system. Techniques exist to increase the usability of interacting with analytic models, such as inferring data models from user interactions to steer the underlying models of the system via semantic interaction, shielding users from having to do so explicitly. Such approaches are often also referred to as mixed-initiative systems. Sensemaking researchers have called for development of tools that facilitate analytic sensemaking through a combination of human and automated activities. However, design guidelines do not exist for mixed-initiative visual analytic systems to support iterative sensemaking. In this paper, we present candidate design guidelines and introduce the Active Data Environment (ADE) prototype, a spatial workspace supporting the analytic process via task recommendations invoked by inferences about user interactions within the workspace. ADE recommends data and relationships based on a task model, enabling users to co-reason with the system about their data in a single, spatial workspace. This paper provides an illustrative use case, a technical description of ADE, and a discussion of the strengths and limitations of the approach."}, {"color": "gray", "id": 1230, "label": 1230, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1230 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2015.7347626\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Chris Bryan;Xue Wu;Susan Mniszewski;Kwan-Liu Ma; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Integrating predictive analytics into a spatiotemporal epidemic simulation; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The Epidemic Simulation System (EpiSimS) is a scalable, complex modeling tool for analyzing disease within the United States. Due to its high input dimensionality, time requirements, and resource constraints, simulating over the entire parameter space is unfeasible. One solution is to take a granular sampling of the input space and use simpler predictive models (emulators) in between. The quality of the implemented emulator depends on many factors: robustness, sophistication, configuration, and suitability to the input data. Visual analytics can be leveraged to provide guidance and understanding of these things to the user. In this paper, we have implemented a novel interface and workflow for emulator building and use. We introduce a workflow to build emulators, make predictions, and then analyze the results. Our prediction process first predicts temporal time series, and uses these to derive predicted spatial densities. Integrated into the EpiSimS framework, we target users who are non-experts at statistical modeling. This approach allows for a high level of analysis into the state of the built emulators and their resultant predictions. We present our workflow, models, the associated system, and evaluate the overall utility with feedback from EpiSimS scientists."}, {"color": "gray", "id": 1236, "label": 1236, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1236 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2015.7347632\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Qingsong Liu;Yifan Hu;Lei Shi;Xinzhu Mu;Yutao Zhang;Jie Tang; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: EgoNetCloud: Event-based egocentric dynamic network visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Event-based egocentric dynamic networks are an important class of networks widely seen in many domains. In this paper, we present a visual analytics approach for these networks by combining data-driven network simplifications with a novel visualization design - EgoNetCloud. In particular, an integrated data processing pipeline is proposed to prune, compress and filter the networks into smaller but salient abstractions. To accommodate the simplified network into the visual design, we introduce a constrained graph layout algorithm on the dynamic network. Through a real-life case study as well as conversations with the domain expert, we demonstrate the effectiveness of the EgoNetCloud design and system in completing analysis tasks on event-based dynamic networks. The user study comparing EgoNetCloud with a working system on academic search confirms the effectiveness and convenience of our visual analytics based approach."}, {"color": "gray", "id": 1237, "label": 1237, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1237 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2015.7347633\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Quan Li;Peng Xu;Huamin Qu; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: FPSSeer: Visual analysis of game frame rate data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The rate at which frames are rendered in a computer game directly influences both game playability and enjoyability. Players frequently have to deal with the trade-off between high frame rates and good resolution. Analyzing patterns in frame rate data and their correlation with the overall game performance is important in designing games (e.g., graphic card/display setting suggestion and game performance measurement). However, this task is challenging because game frame rates vary both temporally and spatially. In addition, players may adjust their display settings based on their gaming experience and hardware conditions, which further contributes to the unpredictability of frame rates. In this paper, we present a comprehensive visual analytics system FPSSeer, to help game designers gain insight into frame rate data. Our system consists of four major views: 1) a frame rate view to show the overall distribution in a geographic scale, 2) a grid view to show the frame rate distribution and grid element clusters based on their similarity, 3) a FootRiver view to reveal the temporal patterns in game condition changes and potential spatiotemporal correlations, and 4) a comparison view to evaluate game performance discrepancy under different game tests. The real-world case studies demonstrate the effectiveness of our system. The system has been applied to an online commercial game to monitor its performance and to provide feedbacks to designers and developers."}, {"color": "gray", "id": 1238, "label": 1238, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1238 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2015.7347634\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Mihaela Jarema;Ismail Demir;Johannes Kehrer;R\u00fcdiger Westermann; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Comparative visual analysis of vector field ensembles; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present a new visual analysis approach to support the comparative exploration of 2D vector-valued ensemble fields. Our approach enables the user to quickly identify the most similar groups of ensemble members, as well as the locations where the variation among the members is high. We further provide means to visualize the main features of the potentially multimodal directional distributions at user-selected locations. For this purpose, directional data is modelled using mixtures of probability density functions (pdfs), which allows us to characterize and classify complex distributions with relatively few parameters. The resulting mixture models are used to determine the degree of similarity between ensemble members, and to construct glyphs showing the direction, spread, and strength of the principal modes of the directional distributions. We also propose several similarity measures, based on which we compute pairwise member similarities in the spatial domain and form clusters of similar members. The hierarchical clustering is shown using dendrograms and similarity matrices, which can be used to select particular members and visualize their variations. A user interface providing multiple linked views enables the simultaneous visualization of aggregated global and detailed local variations, as well as the selection of members for a detailed comparison."}, {"color": "gray", "id": 1243, "label": 1243, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1243 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2015.7347672\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: M. B\u00f6gl;P. Filzmoser;T. Gschwandtner;S. Miksch;W. Aigner;A. Rind;T. Lammarsch; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visually and statistically guided imputation of missing values in univariate seasonal time series; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Missing values are a problem in many real world applications, for example failing sensor measurements. For further analysis these missing values need to be imputed. Thus, imputation of such missing values is important in a wide range of applications. We propose a visually and statistically guided imputation approach, that allows applying different imputation techniques to estimate the missing values as well as evaluating and fine tuning the imputation by visual guidance. In our approach we include additional visual information about uncertainty and employ the cyclic structure of time inherent in the data. Including this cyclic structure enables visually judging the adequateness of the estimated values with respect to the uncertainty/error boundaries and according to the patterns of the neighbouring time points in linear and cyclic (e.g., the months of the year) time."}, {"color": "gray", "id": 1245, "label": 1245, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1245 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2015.7347674\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Kristin A. Cook;Jean Scholtz;Mark A. Whiting; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: A software developer\u0027s guide to informal evaluation of Visual Analytics environments using VAST Challenge information; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The VAST Challenge has been a popular venue for academic and industry participants for over ten years. Many participants comment that the majority of their time in preparing VAST Challenge entries is discovering elements in their software environments that need to be redesigned in order to solve the given task. Fortunately, there is no need to wait until the VAST Challenge is announced to test out software systems. The Visual Analytics Benchmark Repository contains all past VAST Challenge tasks, data, solutions and submissions. In this poster we describe how developers can perform informal evaluations of various aspects of their visual analytics environments using VAST Challenge information."}, {"color": "gray", "id": 1246, "label": 1246, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1246 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2015.7347675\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Haoling Dong;Siliang Tang;Si Li;Fei Wu;Yueting Zhuang; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: HTMVS: Visualizing hierarchical topics and their evolution; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Topic model has been an active research area for many years, it can be used for discovering latent semantics and finding hidden knowledge in unstructured data corpus. In this paper, we investigated the problems in visualizing hierarchical topic and their evolution. The contribution of this paper is threefold, first we explore the static visualization of hierarchical topics using the `nested circle\u0027 layout, and then in order to present the topic evolution over time, we extended a hierarchical topic model and employ topic transformation visualizations to track the arising, splitting and disappearing of certain topics under the dynamic topical hierarchy. Finally, a Hierarchical Topic Model Visualization System (HTMVS) is designed to take advantage of both static and dynamic hierarchical topic visualization."}, {"color": "gray", "id": 1247, "label": 1247, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1247 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2015.7347676\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Mar\u00eda Luj\u00e1n Ganuza;Florencia Gargiulo;Gabriela Ferracutti;Silvia Castro;Ernesto Bjerg;Eduard Gr\u00f6ller;Kre\u0161imir Matkovi\u0107; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Interactive semi-automatic categorization for spinel group minerals; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Spinel group minerals are excellent indicators of geological environments (tectonic settings). In 2001, Barnes and Roeder defined a set of contours corresponding to compositional fields for spinel group minerals. Geologists typically use this contours to estimate the tectonic environment where a particular spinel composition could have been formed. This task is prone to errors and requires tedious manual comparison of overlapping diagrams. We introduce a semi-automatic, interactive detection of tectonic settings for an arbitrary dataset based on the Barnes and Roeder contours. The new approach integrates the mentioned contours and includes a novel interaction called contour brush. The new methodology is integrated in the Spinel Explorer system and it improves the scientist\u0027s workflow significantly."}, {"color": "gray", "id": 1248, "label": 1248, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1248 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2015.7347677\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Masahiko Itoh;Daisaku Yokoyama;Masashi Toyoda;Masaru Kitsuregawa; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: A System for visual exploration of caution spots from vehicle recorder data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: It is vital for the transportation industry, which performs most of its work by automobiles, to reduce its accident rate. This paper proposes a 3D visual interaction method for exploring caution areas from large-scale vehicle recorder data. Our method provides (i) a flexible filtering interface for driving operations such as braking or handling operations by various combinations of their attribute values such as velocity and acceleration, and (ii) a 3D visual environment for spatio-temporal exploration of caution areas. The proposed method was able to extract caution areas where some accidents have actually occurred or that are on very narrow roads with bad visibility by using real data given by one of the biggest transportation companies in Japan."}, {"color": "gray", "id": 1249, "label": 1249, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1249 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2015.7347678\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Roger A. Leite;Theresia Gschwandtner;Silvia Miksch;Erich Gstrein;Johannes Kuntner; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visual Analytics for fraud detection and monitoring; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: One of the primary concerns of financial institutions is to guarantee security and legitimacy in their services. Being able to detect and avoid fraudulent schemes also enhances the credibility of these institutions. Currently, fraud detection approaches still lack Visual Analytics techniques. We propose a Visual Analytics process that tackles the main challenges in the area of fraud detection."}, {"color": "gray", "id": 1250, "label": 1250, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1250 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2015.7347679\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Min Lu;Chufan Lai;Tangzhi Ye;Jie Liang;Xiaoru Yuan; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visual analysis of route choice behaviour based on GPS trajectories; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: There are often multiple routes between regions. Many factors potentially affect driver\u0027s route choice, such as expected time cost, length etc. In this work, we present a visual analysis system to explore driver\u0027s route choice behaviour based on taxi GPS trajectory data. With interactive trajectory filtering, the system constructs feasible routes between regions of interest. Using a rank-based visualization, the attributes of multiple routes are explored and compared. Based on a statistical model, the system supports to verify trajectory-related factors\u0027 impact on route choice behaviour. The effectiveness of the system is demonstrated by applying to real trajectory dataset."}, {"color": "gray", "id": 1251, "label": 1251, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1251 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2015.7347680\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Miriam Perkins;Yanlai Chen; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Using visualization and analysis with efficient dimension Reduction to determine underlying factors in hospital inpatient procedure costs; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The Centers for Medicare and Medicaid Services (CMS) has made public a data set showing what hospitals charged and what Medicare paid for the one hundred most common inpatient stays. Here we present the application of Reduced Basis Decomposition (RBD), an efficient novel dimension reduction algorithm for data processing, to the CMS data. This was paired with a comparative visual exploration of the results when put into context with characteristics of the hospitals and marketplaces in which they operate. We used Weave Analyst, a new web-based analysis and visualization environment, to visualize the relationship between the hospital groups, their charge levels, and distinguishing indicator variables. Particular insights to the relatively small number of underlying factors that exert greatest influence on hospital pricing surfaced thanks to the combined synergetic integration of the modeling, reduction, and visualization techniques."}, {"color": "gray", "id": 1252, "label": 1252, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1252 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2015.7347681\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jessica Peter;Steve Szigeti;Ana Jofre;Sara Diamond; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Topicks: Visualizing complex topic models for user comprehension; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The interactive visualization of topic models is a promising approach to summarizing large sets of textual data. Topicks is the working title for a means to visualize topic modelling outputs. Incorporating a radial layout, users can view the relationships between topics, terms and the corpus as a whole. Interacting with topic and term nodes, as well as a related bar chart, provides the user with various ways to manipulate the visualization and explore the data. We describe the visualization and potential user interactions before discussing future work."}, {"color": "gray", "id": 1253, "label": 1253, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1253 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2015.7347682\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Peter J. Polack;Shang-Tse Chen;Minsuk Kahng;Moushumi Sharmin;Duen Horng Chau; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: TimeStitch: Interactive multi-focus cohort discovery and comparison; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Whereas event-based timelines for healthcare enable users to visualize the chronology of events surrounding events of interest, they are often not designed to aid the discovery, construction, or comparison of associated cohorts. We present TimeStitch, a system that helps health researchers discover and understand events that may cause abstinent smokers to lapse. TimeStitch extracts common sequences of events performed by abstinent smokers from large amounts of mobile health sensor data, and offers a suite of interactive and visualization techniques to enable cohort discovery, construction, and comparison, using extracted sequences as interactive elements. We are extending TimeStitch to support more complex health conditions with high mortality risk, such as reducing hospital readmission in congestive heart failure."}, {"color": "gray", "id": 1255, "label": 1255, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1255 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2015.7347684\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Christian Richter;Martin Luboschik;Martin R\u00f6hlig;Heidrun Schumann; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Sequencing of categorical time series; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Exploring and comparing categorical time series and finding temporal patterns are complex tasks in the field of time series data mining. Although different analysis approaches exist, these tasks remain challenging, especially when numerous time series are considered at once. We propose a visual analysis approach that supports exploring such data by ordering time series in meaningful ways. We provide interaction techniques to steer the automated arrangement and to allow users to investigate patterns in detail."}, {"color": "gray", "id": 1257, "label": 1257, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1257 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2015.7347686\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Cecilia di Sciascio;Vedran Sabol;Eduardo Veas; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: uRank: Visual analytics approach for search result exploration; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: uRank is a Web-based tool combining lightweight text analytics and visual methods for topic-wise exploration of document sets. It includes a view summarizing the content of the document set in meaningful terms, a dynamic document ranking view and a detailed view for further inspection of individual documents. Its major strength lies in how it supports users in reorganizing documents on-the-fly as their information interests change. We present a preliminary evaluation showing that uRank helps to reduce cognitive load compared to a traditional list-based representation."}, {"color": "gray", "id": 1260, "label": 1260, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1260 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2015.7347689\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Zuchao Wang;Xiaoru Yuan;Tangzhi Ye;Youfeng hao;Siming Chen;Jie Liangk;Qiusheng Li;Haiyang Wang;Yadong Wu; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visual data quality analysis for taxi GPS data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present a novel visual analysis method to systematically discover data quality problems in raw taxi GPS data. It combines semi-supervised active learning and interactive visual exploration. It helps analysts interactively discover unknown data quality problems, and automatically extract known problems. We report analysis results on Beijing taxi GPS data."}, {"color": "gray", "id": 1261, "label": 1261, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1261 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2598415\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Quan Li;Peng Xu;Yeuk Yin Chan;Yun Wang;Zhipeng Wang;Huamin Qu;Xiaojuan Ma; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: A Visual Analytics Approach for Understanding Reasons behind Snowballing and Comeback in MOBA Games; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: To design a successful Multiplayer Online Battle Arena (MOBA) game, the ratio of snowballing and comeback occurrences to all matches played must be maintained at a certain level to ensure its fairness and engagement. Although it is easy to identify these two types of occurrences, game developers often find it difficult to determine their causes and triggers with so many game design choices and game parameters involved. In addition, the huge amounts of MOBA game data are often heterogeneous, multi-dimensional and highly dynamic in terms of space and time, which poses special challenges for analysts. In this paper, we present a visual analytics system to help game designers find key events and game parameters resulting in snowballing or comeback occurrences in MOBA game data. We follow a user-centered design process developing the system with game analysts and testing with real data of a trial version MOBA game from NetEase Inc. We apply novel visualization techniques in conjunction with well-established ones to depict the evolution of players\u0027 positions, status and the occurrences of events. Our system can reveal players\u0027 strategies and performance throughout a single match and suggest patterns, e.g., specific player\u0027 actions and game events, that have led to the final occurrences. We further demonstrate a workflow of leveraging human analyzed patterns to improve the scalability and generality of match data analysis. Finally, we validate the usability of our system by proving the identified patterns are representative in snowballing or comeback matches in a one-month-long MOBA tournament dataset."}, {"color": "gray", "id": 1264, "label": 1264, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1264 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2598432\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Dongyu Liu;Di Weng;Yuhong Li;Jie Bao;Yu Zheng;Huamin Qu;Yingcai Wu; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: SmartAdP: Visual Analytics of Large-scale Taxi Trajectories for Selecting Billboard Locations; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The problem of formulating solutions immediately and comparing them rapidly for billboard placements has plagued advertising planners for a long time, owing to the lack of efficient tools for in-depth analyses to make informed decisions. In this study, we attempt to employ visual analytics that combines the state-of-the-art mining and visualization techniques to tackle this problem using large-scale GPS trajectory data. In particular, we present SmartAdP, an interactive visual analytics system that deals with the two major challenges including finding good solutions in a huge solution space and comparing the solutions in a visual and intuitive manner. An interactive framework that integrates a novel visualization-driven data mining model enables advertising planners to effectively and efficiently formulate good candidate solutions. In addition, we propose a set of coupled visualizations: a solution view with metaphor-based glyphs to visualize the correlation between different solutions; a location view to display billboard locations in a compact manner; and a ranking view to present multi-typed rankings of the solutions. This system has been demonstrated using case studies with a real-world dataset and domain-expert interviews. Our approach can be adapted for other location selection problems such as selecting locations of retail stores or restaurants using trajectory data."}, {"color": "gray", "id": 1266, "label": 1266, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1266 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2598445\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Minjeong Kim;Kyeongpil Kang;Deokgun Park;Jaegul Choo;Niklas Elmqvist; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: TopicLens: Efficient Multi-Level Visual Topic Exploration of Large-Scale Document Collections; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Topic modeling, which reveals underlying topics of a document corpus, has been actively adopted in visual analytics for large-scale document collections. However, due to its significant processing time and non-interactive nature, topic modeling has so far not been tightly integrated into a visual analytics workflow. Instead, most such systems are limited to utilizing a fixed, initial set of topics. Motivated by this gap in the literature, we propose a novel interaction technique called TopicLens that allows a user to dynamically explore data through a lens interface where topic modeling and the corresponding 2D embedding are efficiently computed on the fly. To support this interaction in real time while maintaining view consistency, we propose a novel efficient topic modeling method and a semi-supervised 2D embedding algorithm. Our work is based on improving state-of-the-art methods such as nonnegative matrix factorization and t-distributed stochastic neighbor embedding. Furthermore, we have built a web-based visual analytics system integrated with TopicLens. We use this system to measure the performance and the visualization quality of our proposed methods. We provide several scenarios showcasing the capability of TopicLens using real-world datasets."}, {"color": "gray", "id": 1270, "label": 1270, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1270 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2598460\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: R. Jordan Crouser;Lyndsey Franklin;Alex Endert;Kris Cook; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Toward Theoretical Techniques for Measuring the Use of Human Effort in Visual Analytic Systems; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Visual analytic systems have long relied on user studies and standard datasets to demonstrate advances to the state of the art, as well as to illustrate the efficiency of solutions to domain-specific challenges. This approach has enabled some important comparisons between systems, but unfortunately the narrow scope required to facilitate these comparisons has prevented many of these lessons from being generalized to new areas. At the same time, advanced visual analytic systems have made increasing use of human-machine collaboration to solve problems not tractable by machine computation alone. To continue to make progress in modeling user tasks in these hybrid visual analytic systems, we must strive to gain insight into what makes certain tasks more complex than others. This will require the development of mechanisms for describing the balance to be struck between machine and human strengths with respect to analytical tasks and workload. In this paper, we argue for the necessity of theoretical tools for reasoning about such balance in visual analytic systems and demonstrate the utility of the Human Oracle Model for this purpose in the context of sensemaking in visual analytics. Additionally, we make use of the Human Oracle Model to guide the development of a new system through a case study in the domain of cybersecurity."}, {"color": "gray", "id": 1271, "label": 1271, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1271 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2598463\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Ievgeniia Gutenko;Konstantin Dmitriev;Arie E. Kaufman;Matthew A. Barish; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: AnaFe: Visual Analytics of Image-derived Temporal Features Focusing on the Spleen; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present a novel visualization framework, AnaFe, targeted at observing changes in the spleen over time through multiple image-derived features. Accurate monitoring of progressive changes is crucial for diseases that result in enlargement of the organ. Our system is comprised of multiple linked views combining visualization of temporal 3D organ data, related measurements, and features. Thus it enables the observation of progression and allows for simultaneous comparison within and between the subjects. AnaFe offers insights into the overall distribution of robustly extracted and reproducible quantitative imaging features and their changes within the population, and also enables detailed analysis of individual cases. It performs similarity comparison of temporal series of one subject to all other series in both sick and healthy groups. We demonstrate our system through two use case scenarios on a population of 189 spleen datasets from 68 subjects with various conditions observed over time."}, {"color": "gray", "id": 1275, "label": 1275, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1275 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2598468\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Davide Ceneda;Theresia Gschwandtner;Thorsten May;Silvia Miksch;Hans-J\u00f6rg Schulz;Marc Streit;Christian Tominski; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Characterizing Guidance in Visual Analytics; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Visual analytics (VA) is typically applied in scenarios where complex data has to be analyzed. Unfortunately, there is a natural correlation between the complexity of the data and the complexity of the tools to study them. An adverse effect of complicated tools is that analytical goals are more difficult to reach. Therefore, it makes sense to consider methods that guide or assist users in the visual analysis process. Several such methods already exist in the literature, yet we are lacking a general model that facilitates in-depth reasoning about guidance. We establish such a model by extending van Wijk\u0027s model of visualization with the fundamental components of guidance. Guidance is defined as a process that gradually narrows the gap that hinders effective continuation of the data analysis. We describe diverse inputs based on which guidance can be generated and discuss different degrees of guidance and means to incorporate guidance into VA tools. We use existing guidance approaches from the literature to illustrate the various aspects of our model. As a conclusion, we identify research challenges and suggest directions for future studies. With our work we take a necessary step to pave the way to a systematic development of guidance techniques that effectively support users in the context of VA."}, {"color": "gray", "id": 1276, "label": 1276, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1276 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2598469\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Michael Glueck;Alina Gvozdik;Fanny Chevalier;Azam Khan;Michael Brudno;Daniel Wigdor; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: PhenoStacks: Cross-Sectional Cohort Phenotype Comparison Visualizations; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Cross-sectional phenotype studies are used by genetics researchers to better understand how phenotypes vary across patients with genetic diseases, both within and between cohorts. Analyses within cohorts identify patterns between phenotypes and patients (e.g., co-occurrence) and isolate special cases (e.g., potential outliers). Comparing the variation of phenotypes between two cohorts can help distinguish how different factors affect disease manifestation (e.g., causal genes, age of onset, etc.). PhenoStacks is a novel visual analytics tool that supports the exploration of phenotype variation within and between cross-sectional patient cohorts. By leveraging the semantic hierarchy of the Human Phenotype Ontology, phenotypes are presented in context, can be grouped and clustered, and are summarized via overviews to support the exploration of phenotype distributions. The design of PhenoStacks was motivated by formative interviews with genetics researchers: we distil high-level tasks, present an algorithm for simplifying ontology topologies for visualization, and report the results of a deployment evaluation with four expert genetics researchers. The results suggest that PhenoStacks can help identify phenotype patterns, investigate data quality issues, and inform data collection design."}, {"color": "gray", "id": 1277, "label": 1277, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1277 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2598470\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Cagatay Turkay;Erdem Kaya;Selim Balcisoy;Helwig Hauser; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Designing Progressive and Interactive Analytics Processes for High-Dimensional Data Analysis; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In interactive data analysis processes, the dialogue between the human and the computer is the enabling mechanism that can lead to actionable observations about the phenomena being investigated. It is of paramount importance that this dialogue is not interrupted by slow computational mechanisms that do not consider any known temporal human-computer interaction characteristics that prioritize the perceptual and cognitive capabilities of the users. In cases where the analysis involves an integrated computational method, for instance to reduce the dimensionality of the data or to perform clustering, such non-optimal processes are often likely. To remedy this, progressive computations, where results are iteratively improved, are getting increasing interest in visual analytics. In this paper, we present techniques and design considerations to incorporate progressive methods within interactive analysis processes that involve high-dimensional data. We define methodologies to facilitate processes that adhere to the perceptual characteristics of users and describe how online algorithms can be incorporated within these. A set of design recommendations and according methods to support analysts in accomplishing high-dimensional data analysis tasks are then presented. Our arguments and decisions here are informed by observations gathered over a series of analysis sessions with analysts from finance. We document observations and recommendations from this study and present evidence on how our approach contribute to the efficiency and productivity of interactive visual analysis sessions involving high-dimensional data."}, {"color": "gray", "id": 1278, "label": 1278, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1278 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2598471\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Filip Dabek;Jesus J Caban; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: A Grammar-based Approach for Modeling User Interactions and Generating Suggestions During the Data Exploration Process; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Despite the recent popularity of visual analytics focusing on big data, little is known about how to support users that use visualization techniques to explore multi-dimensional datasets and accomplish specific tasks. Our lack of models that can assist end-users during the data exploration process has made it challenging to learn from the user\u0027s interactive and analytical process. The ability to model how a user interacts with a specific visualization technique and what difficulties they face are paramount in supporting individuals with discovering new patterns within their complex datasets. This paper introduces the notion of visualization systems understanding and modeling user interactions with the intent of guiding a user through a task thereby enhancing visual data exploration. The challenges faced and the necessary future steps to take are discussed; and to provide a working example, a grammar-based model is presented that can learn from user interactions, determine the common patterns among a number of subjects using a K-Reversible algorithm, build a set of rules, and apply those rules in the form of suggestions to new users with the goal of guiding them along their visual analytic process. A formal evaluation study with 300 subjects was performed showing that our grammar-based model is effective at capturing the interactive process followed by users and that further research in this area has the potential to positively impact how users interact with a visualization system."}, {"color": "gray", "id": 1281, "label": 1281, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1281 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2598495\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Dominik Sacha;Leishi Zhang;Michael Sedlmair;John A. Lee;Jaakko Peltonen;Daniel Weiskopf;Stephen C. North;Daniel A. Keim; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visual Interaction with Dimensionality Reduction: A Structured Literature Analysis; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Dimensionality Reduction (DR) is a core building block in visualizing multidimensional data. For DR techniques to be useful in exploratory data analysis, they need to be adapted to human needs and domain-specific problems, ideally, interactively, and on-the-fly. Many visual analytics systems have already demonstrated the benefits of tightly integrating DR with interactive visualizations. Nevertheless, a general, structured understanding of this integration is missing. To address this, we systematically studied the visual analytics and visualization literature to investigate how analysts interact with automatic DR techniques. The results reveal seven common interaction scenarios that are amenable to interactive control such as specifying algorithmic constraints, selecting relevant features, or choosing among several DR algorithms. We investigate specific implementations of visual analysis systems integrating DR, and analyze ways that other machine learning methods have been combined with DR. Summarizing the results in a \u201chuman in the loop\u201d process model provides a general lens for the evaluation of visual interactive DR systems. We apply the proposed model to study and classify several systems previously described in the literature, and to derive future research opportunities."}, {"color": "gray", "id": 1289, "label": 1289, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1289 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2598544\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Aritra Dasgupta;Joon-Yong Lee;Ryan Wilson;Robert A. Lafrance;Nick Cramer;Kristin Cook;Samuel Payne; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Familiarity Vs Trust: A Comparative Study of Domain Scientists\u0027 Trust in Visual Analytics and Conventional Analysis Methods; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Combining interactive visualization with automated analytical methods like statistics and data mining facilitates data-driven discovery. These visual analytic methods are beginning to be instantiated within mixed-initiative systems, where humans and machines collaboratively influence evidence-gathering and decision-making. But an open research question is that, when domain experts analyze their data, can they completely trust the outputs and operations on the machine-side? Visualization potentially leads to a transparent analysis process, but do domain experts always trust what they see? To address these questions, we present results from the design and evaluation of a mixed-initiative, visual analytics system for biologists, focusing on analyzing the relationships between familiarity of an analysis medium and domain experts\u0027 trust. We propose a trust-augmented design of the visual analytics system, that explicitly takes into account domain-specific tasks, conventions, and preferences. For evaluating the system, we present the results of a controlled user study with 34 biologists where we compare the variation of the level of trust across conventional and visual analytic mediums and explore the influence of familiarity and task complexity on trust. We find that despite being unfamiliar with a visual analytic medium, scientists seem to have an average level of trust that is comparable with the same in conventional analysis medium. In fact, for complex sense-making tasks, we find that the visual analytic system is able to inspire greater trust than other mediums. We summarize the implications of our findings with directions for future research on trustworthiness of visual analytic systems."}, {"color": "gray", "id": 1290, "label": 1290, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1290 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2598545\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Sarah Goodwin;Christopher Mears;Tim Dwyer;Maria Garcia de la Banda;Guido Tack;Mark Wallace; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: What do Constraint Programming Users Want to See? Exploring the Role of Visualisation in Profiling of Models and Search; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Constraint programming allows difficult combinatorial problems to be modelled declaratively and solved automatically. Advances in solver technologies over recent years have allowed the successful use of constraint programming in many application areas. However, when a particular solver\u0027s search for a solution takes too long, the complexity of the constraint program execution hinders the programmer\u0027s ability to profile that search and understand how it relates to their model. Therefore, effective tools to support such profiling and allow users of constraint programming technologies to refine their model or experiment with different search parameters are essential. This paper details the first user-centred design process for visual profiling tools in this domain. We report on: our insights and opportunities identified through an on-line questionnaire and a creativity workshop with domain experts carried out to elicit requirements for analytical and visual profiling techniques; our designs and functional prototypes realising such techniques; and case studies demonstrating how these techniques shed light on the behaviour of the solvers in practice."}, {"color": "gray", "id": 1291, "label": 1291, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1291 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2598585\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Fabio Miranda;Harish Doraiswamy;Marcos Lage;Kai Zhao;Bruno Gon\u00e7alves;Luc Wilson;Mondrian Hsieh;Cl\u00e1udio T. Silva; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Urban Pulse: Capturing the Rhythm of Cities; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Cities are inherently dynamic. Interesting patterns of behavior typically manifest at several key areas of a city over multiple temporal resolutions. Studying these patterns can greatly help a variety of experts ranging from city planners and architects to human behavioral experts. Recent technological innovations have enabled the collection of enormous amounts of data that can help in these studies. However, techniques using these data sets typically focus on understanding the data in the context of the city, thus failing to capture the dynamic aspects of the city. The goal of this work is to instead understand the city in the context of multiple urban data sets. To do so, we define the concept of an \u201curban pulse\u201d which captures the spatio-temporal activity in a city across multiple temporal resolutions. The prominent pulses in a city are obtained using the topology of the data sets, and are characterized as a set of beats. The beats are then used to analyze and compare different pulses. We also design a visual exploration framework that allows users to explore the pulses within and across multiple cities under different conditions. Finally, we present three case studies carried out by experts from two different domains that demonstrate the utility of our framework."}, {"color": "gray", "id": 1298, "label": 1298, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1298 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2598592\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Clemens Arbesser;Florian Spechtenhauser;Thomas M\u00fchlbacher;Harald Piringer; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visplause: Visual Data Quality Assessment of Many Time Series Using Plausibility Checks; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Trends like decentralized energy production lead to an exploding number of time series from sensors and other sources that need to be assessed regarding their data quality (DQ). While the identification of DQ problems for such routinely collected data is typically based on existing automated plausibility checks, an efficient inspection and validation of check results for hundreds or thousands of time series is challenging. The main contribution of this paper is the validated design of Visplause, a system to support an efficient inspection of DQ problems for many time series. The key idea of Visplause is to utilize meta-information concerning the semantics of both the time series and the plausibility checks for structuring and summarizing results of DQ checks in a flexible way. Linked views enable users to inspect anomalies in detail and to generate hypotheses about possible causes. The design of Visplause was guided by goals derived from a comprehensive task analysis with domain experts in the energy sector. We reflect on the design process by discussing design decisions at four stages and we identify lessons learned. We also report feedback from domain experts after using Visplause for a period of one month. This feedback suggests significant efficiency gains for DQ assessment, increased confidence in the DQ, and the applicability of Visplause to summarize indicators also outside the context of DQ."}, {"color": "gray", "id": 1299, "label": 1299, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1299 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2598594\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Evanthia Dimara;Anastasia Bezerianos;Pierre Dragicevic; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: The Attraction Effect in Information Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The attraction effect is a well-studied cognitive bias in decision making research, where one\u0027s choice between two alternatives is influenced by the presence of an irrelevant (dominated) third alternative. We examine whether this cognitive bias, so far only tested with three alternatives and simple presentation formats such as numerical tables, text and pictures, also appears in visualizations. Since visualizations can be used to support decision making - e.g., when choosing a house to buy or an employee to hire - a systematic bias could have important implications. In a first crowdsource experiment, we indeed partially replicated the attraction effect with three alternatives presented as a numerical table, and observed similar effects when they were presented as a scatterplot. In a second experiment, we investigated if the effect extends to larger sets of alternatives, where the number of alternatives is too large for numerical tables to be practical. Our findings indicate that the bias persists for larger sets of alternatives presented as scatterplots. We discuss implications for future research on how to further study and possibly alleviate the attraction effect."}, {"color": "gray", "id": 1301, "label": 1301, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1301 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2598603\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Kai Lawonn;Erik Trostmann;Bernhard Preim;Klaus Hildebrandt; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visualization and Extraction of Carvings for Heritage Conservation; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present novel techniques for visualizing, illustrating, analyzing, and generating carvings in surfaces. In particular, we consider the carvings in the plaster of the cloister of the Magdeburg cathedral, which dates to the 13th century. Due to aging and weathering, the carvings have flattened. Historians and restorers are highly interested in using digitalization techniques to analyze carvings in historic artifacts and monuments and to get impressions and illustrations of their original shape and appearance. Moreover, museums and churches are interested in such illustrations for presenting them to visitors. The techniques that we propose allow for detecting, selecting, and visualizing carving structures. In addition, we introduce an example-based method for generating carvings. The resulting tool, which integrates all techniques, was evaluated by three experienced restorers to assess the usefulness and applicability. Furthermore, we compared our approach with exaggerated shading and other state-of-the-art methods."}, {"color": "gray", "id": 1306, "label": 1306, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1306 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2598619\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Goethem Arthur Van;Frank Staals;Maarten L\u00f6ffler;Jason Dykes;Bettina Speckmann; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Multi-Granular Trend Detection for Time-Series Analysis; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Time series (such as stock prices) and ensembles (such as model runs for weather forecasts) are two important types of one-dimensional time-varying data. Such data is readily available in large quantities but visual analysis of the raw data quickly becomes infeasible, even for moderately sized data sets. Trend detection is an effective way to simplify time-varying data and to summarize salient information for visual display and interactive analysis. We propose a geometric model for trend-detection in one-dimensional time-varying data, inspired by topological grouping structures for moving objects in two- or higher-dimensional space. Our model gives provable guarantees on the trends detected and uses three natural parameters: granularity, support-size, and duration. These parameters can be changed on-demand. Our system also supports a variety of selection brushes and a time-sweep to facilitate refined searches and interactive visualization of (sub-)trends. We explore different visual styles and interactions through which trends, their persistence, and evolution can be explored."}, {"color": "gray", "id": 1310, "label": 1310, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1310 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2598664\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Panpan Xu;Honghui Mei;Liu Ren;Wei Chen; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: ViDX: Visual Diagnostics of Assembly Line Performance in Smart Factories; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Visual analytics plays a key role in the era of connected industry (or industry 4.0, industrial internet) as modern machines and assembly lines generate large amounts of data and effective visual exploration techniques are needed for troubleshooting, process optimization, and decision making. However, developing effective visual analytics solutions for this application domain is a challenging task due to the sheer volume and the complexity of the data collected in the manufacturing processes. We report the design and implementation of a comprehensive visual analytics system, ViDX. It supports both real-time tracking of assembly line performance and historical data exploration to identify inefficiencies, locate anomalies, and form hypotheses about their causes and effects. The system is designed based on a set of requirements gathered through discussions with the managers and operators from manufacturing sites. It features interlinked views displaying data at different levels of detail. In particular, we apply and extend the Marey\u0027s graph by introducing a time-aware outlier-preserving visual aggregation technique to support effective troubleshooting in manufacturing processes. We also introduce two novel interaction techniques, namely the quantiles brush and samples brush, for the users to interactively steer the outlier detection algorithms. We evaluate the system with example use cases and an in-depth user interview, both conducted together with the managers and operators from manufacturing plants. The result demonstrates its effectiveness and reports a successful pilot application of visual analytics for manufacturing in smart factories."}, {"color": "gray", "id": 1316, "label": 1316, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1316 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2598791\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Saad Nadeem;Joseph Marino;Xianfeng Gu;Arie Kaufman; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Corresponding Supine and Prone Colon Visualization Using Eigenfunction Analysis and Fold Modeling; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present a method for registration and visualization of corresponding supine and prone virtual colonoscopy scans based on eigenfunction analysis and fold modeling. In virtual colonoscopy, CT scans are acquired with the patient in two positions, and their registration is desirable so that physicians can corroborate findings between scans. Our algorithm performs this registration efficiently through the use of Fiedler vector representation (the second eigenfunction of the Laplace-Beltrami operator). This representation is employed to first perform global registration of the two colon positions. The registration is then locally refined using the haustral folds, which are automatically segmented using the 3D level sets of the Fiedler vector. The use of Fiedler vectors and the segmented folds presents a precise way of visualizing corresponding regions across datasets and visual modalities. We present multiple methods of visualizing the results, including 2D flattened rendering and the corresponding 3D endoluminal views. The precise fold modeling is used to automatically find a suitable cut for the 2D flattening, which provides a less distorted visualization. Our approach is robust, and we demonstrate its efficiency and efficacy by showing matched views on both the 2D flattened colons and in the 3D endoluminal view. We analytically evaluate the results by measuring the distance between features on the registered colons, and we also assess our fold segmentation against 20 manually labeled datasets. We have compared our results analytically to previous methods, and have found our method to achieve superior results. We also prove the hot spots conjecture for modeling cylindrical topology using Fiedler vector representation, which allows our approach to be used for general cylindrical geometry modeling and feature extraction."}, {"color": "gray", "id": 1320, "label": 1320, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1320 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2598824\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Michael Krone;Florian Frie\u00df;Katrin Scharnowski;Guido Reina;Silvia Fademrecht;Tobias Kulschewski;J\u00fcrgen Pleiss;Thomas Ertl; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Molecular Surface Maps; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present Molecular Surface Maps, a novel, view-independent, and concise representation for molecular surfaces. It transfers the well-known world map metaphor to molecular visualization. Our application maps the complex molecular surface to a simple 2D representation through a spherical intermediate, the Molecular Surface Globe. The Molecular Surface Map concisely shows arbitrary attributes of the original molecular surface, such as biochemical properties or geometrical features. This results in an intuitive overview, which allows researchers to assess all molecular surface attributes at a glance. Our representation can be used as a visual summarization of a molecule\u0027s interface with its environment. In particular, Molecular Surface Maps simplify the analysis and comparison of different data sets or points in time. Furthermore, the map representation can be used in a Space-time Cube to analyze time-dependent data from molecular simulations without the need for animation. We show the feasibility of Molecular Surface Maps for different typical analysis tasks of biomolecular data."}, {"color": "gray", "id": 1326, "label": 1326, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1326 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2598830\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Junpeng Wang;Xiaotong Liu;Han-Wei Shen;Guang Lin; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Multi-Resolution Climate Ensemble Parameter Analysis with Nested Parallel Coordinates Plots; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Due to the uncertain nature of weather prediction, climate simulations are usually performed multiple times with different spatial resolutions. The outputs of simulations are multi-resolution spatial temporal ensembles. Each simulation run uses a unique set of values for multiple convective parameters. Distinct parameter settings from different simulation runs in different resolutions constitute a multi-resolution high-dimensional parameter space. Understanding the correlation between the different convective parameters, and establishing a connection between the parameter settings and the ensemble outputs are crucial to domain scientists. The multi-resolution high-dimensional parameter space, however, presents a unique challenge to the existing correlation visualization techniques. We present Nested Parallel Coordinates Plot (NPCP), a new type of parallel coordinates plots that enables visualization of intra-resolution and inter-resolution parameter correlations. With flexible user control, NPCP integrates superimposition, juxtaposition and explicit encodings in a single view for comparative data visualization and analysis. We develop an integrated visual analytics system to help domain scientists understand the connection between multi-resolution convective parameters and the large spatial temporal ensembles. Our system presents intricate climate ensembles with a comprehensive overview and on-demand geographic details. We demonstrate NPCP, along with the climate ensemble visualization system, based on real-world use-cases from our collaborators in computational and predictive science."}, {"color": "gray", "id": 1327, "label": 1327, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1327 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2598831\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Mengchen Liu;Jiaxin Shi;Zhen Li;Chongxuan Li;Jun Zhu;Shixia Liu; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Towards Better Analysis of Deep Convolutional Neural Networks; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Deep convolutional neural networks (CNNs) have achieved breakthrough performance in many pattern recognition tasks such as image classification. However, the development of high-quality deep models typically relies on a substantial amount of trial-and-error, as there is still no clear understanding of when and why a deep model works. In this paper, we present a visual analytics approach for better understanding, diagnosing, and refining deep CNNs. We formulate a deep CNN as a directed acyclic graph. Based on this formulation, a hybrid visualization is developed to disclose the multiple facets of each neuron and the interactions between them. In particular, we introduce a hierarchical rectangle packing algorithm and a matrix reordering algorithm to show the derived features of a neuron cluster. We also propose a biclustering-based edge bundling method to reduce visual clutter caused by a large number of connections between neurons. We evaluated our method on a set of CNNs and the results are generally favorable."}, {"color": "gray", "id": 1329, "label": 1329, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1329 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2598839\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Bahador Saket;Hannah Kim;Eli T. Brown;Alex Endert; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visualization by Demonstration: An Interaction Paradigm for Visual Data Exploration; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Although data visualization tools continue to improve, during the data exploration process many of them require users to manually specify visualization techniques, mappings, and parameters. In response, we present the Visualization by Demonstration paradigm, a novel interaction method for visual data exploration. A system which adopts this paradigm allows users to provide visual demonstrations of incremental changes to the visual representation. The system then recommends potential transformations (Visual Representation, Data Mapping, Axes, and View Specification transformations) from the given demonstrations. The user and the system continue to collaborate, incrementally producing more demonstrations and refining the transformations, until the most effective possible visualization is created. As a proof of concept, we present VisExemplar, a mixed-initiative prototype that allows users to explore their data by recommending appropriate transformations in response to the given demonstrations."}, {"color": "gray", "id": 1331, "label": 1331, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1331 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2598866\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Allan Rocha;Usman Alim;Julio Daniel Silva;Mario Costa Sousa; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Decal-Maps: Real-Time Layering of Decals on Surfaces for Multivariate Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We introduce the use of decals for multivariate visualization design. Decals are visual representations that are used for communication; for example, a pattern, a text, a glyph, or a symbol, transferred from a 2D-image to a surface upon contact. By creating what we define as decal-maps, we can design a set of images or patterns that represent one or more data attributes. We place decals on the surface considering the data pertaining to the locations we choose. We propose a (texture mapping) local parametrization that allows placing decals on arbitrary surfaces interactively, even when dealing with a high number of decals. Moreover, we extend the concept of layering to allow the co-visualization of an increased number of attributes on arbitrary surfaces. By combining decal-maps, color-maps and a layered visualization, we aim to facilitate and encourage the creative process of designing multivariate visualizations. Finally, we demonstrate the general applicability of our technique by providing examples of its use in a variety of contexts."}, {"color": "gray", "id": 1337, "label": 1337, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1337 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2598885\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Yalong Yang;Tim Dwyer;Sarah Goodwin;Kim Marriott; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Many-to-Many Geographically-Embedded Flow Visualisation: An Evaluation; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Showing flows of people and resources between multiple geographic locations is a challenging visualisation problem. We conducted two quantitative user studies to evaluate different visual representations for such dense many-to-many flows. In our first study we compared a bundled node-link flow map representation and OD Maps [37] with a new visualisation we call MapTrix. Like OD Maps, MapTrix overcomes the clutter associated with a traditional flow map while providing geographic embedding that is missing in standard OD matrix representations. We found that OD Maps and MapTrix had similar performance while bundled node-link flow map representations did not scale at all well. Our second study compared participant performance with OD Maps and MapTrix on larger data sets. Again performance was remarkably similar."}, {"color": "gray", "id": 1340, "label": 1340, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1340 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2598919\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Christoph Schulz;Arlind Nocaj;Jochen Goertler;Oliver Deussen;Ulrik Brandes;Daniel Weiskopf; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Probabilistic Graph Layout for Uncertain Network Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present a novel uncertain network visualization technique based on node-link diagrams. Nodes expand spatially in our probabilistic graph layout, depending on the underlying probability distributions of edges. The visualization is created by computing a two-dimensional graph embedding that combines samples from the probabilistic graph. A Monte Carlo process is used to decompose a probabilistic graph into its possible instances and to continue with our graph layout technique. Splatting and edge bundling are used to visualize point clouds and network topology. The results provide insights into probability distributions for the entire network-not only for individual nodes and edges. We validate our approach using three data sets that represent a wide range of network types: synthetic data, protein-protein interactions from the STRING database, and travel times extracted from Google Maps. Our approach reveals general limitations of the force-directed layout and allows the user to recognize that some nodes of the graph are at a specific position just by chance."}, {"color": "gray", "id": 1342, "label": 1342, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1342 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2598958\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Benjamin Bach;Nathalie Henry Riche;Christophe Hurter;Kim Marriott;Tim Dwyer; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Towards Unambiguous Edge Bundling: Investigating Confluent Drawings for Network Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In this paper, we investigate Confluent Drawings (CD), a technique for bundling edges in node-link diagrams based on network connectivity. Edge-bundling techniques are designed to reduce edge clutter in node-link diagrams by coalescing lines into common paths or bundles. Unfortunately, traditional bundling techniques introduce ambiguity since edges are only bundled by spatial proximity, rather than network connectivity; following an edge from its source to its target can lead to the perception of incorrect connectivity if edges are not clearly separated within the bundles. Contrary, CDs bundle edges based on common sources or targets. Thus, a smooth path along a confluent bundle indicates precise connectivity. While CDs have been described in theory, practical investigation and application to real-world networks (i.e., networks beyond those with certain planarity restrictions) is currently lacking. Here, we provide the first algorithm for constructing CDs from arbitrary directed and undirected networks and present a simple layout method, embedded in a sand box environment providing techniques for interactive exploration. We then investigate patterns and artifacts in CDs, which we compare to other common edge-bundling techniques. Finally, we present the first user study that compares edge-compression techniques, including CD, power graphs, metro-style, and common edge bundling. We found that users without particular expertise in visualization or network analysis are able to read small CDs without difficulty. Compared to existing bundling techniques, CDs are more likely to allow people to correctly perceive connectivity."}, {"color": "gray", "id": 1343, "label": 1343, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1343 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2598998\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Tim Gerrits;Christian R\u00f6ssl;Holger Theisel; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Glyphs for General Second-Order 2D and 3D Tensors; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Glyphs are a powerful tool for visualizing second-order tensors in a variety of scientic data as they allow to encode physical behavior in geometric properties. Most existing techniques focus on symmetric tensors and exclude non-symmetric tensors where the eigenvectors can be non-orthogonal or complex. We present a new construction of 2d and 3d tensor glyphs based on piecewise rational curves and surfaces with the following properties: invariance to (a) isometries and (b) scaling, (c) direct encoding of all real eigenvalues and eigenvectors, (d) one-to-one relation between the tensors and glyphs, (e) glyph continuity under changing the tensor. We apply the glyphs to visualize the Jacobian matrix fields of a number of 2d and 3d vector fields."}, {"color": "gray", "id": 1344, "label": 1344, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1344 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2599016\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Tobias G\u00fcnther;Holger Theisel; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Backward Finite-Time Lyapunov Exponents in Inertial Flows; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Inertial particles are finite-sized objects that are carried by fluid flows and in contrast to massless tracer particles they are subject to inertia effects. In unsteady flows, the dynamics of tracer particles have been extensively studied by the extraction of Lagrangian coherent structures (LCS), such as hyperbolic LCS as ridges of the Finite-Time Lyapunov Exponent (FTLE). The extension of the rich LCS framework to inertial particles is currently a hot topic in the CFD literature and is actively under research. Recently, backward FTLE on tracer particles has been shown to correlate with the preferential particle settling of small inertial particles. For larger particles, inertial trajectories may deviate strongly from (massless) tracer trajectories, and thus for a better agreement, backward FTLE should be computed on inertial trajectories directly. Inertial backward integration, however, has not been possible until the recent introduction of the influence curve concept, which - given an observation and an initial velocity - allows to recover all sources of inertial particles as tangent curves of a derived vector field. In this paper, we show that FTLE on the influence curve vector field is in agreement with preferential particle settling and more importantly it is not only valid for small (near-tracer) particles. We further generalize the influence curve concept to general equations of motion in unsteady spatio-velocity phase spaces, which enables backward integration with more general equations of motion. Applying the influence curve concept to tracer particles in the spatio-velocity domain emits streaklines in massless flows as tangent curves of the influence curve vector field. We demonstrate the correlation between inertial backward FTLE and the preferential particle settling in a number of unsteady vector fields"}, {"color": "gray", "id": 1347, "label": 1347, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1347 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2599030\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Arvind Satyanarayan;Dominik Moritz;Kanit Wongsuphasawat;Jeffrey Heer; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Vega-Lite: A Grammar of Interactive Graphics; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present Vega-Lite, a high-level grammar that enables rapid specification of interactive data visualizations. Vega-Lite combines a traditional grammar of graphics, providing visual encoding rules and a composition algebra for layered and multi-view displays, with a novel grammar of interaction. Users specify interactive semantics by composing selections. In Vega-Lite, a selection is an abstraction that defines input event processing, points of interest, and a predicate function for inclusion testing. Selections parameterize visual encodings by serving as input data, defining scale extents, or by driving conditional logic. The Vega-Lite compiler automatically synthesizes requisite data flow and event handling logic, which users can override for further customization. In contrast to existing reactive specifications, Vega-Lite selections decompose an interaction design into concise, enumerable semantic units. We evaluate Vega-Lite through a range of examples, demonstrating succinct specification of both customized interaction methods and common techniques such as panning, zooming, and linked selection."}, {"color": "gray", "id": 1350, "label": 1350, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1350 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2599042\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Steffen Frey;Thomas Ertl; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Progressive Direct Volume-to-Volume Transformation; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present a novel technique to generate transformations between arbitrary volumes, providing both expressive distances and smooth interpolates. In contrast to conventional morphing or warping approaches, our technique requires no user guidance, intermediate representations (like extracted features), or blending, and imposes no restrictions regarding shape or structure. Our technique operates directly on the volumetric data representation, and while linear programming approaches could solve the underlying problem optimally, their polynomial complexity makes them infeasible for high-resolution volumes. We therefore propose a progressive refinement approach designed for parallel execution that is able to quickly deliver approximate results that are iteratively improved toward the optimum. On this basis, we further present a new approach for the streaming selection of time steps in temporal data that allows for the reconstruction of the full sequence with a user-specified error bound. We finally demonstrate the utility of our technique for different applications, compare our approach against alternatives, and evaluate its characteristics with a variety of different data sets."}, {"color": "gray", "id": 1351, "label": 1351, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1351 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2599043\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jens Schneider;Peter Rautek; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: A Versatile and Efficient GPU Data Structure for Spatial Indexing; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In this paper we present a novel GPU-based data structure for spatial indexing. Based on Fenwick trees-a special type of binary indexed trees-our data structure allows construction in linear time. Updates and prefixes can be computed in logarithmic time, whereas point queries require only constant time on average. Unlike competing data structures such as summed-area tables and spatial hashing, our data structure requires a constant amount of bits for each data element, and it offers unconstrained point queries. This property makes our data structure ideally suited for applications requiring unconstrained indexing of large data, such as block-storage of large and block-sparse volumes. Finally, we provide asymptotic bounds on both run-time and memory requirements, and we show applications for which our new data structure is useful."}, {"color": "gray", "id": 1362, "label": 1362, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1362 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2016.7883507\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Florian Heimerl;Markus John;Qi Han;Steffen Koch;Thomas Ertl; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: DocuCompass: Effective exploration of document landscapes; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The creation of interactive visualization to analyze text documents has gained an impressive momentum in recent years. This is not surprising in the light of massive and still increasing amounts of available digitized texts. Websites, social media, news wire, and digital libraries are just few examples of the diverse text sources whose visual analysis and exploration offers new opportunities to effectively mine and manage the information and knowledge hidden within them. A popular visualization method for large text collections is to represent each document by a glyph in 2D space. These landscapes can be the result of optimizing pairwise distances in 2D to represent document similarities, or they are provided directly as meta data, such as geo-locations. For well-defined information needs, suitable interaction methods are available for these spatializations. However, free exploration and navigation on a level of abstraction between a labeled document spatialization and reading single documents is largely unsupported. As a result, vital foraging steps for task-tailored actions, such as selecting subgroups of documents for detailed inspection, or subsequent sense-making steps are hampered. To fill in this gap, we propose DocuCompass, a focus+context approach based on the lens metaphor. It comprises multiple methods to characterize local groups of documents, and to efficiently guide exploration based on users\u0027 requirements. DocuCompass thus allows for effective interactive exploration of document landscapes without disrupting the mental map of users by changing the layout itself. We discuss the suitability of multiple navigation and characterization methods for different spatializations and texts. Finally, we provide insights generated through user feedback and discuss the effectiveness of our approach."}, {"color": "gray", "id": 1364, "label": 1364, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1364 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2016.7883509\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: David McColgin;Paul Hoover;Mark Igra; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: The DataSpace for HIV vaccine studies; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The DataSpace for HIV vaccine studies is a discovery tool available on the web to hundreds of investigators. We designed it to help them better understand activity in the field and explore new ideas latent in completed research. The DataSpace harmonizes immunoassay results and study metadata so that a broader research community can pursue more flexible discovery than the typical centrally planned analyses. Insights from human-centered design and beta evaluation suggest strong potential for visual analytics that may also apply to other efforts in open science. The contribution of this paper is to elucidate key domain challenges and demonstrate an application that addresses them. We made several changes to familiar visualizations to support key tasks such as identifying and filtering to a cohort of interest, making meaningful comparisons of time series data from multiple studies that have different plans, and preserving analytic context when making data transformations and comparisons that would normally exclude some data."}, {"color": "gray", "id": 1367, "label": 1367, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1367 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2016.7883512\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Fan Du;Catherine Plaisant;Neil Spring;Ben Shneiderman; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: EventAction: Visual analytics for temporal event sequence recommendation; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Recommender systems are being widely used to assist people in making decisions, for example, recommending films to watch or books to buy. Despite its ubiquity, the problem of presenting the recommendations of temporal event sequences has not been studied. We propose EventAction, which to our knowledge, is the first attempt at a prescriptive analytics interface designed to present and explain recommendations of temporal event sequences. EventAction provides a visual analytics approach to (1) identify similar records, (2) explore potential outcomes, (3) review recommended temporal event sequences that might help achieve the users\u0027 goals, and (4) interactively assist users as they define a personalized action plan associated with a probability of success. Following the design study framework, we designed and deployed EventAction in the context of student advising and reported on the evaluation with a student review manager and three graduate students."}, {"color": "gray", "id": 1370, "label": 1370, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1370 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2016.7883515\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Phong H. Nguyen;Kai Xu;Andy Bardill;Betul Salman;Kate Herd;B.L. William Wong; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: SenseMap: Supporting browser-based online sensemaking through analytic provenance; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Sensemaking is described as the process in which people collect, organize and create representations of information, all centered around some problem they need to understand. People often get lost when solving complicated tasks using big datasets over long periods of exploration and analysis. They may forget what they have done, are unaware of where they are in the context of the overall task, and are unsure where to continue. In this paper, we introduce a tool, SenseMap, to address these issues in the context of browser-based online sensemaking. We conducted a semi-structured interview with nine participants to explore their behaviors in online sensemaking with existing browser functionality. A simplified sensemaking model based on Pirolli and Card\u0027s model is derived to better represent the behaviors we found: users iteratively collect information sources relevant to the task, curate them in a way that makes sense, and finally communicate their findings to others. SenseMap automatically captures provenance of user sensemaking actions and provides multi-linked views to visualize the collected information and enable users to curate and communicate their findings. To explore how SenseMap is used, we conducted a user study in a naturalistic work setting with five participants completing the same sensemaking task related to their daily work activities. All participants found the visual representation and interaction of the tool intuitive to use. Three of them engaged with the tool and produced successful outcomes. It helped them to organize information sources, to quickly find and navigate to the sources they wanted, and to effectively communicate their findings."}, {"color": "gray", "id": 1372, "label": 1372, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1372 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2016.7883517\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Yuanzhe Chen;Qing Chen;Mingqian Zhao;Sebastien Boyer;Kalyan Veeramachaneni;Huamin Qu; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: DropoutSeer: Visualizing learning patterns in Massive Open Online Courses for dropout reasoning and prediction; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Aiming at massive participation and open access education, Massive Open Online Courses (MOOCs) have attracted millions of learners over the past few years. However, the high dropout rate of learners is considered to be one of the most crucial factors that may hinder the development of MOOCs. To tackle this problem, statistical models have been developed to predict dropout behavior based on learner activity logs. Although predictive models can foresee the dropout behavior, it is still difficult for users to understand the reasons behind the predicted results and further design interventions to prevent dropout. In addition, with a better understanding of dropout, researchers in the area of predictive modeling in turn can improve the models. In this paper, we introduce DropoutSeer, a visual analytics system which not only helps instructors and education experts understand the reasons for dropout, but also allows researchers to identify crucial features which can further improve the performance of the models. Both the heterogeneous data extracted from three different kinds of learner activity logs (i.e., clickstream, forum posts and assignment records) and the predicted results are visualized in the proposed system. Case studies and expert interviews have been conducted to demonstrate the usefulness and effectiveness of DropoutSeer."}, {"color": "gray", "id": 1373, "label": 1373, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1373 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2016.7883518\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Prithiviraj K. Muthumanickam;Katerina Vrotsou;Matthew Cooper;Jimmy Johansson; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Shape Grammar Extraction for Efficient Query-by-Sketch Pattern Matching in Long Time Series; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Long time-series, involving thousands or even millions of time steps, are common in many application domains but remain very difficult to explore interactively. Often the analytical task in such data is to identify specific patterns, but this is a very complex and computationally difficult problem and so focusing the search in order to only identify interesting patterns is a common solution. We propose an efficient method for exploring user-sketched patterns, incorporating the domain expert\u0027s knowledge, in time series data through a shape grammar based approach. The shape grammar is extracted from the time series by considering the data as a combination of basic elementary shapes positioned across different amplitudes. We represent these basic shapes using a ratio value, perform binning on ratio values and apply a symbolic approximation. Our proposed method for pattern matching is amplitude-, scale- and translation-invariant and, since the pattern search and pattern constraint relaxation happen at the symbolic level, is very efficient permitting its use in a real-time/online system. We demonstrate the effectiveness of our method in a case study on stock market data although it is applicable to any numeric time series data."}, {"color": "gray", "id": 1375, "label": 1375, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1375 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2016.7883520\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Tanja Blascheck;Fabian Beck;Sebastian Baltes;Thomas Ertl;Daniel Weiskopf; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visual analysis and coding of data-rich user behavior; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Investigating user behavior involves abstracting low-level events to higher-level concepts. This requires an analyst to study individual user activities, assign codes which categorize behavior, and develop a consistent classification scheme. To better support this reasoning process of an analyst, we suggest a novel visual analytics approach which integrates rich user data including transcripts, videos, eye movement data, and interaction logs. Word-sized visualizations embedded into a tabular representation provide a space-efficient and detailed overview of user activities. An analyst assigns codes, grouped into code categories, as part of an interactive process. Filtering and searching helps to select specific activities and focus an analysis. A comparison visualization summarizes results of coding and reveals relationships between codes. Editing features support efficient assignment, refinement, and aggregation of codes. We demonstrate the practical applicability and usefulness of our approach in a case study and describe expert feedback."}, {"color": "gray", "id": 1383, "label": 1383, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1383 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2743959\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jochen G\u00f6rtler;Christoph Schulz;Daniel Weiskopf;Oliver Deussen; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Bubble Treemaps for Uncertainty Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present a novel type of circular treemap, where we intentionally allocate extra space for additional visual variables. With this extended visual design space, we encode hierarchically structured data along with their uncertainties in a combined diagram. We introduce a hierarchical and force-based circle-packing algorithm to compute Bubble Treemaps, where each node is visualized using nested contour arcs. Bubble Treemaps do not require any color or shading, which offers additional design choices. We explore uncertainty visualization as an application of our treemaps using standard error and Monte Carlo-based statistical models. To this end, we discuss how uncertainty propagates within hierarchies. Furthermore, we show the effectiveness of our visualization using three different examples: the package structure of Flare, the S\u0026amp;P 500 index, and the US consumer expenditure survey."}, {"color": "gray", "id": 1385, "label": 1385, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1385 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2743979\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Mohamed Ibrahim;Patrick Wickenh\u00e4user;Peter Rautek;Guido Reina;Markus Hadwiger; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Screen-Space Normal Distribution Function Caching for Consistent Multi-Resolution Rendering of Large Particle Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Molecular dynamics (MD) simulations are crucial to investigating important processes in physics and thermodynamics. The simulated atoms are usually visualized as hard spheres with Phong shading, where individual particles and their local density can be perceived well in close-up views. However, for large-scale simulations with 10 million particles or more, the visualization of large fields-of-view usually suffers from strong aliasing artifacts, because the mismatch between data size and output resolution leads to severe under-sampling of the geometry. Excessive super-sampling can alleviate this problem, but is prohibitively expensive. This paper presents a novel visualization method for large-scale particle data that addresses aliasing while enabling interactive high-quality rendering. We introduce the novel concept of screen-space normal distribution functions (S-NDFs) for particle data. S-NDFs represent the distribution of surface normals that map to a given pixel in screen space, which enables high-quality re-lighting without re-rendering particles. In order to facilitate interactive zooming, we cache S-NDFs in a screen-space mipmap (S-MIP). Together, these two concepts enable interactive, scale-consistent re-lighting and shading changes, as well as zooming, without having to re-sample the particle data. We show how our method facilitates the interactive exploration of real-world large-scale MD simulation data in different scenarios."}, {"color": "gray", "id": 1390, "label": 1390, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1390 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2743998\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Romain Vuillemot;Jeremy Boy; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Structuring Visualization Mock-Ups at the Graphical Level by Dividing the Display Space; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Mock-ups are rapid, low fidelity prototypes, that are used in many design-related fields to generate and share ideas. While their creation is supported by many mature methods and tools, surprisingly few are suited for the needs of information visualization. In this article, we introduce a novel approach to creating visualizations mock-ups, based on a dialogue between graphic design and parametric toolkit explorations. Our approach consists in iteratively subdividing the display space, while progressively informing each division with realistic data. We show that a wealth of mock-ups can easily be created using only temporary data attributes, as we wait for more realistic data to become available. We describe the implementation of this approach in a D3-based toolkit, which we use to highlight its generative power, and we discuss the potential for transitioning towards higher fidelity prototypes."}, {"color": "gray", "id": 1391, "label": 1391, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1391 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2744018\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Nils Rodrigues;Daniel Weiskopf; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Nonlinear Dot Plots; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Conventional dot plots use a constant dot size and are typically applied to show the frequency distribution of small data sets. Unfortunately, they are not designed for a high dynamic range of frequencies. We address this problem by introducing nonlinear dot plots. Adopting the idea of nonlinear scaling from logarithmic bar charts, our plots allow for dots of varying size so that columns with a large number of samples are reduced in height. For the construction of these diagrams, we introduce an efficient two-way sweep algorithm that leads to a dense and symmetrical layout. We compensate aliasing artifacts at high dot densities by a specifically designed low-pass filtering method. Examples of nonlinear dot plots are compared to conventional dot plots as well as linear and logarithmic histograms. Finally, we include feedback from an expert review."}, {"color": "gray", "id": 1394, "label": 1394, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1394 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2744058\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Ashok Jallepalli;Julia Docampo-S\u00e1nchez;Jennifer K. Ryan;Robert Haimes;Robert M. Kirby; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: On the Treatment of Field Quantities and Elemental Continuity in FEM Solutions; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: As the finite element method (FEM) and the finite volume method (FVM), both traditional and high-order variants, continue their proliferation into various applied engineering disciplines, it is important that the visualization techniques and corresponding data analysis tools that act on the results produced by these methods faithfully represent the underlying data. To state this in another way: the interpretation of data generated by simulation needs to be consistent with the numerical schemes that underpin the specific solver technology. As the verifiable visualization literature has demonstrated: visual artifacts produced by the introduction of either explicit or implicit data transformations, such as data resampling, can sometimes distort or even obfuscate key scientific features in the data. In this paper, we focus on the handling of elemental continuity, which is often only\u003cinline-formula\u003e\u003ctex-math notation=\"LaTeX\"\u003e$C^{0}$\u003c/tex-math\u003e\u003calternatives\u003e\u003cinline-graphic xlink:href=\"24tvcg01-jallepalli-2744058-ieq-1-source.tif\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"/\u003e\u003c/alternatives\u003e\u003c/inline-formula\u003econtinuous or piecewise discontinuous, when visualizing primary or derived fields from FEM or FVM simulations. We demonstrate that traditional data handling and visualization of these fields introduce visual errors. In addition, we show how the use of the recently proposed line-SIAC filter provides a way of handling elemental continuity issues in an accuracy-conserving manner with the added benefit of casting the data in a smooth context even if the representation is element discontinuous."}, {"color": "gray", "id": 1395, "label": 1395, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1395 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2744059\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jiang Zhang;Hanqi Guo;Fan Hong;Xiaoru Yuan;Tom Peterka; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Dynamic Load Balancing Based on Constrained K-D Tree Decomposition for Parallel Particle Tracing; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We propose a dynamically load-balanced algorithm for parallel particle tracing, which periodically attempts to evenly redistribute particles across processes based on k-d tree decomposition. Each process is assigned with (1) a statically partitioned, axis-aligned data block that partially overlaps with neighboring blocks in other processes and (2) a dynamically determined k-d tree leaf node that bounds the active particles for computation; the bounds of the k-d tree nodes are constrained by the geometries of data blocks. Given a certain degree of overlap between blocks, our method can balance the number of particles as much as possible. Compared with other load-balancing algorithms for parallel particle tracing, the proposed method does not require any preanalysis, does not use any heuristics based on flow features, does not make any assumptions about seed distribution, does not move any data blocks during the run, and does not need any master process for work redistribution. Based on a comprehensive performance study up to 8K processes on a Blue Gene/Q system, the proposed algorithm outperforms baseline approaches in both load balance and scalability on various flow visualization and analysis problems."}, {"color": "gray", "id": 1396, "label": 1396, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1396 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2744078\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Tran Minh Quan;Junyoung Choi;Haejin Jeong;Won-Ki Jeong; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: An Intelligent System Approach for Probabilistic Volume Rendering Using Hierarchical 3D Convolutional Sparse Coding; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In this paper, we propose a novel machine learning-based voxel classification method for highly-accurate volume rendering. Unlike conventional voxel classification methods that incorporate intensity-based features, the proposed method employs dictionary based features learned directly from the input data using hierarchical multi-scale 3D convolutional sparse coding, a novel extension of the state-of-the-art learning-based sparse feature representation method. The proposed approach automatically generates high-dimensional feature vectors in up to 75 dimensions, which are then fed into an intelligent system built on a random forest classifier for accurately classifying voxels from only a handful of selection scribbles made directly on the input data by the user. We apply the probabilistic transfer function to further customize and refine the rendered result. The proposed method is more intuitive to use and more robust to noise in comparison with conventional intensity-based classification methods. We evaluate the proposed method using several synthetic and real-world volume datasets, and demonstrate the methods usability through a user study."}, {"color": "gray", "id": 1403, "label": 1403, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1403 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2744158\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Hendrik Strobelt;Sebastian Gehrmann;Hanspeter Pfister;Alexander M. Rush; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: LSTMVis: A Tool for Visual Analysis of Hidden State Dynamics in Recurrent Neural Networks; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Recurrent neural networks, and in particular long short-term memory (LSTM) networks, are a remarkably effective tool for sequence modeling that learn a dense black-box hidden representation of their sequential input. Researchers interested in better understanding these models have studied the changes in hidden state representations over time and noticed some interpretable patterns but also significant noise. In this work, we present LSTMVis, a visual analysis tool for recurrent neural networks with a focus on understanding these hidden state dynamics. The tool allows users to select a hypothesis input range to focus on local state changes, to match these states changes to similar patterns in a large data set, and to align these results with structural annotations from their domain. We show several use cases of the tool for analyzing specific hidden state properties on dataset containing nesting, phrase structure, and chord progressions, and demonstrate how the tool can be used to isolate patterns for further statistical analysis. We characterize the domain, the different stakeholders, and their goals and tasks. Long-term usage data after putting the tool online revealed great interest in the machine learning community."}, {"color": "gray", "id": 1404, "label": 1404, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1404 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2744159\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Qiaomu Shen;Wei Zeng;Yu Ye;Stefan M\u00fcller Arisona;Simon Schubiger;Remo Burkhard;Huamin Qu; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: StreetVizor: Visual Exploration of Human-Scale Urban Forms Based on Street Views; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Urban forms at human-scale, i.e., urban environments that individuals can sense (e.g., sight, smell, and touch) in their daily lives, can provide unprecedented insights on a variety of applications, such as urban planning and environment auditing. The analysis of urban forms can help planners develop high-quality urban spaces through evidence-based design. However, such analysis is complex because of the involvement of spatial, multi-scale (i.e., city, region, and street), and multivariate (e.g., greenery and sky ratios) natures of urban forms. In addition, current methods either lack quantitative measurements or are limited to a small area. The primary contribution of this work is the design of StreetVizor, an interactive visual analytics system that helps planners leverage their domain knowledge in exploring human-scale urban forms based on street view images. Our system presents two-stage visual exploration: 1) an AOI Explorer for the visual comparison of spatial distributions and quantitative measurements in two areas-of-interest (AOIs) at city- and region-scales; 2) and a Street Explorer with a novel parallel coordinate plot for the exploration of the fine-grained details of the urban forms at the street-scale. We integrate visualization techniques with machine learning models to facilitate the detection of street view patterns. We illustrate the applicability of our approach with case studies on the real-world datasets of four cities, i.e., Hong Kong, Singapore, Greater London and New York City. Interviews with domain experts demonstrate the effectiveness of our system in facilitating various analytical tasks."}, {"color": "gray", "id": 1409, "label": 1409, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1409 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2744238\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Markus Hadwiger;Ali K. Al-Awami;Johanna Beyer;Marco Agus;Hanspeter Pfister; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: SparseLeap: Efficient Empty Space Skipping for Large-Scale Volume Rendering; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Recent advances in data acquisition produce volume data of very high resolution and large size, such as terabyte-sized microscopy volumes. These data often contain many fine and intricate structures, which pose huge challenges for volume rendering, and make it particularly important to efficiently skip empty space. This paper addresses two major challenges: (1) The complexity of large volumes containing fine structures often leads to highly fragmented space subdivisions that make empty regions hard to skip efficiently. (2) The classification of space into empty and non-empty regions changes frequently, because the user or the evaluation of an interactive query activate a different set of objects, which makes it unfeasible to pre-compute a well-adapted space subdivision. We describe the novel SparseLeap method for efficient empty space skipping in very large volumes, even around fine structures. The main performance characteristic of SparseLeap is that it moves the major cost of empty space skipping out of the ray-casting stage. We achieve this via a hybrid strategy that balances the computational load between determining empty ray segments in a rasterization (object-order) stage, and sampling non-empty volume data in the ray-casting (image-order) stage. Before ray-casting, we exploit the fast hardware rasterization of GPUs to create a ray segment list for each pixel, which identifies non-empty regions along the ray. The ray-casting stage then leaps over empty space without hierarchy traversal. Ray segment lists are created by rasterizing a set of fine-grained, view-independent bounding boxes. Frame coherence is exploited by re-using the same bounding boxes unless the set of active objects changes. We show that SparseLeap scales better to large, sparse data than standard octree empty space skipping."}, {"color": "gray", "id": 1410, "label": 1410, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1410 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2744258\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Tobias Klein;Ludovic Autin;Barbora Kozl\u00edkov\u00e1;David S. Goodsell;Arthur Olson;M. Eduard Gr\u00f6ller;Ivan Viola; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Instant Construction and Visualization of Crowded Biological Environments; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present the first approach to integrative structural modeling of the biological mesoscale within an interactive visual environment. These complex models can comprise up to millions of molecules with defined atomic structures, locations, and interactions. Their construction has previously been attempted only within a non-visual and non-interactive environment. Our solution unites the modeling and visualization aspect, enabling interactive construction of atomic resolution mesoscale models of large portions of a cell. We present a novel set of GPU algorithms that build the basis for the rapid construction of complex biological structures. These structures consist of multiple membrane-enclosed compartments including both soluble molecules and fibrous structures. The compartments are defined using volume voxelization of triangulated meshes. For membranes, we present an extension of the Wang Tile concept that populates the bilayer with individual lipids. Soluble molecules are populated within compartments distributed according to a Halton sequence. Fibrous structures, such as RNA or actin filaments, are created by self-avoiding random walks. Resulting overlaps of molecules are resolved by a forced-based system. Our approach opens new possibilities to the world of interactive construction of cellular compartments. We demonstrate its effectiveness by showcasing scenes of different scale and complexity that comprise blood plasma, mycoplasma, and HIV."}, {"color": "gray", "id": 1412, "label": 1412, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1412 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2744298\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Pierre Dragicevic;Yvonne Jansen; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Blinded with Science or Informed by Charts? A Replication Study; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We provide a reappraisal of Tal and Wansink\u0027s study \u201cBlinded with Science\u201d, where seemingly trivial charts were shown to increase belief in drug efficacy, presumably because charts are associated with science. Through a series of four replications conducted on two crowdsourcing platforms, we investigate an alternative explanation, namely, that the charts allowed participants to better assess the drug\u0027s efficacy. Considered together, our experiments suggest that the chart seems to have indeed promoted understanding, although the effect is likely very small. Meanwhile, we were unable to replicate the original study\u0027s findings, as text with chart appeared to be no more persuasive - and sometimes less persuasive - than text alone. This suggests that the effect may not be as robust as claimed and may need specific conditions to be reproduced. Regardless, within our experimental settings and considering our study as a whole (\u003cinline-formula\u003e\u003ctex-math notation=\"LaTeX\"\u003e$\\mathrm{N}=623$\u003c/tex-math\u003e\u003calternatives\u003e\u003cinline-graphic xlink:href=\"24tvcg01-dragicevic-2744298-ieq-1-source.tif\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"/\u003e\u003c/alternatives\u003e\u003c/inline-formula\u003e), the chart\u0027s contribution to understanding was clearly larger than its contribution to persuasion."}, {"color": "gray", "id": 1414, "label": 1414, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1414 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2744318\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Thomas H\u00f6llt;Nicola Pezzotti;Vincent van Unen;Frits Koning;Boudewijn P.F. Lelieveldt;Anna Vilanova; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: CyteGuide: Visual Guidance for Hierarchical Single-Cell Analysis; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Single-cell analysis through mass cytometry has become an increasingly important tool for immunologists to study the immune system in health and disease. Mass cytometry creates a high-dimensional description vector for single cells by time-of-flight measurement. Recently, t-Distributed Stochastic Neighborhood Embedding (t-SNE) has emerged as one of the state-of-the-art techniques for the visualization and exploration of single-cell data. Ever increasing amounts of data lead to the adoption of Hierarchical Stochastic Neighborhood Embedding (HSNE), enabling the hierarchical representation of the data. Here, the hierarchy is explored selectively by the analyst, who can request more and more detail in areas of interest. Such hierarchies are usually explored by visualizing disconnected plots of selections in different levels of the hierarchy. This poses problems for navigation, by imposing a high cognitive load on the analyst. In this work, we present an interactive summary-visualization to tackle this problem. CyteGuide guides the analyst through the exploration of hierarchically represented single-cell data, and provides a complete overview of the current state of the analysis. We conducted a two-phase user study with domain experts that use HSNE for data exploration. We first studied their problems with their current workflow using HSNE and the requirements to ease this workflow in a field study. These requirements have been the basis for our visual design. In the second phase, we verified our proposed solution in a user evaluation."}, {"color": "gray", "id": 1417, "label": 1417, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1417 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2744321\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Bastian Rieck;Ulderico Fugacci;Jonas Lukasczyk;Heike Leitte; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Clique Community Persistence: A Topological Visual Analysis Approach for Complex Networks; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Complex networks require effective tools and visualizations for their analysis and comparison. Clique communities have been recognized as a powerful concept for describing cohesive structures in networks. We propose an approach that extends the computation of clique communities by considering persistent homology, a topological paradigm originally introduced to characterize and compare the global structure of shapes. Our persistence-based algorithm is able to detect clique communities and to keep track of their evolution according to different edge weight thresholds. We use this information to define comparison metrics and a new centrality measure, both reflecting the relevance of the clique communities inherent to the network. Moreover, we propose an interactive visualization tool based on nested graphs that is capable of compactly representing the evolving relationships between communities for different thresholds and clique degrees. We demonstrate the effectiveness of our approach on various network types."}, {"color": "gray", "id": 1419, "label": 1419, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1419 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2744338\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Christophe Hurter;St\u00e9phane Puechmorel;Florence Nicol;Alexandru Telea; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Functional Decomposition for Bundled Simplification of Trail Sets; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Bundling visually aggregates curves to reduce clutter and help finding important patterns in trail-sets or graph drawings. We propose a new approach to bundling based on functional decomposition of the underling dataset. We recover the functional nature of the curves by representing them as linear combinations of piecewise-polynomial basis functions with associated expansion coefficients. Next, we express all curves in a given cluster in terms of a centroid curve and a complementary term, via a set of so-called principal component functions. Based on the above, we propose a two-fold contribution: First, we use cluster centroids to design a new bundling method for 2D and 3D curve-sets. Secondly, we deform the cluster centroids and generate new curves along them, which enables us to modify the underlying data in a statistically-controlled way via its simplified (bundled) view. We demonstrate our method by applications on real-world 2D and 3D datasets for graph bundling, trajectory analysis, and vector field and tensor field visualization."}, {"color": "gray", "id": 1424, "label": 1424, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1424 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2744418\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jie Liu;Tim Dwyer;Kim Marriott;Jeremy Millar;Annette Haworth; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Understanding the Relationship Between Interactive Optimisation and Visual Analytics in the Context of Prostate Brachytherapy; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The fields of operations research and computer science have long sought to find automatic solver techniques that can find high-quality solutions to difficult real-world optimisation problems. The traditional workflow is to exactly model the problem and then enter this model into a general-purpose \u201cblack-box\u201d solver. In practice, however, many problems cannot be solved completely automatically, but require a \u201chuman-in-the-loop\u201d to iteratively refine the model and give hints to the solver. In this paper, we explore the parallels between this interactive optimisation workflow and the visual analytics sense-making loop. We assert that interactive optimisation is essentially a visual analytics task and propose a problem-solving loop analogous to the sense-making loop. We explore these ideas through an in-depth analysis of a use-case in prostate brachytherapy, an application where interactive optimisation may be able to provide significant assistance to practitioners in creating prostate cancer treatment plans customised to each patient\u0027s tumour characteristics. However, current brachytherapy treatment planning is usually a careful, mostly manual process involving multiple professionals. We developed a prototype interactive optimisation tool for brachytherapy that goes beyond current practice in supporting focal therapy - targeting tumour cells directly rather than simply seeking coverage of the whole prostate gland. We conducted semi-structured interviews, in two stages, with seven radiation oncology professionals in order to establish whether they would prefer to use interactive optimisation for treatment planning and whether such a tool could improve their trust in the novel focal therapy approach and in machine generated solutions to the problem."}, {"color": "gray", "id": 1425, "label": 1425, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1425 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2744419\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Nan Cao;Chaoguang Lin;Qiuhan Zhu;Yu-Ru Lin;Xian Teng;Xidao Wen; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Voila: Visual Anomaly Detection and Monitoring with Streaming Spatiotemporal Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The increasing availability of spatiotemporal data continuously collected from various sources provides new opportunities for a timely understanding of the data in their spatial and temporal context. Finding abnormal patterns in such data poses significant challenges. Given that there is often no clear boundary between normal and abnormal patterns, existing solutions are limited in their capacity of identifying anomalies in large, dynamic and heterogeneous data, interpreting anomalies in their multifaceted, spatiotemporal context, and allowing users to provide feedback in the analysis loop. In this work, we introduce a unified visual interactive system and framework, Voila, for interactively detecting anomalies in spatiotemporal data collected from a streaming data source. The system is designed to meet two requirements in real-world applications, i.e., online monitoring and interactivity. We propose a novel tensor-based anomaly analysis algorithm with visualization and interaction design that dynamically produces contextualized, interpretable data summaries and allows for interactively ranking anomalous patterns based on user input. Using the \u201csmart city\u201d as an example scenario, we demonstrate the effectiveness of the proposed framework through quantitative evaluation and qualitative case studies."}, {"color": "gray", "id": 1426, "label": 1426, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1426 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2744438\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jens G. Magnus;Stefan Bruckner; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Interactive Dynamic Volume Illumination with Refraction and Caustics; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In recent years, significant progress has been made in developing high-quality interactive methods for realistic volume illumination. However, refraction - despite being an important aspect of light propagation in participating media - has so far only received little attention. In this paper, we present a novel approach for refractive volume illumination including caustics capable of interactive frame rates. By interleaving light and viewing ray propagation, our technique avoids memory-intensive storage of illumination information and does not require any precomputation. It is fully dynamic and all parameters such as light position and transfer function can be modified interactively without a performance penalty."}, {"color": "gray", "id": 1428, "label": 1428, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1428 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2744459\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: G. Elisabeta Marai; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Activity-Centered Domain Characterization for Problem-Driven Scientific Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Although visualization design models exist in the literature in the form of higher-level methodological frameworks, these models do not present a clear methodological prescription for the domain characterization step. This work presents a framework and end-to-end model for requirements engineering in problem-driven visualization application design. The framework and model are based on the activity-centered design paradigm, which is an enhancement of human-centered design. The proposed activity-centered approach focuses on user tasks and activities, and allows an explicit link between the requirements engineering process with the abstraction stage - and its evaluation - of existing, higher-level visualization design models. In a departure from existing visualization design models, the resulting model: assigns value to a visualization based on user activities; ranks user tasks before the user data; partitions requirements in activity-related capabilities and nonfunctional characteristics and constraints; and explicitly incorporates the user workflows into the requirements process. A further merit of this model is its explicit integration of functional specifications, a concept this work adapts from the software engineering literature, into the visualization design nested model. A quantitative evaluation using two sets of interdisciplinary projects supports the merits of the activity-centered model. The result is a practical roadmap to the domain characterization step of visualization design for problem-driven data visualization. Following this domain characterization model can help remove a number of pitfalls that have been identified multiple times in the visualization design literature."}, {"color": "gray", "id": 1433, "label": 1433, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1433 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2744684\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Enamul Hoque;Vidya Setlur;Melanie Tory;Isaac Dykeman; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Applying Pragmatics Principles for Interaction with Visual Analytics; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Interactive visual data analysis is most productive when users can focus on answering the questions they have about their data, rather than focusing on how to operate the interface to the analysis tool. One viable approach to engaging users in interactive conversations with their data is a natural language interface to visualizations. These interfaces have the potential to be both more expressive and more accessible than other interaction paradigms. We explore how principles from language pragmatics can be applied to the flow of visual analytical conversations, using natural language as an input modality. We evaluate the effectiveness of pragmatics support in our system Evizeon, and present design considerations for conversation interfaces to visual analytics tools."}, {"color": "gray", "id": 1436, "label": 1436, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1436 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2744718\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Minsuk Kahng;Pierre Y. Andrews;Aditya Kalro;Duen Horng (Polo) Chau; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: ActiVis: Visual Exploration of Industry-Scale Deep Neural Network Models; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: While deep learning models have achieved state-of-the-art accuracies for many prediction tasks, understanding these models remains a challenge. Despite the recent interest in developing visual tools to help users interpret deep learning models, the complexity and wide variety of models deployed in industry, and the large-scale datasets that they used, pose unique design challenges that are inadequately addressed by existing work. Through participatory design sessions with over 15 researchers and engineers at Facebook, we have developed, deployed, and iteratively improved ActiVis, an interactive visualization system for interpreting large-scale deep learning models and results. By tightly integrating multiple coordinated views, such as a computation graph overview of the model architecture, and a neuron activation view for pattern discovery and comparison, users can explore complex deep neural network models at both the instance-and subset-level. ActiVis has been deployed on Facebook\u0027s machine learning platform. We present case studies with Facebook researchers and engineers, and usage scenarios of how ActiVis may work with different models."}, {"color": "gray", "id": 1437, "label": 1437, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1437 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2744738\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Xun Zhao;Yanhong Wu;Weiwei Cui;Xinnan Du;Yuan Chen;Yong Wang;Dik Lun Lee;Huamin Qu; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: SkyLens: Visual Analysis of Skyline on Multi-Dimensional Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Skyline queries have wide-ranging applications in fields that involve multi-criteria decision making, including tourism, retail industry, and human resources. By automatically removing incompetent candidates, skyline queries allow users to focus on a subset of superior data items (i.e., the skyline), thus reducing the decision-making overhead. However, users are still required to interpret and compare these superior items manually before making a successful choice. This task is challenging because of two issues. First, people usually have fuzzy, unstable, and inconsistent preferences when presented with multiple candidates. Second, skyline queries do not reveal the reasons for the superiority of certain skyline points in a multi-dimensional space. To address these issues, we propose SkyLens, a visual analytic system aiming at revealing the superiority of skyline points from different perspectives and at different scales to aid users in their decision making. Two scenarios demonstrate the usefulness of SkyLens on two datasets with a dozen of attributes. A qualitative study is also conducted to show that users can efficiently accomplish skyline understanding and comparison tasks with SkyLens."}, {"color": "gray", "id": 1438, "label": 1438, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1438 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2744758\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Roger A. Leite;Theresia Gschwandtner;Silvia Miksch;Simone Kriglstein;Margit Pohl;Erich Gstrein;Johannes Kuntner; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: EVA: Visual Analytics to Identify Fraudulent Events; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Financial institutions are interested in ensuring security and quality for their customers. Banks, for instance, need to identify and stop harmful transactions in a timely manner. In order to detect fraudulent operations, data mining techniques and customer profile analysis are commonly used. However, these approaches are not supported by Visual Analytics techniques yet. Visual Analytics techniques have potential to considerably enhance the knowledge discovery process and increase the detection and prediction accuracy of financial fraud detection systems. Thus, we propose EVA, a Visual Analytics approach for supporting fraud investigation, fine-tuning fraud detection algorithms, and thus, reducing false positive alarms."}, {"color": "gray", "id": 1442, "label": 1442, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1442 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2744878\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Kanit Wongsuphasawat;Daniel Smilkov;James Wexler;Jimbo Wilson;Dandelion Man\u00e9;Doug Fritz;Dilip Krishnan;Fernanda B. Vi\u00e9gas;Martin Wattenberg; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visualizing Dataflow Graphs of Deep Learning Models in TensorFlow; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present a design study of the TensorFlow Graph Visualizer, part of the TensorFlow machine intelligence platform. This tool helps users understand complex machine learning architectures by visualizing their underlying dataflow graphs. The tool works by applying a series of graph transformations that enable standard layout techniques to produce a legible interactive diagram. To declutter the graph, we decouple non-critical nodes from the layout. To provide an overview, we build a clustered graph using the hierarchical structure annotated in the source code. To support exploration of nested structure on demand, we perform edge bundling to enable stable and responsive cluster expansion. Finally, we detect and highlight repeated structures to emphasize a model\u0027s modular composition. To demonstrate the utility of the visualizer, we describe example usage scenarios and report user feedback. Overall, users find the visualizer useful for understanding, debugging, and sharing the structures of their models."}, {"color": "gray", "id": 1447, "label": 1447, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1447 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2745083\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Yuanzhe Chen;Panpan Xu;Liu Ren; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Sequence Synopsis: Optimize Visual Summary of Temporal Event Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Event sequences analysis plays an important role in many application domains such as customer behavior analysis, electronic health record analysis and vehicle fault diagnosis. Real-world event sequence data is often noisy and complex with high event cardinality, making it a challenging task to construct concise yet comprehensive overviews for such data. In this paper, we propose a novel visualization technique based on the minimum description length (MDL) principle to construct a coarse-level overview of event sequence data while balancing the information loss in it. The method addresses a fundamental trade-off in visualization design: reducing visual clutter vs. increasing the information content in a visualization. The method enables simultaneous sequence clustering and pattern extraction and is highly tolerant to noises such as missing or additional events in the data. Based on this approach we propose a visual analytics framework with multiple levels-of-detail to facilitate interactive data exploration. We demonstrate the usability and effectiveness of our approach through case studies with two real-world datasets. One dataset showcases a new application domain for event sequence visualization, i.e., fault development path analysis in vehicles for predictive maintenance. We also discuss the strengths and limitations of the proposed method based on user feedback."}, {"color": "gray", "id": 1449, "label": 1449, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1449 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2745086\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: David Burlinson;Kalpathi Subramanian;Paula Goolkasian; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Open vs. Closed Shapes: New Perceptual Categories?; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Effective communication using visualization relies in part on the use of viable encoding strategies. For example, a viewer\u0027s ability to rapidly and accurately discern between two or more categorical variables in a chart or figure is contingent upon the distinctiveness of the encodings applied to each variable. Research in perception suggests that color is a more salient visual feature when compared to shape and although that finding is supported by visualization studies, characteristics of shape also yield meaningful differences in distinctiveness. We propose that open or closed shapes (that is, whether shapes are composed of line segments that are bounded across a region of space or not) represent a salient characteristic that influences perceptual processing. Three experiments were performed to test the reliability of the open/closed category; the first two from the perspective of attentional allocation, and the third experiment in the context of multi-class scatterplot displays. In the first, a flanker paradigm was used to test whether perceptual load and open/closed feature category would modulate the effect of the flanker on target processing. Results showed an influence of both variables. The second experiment used a Same/Different reaction time task to replicate and extend those findings. Results from both show that responses are faster and more accurate when closed rather than open shapes are processed as targets, and there is more processing interference when two competing shapes come from the same rather than different open or closed feature categories. The third experiment employed three commonly used visual analytic tasks - perception of average value, numerosity, and linear relationships with both single and dual displays of open and closed symbols. Our findings show that for numerosity and trend judgments, in particular, that different symbols from the same open or closed feature category cause more perceptual interference when they are presented together in a plot than symbols from different categories. Moreover, the extent of the interference appears to depend upon whether the participant is focused on processing open or closed symbols."}, {"color": "gray", "id": 1451, "label": 1451, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1451 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2745118\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Michael Glueck;Mahdi Pakdaman Naeini;Finale Doshi-Velez;Fanny Chevalier;Azam Khan;Daniel Wigdor;Michael Brudno; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: PhenoLines: Phenotype Comparison Visualizations for Disease Subtyping via Topic Models; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: PhenoLines is a visual analysis tool for the interpretation of disease subtypes, derived from the application of topic models to clinical data. Topic models enable one to mine cross-sectional patient comorbidity data (e.g., electronic health records) and construct disease subtypes-each with its own temporally evolving prevalence and co-occurrence of phenotypes-without requiring aligned longitudinal phenotype data for all patients. However, the dimensionality of topic models makes interpretation challenging, and de facto analyses provide little intuition regarding phenotype relevance or phenotype interrelationships. PhenoLines enables one to compare phenotype prevalence within and across disease subtype topics, thus supporting subtype characterization, a task that involves identifying a proposed subtype\u0027s dominant phenotypes, ages of effect, and clinical validity. We contribute a data transformation workflow that employs the Human Phenotype Ontology to hierarchically organize phenotypes and aggregate the evolving probabilities produced by topic models. We introduce a novel measure of phenotype relevance that can be used to simplify the resulting topology. The design of PhenoLines was motivated by formative interviews with machine learning and clinical experts. We describe the collaborative design process, distill high-level tasks, and report on initial evaluations with machine learning experts and a medical domain expert. These results suggest that PhenoLines demonstrates promising approaches to support the characterization and optimization of topic models."}, {"color": "gray", "id": 1453, "label": 1453, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1453 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2745139\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Xumeng Wang;Jia-Kai Chou;Wei Chen;Huihua Guan;Wenlong Chen;Tianyi Lao;Kwan-Liu Ma; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: A Utility-Aware Visual Approach for Anonymizing Multi-Attribute Tabular Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Sharing data for public usage requires sanitization to prevent sensitive information from leaking. Previous studies have presented methods for creating privacy preserving visualizations. However, few of them provide sufficient feedback to users on how much utility is reduced (or preserved) during such a process. To address this, we design a visual interface along with a data manipulation pipeline that allows users to gauge utility loss while interactively and iteratively handling privacy issues in their data. Widely known and discussed types of privacy models, i.e., syntactic anonymity and differential privacy, are integrated and compared under different use case scenarios. Case study results on a variety of examples demonstrate the effectiveness of our approach."}, {"color": "gray", "id": 1463, "label": 1463, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1463 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2745278\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Bram C.M. Cappers;Jarke J. van Wijk; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Exploring Multivariate Event Sequences Using Rules, Aggregations, and Selections; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Multivariate event sequences are ubiquitous: travel history, telecommunication conversations, and server logs are some examples. Besides standard properties such as type and timestamp, events often have other associated multivariate data. Current exploration and analysis methods either focus on the temporal analysis of a single attribute or the structural analysis of the multivariate data only. We present an approach where users can explore event sequences at multivariate and sequential level simultaneously by interactively defining a set of rewrite rules using multivariate regular expressions. Users can store resulting patterns as new types of events or attributes to interactively enrich or simplify event sequences for further investigation. In Eventpad we provide a bottom-up glyph-oriented approach for multivariate event sequence analysis by searching, clustering, and aligning them according to newly defined domain specific properties. We illustrate the effectiveness of our approach with real-world data sets including telecommunication traffic and hospital treatments."}, {"color": "gray", "id": 1464, "label": 1464, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1464 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2745279\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jian Zhao;Michael Glueck;Petra Isenberg;Fanny Chevalier;Azam Khan; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Supporting Handoff in Asynchronous Collaborative Sensemaking Using Knowledge-Transfer Graphs; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: During asynchronous collaborative analysis, handoff of partial findings is challenging because externalizations produced by analysts may not adequately communicate their investigative process. To address this challenge, we developed techniques to automatically capture and help encode tacit aspects of the investigative process based on an analyst\u0027s interactions, and streamline explicit authoring of handoff annotations. We designed our techniques to mediate awareness of analysis coverage, support explicit communication of progress and uncertainty with annotation, and implicit communication through playback of investigation histories. To evaluate our techniques, we developed an interactive visual analysis system, KTGraph, that supports an asynchronous investigative document analysis task. We conducted a two-phase user study to characterize a set of handoff strategies and to compare investigative performance with and without our techniques. The results suggest that our techniques promote the use of more effective handoff strategies, help increase an awareness of prior investigative process and insights, as well as improve final investigative outcomes."}, {"color": "gray", "id": 1466, "label": 1466, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1466 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2745298\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Christina Niederer;Holger Stitz;Reem Hourieh;Florian Grassinger;Wolfgang Aigner;Marc Streit; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: TACO: Visualizing Changes in Tables Over Time; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Multivariate, tabular data is one of the most common data structures used in many different domains. Over time, tables can undergo changes in both structure and content, which results in multiple versions of the same table. A challenging task when working with such derived tables is to understand what exactly has changed between versions in terms of additions/deletions, reorder, merge/split, and content changes. For textual data, a variety of commonplace \u201cdiff\u201d tools exist that support the task of investigating changes between revisions of a text. Although there are some comparison tools which assist users in inspecting differences between multiple table instances, the resulting visualizations are often difficult to interpret or do not scale to large tables with thousands of rows and columns. To address these challenges, we developed TACO, an interactive comparison tool that visualizes the differences between multiple tables at various levels of detail. With TACO we show (1) the aggregated differences between multiple table versions over time, (2) the aggregated changes between two selected table versions, and (3) detailed changes between the selected tables. To demonstrate the effectiveness of our approach, we show its application by means of two usage scenarios."}, {"color": "gray", "id": 1467, "label": 1467, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1467 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2745320\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Shunan Guo;Ke Xu;Rongwen Zhao;David Gotz;Hongyuan Zha;Nan Cao; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: EventThread: Visual Summarization and Stage Analysis of Event Sequence Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Event sequence data such as electronic health records, a person\u0027s academic records, or car service records, are ordered series of events which have occurred over a period of time. Analyzing collections of event sequences can reveal common or semantically important sequential patterns. For example, event sequence analysis might reveal frequently used care plans for treating a disease, typical publishing patterns of professors, and the patterns of service that result in a well-maintained car. It is challenging, however, to visually explore large numbers of event sequences, or sequences with large numbers of event types. Existing methods focus on extracting explicitly matching patterns of events using statistical analysis to create stages of event progression over time. However, these methods fail to capture latent clusters of similar but not identical evolutions of event sequences. In this paper, we introduce a novel visualization system named EventThread which clusters event sequences into threads based on tensor analysis and visualizes the latent stage categories and evolution patterns by interactively grouping the threads by similarity into time-specific clusters. We demonstrate the effectiveness of EventThread through usage scenarios in three different application domains and via interviews with an expert user."}, {"color": "gray", "id": 1468, "label": 1468, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1468 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2745859\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Yunhai Wang;Xiaowei Chu;Chen Bao;Lifeng Zhu;Oliver Deussen;Baoquan Chen;Michael Sedlmair; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: EdWordle: Consistency-Preserving Word Cloud Editing; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present EdWordle, a method for consistently editing word clouds. At its heart, EdWordle allows users to move and edit words while preserving the neighborhoods of other words. To do so, we combine a constrained rigid body simulation with a neighborhood-aware local Wordle algorithm to update the cloud and to create very compact layouts. The consistent and stable behavior of EdWordle enables users to create new forms of word clouds such as storytelling clouds in which the position of words is carefully edited. We compare our approach with state-of-the-art methods and show that we can improve user performance, user satisfaction, as well as the layout itself."}, {"color": "gray", "id": 1470, "label": 1470, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1470 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2745919\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Yunhai Wang;Yanyan Wang;Yinqi Sun;Lifeng Zhu;Kecheng Lu;Chi-Wing Fu;Michael Sedlmair;Oliver Deussen;Baoquan Chen; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Revisiting Stress Majorization as a Unified Framework for Interactive Constrained Graph Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present an improved stress majorization method that incorporates various constraints, including directional constraints without the necessity of solving a constraint optimization problem. This is achieved by reformulating the stress function to impose constraints on both the edge vectors and lengths instead of just on the edge lengths (node distances). This is a unified framework for both constrained and unconstrained graph visualizations, where we can model most existing layout constraints, as well as develop new ones such as the star shapes and cluster separation constraints within stress majorization. This improvement also allows us to parallelize computation with an efficient GPU conjugant gradient solver, which yields fast and stable solutions, even for large graphs. As a result, we allow the constraint-based exploration of large graphs with 10K nodes - an approach which previous methods cannot support."}, {"color": "gray", "id": 1477, "label": 1477, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1477 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2017.8585498\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Paolo Federico;Markus Wagner;Alexander Rind;Albert Amor-Amor\u00f3s;Silvia Miksch;Wolfgang Aigner; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: The Role of Explicit Knowledge: A Conceptual Model of Knowledge-Assisted Visual Analytics; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Visual Analytics (VA) aims to combine the strengths of humans and computers for effective data analysis. In this endeavor, humans\u0027 tacit knowledge from prior experience is an important asset that can be leveraged by both human and computer to improve the analytic process. While VA environments are starting to include features to formalize, store, and utilize such knowledge, the mechanisms and degree in which these environments integrate explicit knowledge varies widely. Additionally, this important class of VA environments has never been elaborated on by existing work on VA theory. This paper proposes a conceptual model of Knowledge-assisted VA conceptually grounded on the visualization model by van Wijk. We apply the model to describe various examples of knowledge-assisted VA from the literature and elaborate on three of them in finer detail. Moreover, we illustrate the utilization of the model to compare different design alternatives and to evaluate existing approaches with respect to their use of knowledge. Finally, the model can inspire designers to generate novel VA environments using explicit knowledge effectively."}, {"color": "gray", "id": 1478, "label": 1478, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1478 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2017.8585505\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Stefan J\u00e4nicke;David Joseph Wrisley; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Interactive Visual Alignment of Medieval Text Versions; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Textual criticism consists of the identification and analysis of variant readings among different versions of a text. Being a relatively simple task for modern languages, the collation of medieval text traditions ranges from the complex to the virtually impossible depending on the degree of instability of textual transmission. We present a visual analytics environment that supports computationally aligning such complex textual differences typical of orally inflected medieval poetry. For the purpose of analyzing alignment, we provide interactive visualizations for different text hierarchy levels, specifically, a meso reading view to support investigating repetition and variance at the line level across text segments. In addition to outlining important aspects of our interdisciplinary collaboration, we emphasize the utility of the proposed system by various usage scenarios in medieval French literature."}, {"color": "gray", "id": 1479, "label": 1479, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1479 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2017.8585594\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Yen-Ting Kuan;Yu-Shuen Wang;Jung-Hong Chuang; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visualizing Real-Time Strategy Games: The Example of StarCraft II; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present a visualization system for users to examine real-time strategy games, which have become very popular globally in recent years. Unlike previous systems that focus on showing statistics and build order, our system can depict the most important part - battles in the games. Specifically, we visualize detailed movements of armies belonging to respective nations on a map and enable users to examine battles from a global view to a local view. In the global view, battles are depicted by curved arrows revealing how the armies enter and escape from the battlefield. By observing the arrows and the height map, users can make sense of offensive and defensive strategies easily. In the local view, units of each type are rendered on the map, and their movements are represented by animation. We also render an attack line between a pair of units if one of them can attack the other to help users analyze the advantages and disadvantages of a particular formation. Accordingly, users can utilize our system to discover statistics, build order, and battles, and learn strategies from games played by professionals."}, {"color": "gray", "id": 1486, "label": 1486, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1486 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2017.8585669\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Emily Wall;Leslie M. Blaha;Lyndsey Franklin;Alex Endert; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Warning, Bias May Occur: A Proposed Approach to Detecting Cognitive Bias in Interactive Visual Analytics; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Visual analytic tools combine the complementary strengths of humans and machines in human-in-the-loop systems. Humans provide invaluable domain expertise and sensemaking capabilities to this discourse with analytic models; however, little consideration has yet been given to the ways inherent human biases might shape the visual analytic process. In this paper, we establish a conceptual framework for considering bias assessment through human-in-the-loop systems and lay the theoretical foundations for bias measurement. We propose six preliminary metrics to systematically detect and quantify bias from user interactions and demonstrate how the metrics might be implemented in an existing visual analytic system, InterAxis. We discuss how our proposed metrics could be used by visual analytic systems to mitigate the negative effects of cognitive biases by making users aware of biased processes throughout their analyses."}, {"color": "gray", "id": 1487, "label": 1487, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1487 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2017.8585720\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Josua Krause;Aritra Dasgupta;Jordan Swartz;Yindalon Aphinyanaphongs;Enrico Bertini; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: A Workflow for Visual Diagnostics of Binary Classifiers using Instance-Level Explanations; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Human-in-the-loop data analysis applications necessitate greater transparency in machine learning models for experts to understand and trust their decisions. To this end, we propose a visual analytics workflow to help data scientists and domain experts explore, diagnose, and understand the decisions made by a binary classifier. The approach leverages \u201cinstance-level explanations\u201d, measures of local feature relevance that explain single instances, and uses them to build a set of visual representations that guide the users in their investigation. The workflow is based on three main visual representations and steps: one based on aggregate statistics to see how data distributes across correct / incorrect decisions; one based on explanations to understand which features are used to make these decisions; and one based on raw data, to derive insights on potential root causes for the observed patterns. The workflow is derived from a long-term collaboration with a group of machine learning and healthcare professionals who used our method to make sense of machine learning models they developed. The case study from this collaboration demonstrates that the proposed workflow helps experts derive useful knowledge about the model and the phenomena it describes, thus experts can generate useful hypotheses on how a model can be improved."}, {"color": "gray", "id": 1490, "label": 1490, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1490 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2864432\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Guillaume Favelier;Noura Faraj;Brian Summa;Julien Tierny; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Persistence Atlas for Critical Point Variability in Ensembles; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: This paper presents a new approach for the visualization and analysis of the spatial variability of features of interest represented by critical points in ensemble data. Our framework, called Persistence Atlas, enables the visualization of the dominant spatial patterns of critical points, along with statistics regarding their occurrence in the ensemble. The persistence atlas represents in the geometrical domain each dominant pattern in the form of a confidence map for the appearance of critical points. As a by-product, our method also provides 2-dimensional layouts of the entire ensemble, highlighting the main trends at a global level. Our approach is based on the new notion of Persistence Map, a measure of the geometrical density in critical points which leverages the robustness to noise of topological persistence to better emphasize salient features. We show how to leverage spectral embedding to represent the ensemble members as points in a low-dimensional Euclidean space, where distances between points measure the dissimilarities between critical point layouts and where statistical tasks, such as clustering, can be easily carried out. Further, we show how the notion of mandatory critical point can be leveraged to evaluate for each cluster confidence regions for the appearance of critical points. Most of the steps of this framework can be trivially parallelized and we show how to efficiently implement them. Extensive experiments demonstrate the relevance of our approach. The accuracy of the confidence regions provided by the persistence atlas is quantitatively evaluated and compared to a baseline strategy using an off-the-shelf clustering approach. We illustrate the importance of the persistence atlas in a variety of real-life datasets, where clear trends in feature layouts are identified and analyzed. We provide a lightweight VTK-based C++ implementation of our approach that can be used for reproduction purposes."}, {"color": "gray", "id": 1496, "label": 1496, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1496 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2864500\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Minsuk Kahng;Nikhil Thorat;Duen Horng (Polo) Chau;Fernanda B. Vi\u00e9gas;Martin Wattenberg; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: GAN Lab: Understanding Complex Deep Generative Models using Interactive Visual Experimentation; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Recent success in deep learning has generated immense interest among practitioners and students, inspiring many to learn about this new technology. While visual and interactive approaches have been successfully developed to help people more easily learn deep learning, most existing tools focus on simpler models. In this work, we present GAN Lab, the first interactive visualization tool designed for non-experts to learn and experiment with Generative Adversarial Networks (GANs), a popular class of complex deep learning models. With GAN Lab, users can interactively train generative models and visualize the dynamic training process\u0027s intermediate results. GAN Lab tightly integrates an model overview graph that summarizes GAN\u0027s structure, and a layered distributions view that helps users interpret the interplay between submodels. GAN Lab introduces new interactive experimentation features for learning complex deep learning models, such as step-by-step training at multiple levels of abstraction for understanding intricate training dynamics. Implemented using TensorFlow.js, GAN Lab is accessible to anyone via modern web browsers, without the need for installation or specialized hardware, overcoming a major practical challenge in deploying interactive tools for deep learning."}, {"color": "gray", "id": 1498, "label": 1498, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1498 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2864504\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Junpeng Wang;Liang Gou;Han-Wei Shen;Hao Yang; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: DQNViz: A Visual Analytics Approach to Understand Deep Q-Networks; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Deep Q-Network (DQN), as one type of deep reinforcement learning model, targets to train an intelligent agent that acquires optimal actions while interacting with an environment. The model is well known for its ability to surpass professional human players across many Atari 2600 games. Despite the superhuman performance, in-depth understanding of the model and interpreting the sophisticated behaviors of the DQN agent remain to be challenging tasks, due to the long-time model training process and the large number of experiences dynamically generated by the agent. In this work, we propose DQNViz, a visual analytics system to expose details of the blind training process in four levels, and enable users to dive into the large experience space of the agent for comprehensive analysis. As an initial attempt in visualizing DQN models, our work focuses more on Atari games with a simple action space, most notably the Breakout game. From our visual analytics of the agent\u0027s experiences, we extract useful action/reward patterns that help to interpret the model and control the training. Through multiple case studies conducted together with deep learning experts, we demonstrate that DQNViz can effectively help domain experts to understand, diagnose, and potentially improve DQN models."}, {"color": "gray", "id": 1499, "label": 1499, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1499 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2864505\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Tushar Athawale;Chris R. Johnson; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Probabilistic Asymptotic Decider for Topological Ambiguity Resolution in Level-Set Extraction for Uncertain 2D Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present a framework for the analysis of uncertainty in isocontour extraction. The marching squares (MS) algorithm for isocontour reconstruction generates a linear topology that is consistent with hyperbolic curves of a piecewise bilinear interpolation. The saddle points of the bilinear interpolant cause topological ambiguity in isocontour extraction. The midpoint decider and the asymptotic decider are well-known mathematical techniques for resolving topological ambiguities. The latter technique investigates the data values at the cell saddle points for ambiguity resolution. The uncertainty in data, however, leads to uncertainty in underlying bilinear interpolation functions for the MS algorithm, and hence, their saddle points. In our work, we study the behavior of the asymptotic decider when data at grid vertices is uncertain. First, we derive closed-form distributions characterizing variations in the saddle point values for uncertain bilinear interpolants. The derivation assumes uniform and nonparametric noise models, and it exploits the concept of ratio distribution for analytic formulations. Next, the probabilistic asymptotic decider is devised for ambiguity resolution in uncertain data using distributions of the saddle point values derived in the first step. Finally, the confidence in probabilistic topological decisions is visualized using a colormapping technique. We demonstrate the higher accuracy and stability of the probabilistic asymptotic decider in uncertain data with regard to existing decision frameworks, such as deciders in the mean field and the probabilistic midpoint decider, through the isocontour visualization of synthetic and real datasets."}, {"color": "gray", "id": 1500, "label": 1500, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1500 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2864506\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Hui Zhang;Steffen Frey;Holger Steeb;David Uribe;Thomas Ertl;Wenping Wang; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visualization of Bubble Formation in Porous Media; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present a visualization approach for the analysis of CO\u003csub\u003e2\u003c/sub\u003ebubble-induced attenuation in porous rock formations. As a basis for this, we introduce customized techniques to extract CO\u003csub\u003e2\u003c/sub\u003ebubbles and their surrounding porous structure from X-ray computed tomography data (XCT) measurements. To understand how the structure of porous media influences the occurrence and the shape of formed bubbles, we automatically classify and relate them in terms of morphology and geometric features, and further directly support searching for promising porous structures. To allow for the meaningful direct visual comparison of bubbles and their structures, we propose a customized registration technique considering the bubble shape as well as its points of contact with the porous media surface. With our quantitative extraction of geometric bubble features, we further support the analysis as well as the creation of a physical model. We demonstrate that our approach was successfully used to answer several research questions in the domain, and discuss its high practical relevance to identify critical seismic characteristics of fluid-saturated rock that govern its capability to store CO\u003csub\u003e2\u003c/sub\u003e."}, {"color": "gray", "id": 1502, "label": 1502, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1502 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2864508\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Antoni Sagrist\u00e0;Stefan Jordan;Thomas M\u00fcller;Filip Sadlo; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Gaia Sky: Navigating the Gaia Catalog; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In this paper, we present Gaia Sky, a free and open-source multiplatform 3D Universe system, developed since 2014 in the Data Processing and Analysis Consortium framework of ESA\u0027s Gaia mission. Gaia\u0027s data release 2 represents the largest catalog of the stars of our Galaxy, comprising 1.3 billion star positions, with parallaxes, proper motions, magnitudes, and colors. In this mission, Gaia Sky is the central tool for off-the-shelf visualization of these data, and for aiding production of outreach material. With its capabilities to effectively handle these data, to enable seamless navigation along the high dynamic range of distances, and at the same time to provide advanced visualization techniques including relativistic aberration and gravitational wave effects, currently no actively maintained cross-platform, modern, and open alternative exists."}, {"color": "gray", "id": 1504, "label": 1504, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1504 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2864510\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Johannes Weissenb\u00f6ck;Bernhard Fr\u00f6hler;Eduard Gr\u00f6ller;Johann Kastner;Christoph Heinzl; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Dynamic Volume Lines: Visual Comparison of 3D Volumes through Space-filling Curves; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The comparison of many members of an ensemble is difficult, tedious, and error-prone, which is aggravated by often just subtle differences. In this paper, we introduce Dynamic Volume Lines for the interactive visual analysis and comparison of sets of 3D volumes. Each volume is linearized along a Hilbert space-filling curve into a 1D Hilbert line plot, which depicts the intensities over the Hilbert indices. We present a nonlinear scaling of these 1D Hilbert line plots based on the intensity variations in the ensemble of 3D volumes, which enables a more effective use of the available screen space. The nonlinear scaling builds the basis for our interactive visualization techniques. An interactive histogram heatmap of the intensity frequencies serves as overview visualization. When zooming in, the frequencies are replaced by detailed 1D Hilbert line plots and optional functional boxplots. To focus on important regions of the volume ensemble, nonlinear scaling is incorporated into the plots. An interactive scaling widget depicts the local ensemble variations. Our brushing and linking interface reveals, for example, regions with a high ensemble variation by showing the affected voxels in a 3D spatial view. We show the applicability of our concepts using two case studies on ensembles of 3D volumes resulting from tomographic reconstruction. In the first case study, we evaluate an artificial specimen from simulated industrial 3D X-ray computed tomography (XCT). In the second case study, a real-world XCT foam specimen is investigated. Our results show that Dynamic Volume Lines can identify regions with high local intensity variations, allowing the user to draw conclusions, for example, about the choice of reconstruction parameters. Furthermore, it is possible to detect ring artifacts in reconstructions volumes."}, {"color": "gray", "id": 1505, "label": 1505, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1505 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2864526\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Po-Ming Law;Rahul C. Basole;Yanhong Wu; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Duet: Helping Data Analysis Novices Conduct Pairwise Comparisons by Minimal Specification; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Data analysis novices often encounter barriers in executing low-level operations for pairwise comparisons. They may also run into barriers in interpreting the artifacts (e.g., visualizations) created as a result of the operations. We developed Duet, a visual analysis system designed to help data analysis novices conduct pairwise comparisons by addressing execution and interpretation barriers. To reduce the barriers in executing low-level operations during pairwise comparison, Duet employs minimal specification: when one object group (i.e. a group of records in a data table) is specified, Duet recommends object groups that are similar to or different from the specified one; when two object groups are specified, Duet recommends similar and different attributes between them. To lower the barriers in interpreting its recommendations, Duet explains the recommended groups and attributes using both visualizations and textual descriptions. We conducted a qualitative evaluation with eight participants to understand the effectiveness of Duet. The results suggest that minimal specification is easy to use and Duet\u0027s explanations are helpful for interpreting the recommendations despite some usability issues."}, {"color": "gray", "id": 1506, "label": 1506, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1506 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2864656\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Sergej Stoppel;Magnus Paulson Erga;Stefan Bruckner; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Firefly: Virtual Illumination Drones for Interactive Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Light specification in three dimensional scenes is a complex problem and several approaches have been presented that aim to automate this process. However, there are many scenarios where a static light setup is insufficient, as the scene content and camera position may change. Simultaneous manual control over the camera and light position imposes a high cognitive load on the user. To address this challenge, we introduce a novel approach for automatic scene illumination with Fireflies. Fireflies are intelligent virtual light drones that illuminate the scene by traveling on a closed path. The Firefly path automatically adapts to changes in the scene based on an outcome-oriented energy function. To achieve interactive performance, we employ a parallel rendering pipeline for the light path evaluations. We provide a catalog of energy functions for various application scenarios and discuss the applicability of our method on several examples."}, {"color": "gray", "id": 1507, "label": 1507, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1507 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2864690\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Michael Traor\u00e9;Christophe Hurter;Alexandru Telea; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Interactive obstruction-free lensing for volumetric data visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Occlusion is an issue in volumetric visualization as it prevents direct visualization of the region of interest. While many techniques such as transfer functions, volume segmentation or view distortion have been developed to address this, there is still room for improvement to better support the understanding of objects\u0027 vicinity. However, most existing Focus+Context fail to solve partial occlusion in datasets where the target and the occluder are very similar density-wise. For these reasons, we investigate a new technique which maintains the general structure of the investigated volumetric dataset while addressing occlusion issues. With our technique, the user interactively defines an area of interest where an occluded region or object is partially visible. Then our lens starts pushing at its border occluding objects, thus revealing hidden volumetric data. Next, the lens is modified with an extended field of view (fish-eye deformation) to better see the vicinity of the selected region. Finally, the user can freely explore the surroundings of the area under investigation within the lens. To provide real-time exploration, we implemented our lens using a GPU accelerated ray-casting framework to handle ray deformations, local lighting, and local viewpoint manipulation. We illustrate our technique with five application scenarios in baggage inspection, 3D fluid flow visualization, chest radiology, air traffic planning, and DTI fiber exploration."}, {"color": "gray", "id": 1508, "label": 1508, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1508 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2864768\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Lawrence Roy;Prashant Kumar;Yue Zhang;Eugene Zhang; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Robust and Fast Extraction of 3D Symmetric Tensor Field Topology; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: 3D symmetric tensor fields appear in many science and engineering fields, and topology-driven analysis is important in many of these application domains, such as solid mechanics and fluid dynamics. Degenerate curves and neutral surfaces are important topological features in 3D symmetric tensor fields. Existing methods to extract degenerate curves and neutral surfaces often miss parts of the curves and surfaces, respectively. Moreover, these methods are computationally expensive due to the lack of knowledge of structures of degenerate curves and neutral surfaces.\u0026lt;;/p\u0026gt; \u0026lt;;p\u0026gt;In this paper, we provide theoretical analysis on the geometric and topological structures of degenerate curves and neutral surfaces of 3D linear tensor fields. These structures lead to parameterizations for degenerate curves and neutral surfaces that can not only provide more robust extraction of these features but also incur less computational cost.\u0026lt;;/p\u0026gt; \u0026lt;;p\u0026gt;We demonstrate the benefits of our approach by applying our degenerate curve and neutral surface detection techniques to solid mechanics simulation data sets."}, {"color": "gray", "id": 1513, "label": 1513, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1513 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2864811\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Natalia Andrienko;Gennady Andrienko;Jose Manuel Cordero Garcia;David Scarlatti; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Analysis of Flight Variability: a Systematic Approach; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In movement data analysis, there exists a problem of comparing multiple trajectories of moving objects to common or distinct reference trajectories. We introduce a general conceptual framework for comparative analysis of trajectories and an analytical procedure, which consists of (1) finding corresponding points in pairs of trajectories, (2) computation of pairwise difference measures, and (3) interactive visual analysis of the distributions of the differences with respect to space, time, set of moving objects, trajectory structures, and spatio-temporal context. We propose a combination of visualisation, interaction, and data transformation techniques supporting the analysis and demonstrate the use of our approach for solving a challenging problem from the aviation domain."}, {"color": "gray", "id": 1515, "label": 1515, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1515 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2864813\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Thomas Wilde;Christian R\u00f6ssi;Holger Theisel; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Recirculation Surfaces for Flow Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present a formal approach to the visual analysis of recirculation in flows by introducing recirculation surfaces for 3D unsteady flow fields. Recirculation surfaces are the loci where massless particle integration returns to its starting point after some variable, finite integration. We give a rigorous definition of recirculation surfaces as 2-manifolds embedded in 5D space and study their properties. Based on this we construct an algorithm for their extraction, which searches for intersections of a recirculation surface with lines defined in 3D. This reduces the problem to a repeated search for critical points in 3D vector fields. We provide a uniform sampling of the search space paired with a surface reconstruction and visualize results. This way, we present the first algorithm for a comprehensive feature extraction in the 5D flow map of a 3D flow. The problem of finding isolated closed orbits in steady vector fields occurs as a special case of recirculation surfaces. This includes isolated closed orbits with saddle behavior. We show recirculation surfaces for a number of artificial and real flow data sets."}, {"color": "gray", "id": 1523, "label": 1523, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1523 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2864828\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Tobias G\u00fcnther;Holger Theisel; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Objective Vortex Corelines of Finite-sized Objects in Fluid Flows; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Vortices are one of the most-frequently studied phenomena in fluid flows. The center of the rotating motion is called the vortex coreline and its successful detection strongly depends on the choice of the reference frame. The optimal frame moves with the center of the vortex, which incidentally makes the observed fluid flow steady and thus standard vortex coreline extractors such as Sujudi-Haimes become applicable. Recently, an objective optimization framework was proposed that determines a near-steady reference frame for tracer particles. In this paper, we extend this technique to the detection of vortex corelines of inertial particles. An inertial particle is a finite-sized object that is carried by a fluid flow. In contrast to the usual tracer particles, they do not move tangentially with the flow, since they are subject to gravity and exhibit mass-dependent inertia. Their particle state is determined by their position and own velocity, which makes the search for the optimal frame a high-dimensional problem. We demonstrate in this paper that the objective detection of an inertial vortex coreline can be reduced in 2D to a critical point search in 2D. For 3D flows, however, the vortex coreline criterion remains a parallel vectors condition in 6D. To detect the vortex corelines we propose a recursive subdivision approach that is tailored to the underlying structure of the 6D vectors. The resulting algorithm is objective, and we demonstrate the vortex coreline extraction in a number of 2D and 3D vector fields."}, {"color": "gray", "id": 1525, "label": 1525, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1525 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2864838\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Dominik Sacha;Matthias Kraus;Daniel A. Keim;Min Chen; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: VIS4ML: An Ontology for Visual Analytics Assisted Machine Learning; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: While many VA workflows make use of machine-learned models to support analytical tasks, VA workflows have become increasingly important in understanding and improving Machine Learning (ML) processes. In this paper, we propose an ontology (VIS4ML) for a subarea of VA, namely \u201cVA-assisted ML\u201d. The purpose of VIS4ML is to describe and understand existing VA workflows used in ML as well as to detect gaps in ML processes and the potential of introducing advanced VA techniques to such processes. Ontologies have been widely used to map out the scope of a topic in biology, medicine, and many other disciplines. We adopt the scholarly methodologies for constructing VIS4ML, including the specification, conceptualization, formalization, implementation, and validation of ontologies. In particular, we reinterpret the traditional VA pipeline to encompass model-development workflows. We introduce necessary definitions, rules, syntaxes, and visual notations for formulating VIS4ML and make use of semantic web technologies for implementing it in the Web Ontology Language (OWL). VIS4ML captures the high-level knowledge about previous workflows where VA is used to assist in ML. It is consistent with the established VA concepts and will continue to evolve along with the future developments in VA and ML. While this ontology is an effort for building the theoretical foundation of VA, it can be used by practitioners in real-world applications to optimize model-development workflows by systematically examining the potential benefits that can be brought about by either machine or human capabilities. Meanwhile, VIS4ML is intended to be extensible and will continue to be updated to reflect future advancements in using VA for building high-quality data-analytical models or for building such models rapidly."}, {"color": "gray", "id": 1529, "label": 1529, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1529 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2864844\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Hong Wang;Yafeng Lu;Shade T. Shutters;Michael Steptoe;Feng Wang;Steven Landis;Ross Maciejewski; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: A Visual Analytics Framework for Spatiotemporal Trade Network Analysis; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Economic globalization is increasing connectedness among regions of the world, creating complex interdependencies within various supply chains. Recent studies have indicated that changes and disruptions within such networks can serve as indicators for increased risks of violence and armed conflicts. This is especially true of countries that may not be able to compete for scarce commodities during supply shocks. Thus, network-induced vulnerability to supply disruption is typically exported from wealthier populations to disadvantaged populations. As such, researchers and stakeholders concerned with supply chains, political science, environmental studies, etc. need tools to explore the complex dynamics within global trade networks and how the structure of these networks relates to regional instability. However, the multivariate, spatiotemporal nature of the network structure creates a bottleneck in the extraction and analysis of correlations and anomalies for exploratory data analysis and hypothesis generation. Working closely with experts in political science and sustainability, we have developed a highly coordinated, multi-view framework that utilizes anomaly detection, network analytics, and spatiotemporal visualization methods for exploring the relationship between global trade networks and regional instability. Requirements for analysis and initial research questions to be investigated are elicited from domain experts, and a variety of visual encoding techniques for rapid assessment of analysis and correlations between trade goods, network patterns, and time series signatures are explored. We demonstrate the application of our framework through case studies focusing on armed conflicts in Africa, regional instability measures, and their relationship to international global trade."}, {"color": "gray", "id": 1532, "label": 1532, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1532 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2864847\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Johanna Beyer;Haneen Mohammed;Marco Agus;Ali K. Al-Awami;Hanspeter Pfister;Markus Hadwiger; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Culling for Extreme-Scale Segmentation Volumes: A Hybrid Deterministic and Probabilistic Approach; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: With the rapid increase in raw volume data sizes, such as terabyte-sized microscopy volumes, the corresponding segmentation label volumes have become extremely large as well. We focus on integer label data, whose efficient representation in memory, as well as fast random data access, pose an even greater challenge than the raw image data. Often, it is crucial to be able to rapidly identify which segments are located where, whether for empty space skipping for fast rendering, or for spatial proximity queries. We refer to this process as\u003ci\u003eculling\u003c/i\u003e. In order to enable efficient culling of millions of labeled segments, we present a novel hybrid approach that combines deterministic and probabilistic representations of label data in a data-adaptive hierarchical data structure that we call the label list tree. In each node, we adaptively encode label data using either a probabilistic constant-time access representation for fast conservative culling, or a deterministic logarithmic-time access representation for exact queries. We choose the best data structures for representing the labels of each spatial region while building the label list tree. At run time, we further employ a novel\u003ci\u003equery-adaptive\u003c/i\u003eculling strategy. While filtering a query down the tree, we prune it successively, and in each node adaptively select the representation that is best suited for evaluating the pruned query, depending on its size. We show an analysis of the efficiency of our approach with several large data sets from connectomics, including a brain scan with more than 13 million labeled segments, and compare our method to conventional culling approaches. Our approach achieves significant reductions in storage size as well as faster query times."}, {"color": "gray", "id": 1533, "label": 1533, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1533 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2864848\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Attila Gyulassy;Peer-Timo Bremer;Valerio Pascucci; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Shared-Memory Parallel Computation of Morse-Smale Complexes with Improved Accuracy; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Topological techniques have proven to be a powerful tool in the analysis and visualization of large-scale scientific data. In particular, the Morse-Smale complex and its various components provide a rich framework for robust feature definition and computation. Consequently, there now exist a number of approaches to compute Morse-Smale complexes for large-scale data in parallel. However, existing techniques are based on discrete concepts which produce the correct topological structure but are known to introduce grid artifacts in the resulting geometry. Here, we present a new approach that combines parallel streamline computation with combinatorial methods to construct a high-quality discrete Morse-Smale complex. In addition to being invariant to the orientation of the underlying grid, this algorithm allows users to selectively build a subset of features using high-quality geometry. In particular, a user may specifically select which ascending/descending manifolds are reconstructed with improved accuracy, focusing computational effort where it matters for subsequent analysis. This approach computes Morse-Smale complexes for larger data than previously feasible with significant speedups. We demonstrate and validate our approach using several examples from a variety of different scientific domains, and evaluate the performance of our method."}, {"color": "gray", "id": 1535, "label": 1535, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1535 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2864850\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Feng Wang;Ingo Wald;Qi Wu;Will Usher;Chris R. Johnson; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: CPU Isosurface Ray Tracing of Adaptive Mesh Refinement Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Adaptive mesh refinement (AMR) is a key technology for large-scale simulations that allows for adaptively changing the simulation mesh resolution, resulting in significant computational and storage savings. However, visualizing such AMR data poses a significant challenge due to the difficulties introduced by the hierarchical representation when reconstructing continuous field values. In this paper, we detail a comprehensive solution for interactive isosurface rendering of block-structured AMR data. We contribute a novel reconstruction strategy-the octant method-which is continuous, adaptive and simple to implement. Furthermore, we present a generally applicable hybrid implicit isosurface ray-tracing method, which provides better rendering quality and performance than the built-in sampling-based approach in OSPRay. Finally, we integrate our octant method and hybrid isosurface geometry into OSPRay as a module, providing the ability to create high-quality interactive visualizations combining volume and isosurface representations of BS-AMR data. We evaluate the rendering performance, memory consumption and quality of our method on two gigascale block-structured AMR datasets."}, {"color": "gray", "id": 1536, "label": 1536, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1536 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2864851\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: David Duran;Pedro Hermosilla;Timo Ropinski;Barbora Kozl\u00edkov\u00e1;\u00c1lvar Vinacua;Pere-Pau V\u00e1zquez; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visualization of Large Molecular Trajectories; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The analysis of protein-ligand interactions is a time-intensive task. Researchers have to analyze multiple physico-chemical properties of the protein at once and combine them to derive conclusions about the protein-ligand interplay. Typically, several charts are inspected, and 3D animations can be played side-by-side to obtain a deeper understanding of the data. With the advances in simulation techniques, larger and larger datasets are available, with up to hundreds of thousands of steps. Unfortunately, such large trajectories are very difficult to investigate with traditional approaches. Therefore, the need for special tools that facilitate inspection of these large trajectories becomes substantial. In this paper, we present a novel system for visual exploration of very large trajectories in an interactive and user-friendly way. Several visualization motifs are automatically derived from the data to give the user the information about interactions between protein and ligand. Our system offers specialized widgets to ease and accelerate data inspection and navigation to interesting parts of the simulation. The system is suitable also for simulations where multiple ligands are involved. We have tested the usefulness of our tool on a set of datasets obtained from protein engineers, and we describe the expert feedback."}, {"color": "gray", "id": 1540, "label": 1540, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1540 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2864885\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Shunan Guo;Zhuochen Jin;David Gotz;Fan Du;Hongyuan Zha;Nan Cao; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visual Progression Analysis of Event Sequence Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Event sequence data is common to a broad range of application domains, from security to health care to scholarly communication. This form of data captures information about the progression of events for an individual entity (e.g., a computer network device; a patient; an author) in the form of a series of time-stamped observations. Moreover, each event is associated with an event type (e.g., a computer login attempt, or a hospital discharge). Analyses of event sequence data have been shown to help reveal important temporal patterns, such as clinical paths resulting in improved outcomes, or an understanding of common career trajectories for scholars. Moreover, recent research has demonstrated a variety of techniques designed to overcome methodological challenges such as large volumes of data and high dimensionality. However, the effective identification and analysis of latent stages of progression, which can allow for variation within different but similarly evolving event sequences, remain a significant challenge with important real-world motivations. In this paper, we propose an unsupervised stage analysis algorithm to identify semantically meaningful progression stages as well as the critical events which help define those stages. The algorithm follows three key steps: (1) event representation estimation, (2) event sequence warping and alignment, and (3) sequence segmentation. We also present a novel visualization system, ET\u003csup\u003e2\u003c/sup\u003e, which interactively illustrates the results of the stage analysis algorithm to help reveal evolution patterns across stages. Finally, we report three forms of evaluation for ET\u003csup\u003e2\u003c/sup\u003e: (1) case studies with two real-world datasets, (2) interviews with domain expert users, and (3) a performance evaluation on the progression analysis algorithm and the visualization design."}, {"color": "gray", "id": 1541, "label": 1541, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1541 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2864886\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Po-Ming Law;Zhicheng Liu;Sana Malik;Rahul C. Basole; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: MAQUI: Interweaving Queries and Pattern Mining for Recursive Event Sequence Exploration; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Exploring event sequences by defining queries alone or by using mining algorithms alone is often not sufficient to support analysis. Analysts often interweave querying and mining in a recursive manner during event sequence analysis: sequences extracted as query results are used for mining patterns, patterns generated are incorporated into a new query for segmenting the sequences, and the resulting segments are mined or queried again. To support flexible analysis, we propose a framework that describes the process of interwoven querying and mining. Based on this framework, we developed MAQUI, a Mining And Querying User Interface that enables recursive event sequence exploration. To understand the efficacy of MAQUI, we conducted two case studies with domain experts. The findings suggest that the capability of interweaving querying and mining helps the participants articulate their questions and gain novel insights from their data."}, {"color": "gray", "id": 1544, "label": 1544, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1544 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2864899\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Tan Tang;Sadia Rubab;Jiewen Lai;Weiwei Cui;Lingyun Yu;Yingcai Wu; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: iStoryline: Effective Convergence to Hand-drawn Storylines; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Storyline visualization techniques have progressed significantly to generate illustrations of complex stories automatically. However, the visual layouts of storylines are not enhanced accordingly despite the improvement in the performance and extension of its application area. Existing methods attempt to achieve several shared optimization goals, such as reducing empty space and minimizing line crossings and wiggles. However, these goals do not always produce optimal results when compared to hand-drawn storylines. We conducted a preliminary study to learn how users translate a narrative into a hand-drawn storyline and check whether the visual elements in hand-drawn illustrations can be mapped back to appropriate narrative contexts. We also compared the hand-drawn storylines with storylines generated by the state-of-the-art methods and found they have significant differences. Our findings led to a design space that summarizes (1) how artists utilize narrative elements and (2) the sequence of actions artists follow to portray expressive and attractive storylines. We developed iStoryline, an authoring tool for integrating high-level user interactions into optimization algorithms and achieving a balance between hand-drawn storylines and automatic layouts. iStoryline allows users to create novel storyline visualizations easily according to their preferences by modifying the automatically generated layouts. The effectiveness and usability of iStoryline are studied with qualitative evaluations."}, {"color": "gray", "id": 1550, "label": 1550, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1550 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2864911\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Yunhai Wang;Yanyan Wang;Haifeng Zhang;Yinqi Sun;Chi-Wing Fu;Michael Sedlmair;Baoquan Chen;Oliver Deussen; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Structure-aware Fisheye Views for Efficient Large Graph Exploration; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Traditional fisheye views for exploring large graphs introduce substantial distortions that often lead to a decreased readability of paths and other interesting structures. To overcome these problems, we propose a framework for structure-aware fisheye views. Using edge orientations as constraints for graph layout optimization allows us not only to reduce spatial and temporal distortions during fisheye zooms, but also to improve the readability of the graph structure. Furthermore, the framework enables us to optimize fisheye lenses towards specific tasks and design a family of new lenses: polyfocal, cluster, and path lenses. A GPU implementation lets us process large graphs with up to 15,000 nodes at interactive rates. A comprehensive evaluation, a user study, and two case studies demonstrate that our structure-aware fisheye views improve layout readability and user performance."}, {"color": "gray", "id": 1551, "label": 1551, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1551 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2864912\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Yunhai Wang;Xin Chen;Tong Ge;Chen Bao;Michael Sedlmair;Chi-Wing Fu;Oliver Deussen;Baoquan Chen; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Optimizing Color Assignment for Perception of Class Separability in Multiclass Scatterplots; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Appropriate choice of colors significantly aids viewers in understanding the structures in multiclass scatterplots and becomes more important with a growing number of data points and groups. An appropriate color mapping is also an important parameter for the creation of an aesthetically pleasing scatterplot. Currently, users of visualization software routinely rely on color mappings that have been pre-defined by the software. A default color mapping, however, cannot ensure an optimal perceptual separability between groups, and sometimes may even lead to a misinterpretation of the data. In this paper, we present an effective approach for color assignment based on a set of given colors that is designed to optimize the perception of scatterplots. Our approach takes into account the spatial relationships, density, degree of overlap between point clusters, and also the background color. For this purpose, we use a genetic algorithm that is able to efficiently find good color assignments. We implemented an interactive color assignment system with three extensions of the basic method that incorporates top K suggestions, user-defined color subsets, and classes of interest for the optimization. To demonstrate the effectiveness of our assignment technique, we conducted a numerical study and a controlled user study to compare our approach with default color assignments; our findings were verified by two expert studies. The results show that our approach is able to support users in distinguishing cluster numbers faster and more precisely than default assignment methods."}, {"color": "gray", "id": 1552, "label": 1552, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1552 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2864913\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Nina Mccurdy;Julie Gerdes;Miriah Meyer; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: A Framework for Externalizing Implicit Error Using Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: This paper presents a framework for externalizing and analyzing expert knowledge about discrepancies in data through the use of visualization. Grounded in an 18-month design study with global health experts, the framework formalizes the notion of data discrepancies as implicit error, both in global health data and more broadly. We use the term implicit error to describe measurement error that is inherent to and pervasive throughout a dataset, but that isn\u0027t explicitly accounted for or defined. Instead, implicit error exists in the minds of experts, is mainly qualitative, and is accounted for subjectively during expert interpretation of the data. Externalizing knowledge surrounding implicit error can assist in synchronizing, validating, and enhancing interpretation, and can inform error analysis and mitigation. The framework consists of a description of implicit error components that are important for downstream analysis, along with a process model for externalizing and analyzing implicit error using visualization. As a second contribution, we provide a rich, reflective, and verifiable description of our research process as an exemplar summary toward the ongoing inquiry into ways of increasing the validity and transferability of design study research."}, {"color": "gray", "id": 1556, "label": 1556, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1556 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2865021\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Xumeng Wang;Wei Chen;Jia-Kai Chou;Chris Bryan;Huihua Guan;Wenlong Chen;Rusheng Pan;Kwan-Liu Ma; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: GraphProtector: A Visual Interface for Employing and Assessing Multiple Privacy Preserving Graph Algorithms; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Analyzing social networks reveals the relationships between individuals and groups in the data. However, such analysis can also lead to privacy exposure (whether intentionally or inadvertently): leaking the real-world identity of ostensibly anonymous individuals. Most sanitization strategies modify the graph\u0027s structure based on hypothesized tactics that an adversary would employ. While combining multiple anonymization schemes provides a more comprehensive privacy protection, deciding the appropriate set of techniques-along with evaluating how applying the strategies will affect the utility of the anonymized results-remains a significant challenge. To address this problem, we introduce GraphProtector, a visual interface that guides a user through a privacy preservation pipeline. GraphProtector enables multiple privacy protection schemes which can be simultaneously combined together as a hybrid approach. To demonstrate the effectiveness of GraphPro tector, we report several case studies and feedback collected from interviews with expert users in various scenarios."}, {"color": "gray", "id": 1560, "label": 1560, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1560 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2865025\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Min Chen;Kelly Gaither;Nigel W. John;Brian Mccann; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: An Information-Theoretic Approach to the Cost-benefit Analysis of Visualization in Virtual Environments; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Visualization and virtual environments (VEs) have been two interconnected parallel strands in visual computing for decades. Some VEs have been purposely developed for visualization applications, while many visualization applications are exemplary showcases in general-purpose VEs. Because of the development and operation costs of VEs, the majority of visualization applications in practice have yet to benefit from the capacity of VEs. In this paper, we examine this status quo from an information-theoretic perspective. Our objectives are to conduct cost-benefit analysis on typical VE systems (including augmented and mixed reality, theater-based systems, and large powerwalls), to explain why some visualization applications benefit more from VEs than others, and to sketch out pathways for the future development of visualization applications in VEs. We support our theoretical propositions and analysis using theories and discoveries in the literature of cognitive sciences and the practical evidence reported in the literatures of visualization and VEs."}, {"color": "gray", "id": 1565, "label": 1565, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1565 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2865039\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Akhilesh Camisetty;Chaitanya Chandurkar;Maoyuan Sun;David Koop; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Enhancing Web-based Analytics Applications through Provenance; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Visual analytics systems continue to integrate new technologies and leverage modern environments for exploration and collaboration, making tools and techniques available to a wide audience through web browsers. Many of these systems have been developed with rich interactions, offering users the opportunity to examine details and explore hypotheses that have not been directly encoded by a designer. Understanding is enhanced when users can replay and revisit the steps in the sensemaking process, and in collaborative settings, it is especially important to be able to review not only the current state but also what decisions were made along the way. Unfortunately, many web-based systems lack the ability to capture such reasoning, and the path to a result is transient, forgotten when a user moves to a new view. This paper explores the requirements to augment existing client-side web applications with support for capturing, reviewing, sharing, and reusing steps in the reasoning process. Furthermore, it considers situations where decisions are made with streaming data, and the insights gained from revisiting those choices when more data is available. It presents a proof of concept, the Shareable Interactive Manipulation Provenance framework (SIMProv.js), that addresses these requirements in a modern, client-side JavaScript library, and describes how it can be integrated with existing frameworks."}, {"color": "gray", "id": 1567, "label": 1567, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1567 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2865041\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Yingcai Wu;Xiao Xie;Jiachen Wang;Dazhen Deng;Hongye Liang;Hui Zhang;Shoubin Cheng;Wei Chen; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: ForVizor: Visualizing Spatio-Temporal Team Formations in Soccer; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Regarded as a high-level tactic in soccer, a team formation assigns players different tasks and indicates their active regions on the pitch, thereby influencing the team performance significantly. Analysis of formations in soccer has become particularly indispensable for soccer analysts. However, formations of a team are intrinsically time-varying and contain inherent spatial information. The spatio-temporal nature of formations and other characteristics of soccer data, such as multivariate features, make analysis of formations in soccer a challenging problem. In this study, we closely worked with domain experts to characterize domain problems of formation analysis in soccer and formulated several design goals. We design a novel spatio-temporal visual representation of changes in team formation, allowing analysts to visually analyze the evolution of formations and track the spatial flow of players within formations over time. Based on the new design, we further design and develop ForVizor, a visual analytics system, which empowers users to track the spatio-temporal changes in formation and understand how and why such changes occur. With ForVizor, domain experts conduct formation analysis of two games. Analysis results with insights and useful feedback are summarized in two case studies."}, {"color": "gray", "id": 1570, "label": 1570, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1570 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2865044\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Hendrik Strobelt;Sebastian Gehrmann;Michael Behrisch;Adam Perer;Hanspeter Pfister;Alexander M. Rush; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Seq2Seq-Vis: A Visual Debugging Tool for Sequence-to-Sequence Models; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Neural sequence-to-sequence models have proven to be accurate and robust for many sequence prediction tasks, and have become the standard approach for automatic translation of text. The models work with a five-stage blackbox pipeline that begins with encoding a source sequence to a vector space and then decoding out to a new target sequence. This process is now standard, but like many deep learning methods remains quite difficult to understand or debug. In this work, we present a visual analysis tool that allows interaction and \u201cwhat if\u201d-style exploration of trained sequence-to-sequence models through each stage of the translation process. The aim is to identify which patterns have been learned, to detect model errors, and to probe the model with counterfactual scenario. We demonstrate the utility of our tool through several real-world sequence-to-sequence use cases on large-scale models."}, {"color": "gray", "id": 1581, "label": 1581, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1581 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2865138\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Daniel Haehn;James Tompkin;Hanspeter Pfister; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Evaluating \u2018Graphical Perception\u2019 with CNNs; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Convolutional neural networks can successfully perform many computer vision tasks on images. For visualization, how do CNNs perform when applied to graphical perception tasks? We investigate this question by reproducing Cleveland and McGill\u0027s seminal 1984 experiments, which measured human perception efficiency of different visual encodings and defined elementary perceptual tasks for visualization. We measure the graphical perceptual capabilities of four network architectures on five different visualization tasks and compare to existing and new human performance baselines. While under limited circumstances CNNs are able to meet or outperform human task performance, we find that CNNs are not currently a good model for human graphical perception. We present the results of these experiments to foster the understanding of how CNNs succeed and fail when applied to data visualizations."}, {"color": "gray", "id": 1582, "label": 1582, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1582 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2865139\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Wei Chen;Fangzhou Guo;Dongming Han;Jacheng Pan;Xiaotao Nie;Jiazhi Xia;Xiaolong Zhang; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Structure-Based Suggestive Exploration: A New Approach for Effective Exploration of Large Networks; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: When analyzing a visualized network, users need to explore different sections of the network to gain insight. However, effective exploration of large networks is often a challenge. While various tools are available for users to explore the global and local features of a network, these tools usually require significant interaction activities, such as repetitive navigation actions to follow network nodes and edges. In this paper, we propose a structure-based suggestive exploration approach to support effective exploration of large networks by suggesting appropriate structures upon user request. Encoding nodes with vectorized representations by transforming information of surrounding structures of nodes into a high dimensional space, our approach can identify similar structures within a large network, enable user interaction with multiple similar structures simultaneously, and guide the exploration of unexplored structures. We develop a web-based visual exploration system to incorporate this suggestive exploration approach and compare performances of our approach under different vectorizing methods and networks. We also present the usability and effectiveness of our approach through a controlled user study with two datasets."}, {"color": "gray", "id": 1583, "label": 1583, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1583 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2865141\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jaemin Jo;Fr\u00e9d\u00e9ric Vernier;Pierre Dragicevic;Jean-Daniel Fekete; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: A Declarative Rendering Model for Multiclass Density Maps; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Multiclass maps are scatterplots, multidimensional projections, or thematic geographic maps where data points have a categorical attribute in addition to two quantitative attributes. This categorical attribute is often rendered using shape or color, which does not scale when overplotting occurs. When the number of data points increases, multiclass maps must resort to data aggregation to remain readable. We present multiclass density maps: multiple 2D histograms computed for each of the category values. Multiclass density maps are meant as a building block to improve the expressiveness and scalability of multiclass map visualization. In this article, we first present a short survey of aggregated multiclass maps, mainly from cartography. We then introduce a declarative model-a simple yet expressive JSON grammar associated with visual semantics-that specifies a wide design space of visualizations for multiclass density maps. Our declarative model is expressive and can be efficiently implemented in visualization front-ends such as modern web browsers. Furthermore, it can be reconfigured dynamically to support data exploration tasks without recomputing the raw data. Finally, we demonstrate how our model can be used to reproduce examples from the past and support exploring data at scale."}, {"color": "gray", "id": 1584, "label": 1584, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1584 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2865142\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Tanja Blascheck;Lonni Besan\u00e7on;Anastasia Bezerianos;Bongshin Lee;Petra Isenberg; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Glanceable Visualization: Studies of Data Comparison Performance on Smartwatches; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present the results of two perception studies to assess how quickly people can perform a simple data comparison task for small-scale visualizations on a smartwatch. The main goal of these studies is to extend our understanding of design constraints for smartwatch visualizations. Previous work has shown that a vast majority of smartwatch interactions last under 5 s. It is still unknown what people can actually perceive from visualizations during such short glances, in particular with such a limited display space of smartwatches. To shed light on this question, we conducted two perception studies that assessed the lower bounds of task time for a simple data comparison task. We tested three chart types common on smartwatches: bar charts, donut charts, and radial bar charts with three different data sizes: 7, 12, and 24 data values. In our first study, we controlled the differences of the two target bars to be compared, while the second study varied the difference randomly. For both studies, we found that participants performed the task on average in \u0026lt;;300 ms for the bar chart, \u0026lt;;220 ms for the donut chart, and in \u0026lt;; 1780 ms for the radial bar chart. Thresholds in the second study per chart type were on average 1.14-1.35\u00d7 higher than in the first study. Our results show that bar and donut charts should be preferred on smartwatch displays when quick data comparisons are necessary."}, {"color": "gray", "id": 1590, "label": 1590, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1590 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2865151\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Timothy Major;Rahul C. Basole; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Graphicle: Exploring Units, Networks, and Context in a Blended Visualization Approach; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Many real-world datasets are large, multivariate, and relational in nature and relevant associated decisions frequently require a simultaneous consideration of both attributes and connections. Existing visualization systems and approaches, however, often make an explicit trade-off between either affording rich exploration of individual data units and their attributes or exploration of the underlying network structure. In doing so, important analysis opportunities and insights are potentially missed. In this study, we aim to address this gap by (1) considering visualizations and interaction techniques that blend the spectrum between unit and network visualizations, (2) discussing the nature of different forms of contexts and the challenges in implementing them, and (3) demonstrating the value of our approach for visual exploration of multivariate, relational data for a real-world use case. Specifically, we demonstrate through a system called Graphicle how network structure can be layered on top of unit visualization techniques to create new opportunities for visual exploration of physician characteristics and referral data. We report on the design, implementation, and evaluation of the system and effectiveness of our blended approach."}, {"color": "gray", "id": 1595, "label": 1595, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1595 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2865192\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Yalong Yang;Tim Dwyer;Bernhard Jenny;Kim Marriott;Maxime Cordeil;Haohui Chen; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Origin-Destination Flow Maps in Immersive Environments; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Immersive virtual- and augmented-reality headsets can overlay a flat image against any surface or hang virtual objects in the space around the user. The technology is rapidly improving and may, in the long term, replace traditional flat panel displays in many situations. When displays are no longer intrinsically flat, how should we use the space around the user for abstract data visualisation? In this paper, we ask this question with respect to origin-destination flow data in a global geographic context. We report on the findings of three studies exploring different spatial encodings for flow maps. The first experiment focuses on different 2D and 3D encodings for flows on flat maps. We find that participants are significantly more accurate with raised flow paths whose height is proportional to flow distance but fastest with traditional straight line 2D flows. In our second and third experiment we compared flat maps, 3D globes and a novel interactive design we call\u003ci\u003eMapsLink\u003c/i\u003e, involving a pair of linked flat maps. We find that participants took significantly more time with MapsLink than other flow maps while the 3D globe with raised flows was the fastest, most accurate, and most preferred method. Our work suggests that\u003ci\u003ecareful\u003c/i\u003euse of the third spatial dimension can resolve visual clutter in complex flow maps."}, {"color": "gray", "id": 1598, "label": 1598, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1598 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2865230\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Shusen Liu;Zhimin Li;Tao Li;Vivek Srikumar;Valerio Pascucci;Peer-Timo Bremer; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: NLIZE: A Perturbation-Driven Visual Interrogation Tool for Analyzing and Interpreting Natural Language Inference Models; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: With the recent advances in deep learning, neural network models have obtained state-of-the-art performances for many linguistic tasks in natural language processing. However, this rapid progress also brings enormous challenges. The opaque nature of a neural network model leads to hard-to-debug-systems and difficult-to-interpret mechanisms. Here, we introduce a visualization system that, through a tight yet flexible integration between visualization elements and the underlying model, allows a user to interrogate the model by perturbing the input, internal state, and prediction while observing changes in other parts of the pipeline. We use the natural language inference problem as an example to illustrate how a perturbation-driven paradigm can help domain experts assess the potential limitation of a model, probe its inner states, and interpret and form hypotheses about fundamental model mechanisms such as attention."}, {"color": "gray", "id": 1608, "label": 1608, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1608 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2865265\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Wiebke K\u00f6pp;Tino Weinkauf; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Temporal Treemaps: Static Visualization of Evolving Trees; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We consider temporally evolving trees with changing topology and data: tree nodes may persist for a time range, merge or split, and the associated data may change. Essentially, one can think of this as a time series of trees with a node correspondence per hierarchy level between consecutive time steps. Existing visualization approaches for such data include animated 2D treemaps, where the dynamically changing layout makes it difficult to observe the data in its entirety. We present a method to visualize this dynamic data in a static, nested, and space-filling visualization. This is based on two major contributions: First, the layout constitutes a graph drawing problem. We approach it for the entire time span at once using a combination of a heuristic and simulated annealing. Second, we propose a rendering that emphasizes the hierarchy through an adaption of the classic cushion treemaps. We showcase the wide range of applicability using data from feature tracking in time-dependent scalar fields, evolution of file system hierarchies, and world population."}, {"color": "gray", "id": 1609, "label": 1609, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1609 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2865266\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Yunhai Wang;Zeyu Wang;Chi-Wing Fu;Hansj\u00f6rq Schmauder;Oliver Deussen;Daniel Weiskopf; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Image-Based Aspect Ratio Selection; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Selecting a good aspect ratio is crucial for effective 2D diagrams. There are several aspect ratio selection methods for function plots and line charts, but only few can handle general, discrete diagrams such as 2D scatter plots. However, these methods either lack a perceptual foundation or heavily rely on intermediate isoline representations, which depend on choosing the right isovalues and are time-consuming to compute. This paper introduces a general image-based approach for selecting aspect ratios for a wide variety of 2D diagrams, ranging from scatter plots and density function plots to line charts. Our approach is derived from Federer\u0027s co-area formula and a line integral representation that enable us to directly construct image-based versions of existing selection methods using density fields. In contrast to previous methods, our approach bypasses isoline computation, so it is faster to compute, while following the perceptual foundation to select aspect ratios. Furthermore, this approach is complemented by an anisotropic kernel density estimation to construct density fields, allowing us to more faithfully characterize data patterns, such as the subgroups in scatterplots or dense regions in time series. We demonstrate the effectiveness of our approach by quantitatively comparing to previous methods and revisiting a prior user study. Finally, we present extensions for ROI banking, multi-scale banking, and the application to image data."}, {"color": "gray", "id": 1611, "label": 1611, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1611 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2018.8802415\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Po-Ming Law;Yanhong Wu;Rahul C. Basole; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Segue: Overviewing Evolution Patterns of Egocentric Networks by Interactive Construction of Spatial Layouts; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Getting the overall picture of how a large number of ego-networks evolve is a common yet challenging task. Existing techniques often require analysts to inspect the evolution patterns of ego-networks one after another. In this study, we explore an approach that allows analysts to interactively create spatial layouts in which each dot is a dynamic ego-network. These spatial layouts provide overviews of the evolution patterns of ego-networks, thereby revealing different global patterns such as trends, clusters and outliers in evolution patterns. To let analysts interactively construct interpretable spatial layouts, we propose a data transformation pipeline, with which analysts can adjust the spatial layouts and convert dynamic ego-networks into event sequences to aid interpretations of the spatial positions. Based on this transformation pipeline, we develop Segue, a visual analysis system that supports thorough exploration of the evolution patterns of ego-networks. Through two usage scenarios, we demonstrate how analysts can gain insights into the overall evolution patterns of a large collection of ego-networks by interactively creating different spatial layouts."}, {"color": "gray", "id": 1617, "label": 1617, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1617 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2019.2934208\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Yating Wei;Honghui Mei;Ying Zhao;Shuyue Zhou;Bingru Lin;Haojing Jiang;Wei Chen; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Evaluating Perceptual Bias During Geometric Scaling of Scatterplots; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Scatterplots are frequently scaled to fit display areas in multi-view and multi-device data analysis environments. A common method used for scaling is to enlarge or shrink the entire scatterplot together with the inside points synchronously and proportionally. This process is called geometric scaling. However, geometric scaling of scatterplots may cause a perceptual bias, that is, the perceived and physical values of visual features may be dissociated with respect to geometric scaling. For example, if a scatterplot is projected from a laptop to a large projector screen, then observers may feel that the scatterplot shown on the projector has fewer points than that viewed on the laptop. This paper presents an evaluation study on the perceptual bias of visual features in scatterplots caused by geometric scaling. The study focuses on three fundamental visual features (i.e., numerosity, correlation, and cluster separation) and three hypotheses that are formulated on the basis of our experience. We carefully design three controlled experiments by using well-prepared synthetic data and recruit participants to complete the experiments on the basis of their subjective experience. With a detailed analysis of the experimental results, we obtain a set of instructive findings. First, geometric scaling causes a bias that has a linear relationship with the scale ratio. Second, no significant difference exists between the biases measured from normally and uniformly distributed scatterplots. Third, changing the point radius can correct the bias to a certain extent. These findings can be used to inspire the design decisions of scatterplots in various scenarios."}, {"color": "gray", "id": 1619, "label": 1619, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1619 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2019.2934242\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Lin Yan;Yusu Wang;Elizabeth Munch;Ellen Gasparovic;Bei Wang; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: A Structural Average of Labeled Merge Trees for Uncertainty Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Physical phenomena in science and engineering are frequently modeled using scalar fields. In scalar field topology, graph-based topological descriptors such as merge trees, contour trees, and Reeb graphs are commonly used to characterize topological changes in the (sub)level sets of scalar fields. One of the biggest challenges and opportunities to advance topology-based visualization is to understand and incorporate uncertainty into such topological descriptors to effectively reason about their underlying data. In this paper, we study a structural average of a set of labeled merge trees and use it to encode uncertainty in data. Specifically, we compute a 1-center tree that minimizes its maximum distance to any other tree in the set under a well-defined metric called the interleaving distance. We provide heuristic strategies that compute structural averages of merge trees whose labels do not fully agree. We further provide an interactive visualization system that resembles a numerical calculator that takes as input a set of merge trees and outputs a tree as their structural average. We also highlight structural similarities between the input and the average and incorporate uncertainty information for visual exploration. We develop a novel measure of uncertainty, referred to as consistency, via a metric-space view of the input trees. Finally, we demonstrate an application of our framework through merge trees that arise from ensembles of scalar fields. Our work is the first to employ interleaving distances and consistency to study a global, mathematically rigorous, structural average of merge trees in the context of uncertainty visualization."}, {"color": "gray", "id": 1620, "label": 1620, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1620 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2019.2934243\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Tom Polk;Dominik J\u00e4ckle;Johannes H\u00e4u\u00dfler;Jing Yang; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: CourtTime: Generating Actionable Insights into Tennis Matches Using Visual Analytics; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Tennis players and coaches of all proficiency levels seek to understand and improve their play. Summary statistics alone are inadequate to provide the insights players need to improve their games. Spatio-temporal data capturing player and ball movements is likely to provide the actionable insights needed to identify player strengths, weaknesses, and strategies. To fully utilize this spatio-temporal data, we need to integrate it with domain-relevant context meta-data. In this paper, we propose CourtTime, a novel approach to perform data-driven visual analysis of individual tennis matches. Our visual approach introduces a novel visual metaphor, namely 1\u2013D Space-Time Charts that enable the analysis of single points at a glance based on small multiples. We also employ user-driven sorting and clustering techniques and a layout technique that aligns the last few shots in a point to facilitate shot pattern discovery. We discuss the usefulness of CourtTime via an extensive case study and report on feedback from an amateur tennis player and three tennis coaches."}, {"color": "gray", "id": 1622, "label": 1622, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1622 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2019.2934255\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jun Han;Chaoli Wang; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: TSR-TVD: Temporal Super-Resolution for Time-Varying Data Analysis and Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present TSR-TVD, a novel deep learning framework that generates temporal super-resolution (TSR) of time-varying data (TVD) using adversarial learning. TSR-TVD is the first work that applies the recurrent generative network (RGN), a combination of the recurrent neural network (RNN) and generative adversarial network (GAN), to generate temporal high-resolution volume sequences from low-resolution ones. The design of TSR-TVD includes a generator and a discriminator. The generator takes a pair of volumes as input and outputs the synthesized intermediate volume sequence through forward and backward predictions. The discriminator takes the synthesized intermediate volumes as input and produces a score indicating the realness of the volumes. Our method handles multivariate data as well where the trained network from one variable is applied to generate TSR for another variable. To demonstrate the effectiveness of TSR-TVD, we show quantitative and qualitative results with several time-varying multivariate data sets and compare our method against standard linear interpolation and solutions solely based on RNN or CNN."}, {"color": "gray", "id": 1623, "label": 1623, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1623 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2019.2934256\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jules Vidal;Joseph Budin;Julien Tierny; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Progressive Wasserstein Barycenters of Persistence Diagrams; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: This paper presents an efficient algorithm for the progressive approximation of Wasserstein barycenters of persistence diagrams, with applications to the visual analysis of ensemble data. Given a set of scalar fields, our approach enables the computation of a persistence diagram which is representative of the set, and which visually conveys the number, data ranges and saliences of the main features of interest found in the set. Such representative diagrams are obtained by computing explicitly the discrete Wasserstein barycenter of the set of persistence diagrams, a notoriously computationally intensive task. In particular, we revisit efficient algorithms for Wasserstein distance approximation [12], [51] to extend previous work on barycenter estimation [94]. We present a new fast algorithm, which progressively approximates the barycenter by iteratively increasing the computation accuracy as well as the number of persistent features in the output diagram. Such a progressivity drastically improves convergence in practice and allows to design an interruptible algorithm, capable of respecting computation time constraints. This enables the approximation of Wasserstein barycenters within interactive times. We present an application to ensemble clustering where we revisit the $k$-means algorithm to exploit our barycenters and compute, within execution time constraints, meaningful clusters of ensemble data along with their barycenter diagram. Extensive experiments on synthetic and real-life data sets report that our algorithm converges to barycenters that are qualitatively meaningful with regard to the applications, and quantitatively comparable to previous techniques, while offering an order of magnitude speedup when run until convergence (without time constraint). Our algorithm can be trivially parallelized to provide additional speedups in practice on standard workstations. We provide a lightweight C++ implementation of our approach that can be used to reproduce our results."}, {"color": "gray", "id": 1625, "label": 1625, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1625 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2019.2934258\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Juraj P\u00e1lenik;Jan By\u0161ka;Stefan Bruckner;Helwig Hauser; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Scale-Space Splatting: Reforming Spacetime for Cross-Scale Exploration of Integral Measures in Molecular Dynamics; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Understanding large amounts of spatiotemporal data from particle-based simulations, such as molecular dynamics, often relies on the computation and analysis of aggregate measures. These, however, by virtue of aggregation, hide structural information about the space/time localization of the studied phenomena. This leads to degenerate cases where the measures fail to capture distinct behaviour. In order to drill into these aggregate values, we propose a multi-scale visual exploration technique. Our novel representation, based on partial domain aggregation, enables the construction of a continuous scale-space for discrete datasets and the simultaneous exploration of scales in both space and time. We link these two scale-spaces in a scale-space space-time cube and model linked views as orthogonal slices through this cube, thus enabling the rapid identification of spatio-temporal patterns at multiple scales. To demonstrate the effectiveness of our approach, we showcase an advanced exploration of a protein-ligand simulation."}, {"color": "gray", "id": 1629, "label": 1629, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1629 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2019.2934262\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Yongsu Ahn;Yu-Ru Lin; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: FairSight: Visual Analytics for Fairness in Decision Making; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Data-driven decision making related to individuals has become increasingly pervasive, but the issue concerning the potential discrimination has been raised by recent studies. In response, researchers have made efforts to propose and implement fairness measures and algorithms, but those efforts have not been translated to the real-world practice of data-driven decision making. As such, there is still an urgent need to create a viable tool to facilitate fair decision making. We propose FairSight, a visual analytic system to address this need; it is designed to achieve different notions of fairness in ranking decisions through identifying the required actions \u2013 understanding, measuring, diagnosing and mitigating biases \u2013 that together lead to fairer decision making. Through a case study and user study, we demonstrate that the proposed visual analytic and diagnostic modules in the system are effective in understanding the fairness-aware decision pipeline and obtaining more fair outcomes."}, {"color": "gray", "id": 1630, "label": 1630, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1630 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2019.2934263\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Shuai Chen;Sihang Li;Siming Chen;Xiaoru Yuan; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: R-Map: A Map Metaphor for Visualizing Information Reposting Process in Social Media; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We propose R-Map (Reposting Map), a visual analytical approach with a map metaphor to support interactive exploration and analysis of the information reposting process in social media. A single original social media post can cause large cascades of repostings (i.e., retweets) on online networks, involving thousands, even millions of people with different opinions. Such reposting behaviors form the reposting tree, in which a node represents a message and a link represents the reposting relation. In R-Map, the reposting tree structure can be spatialized with highlighted key players and tiled nodes. The important reposting behaviors, the following relations and the semantics relations are represented as rivers, routes and bridges, respectively, in a virtual geographical space. R-Map supports a scalable overview of a large number of information repostings with semantics. Additional interactions on the map are provided to support the investigation of temporal patterns and user behaviors in the information diffusion process. We evaluate the usability and effectiveness of our system with two use cases and a formal user study."}, {"color": "gray", "id": 1631, "label": 1631, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1631 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2019.2934264\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Mosab Khayat;Morteza Karimzadeh;David S. Ebert;Arif Ghafoor; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: The Validity, Generalizability and Feasibility of Summative Evaluation Methods in Visual Analytics; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Many evaluation methods have been used to assess the usefulness of Visual Analytics (VA) solutions. These methods stem from a variety of origins with different assumptions and goals, which cause confusion about their proofing capabilities. Moreover, the lack of discussion about the evaluation processes may limit our potential to develop new evaluation methods specialized for VA. In this paper, we present an analysis of evaluation methods that have been used to summatively evaluate VA solutions. We provide a survey and taxonomy of the evaluation methods that have appeared in the VAST literature in the past two years. We then analyze these methods in terms of validity and generalizability of their findings, as well as the feasibility of using them. We propose a new metric called summative quality to compare evaluation methods according to their ability to prove usefulness, and make recommendations for selecting evaluation methods based on their summative quality in the VA domain."}, {"color": "gray", "id": 1632, "label": 1632, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1632 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2019.2934266\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Mosab Khayat;Morteza Karimzadeh;Jieqiong Zhao;David S. Ebert; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: VASSL: A Visual Analytics Toolkit for Social Spambot Labeling; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Social media platforms are filled with social spambots. Detecting these malicious accounts is essential, yet challenging, as they continually evolve to evade detection techniques. In this article, we present VASSL, a visual analytics system that assists in the process of detecting and labeling spambots. Our tool enhances the performance and scalability of manual labeling by providing multiple connected views and utilizing dimensionality reduction, sentiment analysis and topic modeling, enabling insights for the identification of spambots. The system allows users to select and analyze groups of accounts in an interactive manner, which enables the detection of spambots that may not be identified when examined individually. We present a user study to objectively evaluate the performance of VASSL users, as well as capturing subjective opinions about the usefulness and the ease of use of the tool."}, {"color": "gray", "id": 1636, "label": 1636, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1636 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2019.2934281\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Arvind Satyanarayan;Bongshin Lee;Donghao Ren;Jeffrey Heer;John Stasko;John Thompson;Matthew Brehmer;Zhicheng Liu; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Critical Reflections on Visualization Authoring Systems; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: An emerging generation of visualization authoring systems support expressive information visualization without textual programming. As they vary in their visualization models, system architectures, and user interfaces, it is challenging to directly compare these systems using traditional evaluative methods. Recognizing the value of contextualizing our decisions in the broader design space, we present critical reflections on three systems we developed \u2014Lyra, Data Illustrator, and Charticulator. This paper surfaces knowledge that would have been daunting within the constituent papers of these three systems. We compare and contrast their (previously unmentioned) limitations and trade-offs between expressivity and learnability. We also reflect on common assumptions that we made during the development of our systems, thereby informing future research directions in visualization authoring systems."}, {"color": "gray", "id": 1646, "label": 1646, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1646 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2019.2934307\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Nicola Pezzotti;Julian Thijssen;Alexander Mordvintsev;Thomas H\u00f6llt;Baldur Van Lew;Boudewijn P.F. Lelieveldt;Elmar Eisemann;Anna Vilanova; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: GPGPU Linear Complexity t-SNE Optimization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In recent years the t-distributed Stochastic Neighbor Embedding (t-SNE) algorithm has become one of the most used and insightful techniques for exploratory data analysis of high-dimensional data. It reveals clusters of high-dimensional data points at different scales while only requiring minimal tuning of its parameters. However, the computational complexity of the algorithm limits its application to relatively small datasets. To address this problem, several evolutions of t-SNE have been developed in recent years, mainly focusing on the scalability of the similarity computations between data points. However, these contributions are insufficient to achieve interactive rates when visualizing the evolution of the t-SNE embedding for large datasets. In this work, we present a novel approach to the minimization of the t-SNE objective function that heavily relies on graphics hardware and has linear computational complexity. Our technique decreases the computational cost of running t-SNE on datasets by orders of magnitude and retains or improves on the accuracy of past approximated techniques. We propose to approximate the repulsive forces between data points by splatting kernel textures for each data point. This approximation allows us to reformulate the t-SNE minimization problem as a series of tensor operations that can be efficiently executed on the graphics card. An efficient implementation of our technique is integrated and available for use in the widely used Google TensorFlow.js, and an open-source C++ library."}, {"color": "gray", "id": 1649, "label": 1649, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1649 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2019.2934313\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Irene Baeza Rojo;Markus Gross;Tobias G\u00fcnther; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Accelerated Monte Carlo Rendering of Finite-Time Lyapunov Exponents; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Time-dependent fluid flows often contain numerous hyperbolic Lagrangian coherent structures, which act as transport barriers that guide the advection. The finite-time Lyapunov exponent is a commonly-used approximation to locate these repelling or attracting structures. Especially on large numerical simulations, the FTLE ridges can become arbitrarily sharp and very complex. Thus, the discrete sampling onto a grid for a subsequent direct volume rendering is likely to miss sharp ridges in the visualization. For this reason, an unbiased Monte Carlo-based rendering approach was recently proposed that treats the FTLE field as participating medium with single scattering. This method constructs a ground truth rendering without discretization, but it is prohibitively slow with render times in the order of days or weeks for a single image. In this paper, we accelerate the rendering process significantly, which allows us to compute video sequence of high-resolution FTLE animations in a much more reasonable time frame. For this, we follow two orthogonal approaches to improve on the rendering process: the volumetric light path integration in gradient domain and an acceleration of the transmittance estimation. We analyze the convergence and performance of the proposed method and demonstrate the approach by rendering complex FTLE fields in several 3D vector fields."}, {"color": "gray", "id": 1652, "label": 1652, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1652 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2019.2934333\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Katar\u00edna Furmanov\u00e1;Adam Jur\u010d\u00edk;Barbora Kozl\u00edkov\u00e1;Helwig Hauser;Jan By\u0161ka; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Multiscale Visual Drilldown for the Analysis of Large Ensembles of Multi-Body Protein Complexes; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: When studying multi-body protein complexes, biochemists use computational tools that can suggest hundreds or thousands of their possible spatial configurations. However, it is not feasible to experimentally verify more than only a very small subset of them. In this paper, we propose a novel multiscale visual drilldown approach that was designed in tight collaboration with proteomic experts, enabling a systematic exploration of the configuration space. Our approach takes advantage of the hierarchical structure of the data \u2013 from the whole ensemble of protein complex configurations to the individual configurations, their contact interfaces, and the interacting amino acids. Our new solution is based on interactively linked 2D and 3D views for individual hierarchy levels. At each level, we offer a set of selection and filtering operations that enable the user to narrow down the number of configurations that need to be manually scrutinized. Furthermore, we offer a dedicated filter interface, which provides the users with an overview of the applied filtering operations and enables them to examine their impact on the explored ensemble. This way, we maintain the history of the exploration process and thus enable the user to return to an earlier point of the exploration. We demonstrate the effectiveness of our approach on two case studies conducted by collaborating proteomic experts."}, {"color": "gray", "id": 1654, "label": 1654, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1654 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2019.2934335\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Tobias Rapp;Christoph Peters;Carsten Dachsbacher; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Void-and-Cluster Sampling of Large Scattered Data and Trajectories; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We propose a data reduction technique for scattered data based on statistical sampling. Our void-and-cluster sampling technique finds a representative subset that is optimally distributed in the spatial domain with respect to the blue noise property. In addition, it can adapt to a given density function, which we use to sample regions of high complexity in the multivariate value domain more densely. Moreover, our sampling technique implicitly defines an ordering on the samples that enables progressive data loading and a continuous level-of-detail representation. We extend our technique to sample time-dependent trajectories, for example pathlines in a time interval, using an efficient and iterative approach. Furthermore, we introduce a local and continuous error measure to quantify how well a set of samples represents the original dataset. We apply this error measure during sampling to guide the number of samples that are taken. Finally, we use this error measure and other quantities to evaluate the quality, performance, and scalability of our algorithm."}, {"color": "gray", "id": 1657, "label": 1657, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1657 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2019.2934367\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Baldwin Nsonga;Gerik Scheuermann;Stefan Gumhold;Jordi Ventosa-Molina;Denis Koschichow;Jochen Fr\u00f6hlich; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Analysis of the Near-Wall Flow in a Turbine Cascade by Splat Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Turbines are essential components of jet planes and power plants. Therefore, their efficiency and service life are of central engineering interest. In the case of jet planes or thermal power plants, the heating of the turbines due to the hot gas flow is critical. Besides effective cooling, it is a major goal of engineers to minimize heat transfer between gas flow and turbine by design. Since it is known that splat events have a substantial impact on the heat transfer between flow and immersed surfaces, we adapt a splat detection and visualization method to a turbine cascade simulation in this case study. Because splat events are small phenomena, we use a direct numerical simulation resolving the turbulence in the flow as the base of our analysis. The outcome shows promising insights into splat formation and its relation to vortex structures. This may lead to better turbine design in the future."}, {"color": "gray", "id": 1658, "label": 1658, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1658 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2019.2934368\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jonas Lukasczyk;Christoph Garth;Gunther H. Weber;Tim Biedert;Ross Maciejewski;Heike Leitte; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Dynamic Nested Tracking Graphs; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: This work describes an approach for the interactive visual analysis of large-scale simulations, where numerous superlevel set components and their evolution are of primary interest. The approach first derives, at simulation runtime, a specialized Cinema database that consists of images of component groups, and topological abstractions. This database is processed by a novel graph operation-based nested tracking graph algorithm (GO-NTG) that dynamically computes NTGs for component groups based on size, overlap, persistence, and level thresholds. The resulting NTGs are in turn used in a feature-centered visual analytics framework to query specific database elements and update feature parameters, facilitating flexible post hoc analysis."}, {"color": "gray", "id": 1666, "label": 1666, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1666 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2019.2934399\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Cindy Xiong;Joel Shapiro;Jessica Hullman;Steven Franconeri; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Illusion of Causality in Visualized Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Students who eat breakfast more frequently tend to have a higher grade point average. From this data, many people might confidently state that a before-school breakfast program would lead to higher grades. This is a reasoning error, because correlation does not necessarily indicate causation \u2013 X and Y can be correlated without one directly causing the other. While this error is pervasive, its prevalence might be amplified or mitigated by the way that the data is presented to a viewer. Across three crowdsourced experiments, we examined whether how simple data relations are presented would mitigate this reasoning error. The first experiment tested examples similar to the breakfast-GPA relation, varying in the plausibility of the causal link. We asked participants to rate their level of agreement that the relation was correlated, which they rated appropriately as high. However, participants also expressed high agreement with a causal interpretation of the data. Levels of support for the causal interpretation were not equally strong across visualization types: causality ratings were highest for text descriptions and bar graphs, but weaker for scatter plots. But is this effect driven by bar graphs aggregating data into two groups or by the visual encoding type? We isolated data aggregation versus visual encoding type and examined their individual effect on perceived causality. Overall, different visualization designs afford different cognitive reasoning affordances across the same data. High levels of data aggregation by graphs tend to be associated with higher perceived causality in data. Participants perceived line and dot visual encodings as more causal than bar encodings. Our results demonstrate how some visualization designs trigger stronger causal links while choosing others can help mitigate unwarranted perceptions of causality."}, {"color": "gray", "id": 1667, "label": 1667, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1667 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2019.2934400\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Cindy Xiong;Cristina R. Ceja;Casimir J.H. Ludwig;Steven Franconeri; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Biased Average Position Estimates in Line and Bar Graphs: Underestimation, Overestimation, and Perceptual Pull; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In visual depictions of data, position (i.e., the vertical height of a line or a bar) is believed to be the most precise way to encode information compared to other encodings (e.g., hue). Not only are other encodings less precise than position, but they can also be prone to systematic biases (e.g., color category boundaries can distort perceived differences between hues). By comparison, position\u0027s high level of precision may seem to protect it from such biases. In contrast, across three empirical studies, we show that while position may be a precise form of data encoding, it can also produce systematic biases in how values are visually encoded, at least for reports of average position across a short delay. In displays with a single line or a single set of bars, reports of average positions were significantly biased, such that line positions were underestimated and bar positions were overestimated. In displays with multiple data series (i.e., multiple lines and/or sets of bars), this systematic bias still persisted. We also observed an effect of \u201cperceptual pull\u201d, where the average position estimate for each series was \u2018pulled\u2019 toward the other. These findings suggest that, although position may still be the most precise form of visual data encoding, it can also be systematically biased."}, {"color": "gray", "id": 1673, "label": 1673, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1673 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2019.2934433\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Takanori Fujiwara;Jia-Kai Chou;Shilpika Shilpika;Panpan Xu;Liu Ren;Kwan-Liu Ma; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: An Incremental Dimensionality Reduction Method for Visualizing Streaming Multidimensional Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Dimensionality reduction (DR) methods are commonly used for analyzing and visualizing multidimensional data. However, when data is a live streaming feed, conventional DR methods cannot be directly used because of their computational complexity and inability to preserve the projected data positions at previous time points. In addition, the problem becomes even more challenging when the dynamic data records have a varying number of dimensions as often found in real-world applications. This paper presents an incremental DR solution. We enhance an existing incremental PCA method in several ways to ensure its usability for visualizing streaming multidimensional data. First, we use geometric transformation and animation methods to help preserve a viewer\u0027s mental map when visualizing the incremental results. Second, to handle data dimension variants, we use an optimization method to estimate the projected data positions, and also convey the resulting uncertainty in the visualization. We demonstrate the effectiveness of our design with two case studies using real-world datasets."}, {"color": "gray", "id": 1676, "label": 1676, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1676 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2019.2934535\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Guozheng Li;Yu Zhang;Yu Dong;Jie Liang;Jinson Zhang;Jinsong Wang;Michael J. Mcguffin;Xiaoru Yuan; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: BarcodeTree: Scalable Comparison of Multiple Hierarchies; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We propose BarcodeTree (BCT), a novel visualization technique for comparing topological structures and node attribute values of multiple trees. BCT can provide an overview of one hundred shallow and stable trees simultaneously, without aggregating individual nodes. Each BCT is shown within a single row using a style similar to a barcode, allowing trees to be stacked vertically with matching nodes aligned horizontally to ease comparison and maintain space efficiency. We design several visual cues and interactive techniques to help users understand the topological structure and compare trees. In an experiment comparing two variants of BCT with icicle plots, the results suggest that BCTs make it easier to visually compare trees by reducing the vertical distance between different trees. We also present two case studies involving a dataset of hundreds of trees to demonstrate BCT\u0027s utility."}, {"color": "gray", "id": 1677, "label": 1677, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1677 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2019.2934536\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Ragini Rathore;Zachary Leggon;Laurent Lessard;Karen B. Schloss; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Estimating Color-Concept Associations from Image Statistics; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: To interpret the meanings of colors in visualizations of categorical information, people must determine how distinct colors correspond to different concepts. This process is easier when assignments between colors and concepts in visualizations match people\u0027s expectations, making color palettes semantically interpretable. Efforts have been underway to optimize color palette design for semantic interpretablity, but this requires having good estimates of human color-concept associations. Obtaining these data from humans is costly, which motivates the need for automated methods. We developed and evaluated a new method for automatically estimating color-concept associations in a way that strongly correlates with human ratings. Building on prior studies using Google Images, our approach operates directly on Google Image search results without the need for humans in the loop. Specifically, we evaluated several methods for extracting raw pixel content of the images in order to best estimate color-concept associations obtained from human ratings. The most effective method extracted colors using a combination of cylindrical sectors and color categories in color space. We demonstrate that our approach can accurately estimate average human color-concept associations for different fruits using only a small set of images. The approach also generalizes moderately well to more complicated recycling-related concepts of objects that can appear in any color."}, {"color": "gray", "id": 1678, "label": 1678, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1678 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2019.2934537\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jianping Kelvin Li;Kwan-Liu Ma; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: P5: Portable Progressive Parallel Processing Pipelines for Interactive Data Analysis and Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present P5, a web-based visualization toolkit that combines declarative visualization grammar and GPU computing for progressive data analysis and visualization. To interactively analyze and explore big data, progressive analytics and visualization methods have recently emerged. Progressive visualizations of incrementally refining results have the advantages of allowing users to steer the analysis process and make early decisions. P5 leverages declarative grammar for specifying visualization designs and exploits GPU computing to accelerate progressive data processing and rendering. The declarative specifications can be modified during progressive processing to create different visualizations for analyzing the intermediate results. To enable user interactions for progressive data analysis, P5 utilizes the GPU to automatically aggregate and index data based on declarative interaction specifications to facilitate effective interactive visualization. We demonstrate the effectiveness and usefulness of P5 through a variety of example applications and several performance benchmark tests."}, {"color": "gray", "id": 1682, "label": 1682, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1682 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2019.2934541\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Xin Chen;Tong Ge;Jian Zhang;Baoquan Chen;Chi-Wing Fu;Oliver Deussen;Yunhai Wang; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: A Recursive Subdivision Technique for Sampling Multi-class Scatterplots; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present a non-uniform recursive sampling technique for multi-class scatterplots, with the specific goal of faithfully presenting relative data and class densities, while preserving major outliers in the plots. Our technique is based on a customized binary kd-tree, in which leaf nodes are created by recursively subdividing the underlying multi-class density map. By backtracking, we merge leaf nodes until they encompass points of all classes for our subsequently applied outlier-aware multi-class sampling strategy. A quantitative evaluation shows that our approach can better preserve outliers and at the same time relative densities in multi-class scatterplots compared to the previous approaches, several case studies demonstrate the effectiveness of our approach in exploring complex and real world data."}, {"color": "gray", "id": 1687, "label": 1687, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1687 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2019.2934557\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Ying Yang;Michael Wybrow;Yuan-Fang Li;Tobias Czauderna;Yongqun He; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: OntoPlot: A Novel Visualisation for Non-hierarchical Associations in Large Ontologies; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Ontologies are formal representations of concepts and complex relationships among them. They have been widely used to capture comprehensive domain knowledge in areas such as biology and medicine, where large and complex ontologies can contain hundreds of thousands of concepts. Especially due to the large size of ontologies, visualisation is useful for authoring, exploring and understanding their underlying data. Existing ontology visualisation tools generally focus on the hierarchical structure, giving much less emphasis to non-hierarchical associations. In this paper we present OntoPlot, a novel visualisation specifically designed to facilitate the exploration of all concept associations whilst still showing an ontology\u0027s large hierarchical structure. This hybrid visualisation combines icicle plots, visual compression techniques and interactivity, improving space-efficiency and reducing visual structural complexity. We conducted a user study with domain experts to evaluate the usability of OntoPlot, comparing it with the de facto ontology editor Prot\u00e9g\u00e9. The results confirm that OntoPlot attains our design goals for association-related tasks and is strongly favoured by domain experts."}, {"color": "gray", "id": 1689, "label": 1689, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1689 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2019.2934593\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jiali Liu;Nadia Boukhelifa;James R. Eagan; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Understanding the Role of Alternatives in Data Analysis Practices; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Data workers are people who perform data analysis activities as a part of their daily work but do not formally identify as data scientists. They come from various domains and often need to explore diverse sets of hypotheses and theories, a variety of data sources, algorithms, methods, tools, and visual designs. Taken together, we call these alternatives. To better understand and characterize the role of alternatives in their analyses, we conducted semi-structured interviews with 12 data workers with different types of expertise. We conducted four types of analyses to understand 1) why data workers explore alternatives; 2) the different notions of alternatives and how they fit into the sensemaking process; 3) the high-level processes around alternatives; and 4) their strategies to generate, explore, and manage those alternatives. We find that participants\u0027 diverse levels of domain and computational expertise, experience with different tools, and collaboration within their broader context play an important role in how they explore these alternatives. These findings call out the need for more attention towards a deeper understanding of alternatives and the need for better tools to facilitate the exploration, interpretation, and management of alternatives. Drawing upon these analyses and findings, we present a framework based on participants\u0027 1) degree of attention, 2) abstraction level, and 3) analytic processes. We show how this framework can help understand how data workers consider such alternatives in their analyses and how tool designers might create tools to better support them."}, {"color": "gray", "id": 1690, "label": 1690, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1690 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2019.2934594\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Shusen Liu;Luc Peterson;Peter B. Robinson;Harsh Bhatia;Valerio Pascucci;Brian K. Spears;Peer-Timo Bremer;Di Wang;Dan Maljovec;Rushil Anirudh;Jayaraman J. Thiagarajan;Sam Ade Jacobs;Brian C. Van Essen;David Hysom;Jae-Seung Yeom;Jim Gaffney; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Scalable Topological Data Analysis and Visualization for Evaluating Data-Driven Models in Scientific Applications; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: With the rapid adoption of machine learning techniques for large-scale applications in science and engineering comes the convergence of two grand challenges in visualization. First, the utilization of black box models (e.g., deep neural networks) calls for advanced techniques in exploring and interpreting model behaviors. Second, the rapid growth in computing has produced enormous datasets that require techniques that can handle millions or more samples. Although some solutions to these interpretability challenges have been proposed, they typically do not scale beyond thousands of samples, nor do they provide the high-level intuition scientists are looking for. Here, we present the first scalable solution to explore and analyze high-dimensional functions often encountered in the scientific data analysis pipeline. By combining a new streaming neighborhood graph construction, the corresponding topology computation, and a novel data aggregation scheme, namely topology aware datacubes, we enable interactive exploration of both the topological and the geometric aspect of high-dimensional data. Following two use cases from high-energy-density (HED) physics and computational biology, we demonstrate how these capabilities have led to crucial new insights in both applications."}, {"color": "gray", "id": 1691, "label": 1691, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1691 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2019.2934595\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Sebastian Gehrmann;Hendrik Strobelt;Robert Kr\u00fcger;Hanspeter Pfister;Alexander M. Rush; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visual Interaction with Deep Learning Models through Collaborative Semantic Inference; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Automation of tasks can have critical consequences when humans lose agency over decision processes. Deep learning models are particularly susceptible since current black-box approaches lack explainable reasoning. We argue that both the visual interface and model structure of deep learning systems need to take into account interaction design. We propose a framework of collaborative semantic inference (CSI) for the co-design of interactions and models to enable visual collaboration between humans and algorithms. The approach exposes the intermediate reasoning process of models which allows semantic interactions with the visual metaphors of a problem, which means that a user can both understand and control parts of the model reasoning process. We demonstrate the feasibility of CSI with a co-designed case study of a document summarization system."}, {"color": "gray", "id": 1694, "label": 1694, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1694 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2019.2934612\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Tobias Klein;Ivan Viola;Eduard Gr\u00f6ller;Peter Mindek; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Multi-Scale Procedural Animations of Microtubule Dynamics Based on Measured Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Biologists often use computer graphics to visualize structures, which due to physical limitations are not possible to image with a microscope. One example for such structures are microtubules, which are present in every eukaryotic cell. They are part of the cytoskeleton maintaining the shape of the cell and playing a key role in the cell division. In this paper, we propose a scientifically-accurate multi-scale procedural model of microtubule dynamics as a novel application scenario for procedural animation, which can generate visualizations of their overall shape, molecular structure, as well as animations of the dynamic behaviour of their growth and disassembly. The model is spanning from tens of micrometers down to atomic resolution. All the aspects of the model are driven by scientific data. The advantage over a traditional, manual animation approach is that when the underlying data change, for instance due to new evidence, the model can be recreated immediately. The procedural animation concept is presented in its generic form, with several novel extensions, facilitating an easy translation to other domains with emergent multi-scale behavior."}, {"color": "gray", "id": 1695, "label": 1695, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1695 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2019.2934613\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Ke Xu;Yun Wang;Leni Yang;Yifang Wang;Bo Qiao;Si Qin;Yong Xu;Haidong Zhang;Huamin Qu; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: CloudDet: Interactive Visual Analysis of Anomalous Performances in Cloud Computing Systems; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Detecting and analyzing potential anomalous performances in cloud computing systems is essential for avoiding losses to customers and ensuring the efficient operation of the systems. To this end, a variety of automated techniques have been developed to identify anomalies in cloud computing. These techniques are usually adopted to track the performance metrics of the system (e.g., CPU, memory, and disk I/O), represented by a multivariate time series. However, given the complex characteristics of cloud computing data, the effectiveness of these automated methods is affected. Thus, substantial human judgment on the automated analysis results is required for anomaly interpretation. In this paper, we present a unified visual analytics system named CloudDet to interactively detect, inspect, and diagnose anomalies in cloud computing systems. A novel unsupervised anomaly detection algorithm is developed to identify anomalies based on the specific temporal patterns of the given metrics data (e.g., the periodic pattern). Rich visualization and interaction designs are used to help understand the anomalies in the spatial and temporal context. We demonstrate the effectiveness of CloudDet through a quantitative evaluation, two case studies with real-world data, and interviews with domain experts."}, {"color": "gray", "id": 1697, "label": 1697, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1697 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2019.2934619\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: James Wexler;Mahima Pushkarna;Tolga Bolukbasi;Martin Wattenberg;Fernanda Vi\u00e9gas;Jimbo Wilson; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: The What-If Tool: Interactive Probing of Machine Learning Models; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: A key challenge in developing and deploying Machine Learning (ML) systems is understanding their performance across a wide range of inputs. To address this challenge, we created the What-If Tool, an open-source application that allows practitioners to probe, visualize, and analyze ML systems, with minimal coding. The What-If Tool lets practitioners test performance in hypothetical situations, analyze the importance of different data features, and visualize model behavior across multiple models and subsets of input data. It also lets practitioners measure systems according to multiple ML fairness metrics. We describe the design of the tool, and report on real-life usage at different organizations."}, {"color": "gray", "id": 1698, "label": 1698, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1698 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2019.2934620\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Steve Petruzza;Attila Gyulassy;Samuel Leventhal;John J. Baglino;Michael Czabaj;Ashley D. Spear;Valerio Pascucci; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: High-throughput feature extraction for measuring attributes of deforming open-cell foams; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Metallic open-cell foams are promising structural materials with applications in multifunctional systems such as biomedical implants, energy absorbers in impact, noise mitigation, and batteries. There is a high demand for means to understand and correlate the design space of material performance metrics to the material structure in terms of attributes such as density, ligament and node properties, void sizes, and alignments. Currently, X-ray Computed Tomography (CT) scans of these materials are segmented either manually or with skeletonization approaches that may not accurately model the variety of shapes present in nodes and ligaments, especially irregularities that arise from manufacturing, image artifacts, or deterioration due to compression. In this paper, we present a new workflow for analysis of open-cell foams that combines a new density measurement to identify nodal structures, and topological approaches to identify ligament structures between them. Additionally, we provide automated measurement of foam properties. We demonstrate stable extraction of features and time-tracking in an image sequence of a foam being compressed. Our approach allows researchers to study larger and more complex foams than could previously be segmented only manually, and enables the high-throughput analysis needed to predict future foam performance."}, {"color": "gray", "id": 1699, "label": 1699, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1699 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2019.2934629\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Thilo Spinner;Udo Schlegel;Hanna Sch\u00e4fer;Mennatallah El-Assady; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: explAIner: A Visual Analytics Framework for Interactive and Explainable Machine Learning; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We propose a framework for interactive and explainable machine learning that enables users to (1) understand machine learning models; (2) diagnose model limitations using different explainable AI methods; as well as (3) refine and optimize the models. Our framework combines an iterative XAI pipeline with eight global monitoring and steering mechanisms, including quality monitoring, provenance tracking, model comparison, and trust building. To operationalize the framework, we present explAIner, a visual analytics system for interactive and explainable machine learning that instantiates all phases of the suggested pipeline within the commonly used TensorBoard environment. We performed a user-study with nine participants across different expertise levels to examine their perception of our workflow and to collect suggestions to fill the gap between our system and framework. The evaluation confirms that our tightly integrated system leads to an informed machine learning process while disclosing opportunities for further extensions."}, {"color": "gray", "id": 1701, "label": 1701, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1701 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2019.2934631\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Yuxin Ma;Tiankai Xie;Jundong Li;Ross Maciejewski; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Explaining Vulnerabilities to Adversarial Machine Learning through Visual Analytics; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Machine learning models are currently being deployed in a variety of real-world applications where model predictions are used to make decisions about healthcare, bank loans, and numerous other critical tasks. As the deployment of artificial intelligence technologies becomes ubiquitous, it is unsurprising that adversaries have begun developing methods to manipulate machine learning models to their advantage. While the visual analytics community has developed methods for opening the black box of machine learning models, little work has focused on helping the user understand their model vulnerabilities in the context of adversarial attacks. In this paper, we present a visual analytics framework for explaining and exploring model vulnerabilities to adversarial attacks. Our framework employs a multi-faceted visualization scheme designed to support the analysis of data poisoning attacks from the perspective of models, data instances, features, and local structures. We demonstrate our framework through two case studies on binary classifiers and illustrate model vulnerabilities with respect to varying attack strategies."}, {"color": "gray", "id": 1703, "label": 1703, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1703 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2019.2934655\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Ying Zhao;Xiaobo Luo;Xiaoru Lin;Hairong Wang;Xiaoyan Kui;Fangfang Zhou;Jinsong Wang;Yi Chen;Wei Chen; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visual Analytics for Electromagnetic Situation Awareness in Radio Monitoring and Management; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Traditional radio monitoring and management largely depend on radio spectrum data analysis, which requires considerable domain experience and heavy cognition effort and frequently results in incorrect signal judgment and incomprehensive situation awareness. Faced with increasingly complicated electromagnetic environments, radio supervisors urgently need additional data sources and advanced analytical technologies to enhance their situation awareness ability. This paper introduces a visual analytics approach for electromagnetic situation awareness. Guided by a detailed scenario and requirement analysis, we first propose a signal clustering method to process radio signal data and a situation assessment model to obtain qualitative and quantitative descriptions of the electromagnetic situations. We then design a two-module interface with a set of visualization views and interactions to help radio supervisors perceive and understand the electromagnetic situations by a joint analysis of radio signal data and radio spectrum data. Evaluations on real-world data sets and an interview with actual users demonstrate the effectiveness of our prototype system. Finally, we discuss the limitations of the proposed approach and provide future work directions."}, {"color": "gray", "id": 1704, "label": 1704, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1704 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2019.2934656\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Haipeng Zeng;Xingbo Wang;Aoyu Wu;Yong Wang;Quan Li;Alex Endert;Huamin Qu; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: EmoCo: Visual Analysis of Emotion Coherence in Presentation Videos; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Emotions play a key role in human communication and public presentations. Human emotions are usually expressed through multiple modalities. Therefore, exploring multimodal emotions and their coherence is of great value for understanding emotional expressions in presentations and improving presentation skills. However, manually watching and studying presentation videos is often tedious and time-consuming. There is a lack of tool support to help conduct an efficient and in-depth multi-level analysis. Thus, in this paper, we introduce EmoCo, an interactive visual analytics system to facilitate efficient analysis of emotion coherence across facial, text, and audio modalities in presentation videos. Our visualization system features a channel coherence view and a sentence clustering view that together enable users to obtain a quick overview of emotion coherence and its temporal evolution. In addition, a detail view and word view enable detailed exploration and comparison from the sentence level and word level, respectively. We thoroughly evaluate the proposed system and visualization techniques through two usage scenarios based on TED Talk videos and interviews with two domain experts. The results demonstrate the effectiveness of our system in gaining insights into emotion coherence in presentations."}, {"color": "gray", "id": 1707, "label": 1707, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1707 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2019.2934659\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Fred Hohman;Haekyu Park;Caleb Robinson;Duen Horng Polo Chau; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Summit: Scaling Deep Learning Interpretability by Visualizing Activation and Attribution Summarizations; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Deep learning is increasingly used in decision-making tasks. However, understanding how neural networks produce final predictions remains a fundamental challenge. Existing work on interpreting neural network predictions for images often focuses on explaining predictions for single images or neurons. As predictions are often computed from millions of weights that are optimized over millions of images, such explanations can easily miss a bigger picture. We present Summit, an interactive system that scalably and systematically summarizes and visualizes what features a deep learning model has learned and how those features interact to make predictions. Summit introduces two new scalable summarization techniques: (1) activation aggregation discovers important neurons, and (2) neuron-influence aggregation identifies relationships among such neurons. Summit combines these techniques to create the novel attribution graph that reveals and summarizes crucial neuron associations and substructures that contribute to a model\u0027s outcomes. Summit scales to large data, such as the ImageNet dataset with 1.2M images, and leverages neural network feature visualization and dataset examples to help users distill large, complex neural network models into compact, interactive visualizations. We present neural network exploration scenarios where Summit helps us discover multiple surprising insights into a prevalent, large-scale image classifier\u0027s learned representations and informs future neural network architecture design. The Summit visualization runs in modern web browsers and is open-sourced."}, {"color": "gray", "id": 1712, "label": 1712, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1712 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2019.2934668\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Bowen Yu;Cl\u00e1udio T. Silva; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: FlowSense: A Natural Language Interface for Visual Data Exploration within a Dataflow System; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Dataflow visualization systems enable flexible visual data exploration by allowing the user to construct a dataflow diagram that composes query and visualization modules to specify system functionality. However learning dataflow diagram usage presents overhead that often discourages the user. In this work we design FlowSense, a natural language interface for dataflow visualization systems that utilizes state-of-the-art natural language processing techniques to assist dataflow diagram construction. FlowSense employs a semantic parser with special utterance tagging and special utterance placeholders to generalize to different datasets and dataflow diagrams. It explicitly presents recognized dataset and diagram special utterances to the user for dataflow context awareness. With FlowSense the user can expand and adjust dataflow diagrams more conveniently via plain English. We apply FlowSense to the VisFlow subset-flow visualization system to enhance its usability. We evaluate FlowSense by one case study with domain experts on a real-world data analysis problem and a formal user study."}, {"color": "gray", "id": 1713, "label": 1713, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1713 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2019.2934669\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Haris Mumtaz;Shahid Latif;Fabian Beck;Daniel Weiskopf; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Exploranative Code Quality Documents; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Good code quality is a prerequisite for efficiently developing maintainable software. In this paper, we present a novel approach to generate exploranative (explanatory and exploratory) data-driven documents that report code quality in an interactive, exploratory environment. We employ a template-based natural language generation method to create textual explanations about the code quality, dependent on data from software metrics. The interactive document is enriched by different kinds of visualization, including parallel coordinates plots and scatterplots for data exploration and graphics embedded into text. We devise an interaction model that allows users to explore code quality with consistent linking between text and visualizations; through integrated explanatory text, users are taught background knowledge about code quality aspects. Our approach to interactive documents was developed in a design study process that included software engineering and visual analytics experts. Although the solution is specific to the software engineering scenario, we discuss how the concept could generalize to multivariate data and report lessons learned in a broader scope."}, {"color": "gray", "id": 1714, "label": 1714, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1714 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2019.2934670\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Zikun Deng;Di Weng;Jiahui Chen;Ren Liu;Zhibin Wang;Jie Bao;Yu Zheng;Yingcai Wu; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: AirVis: Visual Analytics of Air Pollution Propagation; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Air pollution has become a serious public health problem for many cities around the world. To find the causes of air pollution, the propagation processes of air pollutants must be studied at a large spatial scale. However, the complex and dynamic wind fields lead to highly uncertain pollutant transportation. The state-of-the-art data mining approaches cannot fully support the extensive analysis of such uncertain spatiotemporal propagation processes across multiple districts without the integration of domain knowledge. The limitation of these automated approaches motivates us to design and develop AirVis, a novel visual analytics system that assists domain experts in efficiently capturing and interpreting the uncertain propagation patterns of air pollution based on graph visualizations. Designing such a system poses three challenges: a) the extraction of propagation patterns; b) the scalability of pattern presentations; and c) the analysis of propagation processes. To address these challenges, we develop a novel pattern mining framework to model pollutant transportation and extract frequent propagation patterns efficiently from large-scale atmospheric data. Furthermore, we organize the extracted patterns hierarchically based on the minimum description length (MDL) principle and empower expert users to explore and analyze these patterns effectively on the basis of pattern topologies. We demonstrated the effectiveness of our approach through two case studies conducted with a real-world dataset and positive feedback from domain experts."}, {"color": "gray", "id": 1716, "label": 1716, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1716 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2019.2934783\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Yunhai Wang;Xiaowei Chu;Kaiyi Zhang;Chen Bao;Xiaotong Li;Jian Zhang;Chi-Wing Fu;Christophe Hurter;Oliver Deussen;Bongshin Lee; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: ShapeWordle: Tailoring Wordles using Shape-aware Archimedean Spirals; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present a new technique to enable the creation of shape-bounded Wordles, we call ShapeWordle, in which we fit words to form a given shape. To guide word placement within a shape, we extend the traditional Archimedean spirals to be shape-aware by formulating the spirals in a differential form using the distance field of the shape. To handle non-convex shapes, we introduce a multi-centric Wordle layout method that segments the shape into parts for our shape-aware spirals to adaptively fill the space and generate word placements. In addition, we offer a set of editing interactions to facilitate the creation of semantically-meaningful Wordles. Lastly, we present three evaluations: a comprehensive comparison of our results against the state-of-the-art technique (WordArt), case studies with 14 users, and a gallery to showcase the coverage of our technique."}, {"color": "gray", "id": 1721, "label": 1721, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1721 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2019.2934790\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Kyle Wm. Hall;Adam J. Bradley;Uta Hinrichs;Samuel Huron;Jo Wood;Christopher Collins;Sheelagh Carpendale; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Design by Immersion: A Transdisciplinary Approach to Problem-Driven Visualizations; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: While previous work exists on how to conduct and disseminate insights from problem-driven visualization projects and design studies, the literature does not address how to accomplish these goals in transdisciplinary teams in ways that advance all disciplines involved. In this paper we introduce and define a new methodological paradigm we call design by immersion, which provides an alternative perspective on problem-driven visualization work. Design by immersion embeds transdisciplinary experiences at the center of the visualization process by having visualization researchers participate in the work of the target domain (or domain experts participate in visualization research). Based on our own combined experiences of working on cross-disciplinary, problem-driven visualization projects, we present six case studies that expose the opportunities that design by immersion enables, including (1) exploring new domain-inspired visualization design spaces, (2) enriching domain understanding through personal experiences, and (3) building strong transdisciplinary relationships. Furthermore, we illustrate how the process of design by immersion opens up a diverse set of design activities that can be combined in different ways depending on the type of collaboration, project, and goals. Finally, we discuss the challenges and potential pitfalls of design by immersion."}, {"color": "gray", "id": 1725, "label": 1725, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1725 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2019.2934799\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Ruizhen Hu;Tingkai Sha;Oliver Van Kaick;Oliver Deussen;Hui Huang; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Data Sampling in Multi-view and Multi-class Scatterplots via Set Cover Optimization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present a method for data sampling in scatterplots by jointly optimizing point selection for different views or classes. Our method uses space-filling curves (Z-order curves) that partition a point set into subsets that, when covered each by one sample, provide a sampling or coreset with good approximation guarantees in relation to the original point set. For scatterplot matrices with multiple views, different views provide different space-filling curves, leading to different partitions of the given point set. For multi-class scatterplots, the focus on either per-class distribution or global distribution provides two different partitions of the given point set that need to be considered in the selection of the coreset. For both cases, we convert the coreset selection problem into an Exact Cover Problem (ECP), and demonstrate with quantitative and qualitative evaluations that an approximate solution that solves the ECP efficiently is able to provide high-quality samplings."}, {"color": "gray", "id": 1728, "label": 1728, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1728 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2019.2934802\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Ashley Suh;Mustafa Hajij;Bei Wang;Carlos Scheidegger;Paul Rosen; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Persistent Homology Guided Force-Directed Graph Layouts; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Graphs are commonly used to encode relationships among entities, yet their abstractness makes them difficult to analyze. Node-link diagrams are popular for drawing graphs, and force-directed layouts provide a flexible method for node arrangements that use local relationships in an attempt to reveal the global shape of the graph. However, clutter and overlap of unrelated structures can lead to confusing graph visualizations. This paper leverages the persistent homology features of an undirected graph as derived information for interactive manipulation of force-directed layouts. We first discuss how to efficiently extract 0-dimensional persistent homology features from both weighted and unweighted undirected graphs. We then introduce the interactive persistence barcode used to manipulate the force-directed graph layout. In particular, the user adds and removes contracting and repulsing forces generated by the persistent homology features, eventually selecting the set of persistent homology features that most improve the layout. Finally, we demonstrate the utility of our approach across a variety of synthetic and real datasets."}, {"color": "gray", "id": 1733, "label": 1733, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1733 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2019.2934807\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Vanessa Pe\u00f1a-Araya;Emmanuel Pietriga;Anastasia Bezerianos; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: A Comparison of Visualizations for Identifying Correlation over Space and Time; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Observing the relationship between two or more variables over space and time is essential in many domains. For instance, looking, for different countries, at the evolution of both the life expectancy at birth and the fertility rate will give an overview of their demographics. The choice of visual representation for such multivariate data is key to enabling analysts to extract patterns and trends. Prior work has compared geo-temporal visualization techniques for a single thematic variable that evolves over space and time, or for two variables at a specific point in time. But how effective visualization techniques are at communicating correlation between two variables that evolve over space and time remains to be investigated. We report on a study comparing three techniques that are representative of different strategies to visualize geo-temporal multivariate data: either juxtaposing all locations for a given time step, or juxtaposing all time steps for a given location; and encoding thematic attributes either using symbols overlaid on top of map features, or using visual channels of the map features themselves. Participants performed a series of tasks that required them to identify if two variables were correlated over time and if there was a pattern in their evolution. Tasks varied in granularity for both dimensions: time (all time steps, a subrange of steps, one step only) and space (all locations, locations in a subregion, one location only). Our results show that a visualization\u0027s effectiveness depends strongly on the task to be carried out. Based on these findings we present a set of design guidelines about geo-temporal visualization techniques for communicating correlation."}, {"color": "gray", "id": 1737, "label": 1737, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1737 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST47406.2019.8986909\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Alex Bigelow;Carolina Nobre;Miriah Meyer;Alexander Lex; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Origraph: Interactive Network Wrangling; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Networks are a natural way of thinking about many datasets. The data on which a network is based, however, is rarely collected in a form that suits the analysis process, making it necessary to create and reshape networks. Data wrangling is widely acknowledged to be a critical part of the data analysis pipeline, yet interactive network wrangling has received little attention in the visualization research community. In this paper, we discuss a set of operations that are important for wrangling network datasets and introduce a visual data wrangling tool, Origraph, that enables analysts to apply these operations to their datasets. Key operations include creating a network from source data such as tables, reshaping a network by introducing new node or edge classes, filtering nodes or edges, and deriving new node or edge attributes. Our tool, Origraph, enables analysts to execute these operations with little to no programming, and to immediately visualize the results. Origraph provides views to investigate the network model, a sample of the network, and node and edge attributes. In addition, we introduce interfaces designed to aid analysts in specifying arguments for sensible network wrangling operations. We demonstrate the usefulness of Origraph in two Use Cases: first, we investigate gender bias in the film industry, and then the influence of money on the political support for the war in Yemen."}, {"color": "gray", "id": 1739, "label": 1739, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1739 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST47406.2019.8986918\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Melanie Tory;Vidya Setlur; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Do What I Mean, Not What I Say! Design Considerations for Supporting Intent and Context in Analytical Conversation; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Natural language can be a useful modality for creating and interacting with visualizations but users often have unrealistic expectations about the intelligence of natural language systems. The gulf between user expectations and system capabilities may lead to a disappointing user experience. So - if we want to engineer a natural language system, what are the requirements around system intelligence? This work takes a retrospective look at how we answered this question in the design of Ask Data, a natural language interaction feature for Tableau. We examine two factors contributing to perceived system intelligence: the system\u0027s ability to understand the analytic intent behind an input utterance and the ability to interpret an utterance contextually (i.e. taking into account the current visualization state and recent actions). Our aim was to understand the ways in which a system would need to support these two aspects of intelligence to enable a positive user experience. We first describe a pre-design Wizard of Oz study that offered insight into this question and narrowed the space of designs under consideration. We then reflect on the impact of this study on system development, examining how design implications from the study played out in practice. Our work contributes insights for the design of natural language interaction in visual analytics as well as a reflection on the value of pre-design empirical studies in the development of visual analytic systems."}, {"color": "gray", "id": 1745, "label": 1745, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1745 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST47406.2019.8986948\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: \u00c1ngel Alexander Cabrera;Will Epperson;Fred Hohman;Minsuk Kahng;Jamie Morgenstern;Duen Horng Chau; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: FAIRVIS: Visual Analytics for Discovering Intersectional Bias in Machine Learning; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The growing capability and accessibility of machine learning has led to its application to many real-world domains and data about people. Despite the benefits algorithmic systems may bring, models can reflect, inject, or exacerbate implicit and explicit societal biases into their outputs, disadvantaging certain demographic subgroups. Discovering which biases a machine learning model has introduced is a great challenge, due to the numerous definitions of fairness and the large number of potentially impacted subgroups. We present FAIRVIS, a mixed-initiative visual analytics system that integrates a novel subgroup discovery technique for users to audit the fairness of machine learning models. Through FAIRVIS, users can apply domain knowledge to generate and investigate known subgroups, and explore suggested and similar subgroups. FAIRVIS\u0027s coordinated views enable users to explore a high-level overview of subgroup performance and subsequently drill down into detailed investigation of specific subgroups. We show how FAIRVIS helps to discover biases in two real datasets used in predicting income and recidivism. As a visual analytics system devoted to discovering bias in machine learning, FAIRVIS demonstrates how interactive visualization may help data scientists and the general public understand and create more equitable algorithmic systems."}]);
        edges = new vis.DataSet([{"from": 15, "to": 658, "width": 0.86379313}, {"from": 15, "to": 951, "width": 0.86155427}, {"from": 18, "to": 434, "width": 0.86456186}, {"from": 21, "to": 754, "width": 0.8787076}, {"from": 21, "to": 1453, "width": 0.89144444}, {"from": 25, "to": 1048, "width": 0.87918675}, {"from": 30, "to": 831, "width": 0.8873187}, {"from": 30, "to": 1048, "width": 0.85915375}, {"from": 36, "to": 1331, "width": 0.8705391}, {"from": 38, "to": 1008, "width": 0.8771146}, {"from": 42, "to": 1442, "width": 0.8667661}, {"from": 46, "to": 169, "width": 0.8909398}, {"from": 50, "to": 361, "width": 0.85721034}, {"from": 50, "to": 449, "width": 0.8699426}, {"from": 50, "to": 536, "width": 0.8943839}, {"from": 52, "to": 904, "width": 0.86515266}, {"from": 56, "to": 232, "width": 0.88171726}, {"from": 57, "to": 363, "width": 0.8641474}, {"from": 57, "to": 1410, "width": 0.8722597}, {"from": 57, "to": 1658, "width": 0.9149912}, {"from": 71, "to": 734, "width": 0.8622765}, {"from": 71, "to": 1165, "width": 0.8574146}, {"from": 71, "to": 1373, "width": 0.862917}, {"from": 75, "to": 749, "width": 0.889182}, {"from": 75, "to": 789, "width": 0.87029094}, {"from": 78, "to": 854, "width": 0.87162125}, {"from": 78, "to": 1550, "width": 0.8611632}, {"from": 78, "to": 1658, "width": 0.8683203}, {"from": 79, "to": 214, "width": 0.87824273}, {"from": 79, "to": 347, "width": 0.87049305}, {"from": 79, "to": 1257, "width": 0.8915796}, {"from": 80, "to": 120, "width": 0.8560921}, {"from": 80, "to": 779, "width": 0.8604519}, {"from": 80, "to": 1015, "width": 0.90929323}, {"from": 80, "to": 1108, "width": 0.8633995}, {"from": 83, "to": 363, "width": 0.8554295}, {"from": 83, "to": 1048, "width": 0.86062443}, {"from": 89, "to": 483, "width": 0.9018228}, {"from": 89, "to": 1417, "width": 0.8638357}, {"from": 89, "to": 1550, "width": 0.8782834}, {"from": 93, "to": 1712, "width": 0.8848632}, {"from": 101, "to": 959, "width": 0.85561484}, {"from": 103, "to": 372, "width": 0.8582459}, {"from": 106, "to": 557, "width": 0.87111884}, {"from": 113, "to": 1096, "width": 0.86208177}, {"from": 115, "to": 152, "width": 0.8663632}, {"from": 115, "to": 508, "width": 0.87144923}, {"from": 115, "to": 654, "width": 0.8761689}, {"from": 115, "to": 944, "width": 0.90229875}, {"from": 115, "to": 1009, "width": 0.8601567}, {"from": 115, "to": 1025, "width": 0.93773544}, {"from": 115, "to": 1159, "width": 0.86257976}, {"from": 115, "to": 1214, "width": 0.8808564}, {"from": 116, "to": 1217, "width": 0.86272484}, {"from": 121, "to": 317, "width": 0.86843807}, {"from": 121, "to": 347, "width": 0.8648706}, {"from": 121, "to": 669, "width": 0.8660925}, {"from": 121, "to": 1676, "width": 0.8597097}, {"from": 124, "to": 152, "width": 0.8550256}, {"from": 124, "to": 232, "width": 0.8630256}, {"from": 126, "to": 588, "width": 0.8713697}, {"from": 126, "to": 1673, "width": 0.8624675}, {"from": 127, "to": 597, "width": 0.87743324}, {"from": 129, "to": 347, "width": 0.8660856}, {"from": 129, "to": 686, "width": 0.8654739}, {"from": 129, "to": 1652, "width": 0.888671}, {"from": 130, "to": 247, "width": 0.8658}, {"from": 132, "to": 222, "width": 0.86223197}, {"from": 132, "to": 229, "width": 0.89309025}, {"from": 142, "to": 1550, "width": 0.86246294}, {"from": 147, "to": 631, "width": 0.86700994}, {"from": 151, "to": 243, "width": 0.90883327}, {"from": 151, "to": 252, "width": 0.85858667}, {"from": 151, "to": 399, "width": 0.8576832}, {"from": 151, "to": 567, "width": 0.8588433}, {"from": 151, "to": 581, "width": 0.89908874}, {"from": 151, "to": 653, "width": 0.8653548}, {"from": 151, "to": 1017, "width": 0.8951181}, {"from": 151, "to": 1391, "width": 0.8811894}, {"from": 152, "to": 465, "width": 0.8562344}, {"from": 152, "to": 653, "width": 0.8826332}, {"from": 152, "to": 654, "width": 0.8581623}, {"from": 152, "to": 735, "width": 0.86866003}, {"from": 152, "to": 899, "width": 0.87455136}, {"from": 152, "to": 917, "width": 0.8552456}, {"from": 152, "to": 971, "width": 0.8765181}, {"from": 155, "to": 989, "width": 0.8659479}, {"from": 155, "to": 1449, "width": 0.87177324}, {"from": 157, "to": 208, "width": 0.86980337}, {"from": 157, "to": 724, "width": 0.87077564}, {"from": 158, "to": 234, "width": 0.8632174}, {"from": 160, "to": 1437, "width": 0.8550599}, {"from": 161, "to": 303, "width": 0.85583913}, {"from": 166, "to": 210, "width": 0.85635924}, {"from": 166, "to": 263, "width": 0.8659629}, {"from": 168, "to": 1536, "width": 0.8684261}, {"from": 174, "to": 222, "width": 0.8585096}, {"from": 174, "to": 526, "width": 0.8854175}, {"from": 174, "to": 1396, "width": 0.8724233}, {"from": 174, "to": 1470, "width": 0.8709159}, {"from": 180, "to": 360, "width": 0.858383}, {"from": 182, "to": 1570, "width": 0.87589884}, {"from": 184, "to": 434, "width": 0.91087556}, {"from": 184, "to": 626, "width": 0.87522936}, {"from": 184, "to": 768, "width": 0.87510884}, {"from": 184, "to": 1453, "width": 0.8645677}, {"from": 191, "to": 222, "width": 0.86457074}, {"from": 191, "to": 1008, "width": 0.88204914}, {"from": 192, "to": 361, "width": 0.8625692}, {"from": 192, "to": 866, "width": 0.86398166}, {"from": 192, "to": 1249, "width": 0.8929269}, {"from": 196, "to": 812, "width": 0.86674523}, {"from": 197, "to": 230, "width": 0.8748449}, {"from": 197, "to": 247, "width": 0.8742767}, {"from": 197, "to": 483, "width": 0.85569096}, {"from": 197, "to": 559, "width": 0.8602236}, {"from": 197, "to": 593, "width": 0.85791683}, {"from": 197, "to": 664, "width": 0.858341}, {"from": 197, "to": 937, "width": 0.87000424}, {"from": 197, "to": 1108, "width": 0.88135475}, {"from": 197, "to": 1350, "width": 0.87538046}, {"from": 197, "to": 1470, "width": 0.8615388}, {"from": 200, "to": 459, "width": 0.8675953}, {"from": 201, "to": 365, "width": 0.87274134}, {"from": 201, "to": 513, "width": 0.89379096}, {"from": 201, "to": 1257, "width": 0.85954773}, {"from": 205, "to": 903, "width": 0.8551305}, {"from": 205, "to": 1505, "width": 0.8916645}, {"from": 210, "to": 232, "width": 0.8896899}, {"from": 210, "to": 263, "width": 0.8765298}, {"from": 210, "to": 268, "width": 0.9069228}, {"from": 210, "to": 779, "width": 0.85587287}, {"from": 210, "to": 1108, "width": 0.87619793}, {"from": 211, "to": 768, "width": 0.8776755}, {"from": 211, "to": 979, "width": 0.86311907}, {"from": 211, "to": 1329, "width": 0.8625337}, {"from": 211, "to": 1433, "width": 0.85723025}, {"from": 214, "to": 245, "width": 0.86259395}, {"from": 214, "to": 365, "width": 0.86324143}, {"from": 214, "to": 1257, "width": 0.8819069}, {"from": 214, "to": 1550, "width": 0.8700958}, {"from": 217, "to": 435, "width": 0.88264936}, {"from": 217, "to": 502, "width": 0.86841875}, {"from": 217, "to": 522, "width": 0.86088693}, {"from": 217, "to": 861, "width": 0.88658166}, {"from": 217, "to": 1187, "width": 0.8777343}, {"from": 219, "to": 341, "width": 0.8567142}, {"from": 219, "to": 541, "width": 0.8639111}, {"from": 219, "to": 1506, "width": 0.8582929}, {"from": 221, "to": 1673, "width": 0.8656351}, {"from": 222, "to": 263, "width": 0.9076286}, {"from": 222, "to": 632, "width": 0.87294674}, {"from": 222, "to": 660, "width": 0.8768974}, {"from": 222, "to": 661, "width": 0.8632793}, {"from": 222, "to": 664, "width": 0.88698834}, {"from": 222, "to": 779, "width": 0.85970134}, {"from": 222, "to": 977, "width": 0.86413795}, {"from": 222, "to": 1008, "width": 0.85545975}, {"from": 222, "to": 1108, "width": 0.87194073}, {"from": 222, "to": 1609, "width": 0.87650204}, {"from": 225, "to": 929, "width": 0.8571951}, {"from": 225, "to": 1194, "width": 0.8635314}, {"from": 226, "to": 559, "width": 0.9020059}, {"from": 226, "to": 1128, "width": 0.8687447}, {"from": 226, "to": 1383, "width": 0.86365986}, {"from": 230, "to": 1108, "width": 0.8592188}, {"from": 232, "to": 247, "width": 0.86225575}, {"from": 232, "to": 268, "width": 0.9145705}, {"from": 232, "to": 557, "width": 0.8565481}, {"from": 232, "to": 632, "width": 0.86000484}, {"from": 232, "to": 951, "width": 0.86199325}, {"from": 232, "to": 1533, "width": 0.87582004}, {"from": 232, "to": 1682, "width": 0.86038566}, {"from": 235, "to": 717, "width": 0.85964143}, {"from": 235, "to": 718, "width": 0.8648835}, {"from": 235, "to": 723, "width": 0.86923456}, {"from": 237, "to": 251, "width": 0.86591506}, {"from": 237, "to": 1467, "width": 0.85599005}, {"from": 238, "to": 1689, "width": 0.8550112}, {"from": 243, "to": 750, "width": 0.87105125}, {"from": 243, "to": 907, "width": 0.87226915}, {"from": 243, "to": 1017, "width": 0.86156404}, {"from": 244, "to": 1247, "width": 0.87346256}, {"from": 245, "to": 626, "width": 0.86370194}, {"from": 245, "to": 628, "width": 0.8591224}, {"from": 246, "to": 1533, "width": 0.8567486}, {"from": 247, "to": 557, "width": 0.8726854}, {"from": 247, "to": 653, "width": 0.8590815}, {"from": 247, "to": 751, "width": 0.8738192}, {"from": 247, "to": 971, "width": 0.8647957}, {"from": 247, "to": 1217, "width": 0.8620602}, {"from": 250, "to": 1682, "width": 0.8693469}, {"from": 251, "to": 328, "width": 0.87050754}, {"from": 251, "to": 619, "width": 0.8862494}, {"from": 251, "to": 818, "width": 0.86569923}, {"from": 251, "to": 1174, "width": 0.8588874}, {"from": 252, "to": 653, "width": 0.8988904}, {"from": 256, "to": 1550, "width": 0.86244196}, {"from": 260, "to": 937, "width": 0.8662895}, {"from": 262, "to": 559, "width": 0.87058187}, {"from": 262, "to": 977, "width": 0.8562412}, {"from": 263, "to": 268, "width": 0.8787626}, {"from": 263, "to": 632, "width": 0.85764897}, {"from": 263, "to": 664, "width": 0.8642685}, {"from": 263, "to": 779, "width": 0.8672236}, {"from": 263, "to": 977, "width": 0.86891156}, {"from": 263, "to": 1395, "width": 0.86027}, {"from": 263, "to": 1396, "width": 0.85727763}, {"from": 263, "to": 1468, "width": 0.8575988}, {"from": 263, "to": 1609, "width": 0.85582584}, {"from": 268, "to": 664, "width": 0.8728785}, {"from": 268, "to": 779, "width": 0.856988}, {"from": 281, "to": 1281, "width": 0.8619706}, {"from": 284, "to": 374, "width": 0.8651845}, {"from": 285, "to": 826, "width": 0.85536665}, {"from": 285, "to": 1253, "width": 0.88863266}, {"from": 285, "to": 1467, "width": 0.86308694}, {"from": 289, "to": 1096, "width": 0.8675587}, {"from": 291, "to": 880, "width": 0.85580313}, {"from": 291, "to": 1179, "width": 0.8715618}, {"from": 300, "to": 617, "width": 0.8700563}, {"from": 300, "to": 628, "width": 0.8581654}, {"from": 300, "to": 688, "width": 0.8663061}, {"from": 303, "to": 502, "width": 0.89573365}, {"from": 305, "to": 1216, "width": 0.8607411}, {"from": 306, "to": 436, "width": 0.86853534}, {"from": 319, "to": 368, "width": 0.8670309}, {"from": 322, "to": 393, "width": 0.8603215}, {"from": 322, "to": 1704, "width": 0.8865561}, {"from": 323, "to": 587, "width": 0.87076265}, {"from": 323, "to": 1137, "width": 0.8604282}, {"from": 328, "to": 350, "width": 0.88069147}, {"from": 328, "to": 689, "width": 0.8606591}, {"from": 328, "to": 891, "width": 0.8657039}, {"from": 328, "to": 1174, "width": 0.8674458}, {"from": 328, "to": 1246, "width": 0.86895776}, {"from": 328, "to": 1306, "width": 0.8668444}, {"from": 328, "to": 1513, "width": 0.8746603}, {"from": 328, "to": 1625, "width": 0.85765064}, {"from": 330, "to": 1667, "width": 0.8691878}, {"from": 333, "to": 929, "width": 0.856188}, {"from": 333, "to": 1208, "width": 0.8609461}, {"from": 333, "to": 1449, "width": 0.8626283}, {"from": 333, "to": 1584, "width": 0.86203253}, {"from": 333, "to": 1667, "width": 0.86280555}, {"from": 341, "to": 1266, "width": 0.8680145}, {"from": 342, "to": 447, "width": 0.86566305}, {"from": 342, "to": 555, "width": 0.8633489}, {"from": 342, "to": 719, "width": 0.88509744}, {"from": 342, "to": 723, "width": 0.85863763}, {"from": 342, "to": 836, "width": 0.85691035}, {"from": 342, "to": 1083, "width": 0.8590982}, {"from": 342, "to": 1253, "width": 0.86295575}, {"from": 342, "to": 1541, "width": 0.87100744}, {"from": 347, "to": 1652, "width": 0.8707281}, {"from": 350, "to": 713, "width": 0.89645296}, {"from": 350, "to": 913, "width": 0.86783403}, {"from": 350, "to": 1463, "width": 0.8659495}, {"from": 350, "to": 1625, "width": 0.8672218}, {"from": 351, "to": 502, "width": 0.86190736}, {"from": 354, "to": 973, "width": 0.86188793}, {"from": 355, "to": 496, "width": 0.8633679}, {"from": 356, "to": 419, "width": 0.92127436}, {"from": 356, "to": 452, "width": 0.8557867}, {"from": 356, "to": 519, "width": 0.864554}, {"from": 356, "to": 698, "width": 0.883516}, {"from": 356, "to": 1565, "width": 0.8717773}, {"from": 357, "to": 861, "width": 0.86784834}, {"from": 357, "to": 1372, "width": 0.85592264}, {"from": 357, "to": 1745, "width": 0.89417785}, {"from": 360, "to": 362, "width": 0.88067114}, {"from": 360, "to": 375, "width": 0.9056434}, {"from": 360, "to": 379, "width": 0.9882014}, {"from": 360, "to": 415, "width": 0.86759526}, {"from": 360, "to": 440, "width": 0.85764956}, {"from": 360, "to": 449, "width": 0.90713674}, {"from": 360, "to": 491, "width": 0.86548066}, {"from": 360, "to": 536, "width": 0.8613278}, {"from": 360, "to": 540, "width": 0.8663959}, {"from": 360, "to": 541, "width": 0.8577242}, {"from": 360, "to": 724, "width": 0.8570847}, {"from": 361, "to": 376, "width": 0.88122493}, {"from": 361, "to": 441, "width": 0.8554292}, {"from": 361, "to": 449, "width": 0.8682607}, {"from": 361, "to": 478, "width": 0.8578864}, {"from": 361, "to": 536, "width": 0.87570035}, {"from": 361, "to": 537, "width": 0.9025466}, {"from": 361, "to": 541, "width": 0.8667934}, {"from": 361, "to": 719, "width": 0.8554756}, {"from": 361, "to": 720, "width": 0.87811536}, {"from": 361, "to": 723, "width": 0.8600994}, {"from": 361, "to": 725, "width": 0.8563234}, {"from": 361, "to": 727, "width": 0.86030513}, {"from": 362, "to": 375, "width": 0.9556839}, {"from": 362, "to": 379, "width": 0.88939375}, {"from": 362, "to": 441, "width": 0.8561456}, {"from": 363, "to": 378, "width": 0.964842}, {"from": 363, "to": 402, "width": 0.8808656}, {"from": 363, "to": 526, "width": 0.85961753}, {"from": 363, "to": 628, "width": 0.89401895}, {"from": 363, "to": 677, "width": 0.9044799}, {"from": 363, "to": 693, "width": 0.8561613}, {"from": 363, "to": 820, "width": 0.8624195}, {"from": 363, "to": 825, "width": 0.91471833}, {"from": 363, "to": 1008, "width": 0.909489}, {"from": 363, "to": 1048, "width": 0.86631924}, {"from": 363, "to": 1582, "width": 0.8580376}, {"from": 363, "to": 1658, "width": 0.8604988}, {"from": 363, "to": 1704, "width": 0.85770684}, {"from": 365, "to": 628, "width": 0.87095153}, {"from": 365, "to": 1257, "width": 0.8627963}, {"from": 365, "to": 1375, "width": 0.86283284}, {"from": 367, "to": 510, "width": 0.861879}, {"from": 367, "to": 717, "width": 0.86910707}, {"from": 369, "to": 1180, "width": 0.85619134}, {"from": 369, "to": 1230, "width": 0.855708}, {"from": 370, "to": 406, "width": 0.923163}, {"from": 370, "to": 437, "width": 0.85716915}, {"from": 370, "to": 1083, "width": 0.8683467}, {"from": 370, "to": 1167, "width": 0.8562512}, {"from": 370, "to": 1414, "width": 0.8631274}, {"from": 370, "to": 1447, "width": 0.8643727}, {"from": 371, "to": 447, "width": 0.85576296}, {"from": 372, "to": 849, "width": 0.9027067}, {"from": 372, "to": 1721, "width": 0.86838263}, {"from": 373, "to": 738, "width": 0.9131097}, {"from": 373, "to": 807, "width": 0.8952331}, {"from": 374, "to": 439, "width": 0.8774786}, {"from": 375, "to": 379, "width": 0.91577816}, {"from": 375, "to": 441, "width": 0.88384086}, {"from": 376, "to": 436, "width": 0.8650276}, {"from": 377, "to": 452, "width": 0.8619436}, {"from": 377, "to": 546, "width": 0.873763}, {"from": 377, "to": 582, "width": 0.865475}, {"from": 377, "to": 683, "width": 0.8777531}, {"from": 377, "to": 727, "width": 0.86247563}, {"from": 377, "to": 768, "width": 0.8818578}, {"from": 377, "to": 955, "width": 0.8610143}, {"from": 377, "to": 1034, "width": 0.85749555}, {"from": 377, "to": 1310, "width": 0.8568562}, {"from": 377, "to": 1699, "width": 0.8657022}, {"from": 378, "to": 677, "width": 0.8653362}, {"from": 378, "to": 825, "width": 0.8959957}, {"from": 378, "to": 1008, "width": 0.8568083}, {"from": 378, "to": 1048, "width": 0.85716814}, {"from": 379, "to": 415, "width": 0.8574908}, {"from": 379, "to": 440, "width": 0.8642265}, {"from": 379, "to": 449, "width": 0.90120137}, {"from": 379, "to": 491, "width": 0.885301}, {"from": 379, "to": 536, "width": 0.86794764}, {"from": 379, "to": 540, "width": 0.8575036}, {"from": 379, "to": 717, "width": 0.8563335}, {"from": 379, "to": 724, "width": 0.85805726}, {"from": 383, "to": 755, "width": 0.86342514}, {"from": 388, "to": 645, "width": 0.8751078}, {"from": 388, "to": 777, "width": 0.8656576}, {"from": 388, "to": 1468, "width": 0.863617}, {"from": 390, "to": 1048, "width": 0.8550619}, {"from": 402, "to": 1008, "width": 0.8605414}, {"from": 403, "to": 677, "width": 0.8579082}, {"from": 403, "to": 1541, "width": 0.8590107}, {"from": 404, "to": 626, "width": 0.8674972}, {"from": 405, "to": 600, "width": 0.88954616}, {"from": 408, "to": 641, "width": 0.85821056}, {"from": 411, "to": 695, "width": 0.8571485}, {"from": 411, "to": 1155, "width": 0.88037187}, {"from": 415, "to": 544, "width": 0.87659675}, {"from": 415, "to": 628, "width": 0.85779554}, {"from": 415, "to": 814, "width": 0.86941385}, {"from": 415, "to": 1264, "width": 0.88783586}, {"from": 419, "to": 452, "width": 0.9040179}, {"from": 419, "to": 698, "width": 0.8847614}, {"from": 419, "to": 1040, "width": 0.8753116}, {"from": 419, "to": 1046, "width": 0.88329166}, {"from": 419, "to": 1598, "width": 0.855816}, {"from": 421, "to": 893, "width": 0.8591796}, {"from": 424, "to": 880, "width": 0.8734569}, {"from": 424, "to": 1040, "width": 0.86130154}, {"from": 428, "to": 604, "width": 0.91769946}, {"from": 433, "to": 527, "width": 0.8756859}, {"from": 433, "to": 1249, "width": 0.8584958}, {"from": 434, "to": 768, "width": 0.88093203}, {"from": 435, "to": 610, "width": 0.8623517}, {"from": 435, "to": 861, "width": 0.86110646}, {"from": 436, "to": 447, "width": 0.861237}, {"from": 436, "to": 945, "width": 0.8632807}, {"from": 437, "to": 1053, "width": 0.85692686}, {"from": 437, "to": 1425, "width": 0.8600765}, {"from": 437, "to": 1704, "width": 0.8663654}, {"from": 441, "to": 449, "width": 0.865039}, {"from": 441, "to": 540, "width": 0.8683416}, {"from": 441, "to": 727, "width": 0.8739073}, {"from": 441, "to": 728, "width": 0.86498535}, {"from": 441, "to": 1245, "width": 0.8607757}, {"from": 443, "to": 536, "width": 0.87384737}, {"from": 444, "to": 592, "width": 0.8603682}, {"from": 444, "to": 711, "width": 0.88383555}, {"from": 444, "to": 864, "width": 0.8738968}, {"from": 444, "to": 945, "width": 0.8595888}, {"from": 444, "to": 1070, "width": 0.87261987}, {"from": 444, "to": 1425, "width": 0.8804783}, {"from": 444, "to": 1701, "width": 0.85893387}, {"from": 444, "to": 1704, "width": 0.8784281}, {"from": 445, "to": 449, "width": 0.871781}, {"from": 447, "to": 513, "width": 0.87196624}, {"from": 447, "to": 517, "width": 0.85696083}, {"from": 447, "to": 532, "width": 0.87125206}, {"from": 447, "to": 677, "width": 0.87414956}, {"from": 447, "to": 717, "width": 0.8972829}, {"from": 447, "to": 972, "width": 0.8558099}, {"from": 447, "to": 1249, "width": 0.85542744}, {"from": 447, "to": 1701, "width": 0.86114806}, {"from": 448, "to": 718, "width": 0.866749}, {"from": 448, "to": 855, "width": 0.8561021}, {"from": 449, "to": 536, "width": 0.9271387}, {"from": 449, "to": 540, "width": 0.88785964}, {"from": 449, "to": 717, "width": 0.8675533}, {"from": 450, "to": 716, "width": 0.8859006}, {"from": 450, "to": 1453, "width": 0.8626575}, {"from": 450, "to": 1556, "width": 0.86939603}, {"from": 452, "to": 490, "width": 0.8942935}, {"from": 452, "to": 723, "width": 0.8613582}, {"from": 452, "to": 1040, "width": 0.8823703}, {"from": 452, "to": 1496, "width": 0.8620797}, {"from": 459, "to": 1017, "width": 0.8826591}, {"from": 459, "to": 1048, "width": 0.8619842}, {"from": 459, "to": 1153, "width": 0.87466997}, {"from": 465, "to": 854, "width": 0.8618699}, {"from": 465, "to": 1343, "width": 0.86754537}, {"from": 465, "to": 1504, "width": 0.87499505}, {"from": 465, "to": 1583, "width": 0.8712132}, {"from": 467, "to": 1466, "width": 0.8556223}, {"from": 474, "to": 552, "width": 0.8598061}, {"from": 474, "to": 1466, "width": 0.8891824}, {"from": 476, "to": 716, "width": 0.8581287}, {"from": 480, "to": 621, "width": 0.9072285}, {"from": 480, "to": 628, "width": 0.8709088}, {"from": 480, "to": 697, "width": 0.8649858}, {"from": 480, "to": 717, "width": 0.8835129}, {"from": 480, "to": 832, "width": 0.8610526}, {"from": 480, "to": 1031, "width": 0.87153023}, {"from": 480, "to": 1425, "width": 0.8719226}, {"from": 480, "to": 1704, "width": 0.85729146}, {"from": 483, "to": 633, "width": 0.8634376}, {"from": 483, "to": 1396, "width": 0.85568905}, {"from": 483, "to": 1417, "width": 0.85890466}, {"from": 483, "to": 1470, "width": 0.8701521}, {"from": 490, "to": 546, "width": 0.85881674}, {"from": 490, "to": 1040, "width": 0.8553055}, {"from": 491, "to": 536, "width": 0.86508584}, {"from": 491, "to": 728, "width": 0.8600355}, {"from": 495, "to": 583, "width": 0.8698994}, {"from": 496, "to": 1701, "width": 0.87074935}, {"from": 500, "to": 804, "width": 0.87578696}, {"from": 500, "to": 996, "width": 0.9024554}, {"from": 500, "to": 1148, "width": 0.8611677}, {"from": 500, "to": 1535, "width": 0.8946905}, {"from": 501, "to": 1620, "width": 0.86842054}, {"from": 502, "to": 1372, "width": 0.87894803}, {"from": 508, "to": 598, "width": 0.879426}, {"from": 508, "to": 654, "width": 0.89010495}, {"from": 508, "to": 664, "width": 0.8578841}, {"from": 508, "to": 877, "width": 0.8688083}, {"from": 508, "to": 963, "width": 0.8619738}, {"from": 508, "to": 975, "width": 0.85805416}, {"from": 508, "to": 1049, "width": 0.87705284}, {"from": 508, "to": 1214, "width": 0.8906899}, {"from": 515, "to": 628, "width": 0.8853335}, {"from": 515, "to": 683, "width": 0.8892879}, {"from": 515, "to": 723, "width": 0.8671911}, {"from": 515, "to": 725, "width": 0.85726273}, {"from": 515, "to": 1180, "width": 0.8648519}, {"from": 517, "to": 985, "width": 0.85764885}, {"from": 517, "to": 1048, "width": 0.8879046}, {"from": 517, "to": 1251, "width": 0.86821467}, {"from": 521, "to": 859, "width": 0.8603363}, {"from": 522, "to": 1187, "width": 0.88594264}, {"from": 527, "to": 1466, "width": 0.8645868}, {"from": 528, "to": 717, "width": 0.8606691}, {"from": 529, "to": 1725, "width": 0.8898942}, {"from": 532, "to": 717, "width": 0.88581914}, {"from": 536, "to": 540, "width": 0.87029415}, {"from": 536, "to": 1598, "width": 0.8755729}, {"from": 537, "to": 719, "width": 0.86120945}, {"from": 541, "to": 628, "width": 0.8678805}, {"from": 541, "to": 717, "width": 0.8665127}, {"from": 546, "to": 582, "width": 0.8578672}, {"from": 546, "to": 725, "width": 0.90123546}, {"from": 546, "to": 727, "width": 0.8948057}, {"from": 546, "to": 1180, "width": 0.86660564}, {"from": 547, "to": 670, "width": 0.8855316}, {"from": 549, "to": 1733, "width": 0.8580116}, {"from": 555, "to": 604, "width": 0.8562436}, {"from": 555, "to": 826, "width": 0.8561216}, {"from": 555, "to": 1226, "width": 0.8947136}, {"from": 555, "to": 1478, "width": 0.90904063}, {"from": 557, "to": 1127, "width": 0.86361057}, {"from": 559, "to": 645, "width": 0.874312}, {"from": 559, "to": 652, "width": 0.85644007}, {"from": 559, "to": 653, "width": 0.86612606}, {"from": 559, "to": 664, "width": 0.8695302}, {"from": 559, "to": 884, "width": 0.8651059}, {"from": 559, "to": 1128, "width": 0.8567243}, {"from": 559, "to": 1383, "width": 0.88439083}, {"from": 560, "to": 1210, "width": 0.87649864}, {"from": 562, "to": 1410, "width": 0.86193085}, {"from": 565, "to": 631, "width": 0.8553363}, {"from": 573, "to": 1687, "width": 0.86244863}, {"from": 574, "to": 628, "width": 0.86317265}, {"from": 574, "to": 814, "width": 0.86169225}, {"from": 574, "to": 1404, "width": 0.8607024}, {"from": 580, "to": 1145, "width": 0.87779963}, {"from": 581, "to": 897, "width": 0.8587668}, {"from": 581, "to": 1039, "width": 0.8604799}, {"from": 581, "to": 1385, "width": 0.87630934}, {"from": 582, "to": 628, "width": 0.8592652}, {"from": 582, "to": 688, "width": 0.8675586}, {"from": 582, "to": 768, "width": 0.8872212}, {"from": 582, "to": 955, "width": 0.8745404}, {"from": 582, "to": 1180, "width": 0.8761017}, {"from": 582, "to": 1247, "width": 0.8809865}, {"from": 582, "to": 1310, "width": 0.8713169}, {"from": 582, "to": 1329, "width": 0.90078914}, {"from": 582, "to": 1632, "width": 0.85718083}, {"from": 583, "to": 832, "width": 0.85926044}, {"from": 588, "to": 1673, "width": 0.86447495}, {"from": 591, "to": 592, "width": 0.87654185}, {"from": 591, "to": 614, "width": 0.8586246}, {"from": 591, "to": 723, "width": 0.8566536}, {"from": 592, "to": 614, "width": 0.8550303}, {"from": 593, "to": 1350, "width": 0.87208414}, {"from": 593, "to": 1470, "width": 0.86363405}, {"from": 594, "to": 915, "width": 0.86753863}, {"from": 594, "to": 951, "width": 0.8741709}, {"from": 595, "to": 686, "width": 0.86393493}, {"from": 601, "to": 955, "width": 0.87213546}, {"from": 602, "to": 614, "width": 0.8572661}, {"from": 602, "to": 1529, "width": 0.88081896}, {"from": 605, "to": 767, "width": 0.89133525}, {"from": 605, "to": 832, "width": 0.8607539}, {"from": 605, "to": 964, "width": 0.87091863}, {"from": 606, "to": 1015, "width": 0.87111294}, {"from": 609, "to": 683, "width": 0.8607606}, {"from": 610, "to": 723, "width": 0.89296615}, {"from": 610, "to": 822, "width": 0.8616248}, {"from": 610, "to": 1453, "width": 0.867858}, {"from": 613, "to": 1629, "width": 0.9076591}, {"from": 614, "to": 945, "width": 0.85837114}, {"from": 614, "to": 1070, "width": 0.8705241}, {"from": 616, "to": 1306, "width": 0.85713774}, {"from": 620, "to": 1436, "width": 0.8703938}, {"from": 621, "to": 717, "width": 0.87394553}, {"from": 622, "to": 818, "width": 0.85793185}, {"from": 622, "to": 1271, "width": 0.85654235}, {"from": 624, "to": 1370, "width": 0.8574093}, {"from": 624, "to": 1464, "width": 0.8938666}, {"from": 626, "to": 1260, "width": 0.8670109}, {"from": 628, "to": 683, "width": 0.8820997}, {"from": 628, "to": 688, "width": 0.88441336}, {"from": 628, "to": 717, "width": 0.86779505}, {"from": 628, "to": 719, "width": 0.8635243}, {"from": 628, "to": 723, "width": 0.8694276}, {"from": 628, "to": 913, "width": 0.8656792}, {"from": 628, "to": 955, "width": 0.8677383}, {"from": 628, "to": 979, "width": 0.89177775}, {"from": 628, "to": 1310, "width": 0.86420935}, {"from": 628, "to": 1425, "width": 0.86234474}, {"from": 628, "to": 1632, "width": 0.87298644}, {"from": 628, "to": 1704, "width": 0.9109067}, {"from": 631, "to": 1343, "width": 0.86021197}, {"from": 631, "to": 1385, "width": 0.8580328}, {"from": 633, "to": 1417, "width": 0.86121225}, {"from": 635, "to": 980, "width": 0.8566024}, {"from": 643, "to": 653, "width": 0.859337}, {"from": 643, "to": 1342, "width": 0.8577915}, {"from": 645, "to": 653, "width": 0.8775134}, {"from": 645, "to": 664, "width": 0.87233937}, {"from": 645, "to": 898, "width": 0.8677722}, {"from": 645, "to": 977, "width": 0.85815257}, {"from": 645, "to": 1342, "width": 0.87055594}, {"from": 645, "to": 1468, "width": 0.8565017}, {"from": 645, "to": 1728, "width": 0.85584927}, {"from": 650, "to": 849, "width": 0.86029935}, {"from": 654, "to": 660, "width": 0.85962933}, {"from": 654, "to": 664, "width": 0.8550914}, {"from": 654, "to": 877, "width": 0.8709212}, {"from": 654, "to": 1214, "width": 0.8559447}, {"from": 658, "to": 729, "width": 0.861711}, {"from": 658, "to": 1327, "width": 0.86448616}, {"from": 659, "to": 1622, "width": 0.8779694}, {"from": 660, "to": 1078, "width": 0.8615564}, {"from": 660, "to": 1108, "width": 0.85539734}, {"from": 660, "to": 1148, "width": 0.8618724}, {"from": 660, "to": 1609, "width": 0.8575919}, {"from": 661, "to": 1008, "width": 0.87949973}, {"from": 664, "to": 779, "width": 0.87604207}, {"from": 664, "to": 977, "width": 0.896903}, {"from": 664, "to": 1214, "width": 0.8717105}, {"from": 664, "to": 1340, "width": 0.85899985}, {"from": 675, "to": 1057, "width": 0.86934024}, {"from": 675, "to": 1278, "width": 0.8570791}, {"from": 675, "to": 1289, "width": 0.8777471}, {"from": 677, "to": 1088, "width": 0.85713434}, {"from": 677, "to": 1236, "width": 0.87114143}, {"from": 677, "to": 1582, "width": 0.8721581}, {"from": 678, "to": 864, "width": 0.8710491}, {"from": 682, "to": 1636, "width": 0.8778699}, {"from": 683, "to": 692, "width": 0.8676413}, {"from": 683, "to": 723, "width": 0.88132083}, {"from": 683, "to": 848, "width": 0.8743209}, {"from": 683, "to": 857, "width": 0.8798564}, {"from": 683, "to": 1498, "width": 0.85784966}, {"from": 686, "to": 1652, "width": 0.8565301}, {"from": 688, "to": 725, "width": 0.86324155}, {"from": 688, "to": 727, "width": 0.8706887}, {"from": 688, "to": 768, "width": 0.858626}, {"from": 688, "to": 1180, "width": 0.8758921}, {"from": 688, "to": 1310, "width": 0.90090024}, {"from": 688, "to": 1632, "width": 0.8756665}, {"from": 689, "to": 891, "width": 0.8663759}, {"from": 689, "to": 1223, "width": 0.8551635}, {"from": 689, "to": 1467, "width": 0.871065}, {"from": 689, "to": 1513, "width": 0.86297786}, {"from": 689, "to": 1625, "width": 0.86129344}, {"from": 692, "to": 768, "width": 0.8672164}, {"from": 692, "to": 1498, "width": 0.8816286}, {"from": 692, "to": 1632, "width": 0.8916472}, {"from": 695, "to": 1155, "width": 0.85502845}, {"from": 695, "to": 1367, "width": 0.86118627}, {"from": 698, "to": 738, "width": 0.86184394}, {"from": 698, "to": 849, "width": 0.87223536}, {"from": 698, "to": 1040, "width": 0.8721332}, {"from": 698, "to": 1477, "width": 0.8674561}, {"from": 699, "to": 831, "width": 0.8950691}, {"from": 703, "to": 1425, "width": 0.87597746}, {"from": 711, "to": 1425, "width": 0.8570442}, {"from": 713, "to": 863, "width": 0.85784966}, {"from": 713, "to": 1253, "width": 0.86705846}, {"from": 716, "to": 1252, "width": 0.85828435}, {"from": 716, "to": 1453, "width": 0.8741567}, {"from": 716, "to": 1556, "width": 0.8856641}, {"from": 717, "to": 723, "width": 0.8774183}, {"from": 717, "to": 1425, "width": 0.8665525}, {"from": 719, "to": 1502, "width": 0.857933}, {"from": 719, "to": 1541, "width": 0.8569592}, {"from": 723, "to": 724, "width": 0.86463004}, {"from": 725, "to": 727, "width": 0.91661626}, {"from": 725, "to": 1310, "width": 0.8688616}, {"from": 726, "to": 1631, "width": 0.85742587}, {"from": 727, "to": 1180, "width": 0.87114453}, {"from": 727, "to": 1310, "width": 0.8716254}, {"from": 728, "to": 1135, "width": 0.87084097}, {"from": 728, "to": 1261, "width": 0.8582349}, {"from": 729, "to": 1114, "width": 0.8569174}, {"from": 734, "to": 855, "width": 0.8562584}, {"from": 736, "to": 929, "width": 0.8718554}, {"from": 738, "to": 807, "width": 0.9111318}, {"from": 738, "to": 849, "width": 0.86553985}, {"from": 738, "to": 860, "width": 0.8555223}, {"from": 741, "to": 1608, "width": 0.8649656}, {"from": 749, "to": 989, "width": 0.8554134}, {"from": 749, "to": 1213, "width": 0.86391926}, {"from": 749, "to": 1667, "width": 0.8688882}, {"from": 751, "to": 1533, "width": 0.85638636}, {"from": 751, "to": 1698, "width": 0.85918885}, {"from": 752, "to": 944, "width": 0.8664219}, {"from": 753, "to": 871, "width": 0.8911375}, {"from": 755, "to": 1721, "width": 0.894498}, {"from": 758, "to": 789, "width": 0.87834704}, {"from": 759, "to": 1649, "width": 0.8639811}, {"from": 767, "to": 832, "width": 0.88551253}, {"from": 768, "to": 955, "width": 0.8810747}, {"from": 768, "to": 979, "width": 0.87586486}, {"from": 768, "to": 1310, "width": 0.8720397}, {"from": 768, "to": 1329, "width": 0.8805084}, {"from": 768, "to": 1632, "width": 0.87153536}, {"from": 777, "to": 1153, "width": 0.8975345}, {"from": 779, "to": 1008, "width": 0.8676946}, {"from": 779, "to": 1108, "width": 0.87962323}, {"from": 779, "to": 1350, "width": 0.85564893}, {"from": 779, "to": 1396, "width": 0.8552936}, {"from": 783, "to": 1107, "width": 0.8725707}, {"from": 788, "to": 977, "width": 0.86133456}, {"from": 789, "to": 989, "width": 0.8637404}, {"from": 789, "to": 1075, "width": 0.8630803}, {"from": 789, "to": 1208, "width": 0.8716509}, {"from": 789, "to": 1584, "width": 0.862965}, {"from": 791, "to": 838, "width": 0.8680749}, {"from": 791, "to": 1094, "width": 0.8581847}, {"from": 791, "to": 1221, "width": 0.8633826}, {"from": 797, "to": 1375, "width": 0.86703366}, {"from": 801, "to": 1008, "width": 0.8579455}, {"from": 802, "to": 1320, "width": 0.86766446}, {"from": 802, "to": 1351, "width": 0.8563644}, {"from": 804, "to": 821, "width": 0.87889445}, {"from": 804, "to": 1015, "width": 0.8572475}, {"from": 804, "to": 1247, "width": 0.8754821}, {"from": 815, "to": 1038, "width": 0.8656949}, {"from": 815, "to": 1682, "width": 0.8575715}, {"from": 815, "to": 1725, "width": 0.88853097}, {"from": 818, "to": 891, "width": 0.8586586}, {"from": 818, "to": 1238, "width": 0.8657602}, {"from": 818, "to": 1271, "width": 0.8582813}, {"from": 818, "to": 1625, "width": 0.8618071}, {"from": 826, "to": 1184, "width": 0.88480616}, {"from": 826, "to": 1253, "width": 0.8793186}, {"from": 830, "to": 1690, "width": 0.874007}, {"from": 832, "to": 1031, "width": 0.88537675}, {"from": 832, "to": 1223, "width": 0.9182186}, {"from": 832, "to": 1255, "width": 0.8708542}, {"from": 832, "to": 1291, "width": 0.856526}, {"from": 832, "to": 1466, "width": 0.86323744}, {"from": 832, "to": 1467, "width": 0.86077976}, {"from": 832, "to": 1611, "width": 0.8797093}, {"from": 836, "to": 1707, "width": 0.8669074}, {"from": 838, "to": 1094, "width": 0.9101863}, {"from": 846, "to": 1544, "width": 0.87239516}, {"from": 846, "to": 1581, "width": 0.87800026}, {"from": 848, "to": 1703, "width": 0.8670425}, {"from": 849, "to": 1200, "width": 0.89736485}, {"from": 854, "to": 975, "width": 0.87216157}, {"from": 854, "to": 1009, "width": 0.85987467}, {"from": 854, "to": 1343, "width": 0.8665572}, {"from": 857, "to": 1697, "width": 0.8806805}, {"from": 859, "to": 1174, "width": 0.8627757}, {"from": 859, "to": 1255, "width": 0.8764203}, {"from": 860, "to": 1560, "width": 0.8924974}, {"from": 862, "to": 1552, "width": 0.85647655}, {"from": 863, "to": 1467, "width": 0.90097624}, {"from": 864, "to": 1070, "width": 0.87209505}, {"from": 864, "to": 1184, "width": 0.8773497}, {"from": 864, "to": 1590, "width": 0.85565656}, {"from": 871, "to": 915, "width": 0.8737903}, {"from": 871, "to": 1212, "width": 0.860647}, {"from": 872, "to": 947, "width": 0.8629194}, {"from": 876, "to": 996, "width": 0.8913473}, {"from": 876, "to": 1037, "width": 0.87816614}, {"from": 876, "to": 1205, "width": 0.8557058}, {"from": 876, "to": 1507, "width": 0.85892063}, {"from": 877, "to": 997, "width": 0.92121476}, {"from": 877, "to": 1214, "width": 0.92919993}, {"from": 877, "to": 1499, "width": 0.8565715}, {"from": 877, "to": 1504, "width": 0.87048763}, {"from": 877, "to": 1654, "width": 0.8559263}, {"from": 880, "to": 1464, "width": 0.8561857}, {"from": 883, "to": 886, "width": 0.86314917}, {"from": 886, "to": 905, "width": 0.87734485}, {"from": 888, "to": 996, "width": 0.8606347}, {"from": 888, "to": 1107, "width": 0.85951555}, {"from": 890, "to": 1394, "width": 0.88439286}, {"from": 890, "to": 1694, "width": 0.8796158}, {"from": 891, "to": 961, "width": 0.8631248}, {"from": 891, "to": 1009, "width": 0.87816536}, {"from": 891, "to": 1343, "width": 0.87152326}, {"from": 897, "to": 1030, "width": 0.88943857}, {"from": 897, "to": 1238, "width": 0.8777063}, {"from": 899, "to": 1532, "width": 0.86319757}, {"from": 906, "to": 997, "width": 0.8596527}, {"from": 906, "to": 1214, "width": 0.86491036}, {"from": 908, "to": 1425, "width": 0.8704586}, {"from": 913, "to": 1226, "width": 0.86137795}, {"from": 923, "to": 1385, "width": 0.8589046}, {"from": 923, "to": 1682, "width": 0.8784578}, {"from": 926, "to": 1194, "width": 0.8758046}, {"from": 937, "to": 1205, "width": 0.8629231}, {"from": 937, "to": 1350, "width": 0.86235887}, {"from": 943, "to": 1541, "width": 0.8603519}, {"from": 943, "to": 1695, "width": 0.8654734}, {"from": 944, "to": 1025, "width": 0.87882394}, {"from": 944, "to": 1523, "width": 0.8711301}, {"from": 945, "to": 1070, "width": 0.8656181}, {"from": 945, "to": 1502, "width": 0.8577746}, {"from": 945, "to": 1704, "width": 0.8593209}, {"from": 948, "to": 1266, "width": 0.9086786}, {"from": 951, "to": 1108, "width": 0.8880784}, {"from": 951, "to": 1350, "width": 0.86044574}, {"from": 951, "to": 1533, "width": 0.90337586}, {"from": 954, "to": 1068, "width": 0.8691685}, {"from": 955, "to": 1180, "width": 0.88813955}, {"from": 955, "to": 1310, "width": 0.9115356}, {"from": 955, "to": 1703, "width": 0.86180127}, {"from": 957, "to": 1260, "width": 0.85843366}, {"from": 959, "to": 1031, "width": 0.88488406}, {"from": 961, "to": 1008, "width": 0.8550643}, {"from": 961, "to": 1056, "width": 0.867124}, {"from": 962, "to": 1508, "width": 0.8589326}, {"from": 971, "to": 1682, "width": 0.87315035}, {"from": 974, "to": 1009, "width": 0.8557283}, {"from": 975, "to": 1343, "width": 0.8750781}, {"from": 977, "to": 1468, "width": 0.87099737}, {"from": 978, "to": 1034, "width": 0.87298954}, {"from": 980, "to": 1043, "width": 0.9077291}, {"from": 980, "to": 1275, "width": 0.8550366}, {"from": 980, "to": 1289, "width": 0.8656738}, {"from": 980, "to": 1464, "width": 0.8563145}, {"from": 980, "to": 1486, "width": 0.89131856}, {"from": 985, "to": 1625, "width": 0.8660307}, {"from": 986, "to": 1009, "width": 0.865144}, {"from": 988, "to": 1535, "width": 0.8567511}, {"from": 989, "to": 1073, "width": 0.8575854}, {"from": 989, "to": 1449, "width": 0.8666713}, {"from": 989, "to": 1584, "width": 0.85902274}, {"from": 993, "to": 1037, "width": 0.8554689}, {"from": 993, "to": 1385, "width": 0.87492985}, {"from": 993, "to": 1504, "width": 0.898642}, {"from": 993, "to": 1535, "width": 0.8616583}, {"from": 993, "to": 1658, "width": 0.8577654}, {"from": 993, "to": 1682, "width": 0.8822042}, {"from": 995, "to": 1428, "width": 0.87406844}, {"from": 996, "to": 1499, "width": 0.8551388}, {"from": 997, "to": 1163, "width": 0.858982}, {"from": 997, "to": 1214, "width": 0.8881511}, {"from": 1006, "to": 1007, "width": 0.8846134}, {"from": 1008, "to": 1108, "width": 0.8837218}, {"from": 1008, "to": 1417, "width": 0.8771275}, {"from": 1008, "to": 1658, "width": 0.8707525}, {"from": 1009, "to": 1037, "width": 0.856404}, {"from": 1009, "to": 1108, "width": 0.8576572}, {"from": 1009, "to": 1343, "width": 0.87006944}, {"from": 1009, "to": 1426, "width": 0.8665009}, {"from": 1009, "to": 1682, "width": 0.8723801}, {"from": 1014, "to": 1667, "width": 0.8611292}, {"from": 1015, "to": 1108, "width": 0.88905144}, {"from": 1015, "to": 1247, "width": 0.8716798}, {"from": 1025, "to": 1143, "width": 0.8601474}, {"from": 1030, "to": 1238, "width": 0.9109052}, {"from": 1031, "to": 1067, "width": 0.8629805}, {"from": 1037, "to": 1144, "width": 0.8570888}, {"from": 1037, "to": 1158, "width": 0.8718575}, {"from": 1037, "to": 1504, "width": 0.90070164}, {"from": 1039, "to": 1110, "width": 0.8834972}, {"from": 1040, "to": 1565, "width": 0.85869575}, {"from": 1041, "to": 1249, "width": 0.8581531}, {"from": 1043, "to": 1364, "width": 0.86587584}, {"from": 1043, "to": 1370, "width": 0.90128815}, {"from": 1043, "to": 1487, "width": 0.8552563}, {"from": 1048, "to": 1153, "width": 0.867231}, {"from": 1048, "to": 1255, "width": 0.8584323}, {"from": 1048, "to": 1682, "width": 0.8611145}, {"from": 1049, "to": 1716, "width": 0.8561795}, {"from": 1053, "to": 1463, "width": 0.8894412}, {"from": 1056, "to": 1221, "width": 0.85738325}, {"from": 1063, "to": 1224, "width": 0.8716961}, {"from": 1063, "to": 1425, "width": 0.8605082}, {"from": 1068, "to": 1216, "width": 0.86899465}, {"from": 1070, "to": 1099, "width": 0.85648555}, {"from": 1083, "to": 1088, "width": 0.8654148}, {"from": 1083, "to": 1236, "width": 0.8666466}, {"from": 1085, "to": 1502, "width": 0.86092657}, {"from": 1088, "to": 1425, "width": 0.8568662}, {"from": 1094, "to": 1237, "width": 0.87016004}, {"from": 1094, "to": 1479, "width": 0.8583851}, {"from": 1095, "to": 1676, "width": 0.86527914}, {"from": 1107, "to": 1657, "width": 0.85677236}, {"from": 1108, "to": 1350, "width": 0.87302047}, {"from": 1108, "to": 1396, "width": 0.8627948}, {"from": 1110, "to": 1194, "width": 0.86974424}, {"from": 1116, "to": 1167, "width": 0.8831739}, {"from": 1118, "to": 1238, "width": 0.88620156}, {"from": 1124, "to": 1211, "width": 0.8550977}, {"from": 1125, "to": 1298, "width": 0.8551728}, {"from": 1135, "to": 1567, "width": 0.88651145}, {"from": 1144, "to": 1148, "width": 0.865237}, {"from": 1144, "to": 1419, "width": 0.8735657}, {"from": 1146, "to": 1486, "width": 0.8634026}, {"from": 1148, "to": 1419, "width": 0.86443}, {"from": 1148, "to": 1535, "width": 0.8653169}, {"from": 1148, "to": 1682, "width": 0.8732655}, {"from": 1155, "to": 1451, "width": 0.8676027}, {"from": 1158, "to": 1504, "width": 0.86256063}, {"from": 1159, "to": 1214, "width": 0.856874}, {"from": 1160, "to": 1326, "width": 0.8658134}, {"from": 1161, "to": 1500, "width": 0.8570094}, {"from": 1163, "to": 1214, "width": 0.87203574}, {"from": 1172, "to": 1631, "width": 0.89276105}, {"from": 1174, "to": 1255, "width": 0.8633289}, {"from": 1174, "to": 1306, "width": 0.8799485}, {"from": 1174, "to": 1467, "width": 0.8723252}, {"from": 1180, "to": 1247, "width": 0.87013525}, {"from": 1180, "to": 1310, "width": 0.8834673}, {"from": 1199, "to": 1250, "width": 0.8784103}, {"from": 1203, "to": 1243, "width": 0.8640669}, {"from": 1208, "to": 1584, "width": 0.8563584}, {"from": 1208, "to": 1667, "width": 0.88834995}, {"from": 1211, "to": 1499, "width": 0.8979345}, {"from": 1214, "to": 1419, "width": 0.85637873}, {"from": 1214, "to": 1490, "width": 0.8640463}, {"from": 1214, "to": 1499, "width": 0.8678182}, {"from": 1214, "to": 1619, "width": 0.855475}, {"from": 1217, "to": 1551, "width": 0.8981144}, {"from": 1218, "to": 1347, "width": 0.8591066}, {"from": 1218, "to": 1375, "width": 0.859973}, {"from": 1222, "to": 1306, "width": 0.86321926}, {"from": 1223, "to": 1467, "width": 0.9042122}, {"from": 1223, "to": 1611, "width": 0.860516}, {"from": 1226, "to": 1704, "width": 0.87401813}, {"from": 1227, "to": 1581, "width": 0.86514586}, {"from": 1229, "to": 1691, "width": 0.9005033}, {"from": 1248, "to": 1701, "width": 0.8695462}, {"from": 1249, "to": 1426, "width": 0.88266397}, {"from": 1249, "to": 1438, "width": 0.8942319}, {"from": 1249, "to": 1629, "width": 0.8591206}, {"from": 1251, "to": 1417, "width": 0.87219256}, {"from": 1253, "to": 1704, "width": 0.8678791}, {"from": 1270, "to": 1525, "width": 0.8615614}, {"from": 1276, "to": 1505, "width": 0.869907}, {"from": 1277, "to": 1281, "width": 0.8550011}, {"from": 1278, "to": 1565, "width": 0.8576526}, {"from": 1281, "to": 1565, "width": 0.86414284}, {"from": 1290, "to": 1486, "width": 0.899986}, {"from": 1290, "to": 1565, "width": 0.8730056}, {"from": 1298, "to": 1721, "width": 0.86219233}, {"from": 1299, "to": 1412, "width": 0.8895633}, {"from": 1301, "to": 1390, "width": 0.86649907}, {"from": 1316, "to": 1623, "width": 0.8599025}, {"from": 1326, "to": 1625, "width": 0.88000065}, {"from": 1337, "to": 1595, "width": 0.88116175}, {"from": 1343, "to": 1504, "width": 0.8589232}, {"from": 1344, "to": 1523, "width": 0.8829066}, {"from": 1362, "to": 1630, "width": 0.8635156}, {"from": 1385, "to": 1409, "width": 0.8748739}, {"from": 1385, "to": 1504, "width": 0.8840346}, {"from": 1385, "to": 1682, "width": 0.8779766}, {"from": 1395, "to": 1609, "width": 0.86010534}, {"from": 1403, "to": 1714, "width": 0.8570158}, {"from": 1424, "to": 1565, "width": 0.85963583}, {"from": 1425, "to": 1540, "width": 0.87192535}, {"from": 1425, "to": 1704, "width": 0.9037315}, {"from": 1425, "to": 1714, "width": 0.8651053}, {"from": 1438, "to": 1570, "width": 0.88613516}, {"from": 1438, "to": 1598, "width": 0.8786689}, {"from": 1438, "to": 1629, "width": 0.8684754}, {"from": 1438, "to": 1695, "width": 0.8571197}, {"from": 1438, "to": 1701, "width": 0.87538457}, {"from": 1449, "to": 1584, "width": 0.85684055}, {"from": 1464, "to": 1565, "width": 0.85590696}, {"from": 1464, "to": 1691, "width": 0.86015296}, {"from": 1464, "to": 1699, "width": 0.8731922}, {"from": 1477, "to": 1631, "width": 0.87338716}, {"from": 1486, "to": 1487, "width": 0.8571652}, {"from": 1486, "to": 1739, "width": 0.8617542}, {"from": 1499, "to": 1504, "width": 0.861522}, {"from": 1499, "to": 1515, "width": 0.88681066}, {"from": 1504, "to": 1682, "width": 0.86579674}, {"from": 1533, "to": 1646, "width": 0.8688534}, {"from": 1551, "to": 1677, "width": 0.86794513}, {"from": 1565, "to": 1629, "width": 0.8803499}, {"from": 1584, "to": 1617, "width": 0.8629987}, {"from": 1598, "to": 1701, "width": 0.8756066}, {"from": 1632, "to": 1699, "width": 0.8550505}, {"from": 1666, "to": 1667, "width": 0.89218956}, {"from": 1678, "to": 1713, "width": 0.8797274}, {"from": 1682, "to": 1725, "width": 0.85696894}, {"from": 1707, "to": 1737, "width": 0.88651246}]);

        // adding nodes and edges to the graph
        data = {nodes: nodes, edges: edges};

        var options = {"physics": {"stabilization": false, "barnesHut": {"centralGravity": 0.1, "gravitationalConstant": -5000}}, "edges": {"smooth": {"type": "continuous"}}};
        
        

        

        network = new vis.Network(container, data, options);
	 
        
        // make a custom popup
        var popup = document.createElement("div");
        popup.className = 'popup';
        popupTimeout = null;
        popup.addEventListener('mouseover', function () {
            console.log(popup)
            if (popupTimeout !== null) {
                clearTimeout(popupTimeout);
                popupTimeout = null;
            }
        });
        popup.addEventListener('mouseout', function () {
            if (popupTimeout === null) {
                hidePopup();
            }
        });
        container.appendChild(popup);


        // use the popup event to show
        network.on("showPopup", function (params) {
            showPopup(params);
        });

        // use the hide event to hide it
        network.on("hidePopup", function (params) {
            hidePopup();
        });


        // hiding the popup through css
        function hidePopup() {
            popupTimeout = setTimeout(function () { popup.style.display = 'none'; }, 500);
        }

        // showing the popup
        function showPopup(nodeId) {
            // get the data from the vis.DataSet
            var nodeData = nodes.get([nodeId]);
            popup.innerHTML = nodeData[0].title;

            // get the position of the node
            var posCanvas = network.getPositions([nodeId])[nodeId];

            // get the bounding box of the node
            var boundingBox = network.getBoundingBox(nodeId);

            //position tooltip:
            posCanvas.x = posCanvas.x + 0.5 * (boundingBox.right - boundingBox.left);

            // convert coordinates to the DOM space
            var posDOM = network.canvasToDOM(posCanvas);

            // Give it an offset
            posDOM.x += 10;
            posDOM.y -= 20;

            // show and place the tooltip.
            popup.style.display = 'block';
            popup.style.top = posDOM.y + 'px';
            popup.style.left = posDOM.x + 'px';
        }
        


        return network;

    }

    drawGraph();

</script>
</body>
</html>