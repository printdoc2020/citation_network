<html>
<head>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/vis/4.16.1/vis.css" type="text/css" />
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/vis/4.16.1/vis-network.min.js"> </script>
<center>
<h2>Sub Networks</h2>
</center>

<!-- <link rel="stylesheet" href="../node_modules/vis/dist/vis.min.css" type="text/css" />
<script type="text/javascript" src="../node_modules/vis/dist/vis.js"> </script>-->

<style type="text/css">

        #mynetwork {
            width: 100%;
            height: 700px;
            background-color: #ffffff;
            border: 1px solid lightgray;
            position: relative;
            float: left;
        }

        

        

        
        /* position absolute is important and the container has to be relative or absolute as well. */
	    div.popup {
            position:absolute;
            top:0px;
            left:0px;
            display:none;
            background-color:#f5f4ed;
            -moz-border-radius: 3px;
            -webkit-border-radius: 3px;
            border-radius: 3px;
            border: 1px solid #808074;
            box-shadow: 3px 3px 10px rgba(0, 0, 0, 0.2);
	    }

	    /* hide the original tooltip */
	    .vis-network-tooltip {
	      display:none;
	    }
        
</style>

</head>

<body>
<div id = "mynetwork"></div>


<script type="text/javascript">

    // initialize global variables.
    var edges;
    var nodes;
    var network; 
    var container;
    var options, data;

    
    // This method is responsible for drawing the graph, returns the drawn network
    function drawGraph() {
        var container = document.getElementById('mynetwork');
        
        

        // parsing and collecting nodes and edges from the python
        nodes = new vis.DataSet([{"color": "orange", "id": "reference_673", "label": "reference_673", "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 673 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2011.6102435\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Bum chul Kwon;Brian Fisher;Ji Soo Yi; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visual analytic roadblocks for novice investigators; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We have observed increasing interest in visual analytics tools and their applications in investigative analysis. Despite the growing interest and substantial studies regarding the topic, understanding the major roadblocks of using such tools from novice users\u0027 perspectives is still limited. Therefore, we attempted to identify such \u201cvisual analytic roadblocks\u201d for novice users in an investigative analysis scenario. To achieve this goal, we reviewed the existing models, theories, and frameworks that could explain the cognitive processes of human-visualization interaction in investigative analysis. Then, we conducted a qualitative experiment with six novice participants, using a slightly modified version of pair analytics, and analyzed the results through the open-coding method. As a result, we came up with four visual analytic roadblocks and explained these roadblocks using existing cognitive models and theories. We also provided design suggestions to overcome these roadblocks."}, {"color": "blue", "id": "reference_868", "label": "reference_868", "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 868 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.120\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Hans-J\u00f6rg Schulz;Thomas Nocke;Magnus Heitzler;Heidrun Schumann; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: A Design Space of Visualization Tasks; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Knowledge about visualization tasks plays an important role in choosing or building suitable visual representations to pursue them. Yet, tasks are a multi-faceted concept and it is thus not surprising that the many existing task taxonomies and models all describe different aspects of tasks, depending on what these task descriptions aim to capture. This results in a clear need to bring these different aspects together under the common hood of a general design space of visualization tasks, which we propose in this paper. Our design space consists of five design dimensions that characterize the main aspects of tasks and that have so far been distributed across different task descriptions. We exemplify its concrete use by applying our design space in the domain of climate impact research. To this end, we propose interfaces to our design space for different user roles (developers, authors, and end users) that allow users of different levels of expertise to work with it."}, {"color": "blue", "id": "reference_456", "label": "reference_456", "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 456 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2009.111\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Tamara Munzner; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: A Nested Model for Visualization Design and Validation; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present a nested model for the visualization design and validation with four layers: characterize the task and data in the vocabulary of the problem domain, abstract into operations and data types, design visual encoding and interaction techniques, and create algorithms to execute techniques efficiently. The output from a level above is input to the level below, bringing attention to the design challenge that an upstream error inevitably cascades to all downstream levels. This model provides prescriptive guidance for determining appropriate evaluation approaches by identifying threats to validity unique to each level. We also provide three recommendations motivated by this model: authors should distinguish between these levels when claiming contributions at more than one of them, authors should explicitly state upstream assumptions at levels above the focus of a paper, and visualization venues should accept more papers on domain characterization."}, {"color": "blue", "id": "reference_547", "label": "reference_547", "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 547 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2010.179\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Edward Segel;Jeffrey Heer; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Narrative Visualization: Telling Stories with Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Data visualization is regularly promoted for its ability to reveal stories within data, yet these \u201cdata stories\u201d differ in important ways from traditional forms of storytelling. Storytellers, especially online journalists, have increasingly been integrating visualizations into their narratives, in some cases allowing the visualization to function in place of a written story. In this paper, we systematically review the design space of this emerging class of visualizations. Drawing on case studies from news media to visualization research, we identify distinct genres of narrative visualization. We characterize these design differences, together with interactivity and messaging, in terms of the balance between the narrative flow intended by the author (imposed by graphical elements and the interface) and story discovery on the part of the reader (often through interactive exploration). Our framework suggests design strategies for narrative visualization, including promising under-explored approaches to journalistic storytelling and educational media."}, {"color": "orange", "id": "reference_1040", "label": "reference_1040", "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1040 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346481\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Dominik Sacha;Andreas Stoffel;Florian Stoffel;Bum Chul Kwon;Geoffrey Ellis;Daniel A. Keim; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Knowledge Generation Model for Visual Analytics; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Visual analytics enables us to analyze huge information spaces in order to support complex decision making and data exploration. Humans play a central role in generating knowledge from the snippets of evidence emerging from visual data analysis. Although prior research provides frameworks that generalize this process, their scope is often narrowly focused so they do not encompass different perspectives at different levels. This paper proposes a knowledge generation model for visual analytics that ties together these diverse frameworks, yet retains previously developed models (e.g., KDD process) to describe individual segments of the overall visual analytic processes. To test its utility, a real world visual analytics system is compared against the model, demonstrating that the knowledge generation process model provides a useful guideline when developing and evaluating such systems. The model is used to effectively compare different data analysis systems. Furthermore, the model provides a common language and description of visual analytic processes, which can be used for communication between researchers. At the end, our model reflects areas of research that future researchers can embark on."}, {"color": "blue", "id": "reference_872", "label": "reference_872", "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 872 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.124\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Matthew Brehmer;Tamara Munzner; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: A Multi-Level Typology of Abstract Visualization Tasks; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The considerable previous work characterizing visualization usage has focused on low-level tasks or interactions and high-level tasks, leaving a gap between them that is not addressed. This gap leads to a lack of distinction between the ends and means of a task, limiting the potential for rigorous analysis. We contribute a multi-level typology of visualization tasks to address this gap, distinguishing why and how a visualization task is performed, as well as what the task inputs and outputs are. Our typology allows complex tasks to be expressed as sequences of interdependent simpler tasks, resulting in concise and flexible descriptions for tasks of varying complexity and scope. It provides abstract rather than domain-specific descriptions of tasks, so that useful comparisons can be made between visualization systems targeted at different application domains. This descriptive power supports a level of analysis required for the generation of new designs, by guiding the translation of domain-specific problems into abstract tasks, and for the qualitative evaluation of visualization usage. We demonstrate the benefits of our approach in a detailed case study, comparing task descriptions from our typology to those derived from related work. We also discuss the similarities and differences between our typology and over two dozen extant classification systems and theoretical frameworks from the literatures of visualization, human-computer interaction, information retrieval, communications, and cartography."}, {"color": "blue", "id": "reference_746", "label": "reference_746", "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 746 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2012.204\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Bongshin Lee;Petra Isenberg;Nathalie Henry Riche;Sheelagh Carpendale; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Beyond Mouse and Keyboard: Expanding Design Considerations for Information Visualization Interactions; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The importance of interaction to Information Visualization (InfoVis) and, in particular, of the interplay between interactivity and cognition is widely recognized [12, 15, 32, 55, 70]. This interplay, combined with the demands from increasingly large and complex datasets, is driving the increased significance of interaction in InfoVis. In parallel, there have been rapid advances in many facets of interaction technologies. However, InfoVis interactions have yet to take full advantage of these new possibilities in interaction technologies, as they largely still employ the traditional desktop, mouse, and keyboard setup of WIMP (Windows, Icons, Menus, and a Pointer) interfaces. In this paper, we reflect more broadly about the role of more \u201cnatural\u201d interactions for InfoVis and provide opportunities for future research. We discuss and relate general HCI interaction models to existing InfoVis interaction classifications by looking at interactions from a novel angle, taking into account the entire spectrum of interactions. Our discussion of InfoVis-specific interaction design considerations helps us identify a series of underexplored attributes of interaction that can lead to new, more \u201cnatural,\u201d interaction techniques for InfoVis."}, {"color": "blue", "id": "reference_307", "label": "reference_307", "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 307 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2007.70515\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Ji Soo Yi;Youn ah Kang;John Stasko; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Toward a Deeper Understanding of the Role of Interaction in Information Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Even though interaction is an important part of information visualization (Infovis), it has garnered a relatively low level of attention from the Infovis community. A few frameworks and taxonomies of Infovis interaction techniques exist, but they typically focus on low-level operations and do not address the variety of benefits interaction provides. After conducting an extensive review of Infovis systems and their interactive capabilities, we propose seven general categories of interaction techniques widely used in Infovis: 1) Select, 2) Explore, 3) Reconfigure, 4) Encode, 5) Abstract/Elaborate, 6) Filter, and 7) Connect. These categories are organized around a user\u0027s intent while interacting with a system rather than the low-level interaction techniques provided by a system. The categories can act as a framework to help discuss and evaluate interaction techniques and hopefully lay an initial foundation toward a deeper understanding and a science of interaction."}, {"color": "blue", "id": "reference_550", "label": "reference_550", "shape": "dot", "size": "35", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 550 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2010.177\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Zhicheng Liu;John Stasko; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Mental Models; Visual Reasoning and Interaction in Information Visualization: A Top-down Perspective; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Although previous research has suggested that examining the interplay between internal and external representations can benefit our understanding of the role of information visualization (InfoVis) in human cognitive activities, there has been little work detailing the nature of internal representations, the relationship between internal and external representations and how interaction is related to these representations. In this paper, we identify and illustrate a specific kind of internal representation, mental models, and outline the high-level relationships between mental models and external visualizations. We present a top-down perspective of reasoning as model construction and simulation, and discuss the role of visualization in model based reasoning. From this perspective, interaction can be understood as active modeling for three primary purposes: external anchoring, information foraging, and cognitive offloading. Finally we discuss the implications of our approach for design, evaluation and theory development."}, {"color": "blue", "id": "reference_238", "label": "reference_238", "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 238 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2005.1532136\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: R. Amar;J. Eagan;J. Stasko; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Low-level components of analytic activity in information visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Existing system level taxonomies of visualization tasks are geared more towards the design of particular representations than the facilitation of user analytic activity. We present a set of ten low level analysis tasks that largely capture people\u0027s activities while employing information visualization tools for understanding data. To help develop these tasks, we collected nearly 200 sample questions from students about how they would analyze five particular data sets from different domains. The questions, while not being totally comprehensive, illustrated the sheer variety of analytic questions typically posed by users when employing information visualization systems. We hope that the presented set of tasks is useful for information visualization system designers as a kind of common substrate to discuss the relative analytic capabilities of the systems. Further, the tasks may provide a form of checklist for system designers."}, {"color": "blue", "id": "reference_380", "label": "reference_380", "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 380 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2008.109\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Heidi Lam; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: A Framework of Interaction Costs in Information Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Interaction cost is an important but poorly understood factor in visualization design. We propose a framework of interaction costs inspired by Normanpsilas Seven Stages of Action to facilitate study. From 484 papers, we collected 61 interaction-related usability problems reported in 32 user studies and placed them into our framework of seven costs: (1) Decision costs to form goals; (2) system-power costs to form system operations; (3) Multiple input mode costs to form physical sequences; (4) Physical-motion costs to execute sequences; (5) Visual-cluttering costs to perceive state; (6) View-change costs to interpret perception; (7) State-change costs to evaluate interpretation. We also suggested ways to narrow the gulfs of execution (2-4) and evaluation (5-7) based on collected reports. Our framework suggests a need to consider decision costs (1) as the gulf of goal formation."}, {"color": "blue", "id": "reference_551", "label": "reference_551", "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 551 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2010.164\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Lars Grammel;Melanie Tory;Margaret-Anne Storey; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: How Information Visualization Novices Construct Visualizations; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: It remains challenging for information visualization novices to rapidly construct visualizations during exploratory data analysis. We conducted an exploratory laboratory study in which information visualization novices explored fictitious sales data by communicating visualization specifications to a human mediator, who rapidly constructed the visualizations using commercial visualization software. We found that three activities were central to the iterative visualization construction process: data attribute selection, visual template selection, and visual mapping specification. The major barriers faced by the participants were translating questions into data attributes, designing visual mappings, and interpreting the visualizations. Partial specification was common, and the participants used simple heuristics and preferred visualizations they were already familiar with, such as bar, line and pie charts. We derived abstract models from our observations that describe barriers in the data exploration process and uncovered how information visualization novices think about visualization specifications. Our findings support the need for tools that suggest potential visualizations and support iterative refinement, that provide explanations and help with learning, and that are tightly integrated into tool support for the overall visual analytics process."}]);
        edges = new vis.DataSet([{"color": "gray", "from": "reference_238", "title": "", "to": "reference_307", "width": 16.0}, {"color": "gray", "from": "reference_238", "title": "", "to": "reference_380", "width": 7.0}, {"color": "gray", "from": "reference_238", "title": "", "to": "reference_456", "width": 6.0}, {"color": "gray", "from": "reference_238", "title": "", "to": "reference_550", "width": 4.0}, {"color": "gray", "from": "reference_238", "title": "", "to": "reference_551", "width": 8.0}, {"color": "gray", "from": "reference_238", "title": "", "to": "reference_746", "width": 8.0}, {"color": "gray", "from": "reference_238", "title": "", "to": "reference_868", "width": 6.0}, {"color": "gray", "from": "reference_238", "title": "", "to": "reference_872", "width": 13.0}, {"color": "gray", "from": "reference_307", "title": "", "to": "reference_380", "width": 10.0}, {"color": "gray", "from": "reference_307", "title": "", "to": "reference_456", "width": 5.0}, {"color": "gray", "from": "reference_307", "title": "", "to": "reference_547", "width": 4.0}, {"color": "green", "from": "reference_307", "title": "John Stasko", "to": "reference_550", "width": 5.0}, {"color": "gray", "from": "reference_307", "title": "", "to": "reference_551", "width": 6.0}, {"color": "gray", "from": "reference_307", "title": "", "to": "reference_746", "width": 4.0}, {"color": "gray", "from": "reference_307", "title": "", "to": "reference_872", "width": 7.0}, {"color": "gray", "from": "reference_307", "title": "", "to": "reference_1040", "width": 5.0}, {"color": "gray", "from": "reference_380", "title": "", "to": "reference_456", "width": 5.0}, {"color": "gray", "from": "reference_380", "title": "", "to": "reference_550", "width": 4.0}, {"color": "gray", "from": "reference_380", "title": "", "to": "reference_551", "width": 5.0}, {"color": "gray", "from": "reference_380", "title": "", "to": "reference_673", "width": 5.0}, {"color": "gray", "from": "reference_380", "title": "", "to": "reference_746", "width": 4.0}, {"color": "gray", "from": "reference_380", "title": "", "to": "reference_872", "width": 4.0}, {"color": "gray", "from": "reference_456", "title": "", "to": "reference_550", "width": 7.0}, {"color": "gray", "from": "reference_456", "title": "", "to": "reference_551", "width": 5.0}, {"color": "gray", "from": "reference_456", "title": "", "to": "reference_868", "width": 10.0}, {"color": "green", "from": "reference_456", "title": "Tamara Munzner", "to": "reference_872", "width": 14.0}, {"color": "gray", "from": "reference_547", "title": "", "to": "reference_550", "width": 4.0}, {"color": "gray", "from": "reference_547", "title": "", "to": "reference_551", "width": 6.0}, {"color": "gray", "from": "reference_550", "title": "", "to": "reference_551", "width": 6.0}, {"color": "gray", "from": "reference_550", "title": "", "to": "reference_673", "width": 5.0}, {"color": "gray", "from": "reference_550", "title": "", "to": "reference_746", "width": 4.0}, {"color": "gray", "from": "reference_550", "title": "", "to": "reference_868", "width": 4.0}, {"color": "gray", "from": "reference_550", "title": "", "to": "reference_872", "width": 6.0}, {"color": "gray", "from": "reference_550", "title": "", "to": "reference_1040", "width": 4.0}, {"color": "gray", "from": "reference_551", "title": "", "to": "reference_673", "width": 7.0}, {"color": "gray", "from": "reference_551", "title": "", "to": "reference_746", "width": 4.0}, {"color": "gray", "from": "reference_551", "title": "", "to": "reference_868", "width": 5.0}, {"color": "gray", "from": "reference_551", "title": "", "to": "reference_872", "width": 11.0}, {"color": "gray", "from": "reference_551", "title": "", "to": "reference_1040", "width": 4.0}, {"color": "gray", "from": "reference_673", "title": "", "to": "reference_872", "width": 7.0}, {"color": "gray", "from": "reference_673", "title": "", "to": "reference_1040", "width": 7.0}, {"color": "gray", "from": "reference_746", "title": "", "to": "reference_872", "width": 5.0}, {"color": "gray", "from": "reference_868", "title": "", "to": "reference_872", "width": 16.0}, {"color": "gray", "from": "reference_872", "title": "", "to": "reference_1040", "width": 6.0}]);

        // adding nodes and edges to the graph
        data = {nodes: nodes, edges: edges};

        var options = {
    "configure": {
        "enabled": false
    },
    "edges": {
        "color": {
            "inherit": true
        },
        "smooth": {
            "enabled": true,
            "type": "dynamic"
        }
    },
    "interaction": {
        "dragNodes": true,
        "hideEdgesOnDrag": false,
        "hideNodesOnDrag": false
    },
    "physics": {
        "enabled": true,
        "stabilization": {
            "enabled": true,
            "fit": true,
            "iterations": 1000,
            "onlyDynamicEdges": false,
            "updateInterval": 50
        }
    }
};
        
        

        

        network = new vis.Network(container, data, options);
	 
        
        // make a custom popup
        var popup = document.createElement("div");
        popup.className = 'popup';
        popupTimeout = null;
        popup.addEventListener('mouseover', function () {
            console.log(popup)
            if (popupTimeout !== null) {
                clearTimeout(popupTimeout);
                popupTimeout = null;
            }
        });
        popup.addEventListener('mouseout', function () {
            if (popupTimeout === null) {
                hidePopup();
            }
        });
        container.appendChild(popup);


        // use the popup event to show
        network.on("showPopup", function (params) {
            showPopup(params);
        });

        // use the hide event to hide it
        network.on("hidePopup", function (params) {
            hidePopup();
        });


        // hiding the popup through css
        function hidePopup() {
            popupTimeout = setTimeout(function () { popup.style.display = 'none'; }, 500);
        }

        // showing the popup
        function showPopup(nodeId) {
            // get the data from the vis.DataSet
            var nodeData = nodes.get([nodeId]);
            popup.innerHTML = nodeData[0].title;

            // get the position of the node
            var posCanvas = network.getPositions([nodeId])[nodeId];

            // get the bounding box of the node
            var boundingBox = network.getBoundingBox(nodeId);

            //position tooltip:
            posCanvas.x = posCanvas.x + 0.5 * (boundingBox.right - boundingBox.left);

            // convert coordinates to the DOM space
            var posDOM = network.canvasToDOM(posCanvas);

            // Give it an offset
            posDOM.x += 10;
            posDOM.y -= 20;

            // show and place the tooltip.
            popup.style.display = 'block';
            popup.style.top = posDOM.y + 'px';
            popup.style.left = posDOM.x + 'px';
        }
        


        return network;

    }

    drawGraph();

</script>
</body>
</html>