<html>
<head>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/vis/4.16.1/vis.css" type="text/css" />
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/vis/4.16.1/vis-network.min.js"> </script>
<center>
<h2>Sub Networks</h2>
</center>

<!-- <link rel="stylesheet" href="../node_modules/vis/dist/vis.min.css" type="text/css" />
<script type="text/javascript" src="../node_modules/vis/dist/vis.js"> </script>-->

<style type="text/css">

        #mynetwork {
            width: 100%;
            height: 700px;
            background-color: #ffffff;
            border: 1px solid lightgray;
            position: relative;
            float: left;
        }

        

        

        
        /* position absolute is important and the container has to be relative or absolute as well. */
	    div.popup {
            position:absolute;
            top:0px;
            left:0px;
            display:none;
            background-color:#f5f4ed;
            -moz-border-radius: 3px;
            -webkit-border-radius: 3px;
            border-radius: 3px;
            border: 1px solid #808074;
            box-shadow: 3px 3px 10px rgba(0, 0, 0, 0.2);
	    }

	    /* hide the original tooltip */
	    .vis-network-tooltip {
	      display:none;
	    }
        
</style>

</head>

<body>
<div id = "mynetwork"></div>


<script type="text/javascript">

    // initialize global variables.
    var edges;
    var nodes;
    var network; 
    var container;
    var options, data;

    
    // This method is responsible for drawing the graph, returns the drawn network
    function drawGraph() {
        var container = document.getElementById('mynetwork');
        
        

        // parsing and collecting nodes and edges from the python
        nodes = new vis.DataSet([{"color": "orange", "id": "doc_620", "label": "doc_620", "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 620 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2010.5652958\" target=\"_blank\"\u003eLink\u003c/a\u003e\u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Dong Hyun Jeong;Evan Suma;Thomas Butkiewicz;William Ribarsky;Remco Chang\u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: A continuous analysis process between desktop and collaborative visual analytics environments\u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Since its inception, the field of visual analytics has undergone tremendous growth in understanding how to create interactive visual tools to solve analytical problems. However, with few exceptions, most of these tools have been designed for single users in desktop environments. While often effective on their own, most single-user systems do not reflect the collaborative nature of solving real-world analytical tasks. Many intelligence analysts, for example, have been observed to switch repeatedly between working alone and collaborating with members of a small team. In this paper, we propose that a complete visual analytical system designed for solving real-world tasks ought to have two integrated components: a single-user desktop system and a mirroring system suitable for a collaborative environment."}, {"color": "orange", "id": "ref_1514", "label": "ref_1514", "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1514 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2864812\" target=\"_blank\"\u003eLink\u003c/a\u003e\u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Yao Ming;Huamin Qu;Enrico Bertini\u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: RuleMatrix: Visualizing and Understanding Classifiers with Rules\u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: With the growing adoption of machine learning techniques, there is a surge of research interest towards making machine learning systems more transparent and interpretable. Various visualizations have been developed to help model developers understand, diagnose, and refine machine learning models. However, a large number of potential but neglected users are the domain experts with little knowledge of machine learning but are expected to work with machine learning systems. In this paper, we present an interactive visualization technique to help users with little expertise in machine learning to understand, explore and validate predictive models. By viewing the model as a black box, we extract a standardized rule-based knowledge representation from its input-output behavior. Then, we design RuleMatrix, a matrix-based visualization of rules to help users navigate and verify the rules and the black-box model. We evaluate the effectiveness of RuleMatrix via two use cases and a usability study."}, {"color": "orange", "id": "ref_1488", "label": "ref_1488", "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1488 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2017.8585721\" target=\"_blank\"\u003eLink\u003c/a\u003e\u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Yao Ming;Shaozu Cao;Ruixiang Zhang;Zhen Li;Yuanzhe Chen;Yangqiu Song;Huamin Qu\u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Understanding Hidden Memories of Recurrent Neural Networks\u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Recurrent neural networks (RNNs) have been successfully applied to various natural language processing (NLP) tasks and achieved better results than conventional methods. However, the lack of understanding of the mechanisms behind their effectiveness limits further improvements on their architectures. In this paper, we present a visual analytics method for understanding and comparing RNN models for NLP tasks. We propose a technique to explain the function of individual hidden state units based on their expected response to input texts. We then co-cluster hidden state units and words based on the expected response and visualize co-clustering results as memory chips and word clouds to provide more structured knowledge on RNNs\u0027 hidden states. We also propose a glyph-based sequence visualization based on aggregate information to analyze the behavior of an RNN\u0027s hidden state at the sentence-level. The usability and effectiveness of our method are demonstrated through case studies and reviews from domain experts."}, {"color": "orange", "id": "ref_1444", "label": "ref_1444", "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1444 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2744938\" target=\"_blank\"\u003eLink\u003c/a\u003e\u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Mengchen Liu;Jiaxin Shi;Kelei Cao;Jun Zhu;Shixia Liu\u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Analyzing the Training Processes of Deep Generative Models\u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Among the many types of deep models, deep generative models (DGMs) provide a solution to the important problem of unsupervised and semi-supervised learning. However, training DGMs requires more skill, experience, and know-how because their training is more complex than other types of deep models such as convolutional neural networks (CNNs). We develop a visual analytics approach for better understanding and diagnosing the training process of a DGM. To help experts understand the overall training process, we first extract a large amount of time series data that represents training dynamics (e.g., activation changes over time). A blue-noise polyline sampling scheme is then introduced to select time series samples, which can both preserve outliers and reduce visual clutter. To further investigate the root cause of a failed training process, we propose a credit assignment algorithm that indicates how other neurons contribute to the output of the neuron causing the training failure. Two case studies are conducted with machine learning experts to demonstrate how our approach helps understand and diagnose the training processes of DGMs. We also show how our approach can be directly used to analyze other types of deep models, such as CNNs."}, {"color": "orange", "id": "doc_1436", "label": "doc_1436", "shape": "dot", "size": 32, "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1436 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2744718\" target=\"_blank\"\u003eLink\u003c/a\u003e\u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Minsuk Kahng;Pierre Y. Andrews;Aditya Kalro;Duen Horng (Polo) Chau\u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: ActiVis: Visual Exploration of Industry-Scale Deep Neural Network Models\u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: While deep learning models have achieved state-of-the-art accuracies for many prediction tasks, understanding these models remains a challenge. Despite the recent interest in developing visual tools to help users interpret deep learning models, the complexity and wide variety of models deployed in industry, and the large-scale datasets that they used, pose unique design challenges that are inadequately addressed by existing work. Through participatory design sessions with over 15 researchers and engineers at Facebook, we have developed, deployed, and iteratively improved ActiVis, an interactive visualization system for interpreting large-scale deep learning models and results. By tightly integrating multiple coordinated views, such as a computation graph overview of the model architecture, and a neuron activation view for pattern discovery and comparison, users can explore complex deep neural network models at both the instance-and subset-level. ActiVis has been deployed on Facebook\u0027s machine learning platform. We present case studies with Facebook researchers and engineers, and usage scenarios of how ActiVis may work with different models."}, {"color": "orange", "id": "ref_1432", "label": "ref_1432", "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1432 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2744683\" target=\"_blank\"\u003eLink\u003c/a\u003e\u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Alsallakh Bilal;Amin Jourabloo;Mao Ye;Xiaoming Liu;Liu Ren\u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Do Convolutional Neural Networks Learn Class Hierarchy?\u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Convolutional Neural Networks (CNNs) currently achieve state-of-the-art accuracy in image classification. With a growing number of classes, the accuracy usually drops as the possibilities of confusion increase. Interestingly, the class confusion patterns follow a hierarchical structure over the classes. We present visual-analytics methods to reveal and analyze this hierarchy of similar classes in relation with CNN-internal data. We found that this hierarchy not only dictates the confusion patterns between the classes, it furthermore dictates the learning behavior of CNNs. In particular, the early layers in these networks develop feature detectors that can separate high-level groups of classes quite well, even after a few training epochs. In contrast, the latter layers require substantially more epochs to develop specialized feature detectors that can separate individual classes. We demonstrate how these insights are key to significant improvement in accuracy by designing hierarchy-aware CNNs that accelerate model convergence and alleviate overfitting. We further demonstrate how our methods help in identifying various quality issues in the training data."}, {"color": "orange", "id": "ref_1421", "label": "ref_1421", "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1421 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2744358\" target=\"_blank\"\u003eLink\u003c/a\u003e\u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Nicola Pezzotti;Thomas H\u00f6llt;Jan Van Gemert;Boudewijn P.F. Lelieveldt;Elmar Eisemann;Anna Vilanova\u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: DeepEyes: Progressive Visual Analytics for Designing Deep Neural Networks\u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Deep neural networks are now rivaling human accuracy in several pattern recognition problems. Compared to traditional classifiers, where features are handcrafted, neural networks learn increasingly complex features directly from the data. Instead of handcrafting the features, it is now the network architecture that is manually engineered. The network architecture parameters such as the number of layers or the number of filters per layer and their interconnections are essential for good performance. Even though basic design guidelines exist, designing a neural network is an iterative trial-and-error process that takes days or even weeks to perform due to the large datasets used for training. In this paper, we present DeepEyes, a Progressive Visual Analytics system that supports the design of neural networks during training. We present novel visualizations, supporting the identification of layers that learned a stable set of patterns and, therefore, are of interest for a detailed analysis. The system facilitates the identification of problems, such as superfluous filters or layers, and information that is not being captured by the network. We demonstrate the effectiveness of our system through multiple use cases, showing how a trained network can be compressed, reshaped and adapted to different problems."}, {"color": "orange", "id": "ref_1442", "label": "ref_1442", "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1442 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2744878\" target=\"_blank\"\u003eLink\u003c/a\u003e\u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Kanit Wongsuphasawat;Daniel Smilkov;James Wexler;Jimbo Wilson;Dandelion Man\u00e9;Doug Fritz;Dilip Krishnan;Fernanda B. Vi\u00e9gas;Martin Wattenberg\u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visualizing Dataflow Graphs of Deep Learning Models in TensorFlow\u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present a design study of the TensorFlow Graph Visualizer, part of the TensorFlow machine intelligence platform. This tool helps users understand complex machine learning architectures by visualizing their underlying dataflow graphs. The tool works by applying a series of graph transformations that enable standard layout techniques to produce a legible interactive diagram. To declutter the graph, we decouple non-critical nodes from the layout. To provide an overview, we build a clustered graph using the hierarchical structure annotated in the source code. To support exploration of nested structure on demand, we perform edge bundling to enable stable and responsive cluster expansion. Finally, we detect and highlight repeated structures to emphasize a model\u0027s modular composition. To demonstrate the utility of the visualizer, we describe example usage scenarios and report user feedback. Overall, users find the visualizer useful for understanding, debugging, and sharing the structures of their models."}, {"color": "orange", "id": "ref_1328", "label": "ref_1328", "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1328 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2598838\" target=\"_blank\"\u003eLink\u003c/a\u003e\u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Paulo E. Rauber;Samuel G. Fadel;Alexandre X. Falc\u00e3o;Alexandru C. Telea\u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visualizing the Hidden Activity of Artificial Neural Networks\u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In machine learning, pattern classification assigns high-dimensional vectors (observations) to classes based on generalization from examples. Artificial neural networks currently achieve state-of-the-art results in this task. Although such networks are typically used as black-boxes, they are also widely believed to learn (high-dimensional) higher-level representations of the original observations. In this paper, we propose using dimensionality reduction for two tasks: visualizing the relationships between learned representations of observations, and visualizing the relationships between artificial neurons. Through experiments conducted in three traditional image classification benchmark datasets, we show how visualization can provide highly valuable feedback for network designers. For instance, our discoveries in one of these datasets (SVHN) include the presence of interpretable clusters of learned representations, and the partitioning of artificial neurons into groups with apparently related discriminative roles."}, {"color": "blue", "id": "ref_1403", "label": "ref_1403", "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1403 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2744158\" target=\"_blank\"\u003eLink\u003c/a\u003e\u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Hendrik Strobelt;Sebastian Gehrmann;Hanspeter Pfister;Alexander M. Rush\u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: LSTMVis: A Tool for Visual Analysis of Hidden State Dynamics in Recurrent Neural Networks\u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Recurrent neural networks, and in particular long short-term memory (LSTM) networks, are a remarkably effective tool for sequence modeling that learn a dense black-box hidden representation of their sequential input. Researchers interested in better understanding these models have studied the changes in hidden state representations over time and noticed some interpretable patterns but also significant noise. In this work, we present LSTMVis, a visual analysis tool for recurrent neural networks with a focus on understanding these hidden state dynamics. The tool allows users to select a hypothesis input range to focus on local state changes, to match these states changes to similar patterns in a large data set, and to align these results with structural annotations from their domain. We show several use cases of the tool for analyzing specific hidden state properties on dataset containing nesting, phrase structure, and chord progressions, and demonstrate how the tool can be used to isolate patterns for further statistical analysis. We characterize the domain, the different stakeholders, and their goals and tasks. Long-term usage data after putting the tool online revealed great interest in the machine learning community."}, {"color": "orange", "id": "ref_1423", "label": "ref_1423", "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1423 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2744378\" target=\"_blank\"\u003eLink\u003c/a\u003e\u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Shixia Liu;Jiannan Xiao;Junlin Liu;Xiting Wang;Jing Wu;Jun Zhu\u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visual Diagnosis of Tree Boosting Methods\u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Tree boosting, which combines weak learners (typically decision trees) to generate a strong learner, is a highly effective and widely used machine learning method. However, the development of a high performance tree boosting model is a time-consuming process that requires numerous trial-and-error experiments. To tackle this issue, we have developed a visual diagnosis tool, BOOSTVis, to help experts quickly analyze and diagnose the training process of tree boosting. In particular, we have designed a temporal confusion matrix visualization, and combined it with a t-SNE projection and a tree visualization. These visualization components work together to provide a comprehensive overview of a tree boosting model, and enable an effective diagnosis of an unsatisfactory training process. Two case studies that were conducted on the Otto Group Product Classification Challenge dataset demonstrate that BOOSTVis can provide informative feedback and guidance to improve understanding and diagnosis of tree boosting algorithms."}, {"color": "orange", "id": "ref_1324", "label": "ref_1324", "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1324 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2598828\" target=\"_blank\"\u003eLink\u003c/a\u003e\u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Donghao Ren;Saleema Amershi;Bongshin Lee;Jina Suh;Jason D. Williams\u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Squares: Supporting Interactive Performance Analysis for Multiclass Classifiers\u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Performance analysis is critical in applied machine learning because it influences the models practitioners produce. Current performance analysis tools suffer from issues including obscuring important characteristics of model behavior and dissociating performance from data. In this work, we present Squares, a performance visualization for multiclass classification problems. Squares supports estimating common performance metrics while displaying instance-level distribution information necessary for helping practitioners prioritize efforts and access data. Our controlled study shows that practitioners can assess performance significantly faster and more accurately with Squares than a confusion matrix, a common performance analysis tool in machine learning."}, {"color": "orange", "id": "ref_1327", "label": "ref_1327", "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1327 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2598831\" target=\"_blank\"\u003eLink\u003c/a\u003e\u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Mengchen Liu;Jiaxin Shi;Zhen Li;Chongxuan Li;Jun Zhu;Shixia Liu\u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Towards Better Analysis of Deep Convolutional Neural Networks\u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Deep convolutional neural networks (CNNs) have achieved breakthrough performance in many pattern recognition tasks such as image classification. However, the development of high-quality deep models typically relies on a substantial amount of trial-and-error, as there is still no clear understanding of when and why a deep model works. In this paper, we present a visual analytics approach for better understanding, diagnosing, and refining deep CNNs. We formulate a deep CNN as a directed acyclic graph. Based on this formulation, a hybrid visualization is developed to disclose the multiple facets of each neuron and the interactions between them. In particular, we introduce a hierarchical rectangle packing algorithm and a matrix reordering algorithm to show the derived features of a neuron cluster. We also propose a biclustering-based edge bundling method to reduce visual clutter caused by a large number of connections between neurons. We evaluated our method on a set of CNNs and the results are generally favorable."}, {"color": "orange", "id": "ref_1436", "label": "ref_1436", "shape": "dot", "size": 32, "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1436 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2744718\" target=\"_blank\"\u003eLink\u003c/a\u003e\u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Minsuk Kahng;Pierre Y. Andrews;Aditya Kalro;Duen Horng (Polo) Chau\u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: ActiVis: Visual Exploration of Industry-Scale Deep Neural Network Models\u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: While deep learning models have achieved state-of-the-art accuracies for many prediction tasks, understanding these models remains a challenge. Despite the recent interest in developing visual tools to help users interpret deep learning models, the complexity and wide variety of models deployed in industry, and the large-scale datasets that they used, pose unique design challenges that are inadequately addressed by existing work. Through participatory design sessions with over 15 researchers and engineers at Facebook, we have developed, deployed, and iteratively improved ActiVis, an interactive visualization system for interpreting large-scale deep learning models and results. By tightly integrating multiple coordinated views, such as a computation graph overview of the model architecture, and a neuron activation view for pattern discovery and comparison, users can explore complex deep neural network models at both the instance-and subset-level. ActiVis has been deployed on Facebook\u0027s machine learning platform. We present case studies with Facebook researchers and engineers, and usage scenarios of how ActiVis may work with different models."}]);
        edges = new vis.DataSet([{"color": "gray", "from": "doc_620", "title": "", "to": "doc_1436", "width": 0.4351969}, {"color": "gray", "from": "ref_1324", "title": "", "to": "ref_1327", "width": 3.0}, {"color": "gray", "from": "ref_1324", "title": "", "to": "ref_1328", "width": 3.5}, {"color": "gray", "from": "ref_1324", "title": "", "to": "ref_1403", "width": 2.0}, {"color": "gray", "from": "ref_1324", "title": "", "to": "ref_1423", "width": 3.0}, {"color": "gray", "from": "ref_1324", "title": "", "to": "ref_1432", "width": 2.0}, {"color": "gray", "from": "ref_1324", "title": "", "to": "ref_1436", "width": 2.5}, {"color": "gray", "from": "ref_1327", "title": "", "to": "ref_1328", "width": 5.0}, {"color": "gray", "from": "ref_1327", "title": "", "to": "ref_1403", "width": 4.0}, {"color": "gray", "from": "ref_1327", "title": "", "to": "ref_1421", "width": 3.5}, {"color": "gray", "from": "ref_1327", "title": "", "to": "ref_1432", "width": 3.0}, {"color": "gray", "from": "ref_1327", "title": "", "to": "ref_1436", "width": 3.5}, {"color": "gray", "from": "ref_1327", "title": "", "to": "ref_1442", "width": 3.0}, {"color": "green", "from": "ref_1327", "title": "Mengchen Liu;Shixia Liu;Jiaxin Shi;Jun Zhu", "to": "ref_1444", "width": 4.0}, {"color": "green", "from": "ref_1327", "title": "Zhen Li", "to": "ref_1488", "width": 2.0}, {"color": "gray", "from": "ref_1328", "title": "", "to": "ref_1403", "width": 3.0}, {"color": "gray", "from": "ref_1328", "title": "", "to": "ref_1421", "width": 2.5}, {"color": "gray", "from": "ref_1328", "title": "", "to": "ref_1436", "width": 2.5}, {"color": "gray", "from": "ref_1328", "title": "", "to": "ref_1442", "width": 2.5}, {"color": "gray", "from": "ref_1403", "title": "", "to": "ref_1421", "width": 4.0}, {"color": "gray", "from": "ref_1403", "title": "", "to": "ref_1423", "width": 2.0}, {"color": "gray", "from": "ref_1403", "title": "", "to": "ref_1432", "width": 4.0}, {"color": "gray", "from": "ref_1403", "title": "", "to": "ref_1436", "width": 5.5}, {"color": "gray", "from": "ref_1403", "title": "", "to": "ref_1442", "width": 4.0}, {"color": "gray", "from": "ref_1403", "title": "", "to": "ref_1444", "width": 4.0}, {"color": "gray", "from": "ref_1403", "title": "", "to": "ref_1488", "width": 3.0}, {"color": "gray", "from": "ref_1421", "title": "", "to": "ref_1432", "width": 3.5}, {"color": "gray", "from": "ref_1421", "title": "", "to": "ref_1436", "width": 4.0}, {"color": "gray", "from": "ref_1421", "title": "", "to": "ref_1442", "width": 3.0}, {"color": "gray", "from": "ref_1421", "title": "", "to": "ref_1444", "width": 3.0}, {"color": "gray", "from": "ref_1421", "title": "", "to": "ref_1488", "width": 2.5}, {"color": "gray", "from": "ref_1423", "title": "", "to": "ref_1432", "width": 3.0}, {"color": "gray", "from": "ref_1423", "title": "", "to": "ref_1436", "width": 3.5}, {"color": "green", "from": "ref_1423", "title": "Shixia Liu;Jun Zhu", "to": "ref_1444", "width": 2.5}, {"color": "gray", "from": "ref_1423", "title": "", "to": "ref_1488", "width": 2.0}, {"color": "gray", "from": "ref_1423", "title": "", "to": "ref_1514", "width": 2.0}, {"color": "gray", "from": "ref_1432", "title": "", "to": "ref_1436", "width": 5.5}, {"color": "gray", "from": "ref_1432", "title": "", "to": "ref_1442", "width": 3.0}, {"color": "gray", "from": "ref_1432", "title": "", "to": "ref_1444", "width": 3.5}, {"color": "gray", "from": "ref_1432", "title": "", "to": "ref_1488", "width": 3.5}, {"color": "gray", "from": "ref_1432", "title": "", "to": "ref_1514", "width": 2.5}, {"color": "gray", "from": "ref_1436", "title": "", "to": "ref_1442", "width": 4.0}, {"color": "gray", "from": "ref_1436", "title": "", "to": "ref_1444", "width": 4.0}, {"color": "gray", "from": "ref_1436", "title": "", "to": "ref_1488", "width": 4.5}, {"color": "gray", "from": "ref_1436", "title": "", "to": "ref_1514", "width": 2.0}, {"color": "gray", "from": "ref_1442", "title": "", "to": "ref_1444", "width": 3.0}, {"color": "gray", "from": "ref_1442", "title": "", "to": "ref_1488", "width": 2.0}, {"color": "gray", "from": "ref_1444", "title": "", "to": "ref_1488", "width": 2.0}]);

        // adding nodes and edges to the graph
        data = {nodes: nodes, edges: edges};

        var options = {
    "configure": {
        "enabled": false
    },
    "edges": {
        "color": {
            "inherit": true
        },
        "smooth": {
            "enabled": true,
            "type": "dynamic"
        }
    },
    "interaction": {
        "dragNodes": true,
        "hideEdgesOnDrag": false,
        "hideNodesOnDrag": false
    },
    "physics": {
        "enabled": true,
        "stabilization": {
            "enabled": true,
            "fit": true,
            "iterations": 1000,
            "onlyDynamicEdges": false,
            "updateInterval": 50
        }
    }
};
        
        

        

        network = new vis.Network(container, data, options);
	 
        
        // make a custom popup
        var popup = document.createElement("div");
        popup.className = 'popup';
        popupTimeout = null;
        popup.addEventListener('mouseover', function () {
            console.log(popup)
            if (popupTimeout !== null) {
                clearTimeout(popupTimeout);
                popupTimeout = null;
            }
        });
        popup.addEventListener('mouseout', function () {
            if (popupTimeout === null) {
                hidePopup();
            }
        });
        container.appendChild(popup);


        // use the popup event to show
        network.on("showPopup", function (params) {
            showPopup(params);
        });

        // use the hide event to hide it
        network.on("hidePopup", function (params) {
            hidePopup();
        });


        // hiding the popup through css
        function hidePopup() {
            popupTimeout = setTimeout(function () { popup.style.display = 'none'; }, 500);
        }

        // showing the popup
        function showPopup(nodeId) {
            // get the data from the vis.DataSet
            var nodeData = nodes.get([nodeId]);
            popup.innerHTML = nodeData[0].title;

            // get the position of the node
            var posCanvas = network.getPositions([nodeId])[nodeId];

            // get the bounding box of the node
            var boundingBox = network.getBoundingBox(nodeId);

            //position tooltip:
            posCanvas.x = posCanvas.x + 0.5 * (boundingBox.right - boundingBox.left);

            // convert coordinates to the DOM space
            var posDOM = network.canvasToDOM(posCanvas);

            // Give it an offset
            posDOM.x += 10;
            posDOM.y -= 20;

            // show and place the tooltip.
            popup.style.display = 'block';
            popup.style.top = posDOM.y + 'px';
            popup.style.left = posDOM.x + 'px';
        }
        


        return network;

    }

    drawGraph();

</script>
</body>
</html>