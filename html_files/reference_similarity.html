<html>
<head>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/vis/4.16.1/vis.css" type="text/css" />
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/vis/4.16.1/vis-network.min.js"> </script>
<center>
<h2>Paper Similarity using References</h2>
</center>

<!-- <link rel="stylesheet" href="../node_modules/vis/dist/vis.min.css" type="text/css" />
<script type="text/javascript" src="../node_modules/vis/dist/vis.js"> </script>-->

<style type="text/css">

        #mynetwork {
            width: 100%;
            height: 500px;
            background-color: #ffffff;
            border: 1px solid lightgray;
            position: relative;
            float: left;
        }

        
        #loadingBar {
            position:absolute;
            top:0px;
            left:0px;
            width: 100%;
            height: 500px;
            background-color:rgba(200,200,200,0.8);
            -webkit-transition: all 0.5s ease;
            -moz-transition: all 0.5s ease;
            -ms-transition: all 0.5s ease;
            -o-transition: all 0.5s ease;
            transition: all 0.5s ease;
            opacity:1;
        }

        #bar {
            position:absolute;
            top:0px;
            left:0px;
            width:20px;
            height:20px;
            margin:auto auto auto auto;
            border-radius:11px;
            border:2px solid rgba(30,30,30,0.05);
            background: rgb(0, 173, 246); /* Old browsers */
            box-shadow: 2px 0px 4px rgba(0,0,0,0.4);
        }

        #border {
            position:absolute;
            top:10px;
            left:10px;
            width:500px;
            height:23px;
            margin:auto auto auto auto;
            box-shadow: 0px 0px 4px rgba(0,0,0,0.2);
            border-radius:10px;
        }

        #text {
            position:absolute;
            top:8px;
            left:530px;
            width:30px;
            height:50px;
            margin:auto auto auto auto;
            font-size:22px;
            color: #000000;
        }

        div.outerBorder {
            position:relative;
            top:400px;
            width:600px;
            height:44px;
            margin:auto auto auto auto;
            border:8px solid rgba(0,0,0,0.1);
            background: rgb(252,252,252); /* Old browsers */
            background: -moz-linear-gradient(top,  rgba(252,252,252,1) 0%, rgba(237,237,237,1) 100%); /* FF3.6+ */
            background: -webkit-gradient(linear, left top, left bottom, color-stop(0%,rgba(252,252,252,1)), color-stop(100%,rgba(237,237,237,1))); /* Chrome,Safari4+ */
            background: -webkit-linear-gradient(top,  rgba(252,252,252,1) 0%,rgba(237,237,237,1) 100%); /* Chrome10+,Safari5.1+ */
            background: -o-linear-gradient(top,  rgba(252,252,252,1) 0%,rgba(237,237,237,1) 100%); /* Opera 11.10+ */
            background: -ms-linear-gradient(top,  rgba(252,252,252,1) 0%,rgba(237,237,237,1) 100%); /* IE10+ */
            background: linear-gradient(to bottom,  rgba(252,252,252,1) 0%,rgba(237,237,237,1) 100%); /* W3C */
            filter: progid:DXImageTransform.Microsoft.gradient( startColorstr='#fcfcfc', endColorstr='#ededed',GradientType=0 ); /* IE6-9 */
            border-radius:72px;
            box-shadow: 0px 0px 10px rgba(0,0,0,0.2);
        }
        

        

        
        /* position absolute is important and the container has to be relative or absolute as well. */
	    div.popup {
            position:absolute;
            top:0px;
            left:0px;
            display:none;
            background-color:#f5f4ed;
            -moz-border-radius: 3px;
            -webkit-border-radius: 3px;
            border-radius: 3px;
            border: 1px solid #808074;
            box-shadow: 3px 3px 10px rgba(0, 0, 0, 0.2);
	    }

	    /* hide the original tooltip */
	    .vis-network-tooltip {
	      display:none;
	    }
        
</style>

</head>

<body>
<div id = "mynetwork"></div>


<script type="text/javascript">

    // initialize global variables.
    var edges;
    var nodes;
    var network; 
    var container;
    var options, data;

    
    // This method is responsible for drawing the graph, returns the drawn network
    function drawGraph() {
        var container = document.getElementById('mynetwork');
        
        

        // parsing and collecting nodes and edges from the python
        nodes = new vis.DataSet([{"color": "blue", "id": 6, "label": 6, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 6 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.1995.528686\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: J.A. Wise;J.J. Thomas;K. Pennock;D. Lantrip;M. Pottier;A. Schur;V. Crow; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visualizing the non-visual: spatial analysis and interaction with information from text documents; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The paper describes an approach to IV that involves spatializing text content for enhanced visual browsing and analysis. The application arena is large text document corpora such as digital libraries, regulations and procedures, archived reports, etc. The basic idea is that text content from these sources may be transformed to a spatial representation that preserves informational characteristics from the documents. The spatial representation may then be visually browsed and analyzed in ways that avoid language processing and that reduce the analysts mental workload. The result is an interaction with text that more nearly resembles perception and action with the natural world than with the abstractions of written language."}, {"color": "blue", "id": 21, "label": 21, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 21 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.1996.559213\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: M.C. Chuah;S.F. Roth; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: On the semantics of interactive visualizations; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Interactive techniques are powerful tools for manipulating visualizations to analyze, communicate and acquire information. This is especially true for large data sets or complex 3D visualizations. Although many new types of interaction have been introduced recently, very little work has been done on understanding what their components are, how they are related and how they can be combined. This paper begins to address these issues with a framework for classifying interactive visualizations. Our goal is a framework that will enable us to develop toolkits for assembling visualization interfaces both interactively and automatically."}, {"color": "blue", "id": 22, "label": 22, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 22 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.1996.559214\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: T.A. Keahey;E.L. Robertson; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Techniques for non-linear magnification transformations; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: This paper presents efficient methods for implementing general non-linear magnification transformations. Techniques are provided for: combining linear and non-linear magnifications, constraining the domain of magnifications, combining multiple transformations, and smoothly interpolating between magnified and normal views. In addition, piecewise linear methods are introduced which allow greater efficiency and expressiveness than their continuous counterparts."}, {"color": "blue", "id": 33, "label": 33, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 33 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.1996.559226\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: T. Munzner;E. Hoffman;K. Claffy;B. Fenner; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visualizing the global topology of the MBone; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present a case study of visualizing the global topology of the Internet MBone. The MBone is the Internet\u0027s multicast backbone. Multicast is the most efficient way of distributing data from one sender to multiple receivers with minimal packet duplication. Developed and initially deployed by researchers within the Internet community, the MBone has been extremely popular for efficient transmission across the Internet of real-time video and audio streams such as conferences, meetings, congressional sessions, and NASA shuttle launches. The MBone, like the Internet itself grew exponentially with no central authority. The resulting suboptimal topology is of growing concern to network providers and the multicast research community. We create a geographic representation of the tunnel structure as arcs on a globe by resolving the latitude and longitude of MBone routers. The interactive 3D maps permit an immediate understanding of the global structure unavailable from the data in its original form as lines of text with only hostnames and IP addresses. Data visualization techniques such as grouping and thresholding allow further analysis of specific aspects of the MBone topology. We distribute the interactive 3D maps through the World-Wide Web using the VRML file format thus allowing network maintainers throughout the world to analyze the structure move effectively than would be possible with still pictures or pre-made videos."}, {"color": "blue", "id": 37, "label": 37, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 37 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.1997.636718\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: T. Munzner; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: H3: laying out large directed graphs in 3D hyperbolic space; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present the H3 layout technique for drawing large directed graphs as node-link diagrams in 3D hyperbolic space. We can lay out much larger structures than can be handled using traditional techniques for drawing general graphs because we assume a hierarchical nature of the data. We impose a hierarchy on the graph by using domain-specific knowledge to find an appropriate spanning tree. Links which are not part of the spanning tree do not influence the layout but can be selectively drawn by user request. The volume of hyperbolic 3-space increases exponentially, as opposed to the familiar geometric increase of euclidean 3-space. We exploit this exponential amount of room by computing the layout according to the hyperbolic metric. We optimize the cone tree layout algorithm for 3D hyperbolic space by placing children on a hemisphere around the cone mouth instead of on its perimeter. Hyperbolic navigation affords a Focus+Context view of the structure with minimal visual clutter. We have successfully laid out hierarchies of over 20,000 nodes. Our implementation accommodates navigation through graphs too large to be rendered interactively by allowing the user to explicitly prune or expand subtrees."}, {"color": "blue", "id": 44, "label": 44, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 44 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.1997.636786\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: T.A. Keahey;E.L. Robertson; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Nonlinear magnification fields; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We introduce nonlinear magnification fields as an abstract representation of nonlinear magnification, providing methods for converting transformation routines to magnification fields and vice-versa. This new representation provides ease of manipulation and power of expression. By removing the restrictions of explicit foci and allowing precise specification of magnification values, we can achieve magnification effects which were not previously possible. Of particular interest are techniques we introduce for expressing complex and subtle magnification effects through magnification brushing, and allowing intrinsic properties of the data being visualized to create data-driven magnifications."}, {"color": "blue", "id": 50, "label": 50, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 50 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.1997.636792\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: S.K. Card;J. Mackinlay; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: The structure of the information visualization design space; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Research on information visualization has reached the point where a number of successful point designs have been proposed and a variety of techniques have been discovered. It is now appropriate to describe and analyze portions of the design space so as to understand the differences among designs and to suggest new possibilities. This paper proposes an organization of the information visualization literature and illustrates it with a series of examples. The result is a framework for designing new visualizations and augmenting existing designs."}, {"color": "blue", "id": 59, "label": 59, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 59 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.1998.729559\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: M. Ankerst;S. Berchtold;D.A. Keim; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Similarity clustering of dimensions for an enhanced visualization of multidimensional data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The order and arrangement of dimensions (variates) is crucial for the effectiveness of a large number of visualization techniques such as parallel coordinates, scatterplots, recursive pattern, and many others. We describe a systematic approach to arrange the dimensions according to their similarity. The basic idea is to rearrange the data dimensions such that dimensions showing a similar behavior are positioned next to each other. For the similarity clustering of dimensions, we need to define similarity measures which determine the partial or global similarity of dimensions. We then consider the problem of finding an optimal one- or two-dimensional arrangement of the dimensions based on their similarity. Theoretical considerations show that both, the one- and the two-dimensional arrangement problem are surprisingly hard problems, i.e. they are NP complete. Our solution of the problem is therefore based on heuristic algorithms. An empirical evaluation using a number of different visualization techniques shows the high impact of our similarity clustering of dimensions on the visualization results."}, {"color": "blue", "id": 60, "label": 60, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 60 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.1998.729560\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Ed Huai-Hsin Chi;J.T. Riedl; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: An operator interaction framework for visualization systems; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Information visualization encounters a wide variety of different data domains. The visualization community has developed representation methods and interactive techniques. As a community, we have realized that the requirements in each domain are often dramatically different. In order to easily apply existing methods, researchers have developed a semiology of graphic representations. We have extended this research into a framework that includes operators and interactions in visualization systems, such as a visualization spreadsheet. We discuss properties of this framework and use it to characterize operations spanning a variety of different visualization techniques. The framework developed in the paper enables a new way of exploring and evaluating the design space of visualization operators, and helps end users in their analysis tasks."}, {"color": "blue", "id": 70, "label": 70, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 70 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.1998.729570\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: B. Hetzler;P. Whitney;L. Martucci;J. Thomas; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Multi-faceted insight through interoperable visual information analysis paradigms; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: To gain insight and understanding of complex information collections, users must be able to visualize and explore many facets of the information. The paper presents several novel visual methods from an information analyst\u0027s perspective. The authors present a sample scenario, using the various methods to gain a variety of insights from a large information collection. They conclude that no single paradigm or visual method is sufficient for many analytical tasks. Often a suite of integrated methods offers a better analytic environment in today\u0027s emerging culture of information overload and rapidly changing issues. They also conclude that the interactions among these visual paradigms are equally as important as, if not more important than, the paradigms themselves."}, {"color": "blue", "id": 71, "label": 71, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 71 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.1999.801851\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: J.J. Van Wijk;E.R. Van Selow; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Cluster and calendar based visualization of time series data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: A new method is presented to get an insight into univariate time series data. The problem addressed is how to identify patterns and trends on multiple time scales (days, weeks, seasons) simultaneously. The solution presented is to cluster similar daily data patterns, and to visualize the average patterns as graphs and the corresponding days on a calendar. This presentation provides a quick insight into both standard and exceptional patterns. Furthermore, it is well suited to interactive exploration. Two applications, numbers of employees present and energy consumption, are presented."}, {"color": "blue", "id": 80, "label": 80, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 80 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.1999.801860\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: J.J. Van Wijk;H. Van de Wetering; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Cushion treemaps: visualization of hierarchical information; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: A new method is presented for the visualization of hierarchical information, such as directory structures and organization structures. Cushion treemaps inherit the elegance of standard treemaps: compact, space-filling displays of hierarchical information, based on recursive subdivision of a rectangular image space. Intuitive shading is used to provide insight in the hierarchical structure. During the subdivision, ridges are added per rectangle, which are rendered with a simple shading model. The result is a surface that consists of recursive cushions. The method is efficient, effective, easy to use and implement, and has a wide applicability."}, {"color": "blue", "id": 86, "label": 86, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 86 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.1999.801866\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Pak Chung Wong;P. Whitney;J. Thomas; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visualizing association rules for text mining; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: An association rule in data mining is an implication of the form X/spl rarr/Y where X is a set of antecedent items and Y is the consequent item. For years researchers have developed many tools to visualize association rules. However, few of these tools can handle more than dozens of rules, and none of them can effectively manage rules with multiple antecedents. Thus, it is extremely difficult to visualize and understand the association information of a large data set even when all the rules are available. This paper presents a novel visualization technique to tackle many of these problems. We apply the technology to a text mining study on large corpora. The results indicate that our design can easily handle hundreds of multiple antecedent association rules in a three-dimensional display with minimum human interaction, low occlusion percentage, and no screen swapping."}, {"color": "blue", "id": 101, "label": 101, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 101 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2000.885097\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Pak Chung Wong;W. Cowley;H. Foote;E. Jurrus;J. Thomas; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visualizing sequential patterns for text mining; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: A sequential pattern in data mining is a finite series of elements such as A/spl rarr/B/spl rarr/C/spl rarr/D where A, B, C, and D are elements of the same domain. The mining of sequential patterns is designed to find patterns of discrete events that frequently happen in the same arrangement along a timeline. Like association and clustering, the mining of sequential patterns is among the most popular knowledge discovery techniques that apply statistical measures to extract useful information from large datasets. As out computers become more powerful, we are able to mine bigger datasets and obtain hundreds of thousands of sequential patterns in full detail. With this vast amount of data, we argue that neither data mining nor visualization by itself can manage the information and reflect the knowledge effectively. Subsequently, we apply visualization to augment data mining in a study of sequential patterns in large text corpora. The result shows that we can learn more and more quickly in an integrated visual data-mining environment."}, {"color": "blue", "id": 105, "label": 105, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 105 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2000.885098\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: S. Havre;B. Hetzler;L. Nowell; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: ThemeRiver: visualizing theme changes over time; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: ThemeRiver/sup TM/ is a prototype system that visualizes thematic variations over time within a large collection of documents. The \"river\" flows from left to right through time, changing width to depict changes in thematic strength of temporally associated documents. Colored \"currents\" flowing within the river narrow or widen to indicate decreases or increases in the strength of an individual topic or a group of topics in the associated documents. The river is shown within the context of a timeline and a corresponding textual presentation of external events."}, {"color": "blue", "id": 106, "label": 106, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 106 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2000.885091\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: J. Stasko;E. Zhang; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Focus+context display and navigation techniques for enhancing radial, space-filling hierarchy visualizations; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Radial, space-filling visualizations can be useful for depicting information hierarchies, but they suffer from one major problem. As the hierarchy grows in size, many items become small, peripheral slices that are difficult to distinguish. We have developed three visualization/interaction techniques that provide flexible browsing of the display. The techniques allow viewers to examine the small items in detail while providing context within the entire information hierarchy. Additionally, smooth transitions between views help users maintain orientation within the complete information space."}, {"color": "blue", "id": 107, "label": 107, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 107 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2000.885092\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: E.H. Chi; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: A taxonomy of visualization techniques using the data state reference model; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In previous work, researchers have attempted to construct taxonomies of information visualization techniques by examining the data domains that are compatible with these techniques. This is useful because implementers can quickly identify various techniques that can be applied to their domain of interest. However, these taxonomies do not help the implementers understand how to apply and implement these techniques. The author extends and proposes a new way to taxonomize information visualization techniques by using the Data State Model (E.H. Chi and J.T. Reidl, 1998). In fact, as the taxonomic analysis in the paper will show, many of the techniques share similar operating steps that can easily be reused. The paper shows that the Data State Model not only helps researchers understand the space of design, but also helps implementers understand how information visualization techniques can be applied more broadly."}, {"color": "blue", "id": 108, "label": 108, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 108 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2000.885086\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: C. Stolte;P. Hanrahan; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Polaris: a system for query, analysis and visualization of multi-dimensional relational databases; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In the last several years, large multi-dimensional databases have become common in a variety of applications such as data warehousing and scientific computing. Analysis and exploration tasks place significant demands on the interfaces to these databases. Because of the size of the data sets, dense graphical representations are more effective for exploration than spreadsheets and charts. Furthermore, because of the exploratory nature of the analysis, it must be possible for the analysts to change visualizations rapidly as they pursue a cycle involving first hypothesis and then experimentation. The authors present Polaris, an interface for exploring large multi-dimensional databases that extends the well-known Pivot Table interface. The novel features of Polaris include an interface for constructing visual specifications of table based graphical displays and the ability to generate a precise set of relational queries from the visual specifications. The visual specifications can be rapidly and incrementally developed, giving the analyst visual feedback as they construct complex queries and visualizations."}, {"color": "blue", "id": 119, "label": 119, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 119 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2002.1173148\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: C. Plaisant;J. Grosjean;B.B. Bederson; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: SpaceTree: supporting exploration in large node link tree, design evolution and empirical evaluation; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present a novel tree browser that builds on the conventional node link tree diagrams. It adds dynamic rescaling of branches of the tree to best fit the available screen space, optimized camera movement, and the use of preview icons summarizing the topology of the branches that cannot be expanded. In addition, it includes integrated search and filter functions. This paper reflects on the evolution of the design and highlights the principles that emerged from it. A controlled experiment showed benefits for navigation to already previously visited nodes and estimation of overall tree topology."}, {"color": "blue", "id": 122, "label": 122, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 122 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2002.1173151\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jing Yang;M.O. Ward;E.A. Rundensteiner; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: InterRing: an interactive tool for visually navigating and manipulating hierarchical structures; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Radial, space-filling (RSF) techniques for hierarchy visualization have several advantages over traditional node-link diagrams, including the ability to efficiently use the display space while effectively conveying the hierarchy structure. Several RSF systems and tools have been developed to date, each with varying degrees of support for interactive operations such as selection and navigation. We describe what we believe to be a complete set of desirable operations on hierarchical structures. We then present InterRing, an RSF hierarchy visualization system that supports a significantly more extensive set of these operations than prior systems. In particular, InterRing supports multi-focus distortions, interactive hierarchy reconfiguration, and both semi-automated and manual selection. We show the power and utility of these and other operations, and describe our on-going efforts to evaluate their effectiveness and usability."}, {"color": "blue", "id": 124, "label": 124, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 124 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2002.1173153\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: F. van Ham;J.J. van Wijk; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Beamtrees: compact visualization of large hierarchies; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Beamtrees are a new method for the visualization of large hierarchical data sets. Nodes are shown as stacked circular beams, such that both the hierarchical structure as well as the size of nodes are depicted. The dimensions of beams are calculated using a variation of the treemap algorithm. A small user study indicated that beamtrees are significantly more effective than nested treemaps and cushion treemaps for the extraction of global hierarchical information."}, {"color": "blue", "id": 126, "label": 126, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 126 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2002.1173155\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: M. Wattenberg; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Arc diagrams: visualizing structure in strings; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: This paper introduces a new visualization method, the arc diagram, which is capable of representing complex patterns of repetition in string data. Arc diagrams improve over previous methods such as dotplots because they scale efficiently for strings that contain many instances of the same subsequence. This paper describes design and implementation issues related to arc diagrams and shows how they may be applied to visualize such diverse data as music, text, and compiled code."}, {"color": "blue", "id": 128, "label": 128, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 128 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2002.1173157\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: H. Hauser;F. Ledermann;H. Doleisch; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Angular brushing of extended parallel coordinates; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In this paper we present angular brushing for parallel coordinates (PC) as a new approach to highlighting rational data-properties, i.e., features which - in a non-separable way - depend on two data dimensions. We also demonstrate smooth brushing as an intuitive tool for specifying nonbinary degree-of-interest functions (for focus+context visualization). We also briefly describe our implementation as well as its application to the visualization of CFD data."}, {"color": "blue", "id": 130, "label": 130, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 130 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2002.1173159\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Yehuda Koren;L. Carmel;D. Harel; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: ACE: a fast multiscale eigenvectors computation for drawing huge graphs; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present an extremely fast graph drawing algorithm for very large graphs, which we term ACE (for Algebraic multigrid Computation of Eigenvectors). ACE exhibits an improvement of something like two orders of magnitude over the fastest algorithms we are aware of; it draws graphs of millions of nodes in less than a minute. ACE finds an optimal drawing by minimizing a quadratic energy function. The minimization problem is expressed as a generalized eigenvalue problem, which is rapidly solved using a novel algebraic multigrid technique. The same generalized eigenvalue problem seems to come up also in other fields, hence ACE appears to be applicable outside of graph drawing too."}, {"color": "blue", "id": 132, "label": 132, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 132 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2002.1173161\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: A. Morrison;G. Ross;M. Chalmers; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: A hybrid layout algorithm for sub-quadratic multidimensional scaling; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Many clustering and layout techniques have been used for structuring and visualising complex data. This paper is inspired by a number of such contemporary techniques and presents a novel hybrid approach based upon stochastic sampling, interpolation and spring models. We use Chalmers\u0027 1996 O(N/sup 2/) spring model as a benchmark when evaluating our technique, comparing layout quality and run times using data sets of synthetic and real data. Our algorithm runs in O(N/spl radic/N) and executes significantly faster than Chalmers\u0027 1996 algorithm, whilst producing superior layouts. In reducing complexity and run time, we allow the visualisation of data sets of previously infeasible size. Our results indicate that our method is a solid foundation for interactive and visual exploration of data."}, {"color": "blue", "id": 139, "label": 139, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 139 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2003.1249006\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: A. MacEachren;D. Xiping;F. Hardisty;Diansheng Guo;G. Lengerich; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Exploring high-D spaces with multiform matrices and small multiples; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We introduce an approach to visual analysis of multivariate data that integrates several methods from information visualization, exploratory data analysis (EDA), and geovisualization. The approach leverages the component-based architecture implemented in GeoVISTA Studio to construct a flexible, multiview, tightly (but generically) coordinated, EDA toolkit. This toolkit builds upon traditional ideas behind both small multiples and scatterplot matrices in three fundamental ways. First, we develop a general, multiform, bivariate matrix and a complementary multiform, bivariate small multiple plot in which different bivariate representation forms can be used in combination. We demonstrate the flexibility of this approach with matrices and small multiples that depict multivariate data through combinations of: scatterplots, bivariate maps, and space-filling displays. Second, we apply a measure of conditional entropy to (a) identify variables from a high-dimensional data set that are likely to display interesting relationships and (b) generate a default order of these variables in the matrix or small multiple display. Third, we add conditioning, a kind of dynamic query/filtering in which supplementary (undisplayed) variables are used to constrain the view onto variables that are displayed. Conditioning allows the effects of one or more well understood variables to be removed form the analysis, making relationships among remaining variables easier to explore. We illustrate the individual and combined functionality enabled by this approach through application to analysis of cancer diagnosis and mortality data and their associated covariates and risk factors."}, {"color": "blue", "id": 141, "label": 141, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 141 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2003.1249008\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: N. Wong;S. Carpendale;S. Greenberg; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Edgelens: an interactive method for managing edge congestion in graphs; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: An increasing number of tasks require people to explore, navigate and search extremely complex data sets visualized as graphs. Examples include electrical and telecommunication networks, Web structures, and airline routes. The problem is that graphs of these real world data sets have many interconnected nodes, ultimately leading to edge congestion: the density of edges is so great that they obscure nodes, individual edges, and even the visual information beneath the graph. To address this problem we developed an interactive technique called EdgeLens. An EdgeLens interactively curves graph edges away for a person\u0027s focus attention without changing the node positions. This opens up sufficient space to disambiguate node and edge relationships and to see underlying information while still preserving node layout. Initially two methods of creating this interaction were developed and compared in a user study. The results of this study were used in the selection of a basic approach and the subsequent development of the EdgeLens. We then improved the EdgeLens through use of transparency and colour and by allowing multiple lenses to appear on the graph."}, {"color": "blue", "id": 144, "label": 144, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 144 (InfoVis)  - \u003ca href=\"http://doi.ieeecomputersociety.org/10.1109/INFVIS.2003.1249011\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: D. Auber;Y. Chiricota;F. Jourdan;G. Melancon; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Multiscale Visualization of Small World Networks; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Many networks under study in information visualization are \"small world\" networks. These networks first appeared in the study of social networks and were shown to be relevant models in other application domains such as software reverse engineering and biology. Furthermore, many of these networks actually have a multiscale nature: they can be viewed as a network of groups that are themselves small world networks. We describe a metric that has been designed in order to identify the weakest edges in a small world network leading to an easy and low cost filtering procedure that breaks up a graph into smaller and highly connected components. We show how this metric can be exploited through an interactive navigation of the network based on semantic zooming. Once the network is decomposed into a hierarchy of sub-networks, a user can easily find groups and subgroups of actors and understand their dynamics."}, {"color": "blue", "id": 148, "label": 148, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 148 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2003.1249015\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jing Yang;Wei Peng;M.O. Ward;E.A. Rundensteiner; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Interactive hierarchical dimension ordering, spacing and filtering for exploration of high dimensional datasets; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Large number of dimensions not only cause clutter in multi-dimensional visualizations, but also make it difficult for users to navigate the data space. Effective dimension management, such as dimension ordering, spacing and filtering, is critical for visual exploration of such datasets. Dimension ordering and spacing explicitly reveal dimension relationships in arrangement-sensitive multidimensional visualization techniques, such as parallel coordinates, star glyphs, and pixel-oriented techniques. They facilitate the visual discovery of patterns within the data. Dimension filtering hides some of the dimensions to reduce clutter while preserving the major information of the dataset. In this paper, we propose an interactive hierarchical dimension ordering, spacing and filtering approach, called DOSFA. DOSFA is based on dimension hierarchies derived from similarities among dimensions. It is scalable multi-resolution approach making dimensional management a tractable task. On the one hand, it automatically generates default settings for dimension ordering, spacing and filtering. On the other hand, it allows users to efficiently control all aspects of this dimension management process via visual interaction tools for dimension hierarchy manipulation. A case study visualizing a dataset containing over 200 dimensions reveals high dimensional visualization techniques."}, {"color": "blue", "id": 164, "label": 164, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 164 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2003.1249031\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: T. Skog;S. Ljungblad;L.E. Holmquist; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Between aesthetics and utility: designing ambient information visualizations; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Unlike traditional information visualization, ambient information visualizations reside in the environment of the user rather than on the screen of a desktop computer. Currently, most dynamic information that is displayed in public places consists of text and numbers. We argue that information visualization can be employed to make such dynamic data more useful and appealing. However, visualizations intended for non-desktop spaces will have to both provide valuable information and present an attractive addition to the environment - they must strike a balance between aesthetical appeal and usefulness. To explore this, we designed a real-time visualization of bus departure times and deployed it in a public space, with about 300 potential users. To make the presentation more visually appealing, we took inspiration from a modern abstract artist. The visualization was designed in two passes. First, we did a preliminary version that was presented to and discussed with prospective users. Based on their input, we did a final design. We discuss the lessons learned in designing this and previous ambient information visualizations, including how visual art can be used as a design constraint, and how the choice of information and the placement of the display affect the visualization."}, {"color": "blue", "id": 166, "label": 166, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 166 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2004.1\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: M. Ghoniem;J.-D. Fekete;P. Castagliola; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: A Comparison of the Readability of Graphs Using Node-Link and Matrix-Based Representations; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In this paper, we describe a taxonomy of generic graph related tasks and an evaluation aiming at assessing the readability of two representations of graphs: matrix-based representations and node-link diagrams. This evaluation bears on seven generic tasks and leads to important recommendations with regard to the representation of graphs according to their size and density. For instance, we show that when graphs are bigger than twenty vertices, the matrix-based visualization performs better than node-link diagrams on most tasks. Only path finding is consistently in favor of node-link diagrams throughout the evaluation"}, {"color": "blue", "id": 167, "label": 167, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 167 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2004.10\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: R. Amar;J. Stasko; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: A Knowledge Task-Based Framework for Design and Evaluation of Information Visualizations; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The design and evaluation of most current information visualization systems descend from an emphasis on a user\u0027s ability to \"unpack\" the representations of data of interest and operate on them independently. Too often, successful decision-making and analysis are more a matter of serendipity and user experience than of intentional design and specific support for such tasks; although humans have considerable abilities in analyzing relationships from data, the utility of visualizations remains relatively variable across users, data sets, and domains. In this paper, we discuss the notion of analytic gaps, which represent obstacles faced by visualizations in facilitating higher-level analytic tasks, such as decision-making and learning. We discuss support for bridging the analytic gap, propose a framework for design and evaluation of information visualization systems, and demonstrate its use"}, {"color": "blue", "id": 169, "label": 169, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 169 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2004.12\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: C. Weaver; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Building Highly-Coordinated Visualizations in Improvise; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Improvise is a fully-implemented system in which users build and browse multiview visualizations interactively using a simple shared-object coordination mechanism coupled with a flexible, expression-based visual abstraction language. By coupling visual abstraction with coordination, users gain precise control over how navigation and selection in the visualization affects the appearance of data in individual views. As a result, it is practical to build visualizations with more views and richer coordination in Improvise than in other visualization systems. Building and browsing activities are integrated in a single, live user interface that lets users alter visualizations quickly and incrementally during data exploration"}, {"color": "blue", "id": 171, "label": 171, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 171 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2004.15\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Wei Peng;M.O. Ward;E.A. Rundensteiner; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Clutter Reduction in Multi-Dimensional Data Visualization Using Dimension Reordering; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Visual clutter denotes a disordered collection of graphical entities in information visualization. Clutter can obscure the structure present in the data. Even in a small dataset, clutter can make it hard for the viewer to find patterns, relationships and structure. In this paper, we define visual clutter as any aspect of the visualization that interferes with the viewer\u0027s understanding of the data, and present the concept of clutter-based dimension reordering. Dimension order is an attribute that can significantly affect a visualization\u0027s expressiveness. By varying the dimension order in a display, it is possible to reduce clutter without reducing information content or modifying the data in any way. Clutter reduction is a display-dependent task. In this paper, we follow a three-step procedure for four different visualization techniques. For each display technique, first, we determine what constitutes clutter in terms of display properties; then we design a metric to measure visual clutter in this display; finally we search for an order that minimizes the clutter in a display"}, {"color": "blue", "id": 176, "label": 176, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 176 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2004.2\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: M. Kreuseler;T. Nocke;H. Schumann; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: A History Mechanism for Visual Data Mining; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: A major challenge of current visualization and visual data mining (VDM) frameworks is to support users in the orientation in complex visual mining scenarios. An important aspect to increase user support and user orientation is to use a history mechanism that, first of all, provides un- and redoing functionality. In this paper, we present a new approach to include such history functionality into a VDM framework. Therefore, we introduce the theoretical background, outline design and implementation aspects of a history management unit, and conclude with a discussion showing the usefulness of our history management in a VDM framework"}, {"color": "blue", "id": 182, "label": 182, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 182 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2004.27\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: T. Kapler;W. Wright; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: GeoTime Information Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Analyzing observations over time and geography is a common task but typically requires multiple, separate tools. The objective of our research has been to develop a method to visualize, and work with, the spatial interconnectedness of information over time and geography within a single, highly interactive 3D view. A novel visualization technique for displaying and tracking events, objects and activities within a combined temporal and geospatial display has been developed. This technique has been implemented as a demonstratable prototype called GeoTime in order to determine potential utility. Initial evaluations have been with military users. However, we believe the concept is applicable to a variety of government and business analysis tasks"}, {"color": "blue", "id": 185, "label": 185, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 185 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2004.3\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jinwook Seo;B. Shneiderman; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: A Rank-by-Feature Framework for Unsupervised Multidimensional Data Exploration Using Low Dimensional Projections; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Exploratory analysis of multidimensional data sets is challenging because of the difficulty in comprehending more than three dimensions. Two fundamental statistical principles for the exploratory analysis are (1) to examine each dimension first and then find relationships among dimensions, and (2) to try graphical displays first and then find numerical summaries (D.S. Moore, (1999). We implement these principles in a novel conceptual framework called the rank-by-feature framework. In the framework, users can choose a ranking criterion interesting to them and sort 1D or 2D axis-parallel projections according to the criterion. We introduce the rank-by-feature prism that is a color-coded lower-triangular matrix that guides users to desired features. Statistical graphs (histogram, boxplot, and scatterplot) and information visualization techniques (overview, coordination, and dynamic query) are combined to help users effectively traverse 1D and 2D axis-parallel projections, and finally to help them interactively find interesting features"}, {"color": "blue", "id": 191, "label": 191, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 191 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2004.43\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: F. van Ham;J.J. van Wijk; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Interactive Visualization of Small World Graphs; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Many real world graphs have small world characteristics, that is, they have a small diameter compared to the number of nodes and exhibit a local cluster structure. Examples are social networks, software structures, bibliographic references and biological neural nets. Their high connectivity makes both finding a pleasing layout and a suitable clustering hard. In this paper we present a method to create scalable, interactive visualizations of small world graphs, allowing the user to inspect local clusters while maintaining a global overview of the entire structure. The visualization method uses a combination of both semantical and geometrical distortions, while the layout is generated by a spring embedder algorithm using recently developed force model. We use a cross referenced database of 500 artists as a running example"}, {"color": "blue", "id": 204, "label": 204, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 204 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2004.59\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: M. Tory;T. Moller; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Rethinking Visualization: A High-Level Taxonomy; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present the novel high-level visualization taxonomy. Our taxonomy classifies visualization algorithms rather than data. Algorithms are categorized based on the assumptions they make about the data being visualized; we call this set of assumptions the design model. Because our taxonomy is based on design models, it is more flexible than existing taxonomies and considers the user\u0027s conceptual model, emphasizing the human aspect of visualization. Design models are classified according to whether they are discrete or continuous and by how much the algorithm designer chooses display attributes such as spatialization, timing, colour, and transparency. This novel approach provides an alternative view of the visualization field that helps explain how traditional divisions (e.g., information and scientific visualization) relates and overlap, and that may inspire research ideas in hybrid visualization areas"}, {"color": "blue", "id": 206, "label": 206, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 206 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2004.60\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: M. Williams;T. Munzner; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Steerable, Progressive Multidimensional Scaling; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Current implementations of multidimensional scaling (MDS), an approach that attempts to best represent data point similarity in a low-dimensional representation, are not suited for many of today\u0027s large-scale datasets. We propose an extension to the spring model approach that allows the user to interactively explore datasets that are far beyond the scale of previous implementations of MDS. We present MDSteer, a steerable MDS computation engine and visualization tool that progressively computes an MDS layout and handles datasets of over one million points. Our technique employs hierarchical data structures and progressive layouts to allow the user to steer the computation of the algorithm to the interesting areas of the dataset. The algorithm iteratively alternates between a layout stage in which a subselection of points are added to the set of active points affected by the MDS iteration, and a binning stage which increases the depth of the bin hierarchy and organizes the currently unplaced points into separate spatial regions. This binning strategy allows the user to select onscreen regions of the layout to focus the MDS computation into the areas of the dataset that are assigned to the selected bins. We show both real and common synthetic benchmark datasets with dimensionalities ranging from 3 to 300 and cardinalities of over one million points"}, {"color": "blue", "id": 208, "label": 208, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 208 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2004.64\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: J.-D. Fekete; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: The InfoVis Toolkit; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: This article presents the InfoVis toolkit, designed to support the creation, extension and integration of advanced 2D information visualization components into interactive Java swing applications. The InfoVis toolkit provides specific data structures to achieve a fast action/feedback loop required by dynamic queries. It comes with a large set of components such as range sliders and tailored control panels required to control and configure the visualizations. These components are integrated into a coherent framework that simplifies the management of rich data structures and the design and extension of visualizations. Supported data structures currently include tables, trees and graphs. Supported visualizations include scatter plots, time series, parallel coordinates, treemaps, icicle trees, node-link diagrams for trees and graphs and adjacency matrices for graphs. All visualizations can use fisheye lenses and dynamic labeling. The InfoVis toolkit supports hardware acceleration when available through Agile2D, an implementation of the Java graphics API based on OpenGL, achieving speedups of 10 to 200 times. The article also shows how new visualizations can be added and extended to become components, enriching visualizations as well as general applications"}, {"color": "blue", "id": 210, "label": 210, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 210 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2004.66\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: E. Gansner;Y. Koren;S. North; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Topological Fisheye Views for Visualizing Large Graphs; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Graph drawing is a basic visualization tool. For graphs of up to hundreds of nodes and edges, there are many effective techniques available. At greater scale, data density and occlusion problems often negate its effectiveness. Conventional pan-and-zoom, and multiscale and geometric fisheye views are not fully satisfactory solutions to this problem. As an alternative, we describe a topological zooming method. It is based on the precomputation of a hierarchy of coarsened graphs, which are combined on the fly into renderings with the level of detail dependent on the distance from one or more foci. We also discuss a related distortion method that allows our technique to achieve constant information density displays"}, {"color": "blue", "id": 212, "label": 212, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 212 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2004.68\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: A.O. Artero;M.C.F. de Oliveira;H. Levkowitz; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Uncovering Clusters in Crowded Parallel Coordinates Visualizations; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The one-to-one strategy of mapping each single data item into a graphical marker adopted in many visualization techniques has limited usefulness when the number of records and/or the dimensionality of the data set are very high. In this situation, the strong overlapping of graphical markers severely hampers the user\u0027s ability to identify patterns in the data from its visual representation. We tackle this problem here with a strategy that computes frequency or density information from the data set, and uses such information in parallel coordinates visualizations to filter out the information to be presented to the user, thus reducing visual clutter and allowing the analyst to observe relevant patterns in the data. The algorithms to construct such visualizations, and the interaction mechanisms supported, inspired by traditional image processing techniques such as grayscale manipulation and thresholding are also presented. We also illustrate how such algorithms can assist users to effectively identify clusters in very noisy large data sets"}, {"color": "blue", "id": 215, "label": 215, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 215 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2004.70\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: A. Kobsa; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: User Experiments with Tree Visualization Systems; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: This paper describes a comparative experiment with five well-known tree visualization systems, and Windows Explorer as a baseline system. Subjects performed tasks relating to the structure of a directory hierarchy, and to attributes of files and directories. Task completion times, correctness and user satisfaction were measured, and video recordings of subjects\u0027 interaction with the systems were made. Significant system and task type effects and an interaction between system and task type were found. Qualitative analyses of the video recordings were thereupon conducted to determine reasons for the observed differences, resulting in several findings and design recommendations as well as implications for future experiments with tree visualization systems"}, {"color": "blue", "id": 216, "label": 216, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 216 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2004.71\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jing Yang;A. Patro;Shiping Huang;N. Mehta;M.O. Ward;E.A. Rundensteiner; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Value and Relation Display for Interactive Exploration of High Dimensional Datasets; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Traditional multidimensional visualization techniques, such as glyphs, parallel coordinates and scatterplot matrices, suffer from clutter at the display level and difficult user navigation among dimensions when visualizing high dimensional datasets. In this paper, we propose a new multidimensional visualization technique named a value and relation (VaR) display, together with a rich set of navigation and selection tools, for interactive exploration of datasets with up to hundreds of dimensions. By explicitly conveying the relationships among the dimensions of a high dimensional dataset, the VaR display helps users grasp the associations among dimensions. By using pixel-oriented techniques to present values of the data items in a condensed manner, the VaR display reveals data patterns in the dataset using as little screen space as possible. The navigation and selection tools enable users to interactively reduce clutter, navigate within the dimension space, and examine data value details within context effectively and efficiently. The VaR display scales well to datasets with large numbers of data items by employing sampling and texture mapping. A case study on a real dataset, as well as the VaR displays of multiple real datasets throughout the paper, reveals how our proposed approach helps users interactively explore high dimensional datasets with large numbers of data items"}, {"color": "blue", "id": 224, "label": 224, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 224 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2005.1532122\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: M. Wattenberg; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Baby names, visualization, and social data analysis; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The Name Voyager, a Web based visualization of historical trends in baby naming, has proven remarkably popular. This paper discusses the interaction techniques it uses for smooth visual exploration of thousands of time series. We also describe design decisions behind the application and lessons learned in creating an application that makes do-it-yourself data mining popular. The prime lesson, it is hypothesized, is that an information visualization tool may be fruitfully viewed not as a tool but as part of an online social environment. In other words, to design a successful exploratory data analysis tool, one good strategy is to create a system that enables \"social\" data analysis"}, {"color": "blue", "id": 228, "label": 228, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 228 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2005.1532126\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: J. Heer;D. Boyd; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Vizster: visualizing online social networks; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Recent years have witnessed the dramatic popularity of online social networking services, in which millions of members publicly articulate mutual \"friendship\" relations. Guided by ethnographic research of these online communities, we have designed and implemented a visualization system for playful end-user exploration and navigation of large scale online social networks. Our design builds upon familiar node link network layouts to contribute customized techniques for exploring connectivity in large graph structures, supporting visual search and analysis, and automatically identifying and visualizing community structures. Both public installation and controlled studies of the system provide evidence of the system\u0027s usability, capacity for facilitating discovery, and potential for fun and engaged social activity"}, {"color": "blue", "id": 231, "label": 231, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 231 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2005.1532129\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Shengdong Zhao;M.J. McGuffin;M.H. Chignell; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Elastic hierarchies: combining treemaps and node-link diagrams; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We investigate the use of elastic hierarchies for representing trees, where a single graphical depiction uses a hybrid mixture, or \"interleaving\", of more basic forms at different nodes of the tree. In particular, we explore combinations of node link and treemap forms, to combine the space efficiency of treemaps with the structural clarity of node link diagrams. A taxonomy is developed to characterize the design space of such hybrid combinations. A software prototype is described, which we used to explore various techniques for visualizing, browsing and interacting with elastic hierarchies, such as side by side overview and detail views, highlighting and rubber banding across views, visualization of multiple foci, and smooth animations across transitions. The paper concludes with a discussion of the characteristics of elastic hierarchies and suggestions for research on their properties and uses."}, {"color": "blue", "id": 238, "label": 238, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 238 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2005.1532136\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: R. Amar;J. Eagan;J. Stasko; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Low-level components of analytic activity in information visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Existing system level taxonomies of visualization tasks are geared more towards the design of particular representations than the facilitation of user analytic activity. We present a set of ten low level analysis tasks that largely capture people\u0027s activities while employing information visualization tools for understanding data. To help develop these tasks, we collected nearly 200 sample questions from students about how they would analyze five particular data sets from different domains. The questions, while not being totally comprehensive, illustrated the sheer variety of analytic questions typically posed by users when employing information visualization systems. We hope that the presented set of tasks is useful for information visualization system designers as a kind of common substrate to discuss the relative analytic capabilities of the systems. Further, the tasks may provide a form of checklist for system designers."}, {"color": "blue", "id": 240, "label": 240, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 240 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2005.1532138\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: J. Johansson;P. Ljung;M. Jern;M. Cooper; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Revealing structure within clustered parallel coordinates displays; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In order to gain insight into multivariate data, complex structures must be analysed and understood. Parallel coordinates is an excellent tool for visualizing this type of data but has its limitations. This paper deals with one of its main limitations - how to visualize a large number of data items without hiding the inherent structure they constitute. We solve this problem by constructing clusters and using high precision textures to represent them. We also use transfer functions that operate on the high precision textures in order to highlight different aspects of the cluster characteristics. Providing predefined transfer functions as well as the support to draw customized transfer functions makes it possible to extract different aspects of the data. We also show how feature animation can be used as guidance when simultaneously analysing several clusters. This technique makes it possible to visually represent statistical information about clusters and thus guides the user, making the analysis process more efficient."}, {"color": "blue", "id": 243, "label": 243, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 243 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2005.1532141\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: E. Fanea;S. Carpendale;T. Isenberg; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: An interactive 3D integration of parallel coordinates and star glyphs; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Parallel coordinates are a powerful method for visualizing multidimensional data but, when applied to large data sets, they become cluttered and difficult to read. Star glyphs, on the other hand, can be used to display either the attributes of a data item or the values across all items for a single attribute. Star glyphs may readily provide a quick impression; however, since the full data set require multiple glyphs, overall readings are more difficult. We present parallel glyphs, an interactive integration of the visual representations of parallel coordinates and star glyphs that utilizes the advantages of both representations to offset the disadvantages they have separately. We discuss the role of uniform and stepped colour scales in the visual comparison of non-adjacent items and star glyphs. Parallel glyphs provide capabilities for focus-in-context exploration using two types of lenses and interactions specific to the 3D space."}, {"color": "blue", "id": 244, "label": 244, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 244 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2005.1532142\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: L. Wilkinson;A. Anand;R. Grossman; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Graph-theoretic scagnostics; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We introduce Tukey and Tukey scagnostics and develop graph-theoretic methods for implementing their procedure on large datasets."}, {"color": "blue", "id": 247, "label": 247, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 247 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2005.1532145\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: M. Wattenberg; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: A note on space-filling visualizations and space-filling curves; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: A recent line of treemap research has focused on layout algorithms that optimize properties such as stability, preservation of ordering information, and aspect ratio of rectangles. No ideal treemap layout algorithm has been found, and so it is natural to explore layouts that produce nonrectangular regions. This note describes a connection between space-filling visualizations and the mathematics of space-filling curves, and uses that connection to characterize a family of layout algorithms which produce nonrectangular regions but enjoy geometric continuity under changes to the data and legibility even for highly unbalanced trees."}, {"color": "blue", "id": 250, "label": 250, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 250 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2005.1532148\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: M.C. Hao;Umeshwar Dayal;D.A. Keim;T. Schreck; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Importance-driven visualization layouts for large time series data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Time series are an important type of data with applications in virtually every aspect of the real world. Often a large number of time series have to be monitored and analyzed in parallel. Sets of time series may show intrinsic hierarchical relationships and varying degrees of importance among the individual time series. Effective techniques for visually analyzing large sets of time series should encode the relative importance and hierarchical ordering of the time series data by size and position, and should also provide a high degree of regularity in order to support comparability by the analyst. In this paper, we present a framework for visualizing large sets of time series. Based on the notion of inter time series importance relationships, we define a set of objective functions that space-filling layout schemes for time series data should obey. We develop an efficient algorithm addressing the identified problems by generating layouts that reflect hierarchy and importance based relationships in a regular layout with favorable aspect ratios. We apply our technique to a number of real world data sets including sales and stock data, and we compare our technique with an aspect ratio aware variant of the well known TreeMap algorithm. The examples show the advantages and practical usefulness of our layout algorithm."}, {"color": "blue", "id": 252, "label": 252, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 252 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2005.1532150\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Doantam Phan;Ling Xiao;R. Yeh;P. Hanrahan; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Flow map layout; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Cartographers have long used flow maps to show the movement of objects from one location to another, such as the number of people in a migration, the amount of goods being traded, or the number of packets in a network. The advantage of flow maps is that they reduce visual clutter by merging edges. Most flow maps are drawn by hand and there are few computer algorithms available. We present a method for generating flow maps using hierarchical clustering given a set of nodes, positions, and flow data between the nodes. Our techniques are inspired by graph layout algorithms that minimize edge crossings and distort node positions while maintaining their relative position to one another. We demonstrate our technique by producing flow maps for network traffic, census data, and trade data."}, {"color": "blue", "id": 254, "label": 254, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 254 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/INFVIS.2005.1532152\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: P. Riehmann;M. Hanfler;B. Froehlich; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Interactive Sankey diagrams; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present a system that allows users to interactively explore complex flow scenarios represented as Sankey diagrams. Our system provides an overview of the flow graph and allows users to zoom in and explore details on demand. The support for quantitative flow tracing across the flow graph as well as representations at different levels of detail facilitate the understanding of complex flow situations. The energy flow in a city serves as a sample scenario for our system. Different forms of energy are distributed within the city and they are transformed into heat, electricity, or other forms of energy. These processes are visualized and interactively explored. In addition our system can be used as a planning tool for the exploration of alternative scenarios by interactively manipulating different parameters in the energy flow network."}, {"color": "blue", "id": 256, "label": 256, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 256 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2006.120\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: James Abello;Frank Van Ham;Neeraj Krishnan; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: ASK-graphView: a large scale graph visualization system; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We describe ASK-GraphView, a node-link-based graph visualization system that allows clustering and interactive navigation of large graphs, ranging in size up to 16 million edges. The system uses a scalable architecture and a series of increasingly sophisticated clustering algorithms to construct a hierarchy on an arbitrary, weighted undirected input graph. By lowering the interactivity requirements we can scale to substantially bigger graphs. The user is allowed to navigate this hierarchy in a top down manner by interactively expanding individual clusters. ASK-GraphView also provides facilities for filtering and coloring, annotation and cluster labeling"}, {"color": "blue", "id": 257, "label": 257, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 257 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2006.122\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Adam Perer;Ben Shneiderman; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Balancing Systematic and Flexible Exploration of Social Networks; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Social network analysis (SNA) has emerged as a powerful method for understanding the importance of relationships in networks. However, interactive exploration of networks is currently challenging because: (1) it is difficult to find patterns and comprehend the structure of networks with many nodes and links, and (2) current systems are often a medley of statistical methods and overwhelming visual output which leaves many analysts uncertain about how to explore in an orderly manner. This results in exploration that is largely opportunistic. Our contributions are techniques to help structural analysts understand social networks more effectively. We present SocialAction, a system that uses attribute ranking and coordinated views to help users systematically examine numerous SNA measures. Users can (1) flexibly iterate through visualizations of measures to gain an overview, filter nodes, and find outliers, (2) aggregate networks using link structure, find cohesive subgroups, and focus on communities of interest, and (3) untangle networks by viewing different link types separately, or find patterns across different link types using a matrix overview. For each operation, a stable node layout is maintained in the network visualization so users can make comparisons. SocialAction offers analysts a strategy beyond opportunism, as it provides systematic, yet flexible, techniques for exploring social networks"}, {"color": "blue", "id": 260, "label": 260, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 260 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2006.138\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Geoffrey Ellis;Alan Dix; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Enabling Automatic Clutter Reduction in Parallel Coordinate Plots; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We have previously shown that random sampling is an effective clutter reduction technique and that a sampling lens can facilitate focus+context viewing of particular regions. This demands an efficient method of estimating the overlap or occlusion of large numbers of intersecting lines in order to automatically adjust the sampling rate within the lens. This paper proposes several ways for measuring occlusion in parallel coordinate plots. An empirical study into the accuracy and efficiency of the occlusion measures show that a probabilistic approach combined with a \u0027binning\u0027 technique is very fast and yet approaches the accuracy of the more expensive \u0027true\u0027 complete measurement"}, {"color": "blue", "id": 262, "label": 262, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 262 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2006.147\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Danny Holten; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Hierarchical Edge Bundles: Visualization of Adjacency Relations in Hierarchical Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: A compound graph is a frequently encountered type of data set. Relations are given between items, and a hierarchy is defined on the items as well. We present a new method for visualizing such compound graphs. Our approach is based on visually bundling the adjacency edges, i.e., non-hierarchical edges, together. We realize this as follows. We assume that the hierarchy is shown via a standard tree visualization method. Next, we bend each adjacency edge, modeled as a B-spline curve, toward the polyline defined by the path via the inclusion edges from one node to another. This hierarchical bundling reduces visual clutter and also visualizes implicit adjacency edges between parent nodes that are the result of explicit adjacency edges between their respective child nodes. Furthermore, hierarchical edge bundling is a generic method which can be used in conjunction with existing tree visualization techniques. We illustrate our technique by providing example visualizations and discuss the results based on an informal evaluation provided by potential users of such visualizations"}, {"color": "blue", "id": 263, "label": 263, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 263 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2006.156\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Tim Dwyer;Yehuda Koren;Kim Marriott; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: IPSep-CoLa: An Incremental Procedure for Separation Constraint Layout of Graphs; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We extend the popular force-directed approach to network (or graph) layout to allow separation constraints, which enforce a minimum horizontal or vertical separation between selected pairs of nodes. This simple class of linear constraints is expressive enough to satisfy a wide variety of application-specific layout requirements, including: layout of directed graphs to better show flow; layout with non-overlapping node labels; and layout of graphs with grouped nodes (called clusters). In the stress majorization force-directed layout process, separation constraints can be treated as a quadratic programming problem. We give an incremental algorithm based on gradient projection for efficiently solving this problem. The algorithm is considerably faster than using generic constraint optimization techniques and is comparable in speed to unconstrained stress majorization. We demonstrate the utility of our technique with sample data from a number of practical applications including gene-activation networks, terrorist networks and visualization of high-dimensional data."}, {"color": "blue", "id": 264, "label": 264, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 264 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2006.160\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Nathalie Henry;Jean-daniel Fekete; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: MatrixExplorer: a Dual-Representation System to Explore Social Networks; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: MatrixExplorer is a network visualization system that uses two representations: node-link diagrams and matrices. Its design comes from a list of requirements formalized after several interviews and a participatory design session conducted with social science researchers. Although matrices are commonly used in social networks analysis, very few systems support the matrix-based representations to visualize and analyze networks. MatrixExplorer provides several novel features to support the exploration of social networks with a matrix-based representation, in addition to the standard interactive filtering and clustering functions. It provides tools to reorder (layout) matrices, to annotate and compare findings across different layouts and find consensus among several clusterings. MatrixExplorer also supports node-link diagram views which are familiar to most users and remain a convenient way to publish or communicate exploration results. Matrix and node-link representations are kept synchronized at all stages of the exploration process"}, {"color": "blue", "id": 265, "label": 265, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 265 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2006.161\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Qingguang Cui;Matthew Ward;Elke Rundensteiner;Jing Yang; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Measuring Data Abstraction Quality in Multiresolution Visualizations; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Data abstraction techniques are widely used in multiresolution visualization systems to reduce visual clutter and facilitate analysis from overview to detail. However, analysts are usually unaware of how well the abstracted data represent the original dataset, which can impact the reliability of results gleaned from the abstractions. In this paper, we define two data abstraction quality measures for computing the degree to which the abstraction conveys the original dataset: the histogram difference measure and the nearest neighbor measure. They have been integrated within XmdvTool, a public-domain multiresolution visualization system for multivariate data analysis that supports sampling as well as clustering to simplify data. Several interactive operations are provided, including adjusting the data abstraction level, changing selected regions, and setting the acceptable data abstraction quality level. Conducting these operations, analysts can select an optimal data abstraction level. Also, analysts can compare different abstraction methods using the measures to see how well relative data density and outliers are maintained, and then select an abstraction method that meets the requirement of their analytic tasks"}, {"color": "blue", "id": 266, "label": 266, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 266 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2006.163\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jeffrey Heer;Maneesh Agrawala; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Multi-Scale Banking to 45 Degrees; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In his text Visualizing Data, William Cleveland demonstrates how the aspect ratio of a line chart can affect an analyst\u0027s perception of trends in the data. Cleveland proposes an optimization technique for computing the aspect ratio such that the average absolute orientation of line segments in the chart is equal to 45 degrees. This technique, called banking to 45deg, is designed to maximize the discriminability of the orientations of the line segments in the chart. In this paper, we revisit this classic result and describe two new extensions. First, we propose alternate optimization criteria designed to further improve the visual perception of line segment orientations. Second, we develop multi-scale banking, a technique that combines spectral analysis with banking to 45deg. Our technique automatically identifies trends at various frequency scales and then generates a banked chart for each of these scales. We demonstrate the utility of our techniques in a range of visualization tools and analysis examples"}, {"color": "blue", "id": 267, "label": 267, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 267 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2006.166\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Ben Shneiderman;Aleks Aris; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Network Visualization by Semantic Substrates; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Networks have remained a challenge for information visualization designers because of the complex issues of node and link layout coupled with the rich set of tasks that users present. This paper offers a strategy based on two principles: (1) layouts are based on user-defined semantic substrates, which are non-overlapping regions in which node placement is based on node attributes, (2) users interactively adjust sliders to control link visibility to limit clutter and thus ensure comprehensibility of source and destination. Scalability is further facilitated by user control of which nodes are visible. We illustrate our semantic substrates approach as implemented in NVSS 1.0 with legal precedent data for up to 1122 court cases in three regions with 7645 legal citations"}, {"color": "blue", "id": 269, "label": 269, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 269 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2006.178\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jeffrey Heer;Maneesh Agrawala; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Software Design Patterns for Information Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Despite a diversity of software architectures supporting information visualization, it is often difficult to identify, evaluate, and re-apply the design solutions implemented within such frameworks. One popular and effective approach for addressing such difficulties is to capture successful solutions in design patterns, abstract descriptions of interacting software components that can be customized to solve design problems within a particular context. Based upon a review of existing frameworks and our own experiences building visualization software, we present a series of design patterns for the domain of information visualization. We discuss the structure, context of use, and interrelations of patterns spanning data representation, graphics, and interaction. By representing design knowledge in a reusable form, these patterns can be used to facilitate software design, implementation, and evaluation, and improve developer education and communication"}, {"color": "blue", "id": 275, "label": 275, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 275 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2006.193\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: D. Auber;T. Munzner;D. Archambault;D. Auber;T. Munzner;D. Archambault; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visual Exploration of Complex Time-Varying Graphs; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Many graph drawing and visualization algorithms, such as force-directed layout and line-dot rendering, work very well on relatively small and sparse graphs. However, they often produce extremely tangled results and exhibit impractical running times for highly non-planar graphs with large edge density. And very few graph layout algorithms support dynamic time-varying graphs; applying them independently to each frame produces distracting temporally incoherent visualizations. We have developed a new visualization technique based on a novel approach to hierarchically structuring dense graphs via stratification. Using this structure, we formulate a hierarchical force-directed layout algorithm that is both efficient and produces quality graph layouts. The stratification of the graph also allows us to present views of the data that abstract away many small details of its structure. Rather than displaying all edges and nodes at once, resulting in a convoluted rendering, we present an interactive tool that filters edges and nodes using the graph hierarchy and allows users to drill down into the graph for details. Our layout algorithm also accommodates time-varying graphs in a natural way, producing a temporally coherent animation that can be used to analyze and extract trends from dynamic graph data. For example, we demonstrate the use of our method to explore financial correlation data for the U.S. stock market in the period from 1990 to 2005. The user can easily analyze the time-varying correlation graph of the market, uncovering information such as market sector trends, representative stocks for portfolio construction, and the interrelationship of stocks over time."}, {"color": "orange", "id": 285, "label": 285, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 285 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2006.261421\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jerry Alan Fails;Amy Karlson;Layla Shahamat;Ben Shneiderman; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: A Visual Interface for Multivariate Temporal Data: Finding Patterns of Events across Multiple Histories; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Finding patterns of events over time is important in searching patient histories, Web logs, news stories, and criminal activities. This paper presents PatternFinder, an integrated interface for query and result-set visualization for search and discovery of temporal patterns within multivariate and categorical data sets. We define temporal patterns as sequences of events with inter-event time spans. PatternFinder allows users to specify the attributes of events and time spans to produce powerful pattern queries that are difficult to express with other formalisms. We characterize the range of queries PatternFinder supports as users vary the specificity at which events and time spans are defined. Pattern Finder\u0027s query capabilities together with coupled ball-and-chain and tabular visualizations enable users to effectively query, explore and analyze event patterns both within and across data entities (e.g. patient histories, terrorist groups, Web logs, etc.)"}, {"color": "orange", "id": 287, "label": 287, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 287 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2006.261423\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jorn Schneidewind;Mike Sips;Daniel A. Keim; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Pixnostics: Towards Measuring the Value of Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: During the last two decades a wide variety of advanced methods for the visual exploration of large data sets have been proposed. For most of these techniques user interaction has become a crucial element, since there are many situations in which a user or an analyst has to select the right parameter settings from among many or select a subset of the available attribute space for the visualization process, in order to construct valuable visualizations that provide insight, into the data and reveal interesting patterns. The right choice of input parameters is often essential, since suboptimal parameter settings or the investigation of irrelevant data dimensions make the exploration process more time consuming and may result in wrong conclusions. In this paper we propose a novel method for automatically determining meaningful parameter- and attribute settings based on the information content of the resulting visualizations. Our technique called Pixnostics, in analogy to Scagnostics (Wilkinson et al., 2005), automatically analyses pixel images resulting from diverse parameter mappings and ranks them according to the potential value for the user. This allows a more effective and more efficient visual data analysis process, since the attribute/parameter space is reduced to meaningful selections and thus the analyst obtains faster insight into the data. Real world applications are provided to show the benefit of the proposed approach"}, {"color": "orange", "id": 290, "label": 290, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 290 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2006.261426\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Hyunmo Kang;Catherine Plaisant;Bongshin Lee;Benjamin B. Bederson; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: NetLens: Iterative Exploration of Content-Actor Network Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Networks have remained a challenge for information retrieval and visualization because of the rich set of tasks that users want to accomplish. This paper offers an abstract content-actor network data model, a classification of tasks, and a tool to support them. The NetLens interface was designed around the abstract content-actor network data model to allow users to pose a series of elementary queries and iteratively refine visual overviews and sorted lists. This enables the support of complex queries that are traditionally hard to specify. NetLens is general and scalable in that it applies to any dataset that can be represented with our abstract data model. This paper describes NetLens applying a subset of the ACM Digital Library consisting of about 4,000 papers from the CM I conference written by about 6,000 authors. In addition, we are now working on a collection of half a million emails, and a dataset of legal cases"}, {"color": "orange", "id": 292, "label": 292, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 292 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2006.261428\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Chris Weaver;David Fyfe;Anthony Robinson;Deryck Holdsworth;Donna Peuquet;Alan M. MacEachren; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visual Analysis of Historic Hotel Visitation Patterns; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Understanding the space and time characteristics of human interaction in complex social networks is a critical component of visual tools for intelligence analysis, consumer behavior analysis, and human geography. Visual identification and comparison of patterns of recurring events is an essential feature of such tools. In this paper, we describe a tool for exploring hotel visitation patterns in and around Rebersburg, Pennsylvania from 1898-1900. The tool uses a wrapping spreadsheet technique, called reruns, to display cyclic patterns of geographic events in multiple overlapping natural and artificial calendars. Implemented as an improvise visualization, the tool is in active development through a iterative process of data collection, hypothesis, design, discovery, and evaluation in close collaboration with historical geographers. Several discoveries have inspired ongoing data collection and plans to expand exploration to include historic weather records and railroad schedules. Distributed online evaluations of usability and usefulness have resulted in numerous feature and design recommendations"}, {"color": "orange", "id": 303, "label": 303, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 303 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2006.261439\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Susan E. Brennan;Klaus Mueller;Greg Zelinsky;IV Ramakrishnan;David S. Warren;Arie Kaufman; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Toward a Multi-Analyst, Collaborative Framework for Visual Analytics; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We describe a framework for the display of complex, multidimensional data, designed to facilitate exploration, analysis, and collaboration among multiple analysts. This framework aims to support human collaboration by making it easier to share representations, to translate from one point of view to another, to explain arguments, to update conclusions when underlying assumptions change, and to justify or account for decisions or actions. Multidimensional visualization techniques are used with interactive, context-sensitive, and tunable graphs. Visual representations are flexibly generated using a knowledge representation scheme based on annotated logic; this enables not only tracking and fusing different viewpoints, but also unpacking them. Fusing representations supports the creation of multidimensional meta-displays as well as the translation or mapping from one point of view to another. At the same time, analysts also need to be able to unpack one another\u0027s complex chains of reasoning, especially if they have reached different conclusions, and to determine the implications, if any, when underlying assumptions or evidence turn out to be false. The framework enables us to support a variety of scenarios as well as to systematically generate and test experimental hypotheses about the impact of different kinds of visual representations upon interactive collaboration by teams of distributed analysts"}, {"color": "blue", "id": 307, "label": 307, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 307 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2007.70515\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Ji Soo Yi;Youn ah Kang;John Stasko; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Toward a Deeper Understanding of the Role of Interaction in Information Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Even though interaction is an important part of information visualization (Infovis), it has garnered a relatively low level of attention from the Infovis community. A few frameworks and taxonomies of Infovis interaction techniques exist, but they typically focus on low-level operations and do not address the variety of benefits interaction provides. After conducting an extensive review of Infovis systems and their interactive capabilities, we propose seven general categories of interaction techniques widely used in Infovis: 1) Select, 2) Explore, 3) Reconfigure, 4) Encode, 5) Abstract/Elaborate, 6) Filter, and 7) Connect. These categories are organized around a user\u0027s intent while interacting with a system rather than the low-level interaction techniques provided by a system. The categories can act as a framework to help discuss and evaluate interaction techniques and hopefully lay an initial foundation toward a deeper understanding and a science of interaction."}, {"color": "blue", "id": 308, "label": 308, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 308 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2007.70521\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Christopher Collins;Sheelagh Carpendale; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: VisLink: Revealing Relationships Amongst Visualizations; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present VisLink, a method by which visualizations and the relationships between them can be interactively explored. VisLink readily generalizes to support multiple visualizations, empowers inter-representational queries, and enables the reuse of the spatial variables, thus supporting efficient information encoding and providing for powerful visualization bridging. Our approach uses multiple 2D layouts, drawing each one in its own plane. These planes can then be placed and re-positioned in 3D space: side by side, in parallel, or in chosen placements that provide favoured views. Relationships, connections, and patterns between visualizations can be revealed and explored using a variety of interaction techniques including spreading activation and search filters."}, {"color": "blue", "id": 311, "label": 311, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 311 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2007.70529\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Ying Tu;Han-Wei Shen; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visualizing Changes of Hierarchical Data using Treemaps; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: While the treemap is a popular method for visualizing hierarchical data, it is often difficult for users to track layout and attribute changes when the data evolve over time. When viewing the treemaps side by side or back and forth, there exist several problems that can prevent viewers from performing effective comparisons. Those problems include abrupt layout changes, a lack of prominent visual patterns to represent layouts, and a lack of direct contrast to highlight differences. In this paper, we present strategies to visualize changes of hierarchical data using treemaps. A new treemap layout algorithm is presented to reduce abrupt layout changes and produce consistent visual patterns. Techniques are proposed to effectively visualize the difference and contrast between two treemap snapshots in terms of the map items\u0027 colors, sizes, and positions. Experimental data show that our algorithm can achieve a good balance in maintaining a treemap\u0027s stability, continuity, readability, and average aspect ratio. A software tool is created to compare treemaps and generate the visualizations. User studies show that the users can better understand the changes in the hierarchy and layout, and more quickly notice the color and size differences using our method."}, {"color": "blue", "id": 312, "label": 312, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 312 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2007.70535\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Geoffrey Ellis;Alan Dix; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: A Taxonomy of Clutter Reduction for Information Visualisation; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Information visualisation is about gaining insight into data through a visual representation. This data is often multivariate and increasingly, the datasets are very large. To help us explore all this data, numerous visualisation applications, both commercial and research prototypes, have been designed using a variety of techniques and algorithms. Whether they are dedicated to geo-spatial data or skewed hierarchical data, most of the visualisations need to adopt strategies for dealing with overcrowded displays, brought about by too much data to fit in too small a display space. This paper analyses a large number of these clutter reduction methods, classifying them both in terms of how they deal with clutter reduction and more importantly, in terms of the benefits and losses. The aim of the resulting taxonomy is to act as a guide to match techniques to problems where different criteria may have different importance, and more importantly as a means to critique and hence develop existing and new techniques."}, {"color": "blue", "id": 314, "label": 314, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 314 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2007.70539\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jeffrey Heer;George Robertson; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Animated Transitions in Statistical Data Graphics; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In this paper we investigate the effectiveness of animated transitions between common statistical data graphics such as bar charts, pie charts, and scatter plots. We extend theoretical models of data graphics to include such transitions, introducing a taxonomy of transition types. We then propose design principles for creating effective transitions and illustrate the application of these principles in \u0026lt;i\u0026gt;DynaVis\u0026lt;/i\u0026gt;, a visualization system featuring animated data graphics. Two controlled experiments were conducted to assess the efficacy of various transition types, finding that animated transitions can significantly improve graphical perception."}, {"color": "blue", "id": 316, "label": 316, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 316 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2007.70541\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Zachary Pousman;John Stasko;Michael Mateas; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Casual Information Visualization: Depictions of Data in Everyday Life; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Information visualization has often focused on providing deep insight for expert user populations and on techniques for amplifying cognition through complicated interactive visual models. This paper proposes a new subdomain for infovis research that complements the focus on analytic tasks and expert use. Instead of work-related and analytically driven infovis, we propose casual information visualization (or casual infovis) as a complement to more traditional infovis domains. Traditional infovis systems, techniques, and methods do not easily lend themselves to the broad range of user populations, from expert to novices, or from work tasks to more everyday situations. We propose definitions, perspectives, and research directions for further investigations of this emerging subfield. These perspectives build from ambient information visualization (Skog et al., 2003), social visualization, and also from artistic work that visualizes information (Viegas and Wattenberg, 2007). We seek to provide a perspective on infovis that integrates these research agendas under a coherent vocabulary and framework for design. We enumerate the following contributions. First, we demonstrate how blurry the boundary of infovis is by examining systems that exhibit many of the putative properties of infovis systems, but perhaps would not be considered so. Second, we explore the notion of insight and how, instead of a monolithic definition of insight, there may be multiple types, each with particular characteristics. Third, we discuss design challenges for systems intended for casual audiences. Finally we conclude with challenges for system evaluation in this emerging subfield."}, {"color": "blue", "id": 317, "label": 317, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 317 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2007.70556\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Martin Graham;Jessie Kennedy; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Exploring Multiple Trees through DAG Representations; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present a directed acyclic graph visualisation designed to allow interaction with a set of multiple classification trees, specifically to find overlaps and differences between groups of trees and individual trees. The work is motivated by the need to find a representation for multiple trees that has the space-saving property of a general graph representation and the intuitive parent-child direction cues present in individual representation of trees. Using example taxonomic data sets, we describe augmentations to the common barycenter DAG layout method that reveal shared sets of child nodes between common parents in a clearer manner. Other interactions such as displaying the multiple ancestor paths of a node when it occurs in several trees, and revealing intersecting sibling sets within the context of a single DAG representation are also discussed."}, {"color": "blue", "id": 320, "label": 320, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 320 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2007.70568\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Petra Isenberg;Sheelagh Carpendale; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Interactive Tree Comparison for Co-located Collaborative Information Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In many domains, increased collaboration has lead to more innovation by fostering the sharing of knowledge, skills, and ideas. Shared analysis of information visualizations does not only lead to increased information processing power, but team members can also share, negotiate, and discuss their views and interpretations on a dataset and contribute unique perspectives on a given problem. Designing technologies to support collaboration around information visualizations poses special challenges and relatively few systems have been designed. We focus on supporting small groups collaborating around information visualizations in a co-located setting, using a shared interactive tabletop display. We introduce an analysis of challenges and requirements for the design of co-located collaborative information visualization systems. We then present a new system that facilitates hierarchical data comparison tasks for this type of collaborative work. Our system supports multi-user input, shared and individual views on the hierarchical data visualization, flexible use of representations, and flexible workspace organization to facilitate group work around visualizations."}, {"color": "blue", "id": 322, "label": 322, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 322 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2007.70574\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Remco Chang;Ginette Wessel;Robert Kosara;Eric Sauda;William Ribarsky; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Legible Cities: Focus-Dependent Multi-Resolution Visualization of Urban Relationships; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Numerous systems have been developed to display large collections of data for urban contexts; however, most have focused on layering of single dimensions of data and manual calculations to understand relationships within the urban environment. Furthermore, these systems often limit the user\u0027s perspectives on the data, thereby diminishing the user\u0027s spatial understanding of the viewing region. In this paper, we introduce a highly interactive urban visualization tool that provides intuitive understanding of the urban data. Our system utilizes an aggregation method that combines buildings and city blocks into legible clusters, thus providing continuous levels of abstraction while preserving the user\u0027s mental model of the city. In conjunction with a 3D view of the urban model, a separate but integrated information visualization view displays multiple disparate dimensions of the urban data, allowing the user to understand the urban environment both spatially and cognitively in one glance. For our evaluation, expert users from various backgrounds viewed a real city model with census data and confirmed that our system allowed them to gain more intuitive and deeper understanding of the urban model from different perspectives and levels of abstraction than existing commercial urban visualization systems."}, {"color": "blue", "id": 323, "label": 323, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 323 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2007.70577\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Fernanda B. Viegas;Martin Wattenberg;Frank van Ham;Jesse Kriss;Matt McKeon; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: ManyEyes: a Site for Visualization at Internet Scale; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We describe the design and deployment of Many Eyes, a public Web site where users may upload data, create interactive visualizations, and carry on discussions. The goal of the site is to support collaboration around visualizations at a large scale by fostering a social style of data analysis in which visualizations not only serve as a discovery tool for individuals but also as a medium to spur discussion among users. To support this goal, the site includes novel mechanisms for end-user creation of visualizations and asynchronous collaboration around those visualizations. In addition to describing these technologies, we provide a preliminary report on the activity of our users."}, {"color": "blue", "id": 324, "label": 324, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 324 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2007.70580\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Yaniv Frishman;Ayellet Tal; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Multi-Level Graph Layout on the GPU; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: This paper presents a new algorithm for force directed graph layout on the GPU. The algorithm, whose goal is to compute layouts accurately and quickly, has two contributions. The first contribution is proposing a general multi-level scheme, which is based on spectral partitioning. The second contribution is computing the layout on the GPU. Since the GPU requires a data parallel programming model, the challenge is devising a mapping of a naturally unstructured graph into a well-partitioned structured one. This is done by computing a balanced partitioning of a general graph. This algorithm provides a general multi-level scheme, which has the potential to be used not only for computation on the GPU, but also on emerging multi-core architectures. The algorithm manages to compute high quality layouts of large graphs in a fraction of the time required by existing algorithms of similar quality. An application for visualization of the topologies of ISP (Internet service provider) networks is presented."}, {"color": "blue", "id": 325, "label": 325, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 325 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2007.70582\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Nathalie Henry;Jean-Daniel Fekete;Michael J. McGuffin; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: NodeTrix: a Hybrid Visualization of Social Networks; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The need to visualize large social networks is growing as hardware capabilities make analyzing large networks feasible and many new data sets become available. Unfortunately, the visualizations in existing systems do not satisfactorily resolve the basic dilemma of being readable both for the global structure of the network and also for detailed analysis of local communities. To address this problem, we present NodeTrix, a hybrid representation for networks that combines the advantages of two traditional representations: node-link diagrams are used to show the global structure of a network, while arbitrary portions of the network can be shown as adjacency matrices to better support the analysis of communities. A key contribution is a set of interaction techniques. These allow analysts to create a NodeTrix visualization by dragging selections to and from node-link and matrix forms, and to flexibly manipulate the NodeTrix representation to explore the dataset and create meaningful summary visualizations of their findings. Finally, we present a case study applying NodeTrix to the analysis of the InfoVis 2004 coauthorship dataset to illustrate the capabilities of NodeTrix as both an exploration tool and an effective means of communicating results."}, {"color": "blue", "id": 327, "label": 327, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 327 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2007.70589\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Wesley Willett;Jeffrey Heer;Maneesh Agrawala; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Scented Widgets: Improving Navigation Cues with Embedded Visualizations; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: This paper presents scented widgets, graphical user interface controls enhanced with embedded visualizations that facilitate navigation in information spaces. We describe design guidelines for adding visual cues to common user interface widgets such as radio buttons, sliders, and combo boxes and contribute a general software framework for applying scented widgets within applications with minimal modifications to existing source code. We provide a number of example applications and describe a controlled experiment which finds that users exploring unfamiliar data make up to twice as many unique discoveries using widgets imbued with social navigation data. However, these differences equalize as familiarity with the data increases."}, {"color": "blue", "id": 329, "label": 329, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 329 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2007.70594\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jock Mackinlay;Pat Hanrahan;Chris Stolte; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Show Me: Automatic Presentation for Visual Analysis; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: This paper describes Show Me, an integrated set of user interface commands and defaults that incorporate automatic presentation into a commercial visual analysis system called Tableau. A key aspect of Tableau is VizQL, a language for specifying views, which is used by Show Me to extend automatic presentation to the generation of tables of views (commonly called small multiple displays). A key research issue for the commercial application of automatic presentation is the user experience, which must support the flow of visual analysis. User experience has not been the focus of previous research on automatic presentation. The Show Me user experience includes the automatic selection of mark types, a command to add a single field to a view, and a pair of commands to build views for multiple fields. Although the use of these defaults and commands is optional, user interface logs indicate that Show Me is used by commercial users."}, {"color": "blue", "id": 330, "label": 330, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 330 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2007.70596\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Melanie Tory;David Sprague;Fuqu Wu;Wing Yan So;Tamara Munzner; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Spatialization Design: Comparing Points and Landscapes; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Spatializations represent non-spatial data using a spatial layout similar to a map. We present an experiment comparing different visual representations of spatialized data, to determine which representations are best for a non-trivial search and point estimation task. Primarily, we compare point-based displays to 2D and 3D information landscapes. We also compare a colour (hue) scale to a grey (lightness) scale. For the task we studied, point-based spatializations were far superior to landscapes, and 2D landscapes were superior to 3D landscapes. Little or no benefit was found for redundantly encoding data using colour or greyscale combined with landscape height. 3D landscapes with no colour scale (height-only) were particularly slow and inaccurate. A colour scale was found to be better than a greyscale for all display types, but a greyscale was helpful compared to height-only. These results suggest that point-based spatializations should be chosen over landscape representations, at least for tasks involving only point data itself rather than derived information about the data space."}, {"color": "orange", "id": 337, "label": 337, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 337 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2007.4388992\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Ryan Eccles;Thomas Kapler;Robert Harper;William Wright; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Stories in GeoTime; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: A story is a powerful abstraction used by intelligence analysts to conceptualize threats and understand patterns as part of the analytical process. This paper demonstrates a system that detects geo-temporal patterns and integrates story narration to increase analytic sense-making cohesion in GeoTime. The GeoTime geo-temporal event visualization tool was augmented with a story system that uses narratives, hypertext linked visualizations, visual annotations, and pattern detection to create an environment for analytic exploration and communication, thereby assisting the analyst in identifying, extracting, arranging and presenting stories within the data The story system lets analysts operate at the story level with higher-level abstractions of data, such as behaviors and events, while staying connected to the evidence. The story system was developed and evaluated in collaboration with analysts."}, {"color": "orange", "id": 344, "label": 344, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 344 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2007.4388999\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Eun Ju Nam;Yiping Han;Klaus Mueller;Alla Zelenyuk;Dan Imre; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: ClusterSculptor: A Visual Analytics Tool for High-Dimensional Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Cluster analysis (CA) is a powerful strategy for the exploration of high-dimensional data in the absence of a-priori hypotheses or data classification models, and the results of CA can then be used to form such models. But even though formal models and classification rules may not exist in these data exploration scenarios, domain scientists and experts generally have a vast amount of non-compiled knowledge and intuition that they can bring to bear in this effort. In CA, there are various popular mechanisms to generate the clusters, however, the results from their non- supervised deployment rarely fully agree with this expert knowledge and intuition. To this end, our paper describes a comprehensive and intuitive framework to aid scientists in the derivation of classification hierarchies in CA, using k-means as the overall clustering engine, but allowing them to tune its parameters interactively based on a non-distorted compact visual presentation of the inherent characteristics of the data in high- dimensional space. These include cluster geometry, composition, spatial relations to neighbors, and others. In essence, we provide all the tools necessary for a high-dimensional activity we call cluster sculpting, and the evolving hierarchy can then be viewed in a space-efficient radial dendrogram. We demonstrate our system in the context of the mining and classification of a large collection of millions of data items of aerosol mass spectra, but our framework readily applies to any high-dimensional CA scenario."}, {"color": "orange", "id": 345, "label": 345, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 345 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2007.4389000\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Di Yang;Elke A. Rundensteiner;Matthew O. Ward; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Analysis Guided Visual Exploration of Multivariate Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Visualization systems traditionally focus on graphical representation of information. They tend not to provide integrated analytical services that could aid users in tackling complex knowledge discovery tasks. Users\u0027 exploration in such environments is usually impeded due to several problems: 1) valuable information is hard to discover when too much data is visualized on the screen; 2) Users have to manage and organize their discoveries off line, because no systematic discovery management mechanism exists; 3) their discoveries based on visual exploration alone may lack accuracy; 4) and they have no convenient access to the important knowledge learned by other users. To tackle these problems, it has been recognized that analytical tools must be introduced into visualization systems. In this paper, we present a novel analysis-guided exploration system, called the nugget management system (NMS). It leverages the collaborative effort of human comprehensibility and machine computations to facilitate users\u0027 visual exploration processes. Specifically, NMS first extracts the valuable information (nuggets) hidden in datasets based on the interests of users. Given that similar nuggets may be re-discovered by different users, NMS consolidates the nugget candidate set by clustering based on their semantic similarity. To solve the problem of inaccurate discoveries, localized data mining techniques are applied to refine the nuggets to best represent the captured patterns in datasets. Lastly, the resulting well-organized nugget pool is used to guide users\u0027 exploration. To evaluate the effectiveness of NMS, we integrated NMS into Xmd- vTool, a freeware multivariate visualization system. User studies were performed to compare the users\u0027 efficiency and accuracy in finishing tasks on real datasets, with and without the help of NMS. Our user studies confirmed the effectiveness of NMS."}, {"color": "orange", "id": 349, "label": 349, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 349 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2007.4389004\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Daniel A. Keim;Daniela Oelke; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Literature Fingerprinting: A New Method for Visual Literary Analysis; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In computer-based literary analysis different types of features are used to characterize a text. Usually, only a single feature value or vector is calculated for the whole text. In this paper, we combine automatic literature analysis methods with an effective visualization technique to analyze the behavior of the feature values across the text. For an interactive visual analysis, we calculate a sequence of feature values per text and present them to the user as a characteristic fingerprint. The feature values may be calculated on different hierarchy levels, allowing the analysis to be done on different resolution levels. A case study shows several successful applications of our new method to known literature problems and demonstrates the advantage of our new visual literature fingerprinting."}, {"color": "orange", "id": 351, "label": 351, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 351 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2007.4389006\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: John Stasko;Carsten Gorg;Zhicheng Liu;Kanupriya Singhal; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Jigsaw: Supporting Investigative Analysis through Interactive Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Investigative analysts who work with collections of text documents connect embedded threads of evidence in order to formulate hypotheses about plans and activities of potential interest. As the number of documents and the corresponding number of concepts and entities within the documents grow larger, sense-making processes become more and more difficult for the analysts. We have developed a visual analytic system called Jigsaw that represents documents and their entities visually in order to help analysts examine reports more efficiently and develop theories about potential actions more quickly. Jigsaw provides multiple coordinated views of document entities with a special emphasis on visually illustrating connections between entities across the different documents."}, {"color": "orange", "id": 353, "label": 353, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 353 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2007.4389008\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Heidi Lam;Daniel Russell;Diane Tang;Tamara Munzner; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Session Viewer: Visual Exploratory Analysis of Web Session Logs; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Large-scale session log analysis typically includes statistical methods and detailed log examinations. While both methods have merits, statistical methods can miss previously unknown sub- populations in the data and detailed analyses may have selection biases. We therefore built Session Viewer, a visualization tool to facilitate and bridge between statistical and detailed analyses. Taking a multiple-coordinated view approach, Session Viewer shows multiple session populations at the Aggregate, Multiple, and Detail data levels to support different analysis styles. To bridge between the statistical and the detailed analysis levels, Session Viewer provides fluid traversal between data levels and side-by-side comparison at all data levels. We describe an analysis of a large-scale web usage study to demonstrate the use of Session Viewer, where we quantified the importance of grouping sessions based on task type."}, {"color": "orange", "id": 354, "label": 354, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 354 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2007.4389009\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Remco Chang;Mohammad Ghoniem;Robert Kosara;William Ribarsky;Jing Yang;Evan Suma;Caroline Ziemkiewicz;Daniel Kern;Agus Sudjianto; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: WireVis: Visualization of Categorical, Time-Varying Data From Financial Transactions; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Large financial institutions such as Bank of America handle hundreds of thousands of wire transactions per day. Although most transactions are legitimate, these institutions have legal and financial obligations in discovering those that are suspicious. With the methods of fraudulent activities ever changing, searching on predefined patterns is often insufficient in detecting previously undiscovered methods. In this paper, we present a set of coordinated visualizations based on identifying specific keywords within the wire transactions. The different views used in our system depict relationships among keywords and accounts over time. Furthermore, we introduce a search-by-example technique which extracts accounts that show similar transaction patterns. In collaboration with the Anti-Money Laundering division at Bank of America, we demonstrate that using our tool, investigators are able to detect accounts and transactions that exhibit suspicious behaviors."}, {"color": "orange", "id": 356, "label": 356, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 356 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2007.4389011\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jeffrey Heer;Maneesh Agrawala; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Design Considerations for Collaborative Visual Analytics; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Information visualization leverages the human visual system to support the process of sensemaking, in which information is collected, organized, and analyzed to generate knowledge and inform action. Though most research to date assumes a single-user focus on perceptual and cognitive processes, in practice, sensemaking is often a social process involving parallelization of effort, discussion, and consensus building. This suggests that to fully support sensemaking, interactive visualization should also support social interaction. However, the most appropriate collaboration mechanisms for supporting this interaction are not immediately clear. In this article, we present design considerations for asynchronous collaboration in visual analysis environments, highlighting issues of work parallelization, communication, and social organization. These considerations provide a guide for the design and evaluation of collaborative visualization systems."}, {"color": "orange", "id": 358, "label": 358, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 358 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2007.4389013\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Niklas Elmqvist;John Stasko;Philippas Tsigas; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: DataMeadow: A Visual Canvas for Analysis of Large-Scale Multivariate Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Supporting visual analytics of multiple large-scale multidimensional datasets requires a high degree of interactivity and user control beyond the conventional challenges of visualizing such datasets. We present the DataMeadow, a visual canvas providing rich interaction for constructing visual queries using graphical set representations called DataRoses. A DataRose is essentially a starplot of selected columns in a dataset displayed as multivariate visualizations with dynamic query sliders integrated into each axis. The purpose of the DataMeadow is to allow users to create advanced visual queries by iteratively selecting and filtering into the multidimensional data. Furthermore, the canvas provides a clear history of the analysis that can be annotated to facilitate dissemination of analytical results to outsiders. Towards this end, the DataMeadow has a direct manipulation interface for selection, filtering, and creation of sets, subsets, and data dependencies using both simple and complex mouse gestures. We have evaluated our system using a qualitative expert review involving two researchers working in the area. Results from this review are favorable for our new method."}, {"color": "blue", "id": 380, "label": 380, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 380 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2008.109\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Heidi Lam; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: A Framework of Interaction Costs in Information Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Interaction cost is an important but poorly understood factor in visualization design. We propose a framework of interaction costs inspired by Normanpsilas Seven Stages of Action to facilitate study. From 484 papers, we collected 61 interaction-related usability problems reported in 32 user studies and placed them into our framework of seven costs: (1) Decision costs to form goals; (2) system-power costs to form system operations; (3) Multiple input mode costs to form physical sequences; (4) Physical-motion costs to execute sequences; (5) Visual-cluttering costs to perceive state; (6) View-change costs to interpret perception; (7) State-change costs to evaluate interpretation. We also suggested ways to narrow the gulfs of execution (2-4) and evaluation (5-7) based on collected reports. Our framework suggests a need to consider decision costs (1) as the gulf of goal formation."}, {"color": "blue", "id": 383, "label": 383, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 383 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2008.121\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Zhicheng Liu;Nancy Nersessian;John Stasko; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Distributed Cognition as a Theoretical Framework for Information Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Even though information visualization (InfoVis) research has matured in recent years, it is generally acknowledged that the field still lacks supporting, encompassing theories. In this paper, we argue that the distributed cognition framework can be used to substantiate the theoretical foundation of InfoVis. We highlight fundamental assumptions and theoretical constructs of the distributed cognition approach, based on the cognitive science literature and a real life scenario. We then discuss how the distributed cognition framework can have an impact on the research directions and methodologies we take as InfoVis researchers. Our contributions are as follows. First, we highlight the view that cognition is more an emergent property of interaction than a property of the human mind. Second, we argue that a reductionist approach to study the abstract properties of isolated human minds may not be useful in informing InfoVis design. Finally we propose to make cognition an explicit research agenda, and discuss the implications on how we perform evaluation and theory building."}, {"color": "blue", "id": 384, "label": 384, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 384 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2008.125\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: George Robertson;Roland Fernandez;Danyel Fisher;Bongshin Lee;John Stasko; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Effectiveness of Animation in Trend Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Animation has been used to show trends in multi-dimensional data. This technique has recently gained new prominence for presentations, most notably with Gapminder Trendalyzer. In Trendalyzer, animation together with interesting data and an engaging presenter helps the audience understand the results of an analysis of the data. It is less clear whether trend animation is effective for analysis. This paper proposes two alternative trend visualizations that use static depictions of trends: one which shows traces of all trends overlaid simultaneously in one display and a second that uses a small multiples display to show the trend traces side-by-side. The paper evaluates the three visualizations for both analysis and presentation. Results indicate that trend animation can be challenging to use even for presentations; while it is the fastest technique for presentation and participants find it enjoyable and exciting, it does lead to many participant errors. Animation is the least effective form for analysis; both static depictions of trends are significantly faster than animation, and the small multiples display is more accurate."}, {"color": "blue", "id": 385, "label": 385, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 385 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2008.127\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Uta Hinrichs;Holly Schmidt;Sheelagh Carpendale; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: EMDialog: Bringing Information Visualization into the Museum; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Digital information displays are becoming more common in public spaces such as museums, galleries, and libraries. However, the public nature of these locations requires special considerations concerning the design of information visualization in terms of visual representations and interaction techniques. We discuss the potential for, and challenges of, information visualization in the museum context based on our practical experience with EMDialog, an interactive information presentation that was part of the Emily Carr exhibition at the Glenbow Museum in Calgary. EMDialog visualizes the diverse and multi-faceted discourse about this Canadian artist with the goal to both inform and provoke discussion. It provides a visual exploration environment that offers interplay between two integrated visualizations, one for information access along temporal, and the other along contextual dimensions. We describe the results of an observational study we conducted at the museum that revealed the different ways visitors approached and interacted with EMDialog, as well as how they perceived this form of information presentation in the museum context. Our results include the need to present information in a manner sufficiently attractive to draw attention and the importance of rewarding passive observation as well as both short- and longer term information exploration."}, {"color": "blue", "id": 387, "label": 387, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 387 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2008.130\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Tim Dwyer;Kim Marriott;Falk Schreiber;Peter Stuckey;Michael Woodward;Michael Wybrow; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Exploration of Networks using overview+detail with Constraint-based cooperative layout; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: A standard approach to large network visualization is to provide an overview of the network and a detailed view of a small component of the graph centred around a focal node. The user explores the network by changing the focal node in the detailed view or by changing the level of detail of a node or cluster. For scalability, fast force-based layout algorithms are used for the overview and the detailed view. However, using the same layout algorithm in both views is problematic since layout for the detailed view has different requirements to that in the overview. Here we present a model in which constrained graph layout algorithms are used for layout in the detailed view. This means the detailed view has high-quality layout including sophisticated edge routing and is customisable by the user who can add placement constraints on the layout. Scalability is still ensured since the slower layout techniques are only applied to the small subgraph shown in the detailed view. The main technical innovations are techniques to ensure that the overview and detailed view remain synchronized, and modifying constrained graph layout algorithms to support smooth, stable layout. The key innovation supporting stability are new dynamic graph layout algorithms that preserve the topology or structure of the network when the user changes the focus node or the level of detail by in situ semantic zooming. We have built a prototype tool and demonstrate its use in two application domains, UML class diagrams and biological networks."}, {"color": "blue", "id": 388, "label": 388, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 388 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2008.135\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Weiwei Cui;Hong Zhou;Huamin Qu;Pak Chung Wong;Xiaoming Li; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Geometry-Based Edge Clustering for Graph Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Graphs have been widely used to model relationships among data. For large graphs, excessive edge crossings make the display visually cluttered and thus difficult to explore. In this paper, we propose a novel geometry-based edge-clustering framework that can group edges into bundles to reduce the overall edge crossings. Our method uses a control mesh to guide the edge-clustering process; edge bundles can be formed by forcing all edges to pass through some control points on the mesh. The control mesh can be generated at different levels of detail either manually or automatically based on underlying graph patterns. Users can further interact with the edge-clustering results through several advanced visualization techniques such as color and opacity enhancement. Compared with other edge-clustering methods, our approach is intuitive, flexible, and efficient. The experiments on some large graphs demonstrate the effectiveness of our method."}, {"color": "blue", "id": 389, "label": 389, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 389 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2008.137\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jeffrey Heer;Jock Mackinlay;Chris Stolte;Maneesh Agrawala; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Graphical Histories for Visualization: Supporting Analysis, Communication, and Evaluation; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Interactive history tools, ranging from basic undo and redo to branching timelines of user actions, facilitate iterative forms of interaction. In this paper, we investigate the design of history mechanisms for information visualization. We present a design space analysis of both architectural and interface issues, identifying design decisions and associated trade-offs. Based on this analysis, we contribute a design study of graphical history tools for Tableau, a database visualization system. These tools record and visualize interaction histories, support data analysis and communication of findings, and contribute novel mechanisms for presenting, managing, and exporting histories. Furthermore, we have analyzed aggregated collections of history sessions to evaluate Tableau usage. We describe additional tools for analyzing userspsila history logs and how they have been applied to study usage patterns in Tableau."}, {"color": "blue", "id": 391, "label": 391, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 391 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2008.141\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Nathalie y Henr;Anastasia Bezerianos;Jean-Daniel Fekete; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Improving the Readability of Clustered Social Networks using Node Duplication; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Exploring communities is an important task in social network analysis. Such communities are currently identified using clustering methods to group actors. This approach often leads to actors belonging to one and only one cluster, whereas in real life a person can belong to several communities. As a solution we propose duplicating actors in social networks and discuss potential impact of such a move. Several visual duplication designs are discussed and a controlled experiment comparing network visualization with and without duplication is performed, using 6 tasks that are important for graph readability and visual interpretation of social networks. We show that in our experiment, duplications significantly improve community-related tasks but sometimes interfere with other graph readability tasks. Finally, we propose a set of guidelines for deciding when to duplicate actors and choosing candidates for duplication, and alternative ways to render them in social network representations."}, {"color": "blue", "id": 392, "label": 392, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 392 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2008.144\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Wolfgang Freiler;Kresimir Matkovic;Helwig Hauser; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Interactive Visual Analysis of Set-Typed Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: While it is quite typical to deal with attributes of different data types in the visualization of heterogeneous and multivariate datasets, most existing techniques still focus on the most usual data types such as numerical attributes or strings. In this paper we present a new approach to the interactive visual exploration and analysis of data that contains attributes which are of set type. A set-typed attribute of a data item - like one cell in a table - has a list of nGt=0 elements as its value. We present the setpsilaopsilagram as a new visualization approach to represent data of set type and to enable interactive visual exploration and analysis. We also demonstrate how this approach is capable to help in dealing with datasets that have a larger number of dimensions (more than a dozen or more), especially also in the context of categorical data. To illustrate the effectiveness of our approach, we present the interactive visual analysis of a CRM dataset with data from a questionnaire on the education and shopping habits of about 90000 people."}, {"color": "blue", "id": 396, "label": 396, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 396 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2008.153\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Niklas Elmqvist;Pierre Dragicevic;Jean-Daniel Fekete; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Rolling the Dice: Multidimensional Visual Exploration using Scatterplot Matrix Navigation; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Scatterplots remain one of the most popular and widely-used visual representations for multidimensional data due to their simplicity, familiarity and visual clarity, even if they lack some of the flexibility and visual expressiveness of newer multidimensional visualization techniques. This paper presents new interactive methods to explore multidimensional data using scatterplots. This exploration is performed using a matrix of scatterplots that gives an overview of the possible configurations, thumbnails of the scatterplots, and support for interactive navigation in the multidimensional space. Transitions between scatterplots are performed as animated rotations in 3D space, somewhat akin to rolling dice. Users can iteratively build queries using bounding volumes in the dataset, sculpting the query from different viewpoints to become more and more refined. Furthermore, the dimensions in the navigation space can be reordered, manually or automatically, to highlight salient correlations and differences among them. An example scenario presents the interaction techniques supporting smooth and effortless visual exploration of multidimensional datasets."}, {"color": "blue", "id": 397, "label": 397, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 397 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2008.155\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Frank van Ham;Bernice Rogowitz; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Perceptual Organization in User-Generated Graph Layouts; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Many graph layout algorithms optimize visual characteristics to achieve useful representations. Implicitly, their goal is to create visual representations that are more intuitive to human observers. In this paper, we asked users to explicitly manipulate nodes in a network diagram to create layouts that they felt best captured the relationships in the data. This allowed us to measure organizational behavior directly, allowing us to evaluate the perceptual importance of particular visual features, such as edge crossings and edge-lengths uniformity. We also manipulated the interior structure of the node relationships by designing data sets that contained clusters, that is, sets of nodes that are strongly interconnected. By varying the degree to which these clusters were ldquomaskedrdquo by extraneous edges we were able to measure observerspsila sensitivity to the existence of clusters and how they revealed them in the network diagram. Based on these measurements we found that observers are able to recover cluster structure, that the distance between clusters is inversely related to the strength of the clustering, and that users exhibit the tendency to use edges to visually delineate perceptual groups. These results demonstrate the role of perceptual organization in representing graph data and provide concrete recommendations for graph layout algorithms."}, {"color": "blue", "id": 399, "label": 399, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 399 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2008.165\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jo Wood;Jason Dykes; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Spatially Ordered Treemaps; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Existing treemap layout algorithms suffer to some extent from poor or inconsistent mappings between data order and visual ordering in their representation, reducing their cognitive plausibility. While attempts have been made to quantify this mismatch, and algorithms proposed to minimize inconsistency, solutions provided tend to concentrate on one-dimensional ordering. We propose extensions to the existing squarified layout algorithm that exploit the two-dimensional arrangement of treemap nodes more effectively. Our proposed spatial squarified layout algorithm provides a more consistent arrangement of nodes while maintaining low aspect ratios. It is suitable for the arrangement of data with a geographic component and can be used to create tessellated cartograms for geovisualization. Locational consistency is measured and visualized and a number of layout algorithms are compared. CIELab color space and displacement vector overlays are used to assess and emphasize the spatial layout of treemap nodes. A case study involving locations of tagged photographs in the Flickr database is described."}, {"color": "blue", "id": 400, "label": 400, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 400 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2008.166\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Lee Byron;Martin Wattenberg; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Stacked Graphs - Geometry \u0026 Aesthetics; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In February 2008, the New York Times published an unusual chart of box office revenues for 7500 movies over 21 years. The chart was based on a similar visualization, developed by the first author, that displayed trends in music listening. This paper describes the design decisions and algorithms behind these graphics, and discusses the reaction on the Web. We suggest that this type of complex layered graph is effective for displaying large data sets to a mass audience. We provide a mathematical analysis of how this layered graph relates to traditional stacked graphs and to techniques such as ThemeRiver, showing how each method is optimizing a different ldquoenergy functionrdquo. Finally, we discuss techniques for coloring and ordering the layers of such graphs. Throughout the paper, we emphasize the interplay between considerations of aesthetics and legibility."}, {"color": "blue", "id": 402, "label": 402, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 402 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2008.172\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Martin Wattenberg;Fernanda B. Vi\u00e9gas; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: The Word Tree, an Interactive Visual Concordance; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We introduce the Word Tree, a new visualization and information-retrieval technique aimed at text documents. A Word Tree is a graphical version of the traditional \"keyword-in-context\" method, and enables rapid querying and exploration of bodies of text. In this paper we describe the design of the technique, along with some of the technical issues that arise in its implementation. In addition, we discuss the results of several months of public deployment of word trees on Many Eyes, which provides a window onto the ways in which users obtain value from the visualization."}, {"color": "blue", "id": 403, "label": 403, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 403 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2008.175\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Marian D\u00f6rk;Sheelagh Carpendale;Christopher Collins;Carey Williamson; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: VisGets: Coordinated Visualizations for Web-based Information Exploration and Discovery; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In common Web-based search interfaces, it can be difficult to formulate queries that simultaneously combine temporal, spatial, and topical data filters. We investigate how coordinated visualizations can enhance search and exploration of information on the World Wide Web by easing the formulation of these types of queries. Drawing from visual information seeking and exploratory search, we introduce VisGets - interactive query visualizations of Web-based information that operate with online information within a Web browser. VisGets provide the information seeker with visual overviews of Web resources and offer a way to visually filter the data. Our goal is to facilitate the construction of dynamic search queries that combine filters from more than one data dimension. We present a prototype information exploration system featuring three linked VisGets (temporal, spatial, and topical), and used it to visually explore news items from online RSS feeds."}, {"color": "blue", "id": 407, "label": 407, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 407 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2008.187\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Geoffrey Draper;Richard Riesenfeld; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Who Votes For What? A Visual Query Language for Opinion Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Surveys and opinion polls are extremely popular in the media, especially in the months preceding a general election. However, the available tools for analyzing poll results often require specialized training. Hence, data analysis remains out of reach for many casual computer users. Moreover, the visualizations used to communicate the results of surveys are typically limited to traditional statistical graphics like bar graphs and pie charts, both of which are fundamentally noninteractive. We present a simple interactive visualization that allows users to construct queries on large tabular data sets, and view the results in real time. The results of two separate user studies suggest that our interface lowers the learning curve for naive users, while still providing enough analytical power to discover interesting correlations in the data."}, {"color": "orange", "id": 408, "label": 408, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 408 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2008.4677350\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Tobias Schreck;Jurgen Bernard;Tatiana Tekusova;Jorn Kohlhammer; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visual cluster analysis of trajectory data with interactive Kohonen Maps; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Visual-interactive cluster analysis provides valuable tools for effectively analyzing large and complex data sets. Due to desirable properties and an inherent predisposition for visualization, the Kohonen Feature Map (or self-organizing map, or SOM) algorithm is among the most popular and widely used visual clustering techniques. However, the unsupervised nature of the algorithm may be disadvantageous in certain applications. Depending on initialization and data characteristics, cluster maps (cluster layouts) may emerge that do not comply with user preferences, expectations, or the application context. Considering SOM-based analysis of trajectory data, we propose a comprehensive visual-interactive monitoring and control framework extending the basic SOM algorithm. The framework implements the general Visual Analytics idea to effectively combine automatic data analysis with human expert supervision. It provides simple, yet effective facilities for visually monitoring and interactively controlling the trajectory clustering process at arbitrary levels of detail. The approach allows the user to leverage existing domain knowledge and user preferences, arriving at improved cluster maps. We apply the framework on a trajectory clustering problem, demonstrating its potential in combining both unsupervised (machine) and supervised (human expert) processing, in producing appropriate cluster results."}, {"color": "orange", "id": 414, "label": 414, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 414 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2008.4677356\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Gennady Andrienko;Natalia Andrienko; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Spatio-temporal aggregation for visual analysis of movements; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Data about movements of various objects are collected in growing amounts by means of current tracking technologies. Traditional approaches to visualization and interactive exploration of movement data cannot cope with data of such sizes. In this research paper we investigate the ways of using aggregation for visual analysis of movement data. We define aggregation methods suitable for movement data and find visualization and interaction techniques to represent results of aggregations and enable comprehensive exploration of the data. We consider two possible views of movement, traffic-oriented and trajectory-oriented. Each view requires different methods of analysis and of data aggregation. We illustrate our argument with example data resulting from tracking multiple cars in Milan and example analysis tasks from the domain of city traffic management."}, {"color": "orange", "id": 416, "label": 416, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 416 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2008.4677358\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Anthony C. Robinson; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Collaborative synthesis of visual analytic results; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Visual analytic tools allow analysts to generate large collections of useful analytical results. We anticipate that analysts in most real world situations will draw from these collections when working together to solve complicated problems. This indicates a need to understand how users synthesize multiple collections of results. This paper reports the results of collaborative synthesis experiments conducted with expert geographers and disease biologists. Ten participants were worked in pairs to complete a simulated real-world synthesis task using artifacts printed on cards on a large, paper-covered workspace. Experiment results indicate that groups use a number of different approaches to collaborative synthesis, and that they employ a variety of organizational metaphors to structure their information. It is further evident that establishing common ground and role assignment are critical aspects of collaborative synthesis. We conclude with a set of general design guidelines for collaborative synthesis support tools."}, {"color": "orange", "id": 419, "label": 419, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 419 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2008.4677361\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Tera Marie Green;William Ribarsky;Brian Fisher; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visual analytics for complex concepts using a human cognition model; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: As the information being visualized and the process of understanding that information both become increasingly complex, it is necessary to develop new visualization approaches that facilitate the flow of human reasoning. In this paper, we endeavor to push visualization design a step beyond current user models by discussing a modeling framework of human ldquohigher cognition.rdquo Based on this cognition model, we present design guidelines for the development of visual interfaces designed to maximize the complementary cognitive strengths of both human and computer. Some of these principles are already being reflected in the better visual analytics designs, while others have not yet been applied or fully applied. But none of the guidelines have explained the deeper rationale that the model provides. Lastly, we discuss and assess these visual analytics guidelines through the evaluation of several visualization examples."}, {"color": "orange", "id": 420, "label": 420, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 420 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2008.4677362\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Eric A. Bier;Stuart K. Card;John W. Bodnar; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Entity-based collaboration tools for intelligence analysis; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Software tools that make it easier for analysts to collaborate as a natural part of their work will lead to better analysis that is informed by more perspectives. We are interested to know if software tools can be designed that support collaboration even as they allow analysts to find documents and organize information (including evidence, schemas, and hypotheses). We have modified the Entity Workspace system, described previously, to test such designs. We have evaluated the resulting design in both a laboratory study and a study where it is situated with an analysis team. In both cases, effects on collaboration appear to be positive. Key aspects of the design include an evidence notebook optimized for organizing entities (rather than text characters), information structures that can be collapsed and expanded, visualization of evidence that emphasizes events and documents (rather than emphasizing the entity graph), and a notification system that finds entities of mutual interest to multiple analysts."}, {"color": "orange", "id": 422, "label": 422, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 422 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2008.4677364\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Danyel Fisher;Aaron Hoff;George Robertson;Matthew Hurst; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Narratives: A visualization to track narrative events as they develop; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Analyzing unstructured text streams can be challenging. One popular approach is to isolate specific themes in the text, and to visualize the connections between them. Some existing systems, like ThemeRiver, provide a temporal view of changes in themes; other systems, like In-Spire, use clustering techniques to help an analyst identify the themes at a single point in time. Narratives combines both of these techniques; it uses a temporal axis to visualize ways that concepts have changed over time, and introduces several methods to explore how those concepts relate to each other. Narratives is designed to help the user place news stories in their historical and social context by understanding how the major topics associated with them have changed over time. Users can relate articles through time by examining the topical keywords that summarize a specific news event. By tracking the attention to a news article in the form of references in social media (such as weblogs), a user discovers both important events and measures the social relevance of these stories."}, {"color": "orange", "id": 423, "label": 423, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 423 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2008.4677365\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: David Gotz;Michelle X. Zhou; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Characterizing users\u0027 visual analytic activity for insight provenance; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Insight provenance - a historical record of the process and rationale by which an insight is derived - is an essential requirement in many visual analytics applications. While work in this area has relied on either manually recorded provenance (e.g., user notes) or automatically recorded event-based insight provenance (e.g., clicks, drags, and key-presses), both approaches have fundamental limitations. Our aim is to develop a new approach that combines the benefits of both approaches while avoiding their deficiencies. Toward this goal, we characterize userspsila visual analytic activity at multiple levels of granularity. Moreover, we identify a critical level of abstraction, Actions, that can be used to represent visual analytic activity with a set of general but semantically meaningful behavior types. In turn, the action types can be used as the semantic building blocks for insight provenance. We present a catalog of common actions identified through observations of several different visual analytic systems. In addition, we define a taxonomy to categorize actions into three major classes based on their semantic intent. The concept of actions has been integrated into our labpsilas prototype visual analytic system, HARVEST, as the basis for its insight provenance capabilities."}, {"color": "orange", "id": 424, "label": 424, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 424 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2008.4677366\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: William A. Pike;Joe Bruce;Bob Baddeley;Daniel Best;Lyndsey Franklin;Richard May;Douglas M. Rice;Rick Riensche;Katarina Younkin; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: The Scalable Reasoning System: Lightweight visualization for distributed analytics; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: A central challenge in visual analytics is the creation of accessible, widely distributable analysis applications that bring the benefits of visual discovery to as broad a user base as possible. Moreover, to support the role of visualization in the knowledge creation process, it is advantageous to allow users to describe the reasoning strategies they employ while interacting with analytic environments. We introduce an application suite called the scalable reasoning system (SRS), which provides Web-based and mobile interfaces for visual analysis. The service-oriented analytic framework that underlies SRS provides a platform for deploying pervasive visual analytic environments across an enterprise. SRS represents a ldquolightweightrdquo approach to visual analytics whereby thin client analytic applications can be rapidly deployed in a platform-agnostic fashion. Client applications support multiple coordinated views while giving analysts the ability to record evidence, assumptions, hypotheses and other reasoning artifacts. We describe the capabilities of SRS in the context of a real-world deployment at a regional law enforcement organization."}, {"color": "orange", "id": 426, "label": 426, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 426 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2008.4677368\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Scott Barlowe;Tianyi Zhang;Yujie Liu;Jing Yang;Donald Jacobs; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Multivariate visual explanation for high dimensional datasets; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Understanding multivariate relationships is an important task in multivariate data analysis. Unfortunately, existing multivariate visualization systems lose effectiveness when analyzing relationships among variables that span more than a few dimensions. We present a novel multivariate visual explanation approach that helps users interactively discover multivariate relationships among a large number of dimensions by integrating automatic numerical differentiation techniques and multidimensional visualization techniques. The result is an efficient workflow for multivariate analysis model construction, interactive dimension reduction, and multivariate knowledge discovery leveraging both automatic multivariate analysis and interactive multivariate data visual exploration. Case studies and a formal user study with a real dataset illustrate the effectiveness of this approach."}, {"color": "orange", "id": 428, "label": 428, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 428 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2008.4677370\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Chris Weaver; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Multidimensional visual analysis using cross-filtered views; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Analysis of multidimensional data often requires careful examination of relationships across dimensions. Coordinated multiple view approaches have become commonplace in visual analysis tools because they directly support expression of complex multidimensional queries using simple interactions. However, generating such tools remains difficult because of the need to map domain-specific data structures and semantics into the idiosyncratic combinations of interdependent data and visual abstractions needed to reveal particular patterns and distributions in cross-dimensional relationships. This paper describes: (1) a method for interactively expressing sequences of multidimensional set queries by cross-filtering data values across pairs of views, and (2) design strategies for constructing coordinated multiple view interfaces for cross-filtered visual analysis of multidimensional data sets. Using examples of cross-filtered visualizations of data from several different domains, we describe how cross-filtering can be modularized and reused across designs, flexibly customized with respect to data types across multiple dimensions, and incorporated into more wide-ranging multiple view designs. The demonstrated analytic utility of these examples suggest that cross-filtering is a suitable design pattern for instantiation in a wide variety of visual analysis tools."}, {"color": "blue", "id": 453, "label": 453, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 453 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2009.108\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Frank van Ham;Adam Perer; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: \"Search, Show Context, Expand on Demand\": Supporting Large Graph Exploration with Degree-of-Interest; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: A common goal in graph visualization research is the design of novel techniques for displaying an overview of an entire graph. However, there are many situations where such an overview is not relevant or practical for users, as analyzing the global structure may not be related to the main task of the users that have semi-specific information needs. Furthermore, users accessing large graph databases through an online connection or users running on less powerful (mobile) hardware simply do not have the resources needed to compute these overviews. In this paper, we advocate an interaction model that allows users to remotely browse the immediate context graph around a specific node of interest. We show how Furnas\u0027 original degree of interest function can be adapted from trees to graphs and how we can use this metric to extract useful contextual subgraphs, control the complexity of the generated visualization and direct users to interesting datapoints in the context. We demonstrate the effectiveness of our approach with an exploration of a dense online database containing over 3 million legal citations."}, {"color": "blue", "id": 454, "label": 454, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 454 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2009.109\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Tim Dwyer;Bongshin Lee;Danyel Fisher;Kori Inkpen Quinn;Petra Isenberg;George Robertson;Chris North; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: A Comparison of User-Generated and Automatic Graph Layouts; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The research presented in this paper compares user-generated and automatic graph layouts. Following the methods suggested by van Ham et al. (2008), a group of users generated graph layouts using both multi-touch interaction on a tabletop display and mouse interaction on a desktop computer. Users were asked to optimize their layout for aesthetics and analytical tasks with a social network. We discuss characteristics of the user-generated layouts and interaction methods employed by users in this process. We then report on a web-based study to compare these layouts with the output of popular automatic layout algorithms. Our results demonstrate that the best of the user-generated layouts performed as well as or better than the physics-based layout. Orthogonal and circular automatic layouts were found to be considerably less effective than either the physics-based layout or the best of the user-generated layouts. We highlight several attributes of the various layouts that led to high accuracy and improved task completion time, as well as aspects in which traditional automatic layout methods were unsuccessful for our tasks."}, {"color": "blue", "id": 455, "label": 455, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 455 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2009.110\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Harald Piringer;Christian Tominski;Philipp Muigg;Wolfgang Berger; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: A Multi-Threading Architecture to Support Interactive Visual Exploration; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: During continuous user interaction, it is hard to provide rich visual feedback at interactive rates for datasets containing millions of entries. The contribution of this paper is a generic architecture that ensures responsiveness of the application even when dealing with large data and that is applicable to most types of information visualizations. Our architecture builds on the separation of the main application thread and the visualization thread, which can be cancelled early due to user interaction. In combination with a layer mechanism, our architecture facilitates generating previews incrementally to provide rich visual feedback quickly. To help avoiding common pitfalls of multi-threading, we discuss synchronization and communication in detail. We explicitly denote design choices to control trade-offs. A quantitative evaluation based on the system VI S P L ORE shows fast visual feedback during continuous interaction even for millions of entries. We describe instantiations of our architecture in additional tools."}, {"color": "blue", "id": 456, "label": 456, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 456 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2009.111\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Tamara Munzner; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: A Nested Model for Visualization Design and Validation; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present a nested model for the visualization design and validation with four layers: characterize the task and data in the vocabulary of the problem domain, abstract into operations and data types, design visual encoding and interaction techniques, and create algorithms to execute techniques efficiently. The output from a level above is input to the level below, bringing attention to the design challenge that an upstream error inevitably cascades to all downstream levels. This model provides prescriptive guidance for determining appropriate evaluation approaches by identifying threats to validity unique to each level. We also provide three recommendations motivated by this model: authors should distinguish between these levels when claiming contributions at more than one of them, authors should explicitly state upstream assumptions at levels above the focus of a paper, and visualization venues should accept more papers on domain characterization."}, {"color": "blue", "id": 457, "label": 457, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 457 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2009.116\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Cydney B. Nielsen;Shaun D. Jackman;Inan\u00e7 Birol;Steven J.M. Jones; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: ABySS-Explorer: Visualizing Genome Sequence Assemblies; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: One bottleneck in large-scale genome sequencing projects is reconstructing the full genome sequence from the short subsequences produced by current technologies. The final stages of the genome assembly process inevitably require manual inspection of data inconsistencies and could be greatly aided by visualization. This paper presents our design decisions in translating key data features identified through discussions with analysts into a concise visual encoding. Current visualization tools in this domain focus on local sequence errors making high-level inspection of the assembly difficult if not impossible. We present a novel interactive graph display, ABySS-Explorer, that emphasizes the global assembly structure while also integrating salient data features such as sequence length. Our tool replaces manual and in some cases pen-and-paper based analysis tasks, and we discuss how user feedback was incorporated into iterative design refinements. Finally, we touch on applications of this representation not initially considered in our design phase, suggesting the generality of this encoding for DNA sequence data."}, {"color": "blue", "id": 458, "label": 458, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 458 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2009.117\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Katerina Vrotsou;Jimmy Johansson;Matthew Cooper; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: ActiviTree: Interactive Visual Exploration of Sequences in Event-Based Data Using Graph Similarity; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The identification of significant sequences in large and complex event-based temporal data is a challenging problem with applications in many areas of today\u0027s information intensive society. Pure visual representations can be used for the analysis, but are constrained to small data sets. Algorithmic search mechanisms used for larger data sets become expensive as the data size increases and typically focus on frequency of occurrence to reduce the computational complexity, often overlooking important infrequent sequences and outliers. In this paper we introduce an interactive visual data mining approach based on an adaptation of techniques developed for Web searching, combined with an intuitive visual interface, to facilitate user-centred exploration of the data and identification of sequences significant to that user. The search algorithm used in the exploration executes in negligible time, even for large data, and so no pre-processing of the selected data is required, making this a completely interactive experience for the user. Our particular application area is social science diary data but the technique is applicable across many other disciplines."}, {"color": "blue", "id": 459, "label": 459, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 459 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2009.122\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Christopher Collins;Gerald Penn;Sheelagh Carpendale; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Bubble Sets: Revealing Set Relations with Isocontours over Existing Visualizations; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: While many data sets contain multiple relationships, depicting more than one data relationship within a single visualization is challenging. We introduce Bubble Sets as a visualization technique for data that has both a primary data relation with a semantically significant spatial organization and a significant set membership relation in which members of the same set are not necessarily adjacent in the primary layout. In order to maintain the spatial rights of the primary data relation, we avoid layout adjustment techniques that improve set cluster continuity and density. Instead, we use a continuous, possibly concave, isocontour to delineate set membership, without disrupting the primary layout. Optimizations minimize cluster overlap and provide for calculation of the isocontours at interactive speeds. Case studies show how this technique can be used to indicate multiple sets on a variety of common visualizations."}, {"color": "blue", "id": 461, "label": 461, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 461 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2009.127\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Melanie Tory;Colin Swindells;Rebecca Dreezer; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Comparing Dot and Landscape Spatializations for Visual Memory Differences; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Spatialization displays use a geographic metaphor to arrange non-spatial data. For example, spatializations are commonly applied to document collections so that document themes appear as geographic features such as hills. Many common spatialization interfaces use a 3-D landscape metaphor to present data. However, it is not clear whether 3-D spatializations afford improved speed and accuracy for user tasks compared to similar 2-D spatializations. We describe a user study comparing users\u0027 ability to remember dot displays, 2-D landscapes, and 3-D landscapes for two different data densities (500 vs. 1000 points). Participants\u0027 visual memory was statistically more accurate when viewing dot displays and 3-D landscapes compared to 2-D landscapes. Furthermore, accuracy remembering a spatialization was significantly better overall for denser spatializations. Theseresults are of benefit to visualization designers who are contemplating the best ways to present data using spatialization techniques."}, {"color": "blue", "id": 462, "label": 462, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 462 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2009.128\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Aidan Slingsby;Jason Dykes;Jo Wood; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Configuring Hierarchical Layouts to Address Research Questions; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We explore the effects of selecting alternative layouts in hierarchical displays that show multiple aspects of large multivariate datasets, including spatial and temporal characteristics. Hierarchical displays of this type condition a dataset by multiple discrete variable values, creating nested graphical summaries of the resulting subsets in which size, shape and colour can be used to show subset properties. These \u0027small multiples\u0027 are ordered by the conditioning variable values and are laid out hierarchically using dimensional stacking. Crucially, we consider the use of different layouts at different hierarchical levels, so that the coordinates of the plane can be used more effectively to draw attention to trends and anomalies in the data. We argue that these layouts should be informed by the type of conditioning variable and by the research question being explored. We focus on space-filling rectangular layouts that provide data-dense and rich overviews of data to address research questions posed in our exploratory analysis of spatial and temporal aspects of property sales in London. We develop a notation (\u0027HiVE\u0027) that describes visualisation and layout states and provides reconfiguration operators, demonstrate its use for reconfiguring layouts to pursue research questions and provide guidelines for this process. We demonstrate how layouts can be related through animated transitions to reduce the cognitive load associated with their reconfiguration whilst supporting the exploratory process."}, {"color": "blue", "id": 467, "label": 467, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 467 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2009.143\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Diansheng Guo; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Flow Mapping and Multivariate Visualization of Large Spatial Interaction Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Spatial interactions (or flows), such as population migration and disease spread, naturally form a weighted location-to-location network (graph). Such geographically embedded networks (graphs) are usually very large. For example, the county-to-county migration data in the U.S. has thousands of counties and about a million migration paths. Moreover, many variables are associated with each flow, such as the number of migrants for different age groups, income levels, and occupations. It is a challenging task to visualize such data and discover network structures, multivariate relations, and their geographic patterns simultaneously. This paper addresses these challenges by developing an integrated interactive visualization framework that consists three coupled components: (1) a spatially constrained graph partitioning method that can construct a hierarchy of geographical regions (communities), where there are more flows or connections within regions than across regions; (2) a multivariate clustering and visualization method to detect and present multivariate patterns in the aggregated region-to-region flows; and (3) a highly interactive flow mapping component to map both flow and multivariate patterns in the geographic space, at different hierarchical levels. The proposed approach can process relatively large data sets and effectively discover and visualize major flow structures and multivariate relations at the same time. User interactions are supported to facilitate the understanding of both an overview and detailed patterns."}, {"color": "blue", "id": 468, "label": 468, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 468 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2009.145\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Christophe Hurter;Benjamin Tissoires;St\u00e9phane Conversy; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: FromDaDy: Spreading Aircraft Trajectories Across Views to Support Iterative Queries; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: When displaying thousands of aircraft trajectories on a screen, the visualization is spoiled by a tangle of trails. The visual analysis is therefore difficult, especially if a specific class of trajectories in an erroneous dataset has to be studied. We designed FromDaDy, a trajectory visualization tool that tackles the difficulties of exploring the visualization of multiple trails. This multidimensional data exploration is based on scatterplots, brushing, pick and drop, juxtaposed views and rapid visual design. Users can organize the workspace composed of multiple juxtaposed views. They can define the visual configuration of the views by connecting data dimensions from the dataset to Bertin\u0027s visual variables. They can then brush trajectories, and with a pick and drop operation they can spread the brushed information across views. They can then repeat these interactions, until they extract a set of relevant data, thus formulating complex queries. Through two real-world scenarios, we show how FromDaDy supports iterative queries and the extraction of trajectories in a dataset that contains up to 5 million data."}, {"color": "blue", "id": 470, "label": 470, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 470 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2009.148\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Matt McKeon; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Harnessing the Information Ecosystem with Wiki-based Visualization Dashboards; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We describe the design and deployment of Dashiki, a public Website where users may collaboratively build visualization dashboards through a combination of a wiki-like syntax and interactive editors. Our goals are to extend existing research on social data analysis into presentation and organization of data from multiple sources, explore new metaphors for these activities, and participate more fully in the Web\u0027s information ecology by providing tighter integration with real-time data. To support these goals, our design includes novel and low-barrier mechanisms for editing and layout of dashboard pages and visualizations, connection to data sources, and coordinating interaction between visualizations. In addition to describing these technologies, we provide a preliminary report on the public launch of a prototype based on this design, including a description of the activities of our users derived from observation and interviews."}, {"color": "blue", "id": 472, "label": 472, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 472 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2009.153\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Sara Johansson;Jimmy Johansson; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Interactive Dimensionality Reduction Through User-defined Combinations of Quality Metrics; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Multivariate data sets including hundreds of variables are increasingly common in many application areas. Most multivariate visualization techniques are unable to display such data effectively, and a common approach is to employ dimensionality reduction prior to visualization. Most existing dimensionality reduction systems focus on preserving one or a few significant structures in data. For many analysis tasks, however, several types of structures can be of high significance and the importance of a certain structure compared to the importance of another is often task-dependent. This paper introduces a system for dimensionality reduction by combining user-defined quality metrics using weight functions to preserve as many important structures as possible. The system aims at effective visualization and exploration of structures within large multivariate data sets and provides enhancement of diverse structures by supplying a range of automatic variable orderings. Furthermore it enables a quality-guided reduction of variables through an interactive display facilitating investigation of trade-offs between loss of structure and the number of variables to keep. The generality and interactivity of the system is demonstrated through a case scenario."}, {"color": "blue", "id": 473, "label": 473, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 473 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2009.162\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Matthew Tobiasz;Petra Isenberg;Sheelagh Carpendale; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Lark: Coordinating Co-located Collaboration with Information Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Large multi-touch displays are expanding the possibilities of multiple-coordinated views by allowing multiple people to interact with data in concert or independently. We present Lark, a system that facilitates the coordination of interactions with information visualizations on shared digital workspaces. We focus on supporting this coordination according to four main criteria: scoped interaction, temporal flexibility, spatial flexibility, and changing collaboration styles. These are achieved by integrating a representation of the information visualization pipeline into the shared workspace, thus explicitly indicating coordination points on data, representation, presentation, and view levels. This integrated meta-visualization supports both the awareness of how views are linked and the freedom to work in concert or independently. Lark incorporates these four main criteria into a coherent visualization collaboration interaction environment by providing direct visual and algorithmic support for the coordination of data analysis actions over shared large displays."}, {"color": "blue", "id": 474, "label": 474, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 474 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2009.165\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Frank van Ham;Martin Wattenberg;Fernanda B. Viegas; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Mapping Text with Phrase Nets; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present a new technique, the phrase net, for generating visual overviews of unstructured text. A phrase net displays a graph whose nodes are words and whose edges indicate that two words are linked by a user-specified relation. These relations may be defined either at the syntactic or lexical level; different relations often produce very different perspectives on the same text. Taken together, these perspectives often provide an illuminating visual overview of the key concepts and relations in a document or set of documents."}, {"color": "blue", "id": 475, "label": 475, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 475 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2009.167\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Miriah Meyer;Tamara Munzner;Hanspeter Pfister; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: MizBee: A Multiscale Synteny Browser; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In the field of comparative genomics, scientists seek to answer questions about evolution and genomic function by comparing the genomes of species to find regions of shared sequences. Conserve dsyntenic blocks are an important biological data abstraction for indicating regions of shared sequences. The goal of this work is to show multiple types of relationships at multiple scales in a way that is visually comprehensible in accordance with known perceptual principles. We present a task analysis for this domain where the fundamental questions asked by biologists can be understood by a characterization of relationships into the four types of proximity/location, size, orientation, and similarity/strength, and the four scales of genome, chromosome, block, and genomic feature. We also propose a new taxonomy of the design space for visually encoding conservation data. We present MizBee, a multiscale synteny browser with the unique property of providing interactive side-by-side views of the data across the range of scales supporting exploration of all of these relationship types. We conclude with case studies from two biologists who used MizBee to augment their previous automatic analysis work flow, providing anecdotal evidence about the efficacy of the system for the visualization of syntenic data, the analysis of conservation relationships, and the communication of scientific insights."}, {"color": "blue", "id": 476, "label": 476, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 476 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2009.171\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Fernanda B. Viegas;Martin Wattenberg;Jonathan Feinberg; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Participatory Visualization with Wordle; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We discuss the design and usage of ldquoWordle,rdquo a Web-based tool for visualizing text. Wordle creates tag-cloud-like displays that give careful attention to typography, color, and composition. We describe the algorithms used to balance various aesthetic criteria and create the distinctive Wordle layouts. We then present the results of a study of Wordle usage, based both on spontaneous behaviour observed in the wild, and on a large-scale survey of Wordle users. The results suggest that Wordles have become a kind of medium of expression, and that a ldquoparticipatory culturerdquo has arisen around them."}, {"color": "blue", "id": 477, "label": 477, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 477 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2009.174\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Michael Bostock;Jeffrey Heer; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Protovis: A Graphical Toolkit for Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Despite myriad tools for visualizing data, there remains a gap between the notational efficiency of high-level visualization systems and the expressiveness and accessibility of low-level graphical systems. Powerful visualization systems may be inflexible or impose abstractions foreign to visual thinking, while graphical systems such as rendering APIs and vector-based drawing programs are tedious for complex work. We argue that an easy-to-use graphical system tailored for visualization is needed. In response, we contribute Protovis, an extensible toolkit for constructing visualizations by composing simple graphical primitives. In Protovis, designers specify visualizations as a hierarchy of marks with visual properties defined as functions of data. This representation achieves a level of expressiveness comparable to low-level graphics systems, while improving efficiency - the effort required to specify a visualization - and accessibility - the effort required to learn and modify the representation. We substantiate this claim through a diverse collection of examples and comparative analysis with popular visualization tools."}, {"color": "blue", "id": 479, "label": 479, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 479 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2009.179\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Xiaoru Yuan;Peihong Guo;He Xiao;Hong Zhou;Huamin Qu; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Scattering Points in Parallel Coordinates; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In this paper, we present a novel parallel coordinates design integrated with points (scattering points in parallel coordinates, SPPC), by taking advantage of both parallel coordinates and scatterplots. Different from most multiple views visualization frameworks involving parallel coordinates where each visualization type occupies an individual window, we convert two selected neighboring coordinate axes into a scatterplot directly. Multidimensional scaling is adopted to allow converting multiple axes into a single subplot. The transition between two visual types is designed in a seamless way. In our work, a series of interaction tools has been developed. Uniform brushing functionality is implemented to allow the user to perform data selection on both points and parallel coordinate polylines without explicitly switching tools. A GPU accelerated dimensional incremental multidimensional scaling (DIMDS) has been developed to significantly improve the system performance. Our case study shows that our scheme is more efficient than traditional multi-view methods in performing visual analysis tasks."}, {"color": "blue", "id": 481, "label": 481, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 481 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2009.181\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jorik Blaas;Charl Botha;Edward Grundy;Mark Jones;Robert Laramee;Frits Post; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Smooth Graphs for Visual Exploration of Higher-Order State Transitions; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In this paper, we present a new visual way of exploring state sequences in large observational time-series. A key advantage of our method is that it can directly visualize higher-order state transitions. A standard first order state transition is a sequence of two states that are linked by a transition. A higher-order state transition is a sequence of three or more states where the sequence of participating states are linked together by consecutive first order state transitions. Our method extends the current state-graph exploration methods by employing a two dimensional graph, in which higher-order state transitions are visualized as curved lines. All transitions are bundled into thick splines, so that the thickness of an edge represents the frequency of instances. The bundling between two states takes into account the state transitions before and after the transition. This is done in such a way that it forms a continuous representation in which any subsequence of the timeseries is represented by a continuous smooth line. The edge bundles in these graphs can be explored interactively through our incremental selection algorithm. We demonstrate our method with an application in exploring labeled time-series data from a biological survey, where a clustering has assigned a single label to the data at each time-point. In these sequences, a large number of cyclic patterns occur, which in turn are linked to specific activities. We demonstrate how our method helps to find these cycles, and how the interactive selection process helps to find and investigate activities."}, {"color": "blue", "id": 482, "label": 482, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 482 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2009.182\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Peter Bak;Florian Mansmann;Halldor Janetzko;Daniel Keim; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Spatiotemporal Analysis of Sensor Logs using Growth Ring Maps; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Spatiotemporal analysis of sensor logs is a challenging research field due to three facts: a) traditional two-dimensional maps do not support multiple events to occur at the same spatial location, b) three-dimensional solutions introduce ambiguity and are hard to navigate, and c) map distortions to solve the overlap problem are unfamiliar to most users. This paper introduces a novel approach to represent spatial data changing over time by plotting a number of non-overlapping pixels, close to the sensor positions in a map. Thereby, we encode the amount of time that a subject spent at a particular sensor to the number of plotted pixels. Color is used in a twofold manner; while distinct colors distinguish between sensor nodes in different regions, the colors\u0027 intensity is used as an indicator to the temporal property of the subjects\u0027 activity. The resulting visualization technique, called growth ring maps, enables users to find similarities and extract patterns of interest in spatiotemporal data by using humans\u0027 perceptual abilities. We demonstrate the newly introduced technique on a dataset that shows the behavior of healthy and Alzheimer transgenic, male and female mice. We motivate the new technique by showing that the temporal analysis based on hierarchical clustering and the spatial analysis based on transition matrices only reveal limited results. Results and findings are cross-validated using multidimensional scaling. While the focus of this paper is to apply our visualization for monitoring animal behavior, the technique is also applicable for analyzing data, such as packet tracing, geographic monitoring of sales development, or mobile phone capacity planning."}, {"color": "blue", "id": 484, "label": 484, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 484 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2009.187\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Taowei David Wang;Catherine Plaisant;Ben Shneiderman;Neil Spring;David Roseman;Greg Marchand;Vikramjit Mukherjee;Mark Smith; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Temporal Summaries: Supporting Temporal Categorical Searching, Aggregation and Comparison; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: When analyzing thousands of event histories, analysts often want to see the events as an aggregate to detect insights and generate new hypotheses about the data. An analysis tool must emphasize both the prevalence and the temporal ordering of these events. Additionally, the analysis tool must also support flexible comparisons to allow analysts to gather visual evidence. In a previous work, we introduced align, rank, and filter (ARF) to accentuate temporal ordering. In this paper, we present temporal summaries, an interactive visualization technique that highlights the prevalence of event occurrences. Temporal summaries dynamically aggregate events in multiple granularities (year, month, week, day, hour, etc.) for the purpose of spotting trends over time and comparing several groups of records. They provide affordances for analysts to perform temporal range filters. We demonstrate the applicability of this approach in two extensive case studies with analysts who applied temporal summaries to search, filter, and look for patterns in electronic health records and academic records."}, {"color": "orange", "id": 493, "label": 493, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 493 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2009.5332586\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Chad A. Steed;J. Edward Swan;T.J. Jankun-Kelly;Patrick J. Fitzpatrick; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Guided analysis of hurricane trends using statistical processes integrated with interactive parallel coordinates; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: This paper demonstrates the promise of augmenting interactive multivariate representations with information from statistical processes in the domain of weather data analysis. Statistical regression, correlation analysis, and descriptive statistical calculations are integrated via graphical indicators into an enhanced parallel coordinates system, called the Multidimensional Data eXplorer (MDX). These statistical indicators, which highlight significant associations in the data, are complemented with interactive visual analysis capabilities. The resulting system allows a smooth, interactive, and highly visual workflow. The system\u0027s utility is demonstrated with an extensive hurricane climate study that was conducted by a hurricane expert. In the study, the expert used a new data set of environmental weather data, composed of 28 independent variables, to predict annual hurricane activity. MDX shows the Atlantic Meridional Mode increases the explained variance of hurricane seasonal activity by 7-15% and removes less significant variables used in earlier studies. The findings and feedback from the expert (1) validate the utility of the data set for hurricane prediction, and (2) indicate that the integration of statistical processes with interactive parallel coordinates, as implemented in MDX, addresses both deficiencies in traditional weather data analysis and exhibits some of the expected benefits of visual data analysis."}, {"color": "orange", "id": 494, "label": 494, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 494 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2009.5332593\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Tarik Crnovrsanin;Chris Muelder;Carlos Correa;Kwan-Liu Ma; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Proximity-based visualization of movement trace data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The increasing availability of motion sensors and video cameras in living spaces has made possible the analysis of motion patterns and collective behavior in a number of situations. The visualization of this movement data, however, remains a challenge. Although maintaining the actual layout of the data space is often desirable, direct visualization of movement traces becomes cluttered and confusing as the spatial distribution of traces may be disparate and uneven. We present proximity-based visualization as a novel approach to the visualization of movement traces in an abstract space rather than the given spatial layout. This abstract space is obtained by considering proximity data, which is computed as the distance between entities and some number of important locations. These important locations can range from a single fixed point, to a moving point, several points, or even the proximities between the entities themselves. This creates a continuum of proximity spaces, ranging from the fixed absolute reference frame to completely relative reference frames. By combining these abstracted views with the concrete spatial views, we provide a way to mentally map the abstract spaces back to the real space. We demonstrate the effectiveness of this approach, and its applicability to visual analytics problems such as hazard prevention, migration patterns, and behavioral studies."}, {"color": "orange", "id": 495, "label": 495, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 495 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2009.5332595\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Krist Wongsuphasawat;Ben Shneiderman; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Finding comparable temporal categorical records: A similarity measure with an interactive visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: An increasing number of temporal categorical databases are being collected: Electronic Health Records in healthcare organizations, traffic incident logs in transportation systems, or student records in universities. Finding similar records within these large databases requires effective similarity measures that capture the searcher\u0027s intent. Many similarity measures exist for numerical time series, but temporal categorical records are different. We propose a temporal categorical similarity measure, the M\u0026amp;M (Match \u0026amp; Mismatch) measure, which is based on the concept of aligning records by sentinel events, then matching events between the target and the compared records. The M\u0026amp;M measure combines the time differences between pairs of events and the number of mismatches. To accom-modate customization of parameters in the M\u0026amp;M measure and results interpretation, we implemented Similan, an interactive search and visualization tool for temporal categorical records. A usability study with 8 participants demonstrated that Similan was easy to learn and enabled them to find similar records, but users had difficulty understanding the M\u0026amp;M measure. The usability study feedback, led to an improved version with a continuous timeline, which was tested in a pilot study with 5 participants."}, {"color": "orange", "id": 498, "label": 498, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 498 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2009.5332611\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Carlos D. Correa;Yu-Hsuan Chan;Kwan-Liu Ma; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: A framework for uncertainty-aware visual analytics; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Visual analytics has become an important tool for gaining insight on large and complex collections of data. Numerous statistical tools and data transformations, such as projections, binning and clustering, have been coupled with visualization to help analysts understand data better and faster. However, data is inherently uncertain, due to error, noise or unreliable sources. When making decisions based on uncertain data, it is important to quantify and present to the analyst both the aggregated uncertainty of the results and the impact of the sources of that uncertainty. In this paper, we present a new framework to support uncertainty in the visual analytics process, through statistic methods such as uncertainty modeling, propagation and aggregation. We show that data transformations, such as regression, principal component analysis and k-means clustering, can be adapted to account for uncertainty. This framework leads to better visualizations that improve the decision-making process and help analysts gain insight on the analytic process itself."}, {"color": "orange", "id": 499, "label": 499, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 499 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2009.5332628\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Andrada Tatu;Georgia Albuquerque;Martin Eisemann;Jorn Schneidewind;Holger Theisel;Marcus Magnork;Daniel Keim; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Combining automated analysis and visualization techniques for effective exploration of high-dimensional data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Visual exploration of multivariate data typically requires projection onto lower-dimensional representations. The number of possible representations grows rapidly with the number of dimensions, and manual exploration quickly becomes ineffective or even unfeasible. This paper proposes automatic analysis methods to extract potentially relevant visual structures from a set of candidate visualizations. Based on features, the visualizations are ranked in accordance with a specified user task. The user is provided with a manageable number of potentially useful candidate visualizations, which can be used as a starting point for interactive data analysis. This can effectively ease the task of finding truly useful visualizations and potentially speed up the data exploration task. In this paper, we present ranking measures for class-based as well as non class-based Scatterplots and Parallel Coordinates visualizations. The proposed analysis methods are evaluated on different datasets."}, {"color": "orange", "id": 500, "label": 500, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 500 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2009.5332629\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jaegul Choo;Shawn Bohn;Haesun Park; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Two-stage framework for visualization of clustered high dimensional data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In this paper, we discuss dimension reduction methods for 2D visualization of high dimensional clustered data. We propose a two-stage framework for visualizing such data based on dimension reduction methods. In the first stage, we obtain the reduced dimensional data by applying a supervised dimension reduction method such as linear discriminant analysis which preserves the original cluster structure in terms of its criteria. The resulting optimal reduced dimension depends on the optimization criteria and is often larger than 2. In the second stage, the dimension is further reduced to 2 for visualization purposes by another dimension reduction method such as principal component analysis. The role of the second-stage is to minimize the loss of information due to reducing the dimension all the way to 2. Using this framework, we propose several two-stage methods, and present their theoretical characteristics as well as experimental comparisons on both artificial and real-world text data sets."}, {"color": "orange", "id": 501, "label": 501, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 501 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2009.5333020\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Nazanin Kadivar;Victor Chen;Dustin Dunsmuir;Eric Lee;Cheryl Qian;John Dill;Christopher Shaw;Robert Woodbury; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Capturing and supporting the analysis process; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Visual analytics tools provide powerful visual representations in order to support the sense-making process. In this process, analysts typically iterate through sequences of steps many times, varying parameters each time. Few visual analytics tools support this process well, nor do they provide support for visualizing and understanding the analysis process itself. To help analysts understand, explore, reference, and reuse their analysis process, we present a visual analytics system named CzSaw (See-Saw) that provides an editable and re-playable history navigation channel in addition to multiple visual representations of document collections and the entities within them (in a manner inspired by Jigsaw). Conventional history navigation tools range from basic undo and redo to branching timelines of user actions. In CzSaw\u0027s approach to this, first, user interactions are translated into a script language that drives the underlying scripting-driven propagation system. The latter allows analysts to edit analysis steps, and ultimately to program them. Second, on this base, we build both a history view showing progress and alternative paths, and a dependency graph showing the underlying logic of the analysis and dependency relations among the results of each step. These tools result in a visual model of the sense-making process, providing a way for analysts to visualize their analysis process, to reinterpret the problem, explore alternative paths, extract analysis patterns from existing history, and reuse them with other related analyses."}, {"color": "orange", "id": 502, "label": 502, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 502 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2009.5333023\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Yedendra B. Shrinivasan;David Gotzy;Jie Lu; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Connecting the dots in visual analysis; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: During visual analysis, users must often connect insights discovered at various points of time. This process is often called ldquoconnecting the dots.rdquo When analysts interactively explore complex datasets over multiple sessions, they may uncover a large number of findings. As a result, it is often difficult for them to recall the past insights, views and concepts that are most relevant to their current line of inquiry. This challenge is even more difficult during collaborative analysis tasks where they need to find connections between their own discoveries and insights found by others. In this paper, we describe a context-based retrieval algorithm to identify notes, views and concepts from users\u0027 past analyses that are most relevant to a view or a note based on their line of inquiry. We then describe a related notes recommendation feature that surfaces the most relevant items to the user as they work based on this algorithm. We have implemented this recommendation feature in HARVEST, a Web based visual analytic system. We evaluate the related notes recommendation feature of HARVEST through a case study and discuss the implications of our approach."}, {"color": "orange", "id": 507, "label": 507, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 507 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2009.5333248\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Romain Vuillemot;Tanya Clement;Catherine Plaisant;Amit Kumar; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: What\u0027s being said near \"Martha\"? Exploring name entities in literary text collections; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: A common task in literary analysis is to study characters in a novel or collection. Automatic entity extraction, text analysis and effective user interfaces facilitate character analysis. Using our interface, called POSvis, the scholar uses word clouds and self-organizing graphs to review vocabulary, to filter by part of speech, and to explore the network of characters located near characters under review. Further, visualizations show word usages within an analysis window (i.e. a book chapter), which can be compared with a reference window (i.e. the whole book). We describe the interface and report on an early case study with a humanities scholar."}, {"color": "orange", "id": 512, "label": 512, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 512 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2009.5333431\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Zhenyu Guo;Matthew O. Ward;Elke A. Rundensteiner; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Model space visualization for multivariate linear trend discovery; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Discovering and extracting linear trends and correlations in datasets is very important for analysts to understand multivariate phenomena. However, current widely used multivariate visualization techniques, such as parallel coordinates and scatterplot matrices, fail to reveal and illustrate such linear relationships intuitively, especially when more than 3 variables are involved or multiple trends coexist in the dataset. We present a novel multivariate model parameter space visualization system that helps analysts discover single and multiple linear patterns and extract subsets of data that fit a model well. Using this system, analysts are able to explore and navigate in model parameter space, interactively select and tune patterns, and refine the model for accuracy using computational techniques. We build connections between model space and data space visually, allowing analysts to employ their domain knowledge during exploration to better interpret the patterns they discover and their validity. Case studies with real datasets are used to investigate the effectiveness of the visualizations."}, {"color": "orange", "id": 514, "label": 514, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 514 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2009.5333437\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Stuart Rose;Scott Butner;Wendy Cowley;Michelle Gregory;Julia Walker; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Describing story evolution from dynamic information streams; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Sources of streaming information, such as news syndicates, publish information continuously. Information portals and news aggregators list the latest information from around the world enabling information consumers to easily identify events in the past 24 hours. The volume and velocity of these streams causes information from prior days to quickly vanish despite its utility in providing an informative context for interpreting new information. Few capabilities exist to support an individual attempting to identify or understand trends and changes from streaming information over time. The burden of retaining prior information and integrating with the new is left to the skills, determination, and discipline of each individual. In this paper we present a visual analytics system for linking essential content from information streams over time into dynamic stories that develop and change over multiple days. We describe particular challenges to the analysis of streaming information and present a fundamental visual representation for showing story change and evolution over time."}, {"color": "orange", "id": 516, "label": 516, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 516 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2009.5333443\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Christopher Collins;Fernanda B. Viegas;Martin Wattenberg; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Parallel Tag Clouds to explore and analyze faceted text corpora; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Do court cases differ from place to place? What kind of picture do we get by looking at a country\u0027s collection of law cases? We introduce parallel tag clouds: a new way to visualize differences amongst facets of very large metadata-rich text corpora. We have pointed parallel tag clouds at a collection of over 600,000 US Circuit Court decisions spanning a period of 50 years and have discovered regional as well as linguistic differences between courts. The visualization technique combines graphical elements from parallel coordinates and traditional tag clouds to provide rich overviews of a document collection while acting as an entry point for exploration of individual texts. We augment basic parallel tag clouds with a details-in-context display and an option to visualize changes over a second facet of the data, such as time. We also address text mining challenges such as selecting the best words to visualize, and how to do so in reasonable time periods to maintain interactivity."}, {"color": "orange", "id": 524, "label": 524, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 524 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2009.5333878\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Youn-ah Kang;Carsten Gorg;John Stasko; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Evaluating visual analytics systems for investigative analysis: Deriving design principles from a case study; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Despite the growing number of systems providing visual analytic support for investigative analysis, few empirical studies of the potential benefits of such systems have been conducted, particularly controlled, comparative evaluations. Determining how such systems foster insight and sensemaking is important for their continued growth and study, however. Furthermore, studies that identify how people use such systems and why they benefit (or not) can help inform the design of new systems in this area. We conducted an evaluation of the visual analytics system Jigsaw employed in a small investigative sensemaking exercise, and we compared its use to three other more traditional methods of analysis. Sixteen participants performed a simulated intelligence analysis task under one of the four conditions. Experimental results suggest that Jigsaw assisted participants to analyze the data and identify an embedded threat. We describe different analysis strategies used by study participants and how computational support (or the lack thereof) influenced the strategies. We then illustrate several characteristics of the sensemaking process identified in the study and provide design implications for investigative analysis tools based thereon. We conclude with recommendations for metrics and techniques for evaluating other visual analytics investigative analysis tools."}, {"color": "orange", "id": 526, "label": 526, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 526 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2009.5333893\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Tatiana von Landesberger;Melanie Gorner;Tobias Schreck; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visual analysis of graphs with multiple connected components; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In this paper, we present a system for the interactive visualization and exploration of graphs with many weakly connected components. The visualization of large graphs has recently received much research attention. However, specific systems for visual analysis of graph data sets consisting of many components are rare. In our approach, we rely on graph clustering using an extensive set of topology descriptors. Specifically, we use the self-organizing-map algorithm in conjunction with a user-adaptable combination of graph features for clustering of graphs. It offers insight into the overall structure of the data set. The clustering output is presented in a grid containing clusters of the connected components of the input graph. Interactive feature selection and task-tailored data views allow the exploration of the whole graph space. The system provides also tools for assessment and display of cluster quality. We demonstrate the usefulness of our system by application to a shareholder network analysis problem based on a large real-world data set. While so far our approach is applied to weighted directed graphs only, it can be used for various graph types."}, {"color": "blue", "id": 547, "label": 547, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 547 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2010.179\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Edward Segel;Jeffrey Heer; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Narrative Visualization: Telling Stories with Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Data visualization is regularly promoted for its ability to reveal stories within data, yet these \u201cdata stories\u201d differ in important ways from traditional forms of storytelling. Storytellers, especially online journalists, have increasingly been integrating visualizations into their narratives, in some cases allowing the visualization to function in place of a written story. In this paper, we systematically review the design space of this emerging class of visualizations. Drawing on case studies from news media to visualization research, we identify distinct genres of narrative visualization. We characterize these design differences, together with interactivity and messaging, in terms of the balance between the narrative flow intended by the author (imposed by graphical elements and the interface) and story discovery on the part of the reader (often through interactive exploration). Our framework suggests design strategies for narrative visualization, including promising under-explored approaches to journalistic storytelling and educational media."}, {"color": "blue", "id": 548, "label": 548, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 548 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2010.129\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Marian D\u00f6rk;Daniel Gruen;Carey Williamson;Sheelagh Carpendale; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: A Visual Backchannel for Large-Scale Events; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We introduce the concept of a Visual Backchannel as a novel way of following and exploring online conversations about large-scale events. Microblogging communities, such as Twitter, are increasingly used as digital backchannels for timely exchange of brief comments and impressions during political speeches, sport competitions, natural disasters, and other large events. Currently, shared updates are typically displayed in the form of a simple list, making it difficult to get an overview of the fast-paced discussions as it happens in the moment and how it evolves over time. In contrast, our Visual Backchannel design provides an evolving, interactive, and multi-faceted visual overview of large-scale ongoing conversations on Twitter. To visualize a continuously updating information stream, we include visual saliency for what is happening now and what has just happened, set in the context of the evolving conversation. As part of a fully web-based coordinated-view system we introduce Topic Streams, a temporally adjustable stacked graph visualizing topics over time, a People Spiral representing participants and their activity, and an Image Cloud encoding the popularity of event photos by size. Together with a post listing, these mutually linked views support cross-filtering along topics, participants, and time ranges. We discuss our design considerations, in particular with respect to evolving visualizations of dynamically changing data. Initial feedback indicates significant interest and suggests several unanticipated uses."}, {"color": "blue", "id": 549, "label": 549, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 549 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2010.194\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Bongshin Lee;Nathalie Henry Riche;Amy K. Karlson;Sheelash Carpendale; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: SparkClouds: Visualizing Trends in Tag Clouds; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Tag clouds have proliferated over the web over the last decade. They provide a visual summary of a collection of texts by visually depicting the tag frequency by font size. In use, tag clouds can evolve as the associated data source changes over time. Interesting discussions around tag clouds often include a series of tag clouds and consider how they evolve over time. However, since tag clouds do not explicitly represent trends or support comparisons, the cognitive demands placed on the person for perceiving trends in multiple tag clouds are high. In this paper, we introduce SparkClouds, which integrate sparklines into a tag cloud to convey trends between multiple tag clouds. We present results from a controlled study that compares SparkClouds with two traditional trend visualizations-multiple line graphs and stacked bar charts-as well as Parallel Tag Clouds. Results show that SparkClouds\u0027 ability to show trends compares favourably to the alternative visualizations."}, {"color": "blue", "id": 550, "label": 550, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 550 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2010.177\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Zhicheng Liu;John Stasko; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Mental Models; Visual Reasoning and Interaction in Information Visualization: A Top-down Perspective; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Although previous research has suggested that examining the interplay between internal and external representations can benefit our understanding of the role of information visualization (InfoVis) in human cognitive activities, there has been little work detailing the nature of internal representations, the relationship between internal and external representations and how interaction is related to these representations. In this paper, we identify and illustrate a specific kind of internal representation, mental models, and outline the high-level relationships between mental models and external visualizations. We present a top-down perspective of reasoning as model construction and simulation, and discuss the role of visualization in model based reasoning. From this perspective, interaction can be understood as active modeling for three primary purposes: external anchoring, information foraging, and cognitive offloading. Finally we discuss the implications of our approach for design, evaluation and theory development."}, {"color": "blue", "id": 551, "label": 551, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 551 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2010.164\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Lars Grammel;Melanie Tory;Margaret-Anne Storey; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: How Information Visualization Novices Construct Visualizations; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: It remains challenging for information visualization novices to rapidly construct visualizations during exploratory data analysis. We conducted an exploratory laboratory study in which information visualization novices explored fictitious sales data by communicating visualization specifications to a human mediator, who rapidly constructed the visualizations using commercial visualization software. We found that three activities were central to the iterative visualization construction process: data attribute selection, visual template selection, and visual mapping specification. The major barriers faced by the participants were translating questions into data attributes, designing visual mappings, and interpreting the visualizations. Partial specification was common, and the participants used simple heuristics and preferred visualizations they were already familiar with, such as bar, line and pie charts. We derived abstract models from our observations that describe barriers in the data exploration process and uncovered how information visualization novices think about visualization specifications. Our findings support the need for tools that suggest potential visualizations and support iterative refinement, that provide explanations and help with learning, and that are tightly integrated into tool support for the overall visual analytics process."}, {"color": "blue", "id": 552, "label": 552, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 552 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2010.162\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Waqas Javed;Bryan McDonnel;Niklas Elmqvist; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Graphical Perception of Multiple Time Series; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Line graphs have been the visualization of choice for temporal data ever since the days of William Playfair (1759-1823), but realistic temporal analysis tasks often include multiple simultaneous time series. In this work, we explore user performance for comparison, slope, and discrimination tasks for different line graph techniques involving multiple time series. Our results show that techniques that create separate charts for each time series--such as small multiples and horizon graphs--are generally more efficient for comparisons across time series with a large visual span. On the other hand, shared-space techniques--like standard line graphs--are typically more efficient for comparisons over smaller visual spans where the impact of overlap and clutter is reduced."}, {"color": "blue", "id": 553, "label": 553, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 553 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2010.183\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Yingcai Wu;Furu Wei;Shixia Liu;Norman Au;Weiwei Cui;Hong Zhou;Huamin Qu; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: OpinionSeer: Interactive Visualization of Hotel Customer Feedback; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The rapid development of Web technology has resulted in an increasing number of hotel customers sharing their opinions on the hotel services. Effective visual analysis of online customer opinions is needed, as it has a significant impact on building a successful business. In this paper, we present OpinionSeer, an interactive visualization system that could visually analyze a large collection of online hotel customer reviews. The system is built on a new visualization-centric opinion mining technique that considers uncertainty for faithfully modeling and analyzing customer opinions. A new visual representation is developed to convey customer opinions by augmenting well-established scatterplots and radial visualization. To provide multiple-level exploration, we introduce subjective logic to handle and organize subjective opinions with degrees of uncertainty. Several case studies illustrate the effectiveness and usefulness of OpinionSeer on analyzing relationships among multiple data dimensions and comparing opinions of different groups. Aside from data on hotel customer feedback, OpinionSeer could also be applied to visually analyze customer opinions on other products or services."}, {"color": "blue", "id": 554, "label": 554, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 554 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2010.210\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Nathalie Henry Riche;Tim Dwyer; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Untangling Euler Diagrams; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In many common data analysis scenarios the data elements are logically grouped into sets. Venn and Euler style diagrams are a common visual representation of such set membership where the data elements are represented by labels or glyphs and sets are indicated by boundaries surrounding their members. Generating such diagrams automatically such that set regions do not intersect unless the corresponding sets have a non-empty intersection is a difficult problem. Further, it may be impossible in some cases if regions are required to be continuous and convex. Several approaches exist to draw such set regions using more complex shapes, however, the resulting diagrams can be difficult to interpret. In this paper we present two novel approaches for simplifying a complex collection of intersecting sets into a strict hierarchy that can be more easily automatically arranged and drawn (Figure 1). In the first approach, we use compact rectangular shapes for drawing each set, attempting to improve the readability of the set intersections. In the second approach, we avoid drawing intersecting set regions by duplicating elements belonging to multiple sets. We compared both of our techniques to the traditional non-convex region technique using five readability tasks. Our results show that the compact rectangular shapes technique was often preferred by experimental subjects even though the use of duplications dramatically improves the accuracy and performance time for most of our tasks. In addition to general set representation our techniques are also applicable to visualization of networks with intersecting clusters of nodes."}, {"color": "blue", "id": 555, "label": 555, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 555 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2010.154\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Nan Cao;Jimeng Sun;Yu-Ru Lin;David Gotz;Shixia Liu;Huamin Qu; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: FacetAtlas: Multifaceted Visualization for Rich Text Corpora; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Documents in rich text corpora usually contain multiple facets of information. For example, an article about a specific disease often consists of different facets such as symptom, treatment, cause, diagnosis, prognosis, and prevention. Thus, documents may have different relations based on different facets. Powerful search tools have been developed to help users locate lists of individual documents that are most related to specific keywords. However, there is a lack of effective analysis tools that reveal the multifaceted relations of documents within or cross the document clusters. In this paper, we present FacetAtlas, a multifaceted visualization technique for visually analyzing rich text corpora. FacetAtlas combines search technology with advanced visual analytical tools to convey both global and local patterns simultaneously. We describe several unique aspects of FacetAtlas, including (1) node cliques and multifaceted edges, (2) an optimized density map, and (3) automated opacity pattern enhancement for highlighting visual patterns, (4) interactive context switch between facets. In addition, we demonstrate the power of FacetAtlas through a case study that targets patient education in the health care domain. Our evaluation shows the benefits of this work, especially in support of complex multifaceted data analysis."}, {"color": "blue", "id": 557, "label": 557, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 557 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2010.184\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Aritra Dasgupta;Robert Kosara; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Pargnostics: Screen-Space Metrics for Parallel Coordinates; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Interactive visualization requires the translation of data into a screen space of limited resolution. While currently ignored by most visualization models, this translation entails a loss of information and the introduction of a number of artifacts that can be useful, (e.g., aggregation, structures) or distracting (e.g., over-plotting, clutter) for the analysis. This phenomenon is observed in parallel coordinates, where overlapping lines between adjacent axes form distinct patterns, representing the relation between variables they connect. However, even for a small number of dimensions, the challenge is to effectively convey the relationships for all combinations of dimensions. The size of the dataset and a large number of dimensions only add to the complexity of this problem. To address these issues, we propose Pargnostics, parallel coordinates diagnostics, a model based on screen-space metrics that quantify the different visual structures. Pargnostics metrics are calculated for pairs of axes and take into account the resolution of the display as well as potential axis inversions. Metrics include the number of line crossings, crossing angles, convergence, overplotting, etc. To construct a visualization view, the user can pick from a ranked display showing pairs of coordinate axes and the structures between them, or examine all possible combinations of axes at once in a matrix display. Picking the best axes layout is an NP-complete problem in general, but we provide a way of automatically optimizing the display according to the user\u0027s preferences based on our metrics and model."}, {"color": "blue", "id": 558, "label": 558, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 558 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2010.138\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Alexander Lex;Marc Streit;Christian Partl;Karl Kashofer;Dieter Schmalstieg; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Comparative Analysis of Multidimensional; Quantitative Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: When analyzing multidimensional, quantitative data, the comparison of two or more groups of dimensions is a common task. Typical sources of such data are experiments in biology, physics or engineering, which are conducted in different configurations and use replicates to ensure statistically significant results. One common way to analyze this data is to filter it using statistical methods and then run clustering algorithms to group similar values. The clustering results can be visualized using heat maps, which show differences between groups as changes in color. However, in cases where groups of dimensions have an a priori meaning, it is not desirable to cluster all dimensions combined, since a clustering algorithm can fragment continuous blocks of records. Furthermore, identifying relevant elements in heat maps becomes more difficult as the number of dimensions increases. To aid in such situations, we have developed Matchmaker, a visualization technique that allows researchers to arbitrarily arrange and compare multiple groups of dimensions at the same time. We create separate groups of dimensions which can be clustered individually, and place them in an arrangement of heat maps reminiscent of parallel coordinates. To identify relations, we render bundled curves and ribbons between related records in different groups. We then allow interactive drill-downs using enlarged detail views of the data, which enable in-depth comparisons of clusters between groups. To reduce visual clutter, we minimize crossings between the views. This paper concludes with two case studies. The first demonstrates the value of our technique for the comparison of clustering algorithms. In the second, biologists use our system to investigate why certain strains of mice develop liver disease while others remain healthy, informally showing the efficacy of our system when analyzing multidimensional data containing distinct groups of dimensions."}, {"color": "blue", "id": 559, "label": 559, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 559 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2010.205\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Christophe Viau;Michael J. McGuffin;Yves Chiricota;Igor Jurisica; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: The FlowVizMenu and Parallel Scatterplot Matrix: Hybrid Multidimensional Visualizations for Network Exploration; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: A standard approach for visualizing multivariate networks is to use one or more multidimensional views (for example, scatterplots) for selecting nodes by various metrics, possibly coordinated with a node-link view of the network. In this paper, we present three novel approaches for achieving a tighter integration of these views through hybrid techniques for multidimensional visualization, graph selection and layout. First, we present the FlowVizMenu, a radial menu containing a scatterplot that can be popped up transiently and manipulated with rapid, fluid gestures to select and modify the axes of its scatterplot. Second, the FlowVizMenu can be used to steer an attribute-driven layout of the network, causing certain nodes of a node-link diagram to move toward their corresponding positions in a scatterplot while others can be positioned manually or by force-directed layout. Third, we describe a novel hybrid approach that combines a scatterplot matrix (SPLOM) and parallel coordinates called the Parallel Scatterplot Matrix (P-SPLOM), which can be used to visualize and select features within the network. We also describe a novel arrangement of scatterplots called the Scatterplot Staircase (SPLOS) that requires less space than a traditional scatterplot matrix. Initial user feedback is reported."}, {"color": "blue", "id": 560, "label": 560, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 560 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2010.144\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jeffrey Heer;Michael Bostock; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Declarative Language Design for Interactive Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We investigate the design of declarative, domain-specific languages for constructing interactive visualizations. By separating specification from execution, declarative languages can simplify development, enable unobtrusive optimization, and support retargeting across platforms. We describe the design of the Protovis specification language and its implementation within an object-oriented, statically-typed programming language (Java). We demonstrate how to support rich visualizations without requiring a toolkit-specific data model and extend Protovis to enable declarative specification of animated transitions. To support cross-platform deployment, we introduce rendering and event-handling infrastructures decoupled from the runtime platform, letting designers retarget visualization specifications (e.g., from desktop to mobile phone) with reduced effort. We also explore optimizations such as runtime compilation of visualization specifications, parallelized execution, and hardware-accelerated rendering. We present benchmark studies measuring the performance gains provided by these optimizations and compare performance to existing Java-based visualization tools, demonstrating scalability improvements exceeding an order of magnitude."}, {"color": "blue", "id": 561, "label": 561, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 561 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2010.186\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Nicholas Kong;Jeffrey Heer;Maneesh Agrawala; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Perceptual Guidelines for Creating Rectangular Treemaps; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Treemaps are space-filling visualizations that make efficient use of limited display space to depict large amounts of hierarchical data. Creating perceptually effective treemaps requires carefully managing a number of design parameters including the aspect ratio and luminance of rectangles. Moreover, treemaps encode values using area, which has been found to be less accurate than judgments of other visual encodings, such as length. We conduct a series of controlled experiments aimed at producing a set of design guidelines for creating effective rectangular treemaps. We find no evidence that luminance affects area judgments, but observe that aspect ratio does have an effect. Specifically, we find that the accuracy of area comparisons suffers when the compared rectangles have extreme aspect ratios or when both are squares. Contrary to common assumptions, the optimal distribution of rectangle aspect ratios within a treemap should include non-squares, but should avoid extremes. We then compare treemaps with hierarchical bar chart displays to identify the data densities at which length-encoded bar charts become less effective than area-encoded treemaps. We report the transition points at which treemaps exhibit judgment accuracy on par with bar charts for both leaf and non-leaf tree nodes. We also find that even at relatively low data densities treemaps result in faster comparisons than bar charts. Based on these results, we present a set of guidelines for the effective use of treemaps and suggest alternate approaches for treemap layout."}, {"color": "blue", "id": 565, "label": 565, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 565 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2010.176\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: David Feng;Lester Kwock;Yueh Lee;Russell Taylor; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Matching Visual Saliency to Confidence in Plots of Uncertain Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Conveying data uncertainty in visualizations is crucial for preventing viewers from drawing conclusions based on untrustworthy data points. This paper proposes a methodology for efficiently generating density plots of uncertain multivariate data sets that draws viewers to preattentively identify values of high certainty while not calling attention to uncertain values. We demonstrate how to augment scatter plots and parallel coordinates plots to incorporate statistically modeled uncertainty and show how to integrate them with existing multivariate analysis techniques, including outlier detection and interactive brushing. Computing high quality density plots can be expensive for large data sets, so we also describe a probabilistic plotting technique that summarizes the data without requiring explicit density plot computation. These techniques have been useful for identifying brain tumors in multivariate magnetic resonance spectroscopy data and we describe how to extend them to visualize ensemble data sets."}, {"color": "blue", "id": 567, "label": 567, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 567 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2010.193\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Robert Kincaid; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: SignalLens: Focus+Context Applied to Electronic Time Series; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Electronic test and measurement systems are becoming increasingly sophisticated in order to match the increased complexity and ultra-high speed of the devices under test. A key feature in many such instruments is a vastly increased capacity for storage of digital signals. Storage of 109 time points or more is now possible. At the same time, the typical screens on such measurement devices are relatively small. Therefore, these instruments can only render an extremely small fraction of the complete signal at any time. SignalLens uses a Focus+Context approach to provide a means of navigating to and inspecting low-level signal details in the context of the entire signal trace. This approach provides a compact visualization suitable for embedding into the small displays typically provided by electronic measurement instruments. We further augment this display with computed tracks which display time-aligned computed properties of the signal. By combining and filtering these computed tracks it is possible to easily and quickly find computationally detected features in the data which are often obscured by the visual compression required to render the large data sets on a small screen. Further, these tracks can be viewed in the context of the entire signal trace as well as visible high-level signal features. Several examples using real-world electronic measurement data are presented, which demonstrate typical use cases and the effectiveness of the design."}, {"color": "blue", "id": 569, "label": 569, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 569 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2010.191\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jason Dykes;Jo Wood;Aidan Slingsby; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Rethinking Map Legends with Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: This design paper presents new guidance for creating map legends in a dynamic environment. Our contribution is a set ofguidelines for legend design in a visualization context and a series of illustrative themes through which they may be expressed. Theseare demonstrated in an applications context through interactive software prototypes. The guidelines are derived from cartographicliterature and in liaison with EDINA who provide digital mapping services for UK tertiary education. They enhance approaches tolegend design that have evolved for static media with visualization by considering: selection, layout, symbols, position, dynamismand design and process. Broad visualization legend themes include: The Ground Truth Legend, The Legend as Statistical Graphicand The Map is the Legend. Together, these concepts enable us to augment legends with dynamic properties that address specificneeds, rethink their nature and role and contribute to a wider re-evaluation of maps as artifacts of usage rather than statements offact. EDINA has acquired funding to enhance their clients with visualization legends that use these concepts as a consequence ofthis work. The guidance applies to the design of a wide range of legends and keys used in cartography and information visualization."}, {"color": "blue", "id": 571, "label": 571, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 571 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2010.197\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Tuan Nhon Dang;Leland Wilkinson;Anushka Anand; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Stacking Graphic Elements to Avoid Over-Plotting; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: An ongoing challenge for information visualization is how to deal with over-plotting forced by ties or the relatively limited visual field of display devices. A popular solution is to represent local data density with area (bubble plots, treemaps), color(heatmaps), or aggregation (histograms, kernel densities, pixel displays). All of these methods have at least one of three deficiencies:1) magnitude judgments are biased because area and color have convex downward perceptual functions, 2) area, hue, and brightnesshave relatively restricted ranges of perceptual intensity compared to length representations, and/or 3) it is difficult to brush or link toindividual cases when viewing aggregations. In this paper, we introduce a new technique for visualizing and interacting with datasets that preserves density information by stacking overlapping cases. The overlapping data can be points or lines or other geometric elements, depending on the type of plot. We show real-dataset applications of this stacking paradigm and compare them to other techniques that deal with over-plotting in high-dimensional displays."}, {"color": "blue", "id": 572, "label": 572, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 572 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2010.126\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Angus Forbes;Tobias Hollerer;George Legrady; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: behaviorism: a framework for dynamic data visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: While a number of information visualization software frameworks exist, creating new visualizations, especially those that involve novel visualization metaphors, interaction techniques, data analysis strategies, and specialized rendering algorithms, is still often a difficult process. To facilitate the creation of novel visualizations we present a new software framework, behaviorism, which provides a wide range of flexibility when working with dynamic information on visual, temporal, and ontological levels, but at the same time providing appropriate abstractions which allow developers to create prototypes quickly which can then easily be turned into robust systems. The core of the framework is a set of three interconnected graphs, each with associated operators: a scene graph for high-performance 3D rendering, a data graph for different layers of semantically-linked heterogeneous data, and a timing graph for sophisticated control of scheduling, interaction, and animation. In particular, the timing graph provides a unified system to add behaviors to both data and visual elements, as well as to the behaviors themselves. To evaluate the framework we look briefly at three different projects all of which required novel visualizations in different domains, and all of which worked with dynamic data in different ways: an interactive ecological simulation, an information art installation, and an information visualization technique."}, {"color": "blue", "id": 573, "label": 573, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 573 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2010.216\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Tuan Pham;Rob Hess;Crystal Ju;Eugene Zhang;Ronald Metoyer; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visualization of Diversity in Large Multivariate Data Sets; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Understanding the diversity of a set of multivariate objects is an important problem in many domains, including ecology, college admissions, investing, machine learning, and others. However, to date, very little work has been done to help users achieve this kind of understanding. Visual representation is especially appealing for this task because it offers the potential to allow users to efficiently observe the objects of interest in a direct and holistic way. Thus, in this paper, we attempt to formalize the problem of visualizing the diversity of a large (more than 1000 objects), multivariate (more than 5 attributes) data set as one worth deeper investigation by the information visualization community. In doing so, we contribute a precise definition of diversity, a set of requirements for diversity visualizations based on this definition, and a formal user study design intended to evaluate the capacity of a visual representation for communicating diversity information. Our primary contribution, however, is a visual representation, called the Diversity Map, for visualizing diversity. An evaluation of the Diversity Map using our study design shows that users can judge elements of diversity consistently and as or more accurately than when using the only other representation specifically designed to visualize diversity."}, {"color": "blue", "id": 577, "label": 577, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 577 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2010.222\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Danyel Fisher;Steven Drucker;Roland Fernandez;Scott Ruble; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visualizations everywhere: A Multiplatform Infrastructure for Linked Visualizations; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In order to use new visualizations, most toolkits require application developers to rebuild their applications and distribute new versions to users. The WebCharts Framework take a different approach by hosting Javascript from within an application and providing a standard data and events interchange.. In this way, applications can be extended dynamically, with a wide variety of visualizations. We discuss the benefits of this architectural approach, contrast it to existing techniques, and give a variety of examples and extensions of the basic system."}, {"color": "orange", "id": 595, "label": 595, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 595 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2010.5652392\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Stephen Ingram;Tamara Munzner;Veronika Irvine;Melanie Tory;Steven Bergner;Torsten M\u00f6ller; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: DimStiller: Workflows for dimensional analysis and reduction; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: DimStiller is a system for dimensionality reduction and analysis. It frames the task of understanding and transforming input dimensions as a series of analysis steps where users transform data tables by chaining together different techniques, called operators, into pipelines of expressions. The individual operators have controls and views that are linked together based on the structure of the expression. Users interact with the operator controls to tune parameter choices, with immediate visual feedback guiding the exploration of local neighborhoods of the space of possible data tables. DimStiller also provides global guidance for navigating data-table space through expression templates called workflows, which permit re-use of common patterns of analysis."}, {"color": "orange", "id": 596, "label": 596, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 596 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2010.5652398\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Malgorzata Migut;Marcel Worring; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visual exploration of classification models for risk assessment; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In risk assessment applications well informed decisions are made based on huge amounts of multi-dimensional data. In many domains not only the risk of a wrong decision, but in particular the trade-off between the costs of possible decisions are of utmost importance. In this paper we describe a framework tightly integrating interactive visual exploration with machine learning to support the decision making process. The proposed approach uses a series of interactive 2D visualizations of numeric and ordinal data combined with visualization of classification models. These series of visual elements are further linked to the classifier\u0027s performance visualized using an interactive performance curve. An interactive decision point on the performance curve allows the decision maker to steer the classification model and instantly identify the critical, cost changing data elements, in the various linked visualizations. The critical data elements are represented as images in order to trigger associations related to the knowledge of the expert. In this context the data visualization and classification results are not only linked together, but are also linked back to the classification model. Such a visual analytics framework allows the user to interactively explore the costs of his decisions for different settings of the model and accordingly use the most suitable classification model and make more informed and reliable decisions. A case study on data from the Forensic Psychiatry domain reveals the usefulness of the suggested approach."}, {"color": "orange", "id": 597, "label": 597, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 597 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2010.5652433\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Georgia Albuquerque;Martin Eisemann;Dirk J. Lehmann;Holger Theisel;Marcus Magnor; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Improving the visual analysis of high-dimensional datasets using quality measures; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Modern visualization methods are needed to cope with very high-dimensional data. Efficient visual analytical techniques are required to extract the information content in these data. The large number of possible projections for each method, which usually grow quadrat-ically or even exponentially with the number of dimensions, urges the necessity to employ automatic reduction techniques, automatic sorting or selecting the projections, based on their information-bearing content. Different quality measures have been successfully applied for several specified user tasks and established visualization techniques, like Scatterplots, Scatterplot Matrices or Parallel Coordinates. Many other popular visualization techniques exist, but due to the structural differences, the measures are not directly applicable to them and new approaches are needed. In this paper we propose new quality measures for three popular visualization methods: Radviz, Pixel-Oriented Displays and Table Lenses. Our experiments show that these measures efficiently guide the visual analysis task."}, {"color": "orange", "id": 598, "label": 598, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 598 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2010.5652443\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jaegul Choo;Hanseung Lee;Jaeyeon Kihm;Haesun Park; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: iVisClassifier: An interactive visual analytics system for classification based on supervised dimension reduction; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present an interactive visual analytics system for classification, iVisClassifier, based on a supervised dimension reduction method, linear discriminant analysis (LDA). Given high-dimensional data and associated cluster labels, LDA gives their reduced dimensional representation, which provides a good overview about the cluster structure. Instead of a single two- or three-dimensional scatter plot, iVisClassifier fully interacts with all the reduced dimensions obtained by LDA through parallel coordinates and a scatter plot. Furthermore, it significantly improves the interactivity and interpretability of LDA. LDA enables users to understand each of the reduced dimensions and how they influence the data by reconstructing the basis vector into the original data domain. By using heat maps, iVisClassifier gives an overview about the cluster relationship in terms of pairwise distances between cluster centroids both in the original space and in the reduced dimensional space. Equipped with these functionalities, iVisClassifier supports users\u0027 classification tasks in an efficient way. Using several facial image data, we show how the above analysis is performed."}, {"color": "orange", "id": 599, "label": 599, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 599 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2010.5652450\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Bilkis J. Ferdosi;Hugo Buddelmeijer;Scott Trager;Michael H. F. Wilkinson;Jos B. T. M. Roerdink; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: finding and visualizing relevant subspaces for clustering high-dimensional astronomical data using connected morphological operators; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Data sets in astronomy are growing to enormous sizes. Modern astronomical surveys provide not only image data but also catalogues of millions of objects (stars, galaxies), each object with hundreds of associated parameters. Exploration of this very high-dimensional data space poses a huge challenge. Subspace clustering is one among several approaches which have been proposed for this purpose in recent years. However, many clustering algorithms require the user to set a large number of parameters without any guidelines. Some methods also do not provide a concise summary of the datasets, or, if they do, they lack additional important information such as the number of clusters present or the significance of the clusters. In this paper, we propose a method for ranking subspaces for clustering which overcomes many of the above limitations. First we carry out a transformation from parametric space to discrete image space where the data are represented by a grid-based density field. Then we apply so-called connected morphological operators on this density field of astronomical objects that provides visual support for the analysis of the important subspaces. Clusters in subspaces correspond to high-intensity regions in the density image. The importance of a cluster is measured by a new quality criterion based on the dynamics of local maxima of the density. Connected operators are able to extract such regions with an indication of the number of clusters present. The subspaces are visualized during computation of the quality measure, so that the user can interact with the system to improve the results. In the result stage, we use three visualization toolkits linked within a graphical user interface so that the user can perform an in-depth exploration of the ranked subspaces. Evaluation based on synthetic as well as real astronomical datasets demonstrates the power of the new method. We recover various known astronomical relations directly from the data with little or no a priori assumptions. Hence, our method holds good prospects for discovering new relations as well."}, {"color": "orange", "id": 600, "label": 600, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 600 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2010.5652460\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Yu-Hsuan Chan;Carlos D. Correa;Kwan-Liu Ma; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Flow-based scatterplots for sensitivity analysis; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Visualization of multi-dimensional data is challenging due to the number of complex correlations that may be present in the data but that are difficult to be visually identified. One of the main causes for this problem is the inherent loss of information that occurs when high-dimensional data is projected into 2D or 3D. Although 2D scatterplots are ubiquitous due to their simplicity and familiarity, there are not a lot of variations on their basic metaphor. In this paper, we present a new way of visualizing multidimensional data using scatterplots. We extend 2D scatterplots using sensitivity coefficients to highlight local variation of one variable with respect to another. When applied to a scatterplot, these sensitivities can be understood as velocities, and the resulting visualization resembles a flow field. We also present a number of operations, based on flow-field analysis, that help users navigate, select and cluster points in an efficient manner. We show the flexibility and generality of this approach using a number of multidimensional data sets across different domains."}, {"color": "orange", "id": 604, "label": 604, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 604 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2010.5652520\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Chris Weaver; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Multidimensional data dissection using attribute relationship graphs; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Visual exploration and analysis is a process of discovering and dissecting the abundant and complex attribute relationships that pervade multidimensional data. Recent research has identified and characterized patterns of multiple coordinated views, such as cross-filtered views, in which rapid sequences of simple interactions can be used to express queries on subsets of attribute values. In visualizations designed around these patterns, for the most part, distinct views serve to visually isolate each attribute from the others. Although the brush-and-click simplicity of visual isolation facilitates discovery of many-to-many relationships between attributes, dissecting these relationships into more fine-grained one-to-many relationships is interactively tedious and, worse, visually fragmented over prolonged sequences of queries. This paper describes: (1) a method for interactively dissecting multidimensional data by iteratively slicing and manipulating a multigraph representation of data values and value co-occurrences; and (2) design strategies for extending the construction of coordinated multiple view interfaces for dissection as well as discovery of attribute relationships in multidimensional data sets. Using examples from different domains, we describe how attribute relationship graphs can be combined with cross-filtered views, modularized for reuse across designs, and integrated into broader visual analysis tools. The exploratory and analytic utility of these examples suggests that an attribute relationship graph would be a useful addition to a wide variety of visual analysis tools."}, {"color": "orange", "id": 607, "label": 607, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 607 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2010.5652879\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Narges Mahyar;Ali Sarvghad;Melanie Tory; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: A closer look at note taking in the co-located collaborative visual analytics process; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: This paper highlights the important role that record-keeping (i.e. taking notes and saving charts) plays in collaborative data analysis within the business domain. The discussion of record-keeping is based on observations from a user study in which co-located teams worked on collaborative visual analytics tasks using large interactive wall and tabletop displays. Part of our findings is a collaborative data analysis framework that encompasses note taking as one of the main activities. We observed that record-keeping was a critical activity within the analysis process. Based on our observations, we characterize notes according to their content, scope, and usage, and describe how they fit into a process of collaborative data analysis. We then discuss suggestions for the design of collaborative visual analytics tools."}, {"color": "orange", "id": 608, "label": 608, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 608 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2010.5652880\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Petra Isenberg;Danyel Fisher;Meredith Ringel Morris;Kori Inkpen;Mary Czerwinski; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: An exploratory study of co-located collaborative visual analytics around a tabletop display; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Co-located collaboration can be extremely valuable during complex visual analytics tasks. This paper presents an exploratory study of a system designed to support collaborative visual analysis tasks on a digital tabletop display. Fifteen participant pairs employed Cam-biera, a visual analytics system, to solve a problem involving 240 digital documents. Our analysis, supported by observations, system logs, questionnaires, and interview data, explores how pairs approached the problem around the table. We contribute a unique, rich understanding of how users worked together around the table and identify eight types of collaboration styles that can be used to identify how closely people work together while problem solving. We show how the closeness of teams\u0027 collaboration influenced how well they performed on the task overall. We further discuss the role of the tabletop for visual analytics tasks and derive novel design implications for future co-located collaborative tabletop problem solving systems."}, {"color": "orange", "id": 609, "label": 609, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 609 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2010.5652885\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Yang Chen;Scott Barlowe;Jing Yang; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Click2Annotate: Automated Insight Externalization with rich semantics; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Insight Externalization (IE) refers to the process of capturing and recording the semantics of insights in decision making and problem solving. To reduce human effort, Automated Insight Externalization (AIE) is desired. Most existing IE approaches achieve automation by capturing events (e.g., clicks and key presses) or actions (e.g., panning and zooming). In this paper, we propose a novel AIE approach named Click2Annotate. It allows semi-automatic insight annotation that captures low-level analytics task results (e.g., clusters and outliers), which have higher semantic richness and abstraction levels than actions and events. Click2Annotate has two significant benefits. First, it reduces human effort required in IE and generates annotations easy to understand. Second, the rich semantic information encoded in the annotations enables various insight management activities, such as insight browsing and insight retrieval. We present a formal user study that proved this first benefit. We also illustrate the second benefit by presenting the novel insight management activities we developed based on Click2Annotate, namely scented insight browsing and faceted insight search."}, {"color": "orange", "id": 610, "label": 610, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 610 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2010.5652890\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jing Jin;Pedro Szekely; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Interactive querying of temporal data using a comic strip metaphor; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Finding patterns in temporal data is an important data analysis task in many domains. Static visualizations can help users easily see certain instances of patterns, but are not specially designed to support systematic analysis tasks, such as finding all instances of a pattern automatically. VizPattern is an interactive visual query environment that uses a comic strip metaphor to enable users to easily and quickly define and locate complex temporal patterns. Evaluations provide evidence that VizPattern is applicable in many domains, and that it enables a wide variety of users to answer questions about temporal data faster and with fewer errors than existing state-of-the-art visual analysis systems."}, {"color": "orange", "id": 614, "label": 614, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 614 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2010.5652922\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Nicholas Diakopoulos;Mor Naaman;Funda Kivran-Swaine; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Diamonds in the rough: Social media visual analytics for journalistic inquiry; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Journalists increasingly turn to social media sources such as Facebook or Twitter to support their coverage of various news events. For large-scale events such as televised debates and speeches, the amount of content on social media can easily become overwhelming, yet still contain information that may aid and augment reporting via individual content items as well as via aggregate information from the crowd\u0027s response. In this work we present a visual analytic tool, Vox Civitas, designed to help journalists and media professionals extract news value from large-scale aggregations of social media content around broadcast events. We discuss the design of the tool, present the text analysis techniques used to enable the presentation, and provide details on the visual and interaction design. We provide an exploratory evaluation based on a user study in which journalists interacted with the system to explore and report on a dataset of over one hundred thousand twitter messages collected during the U.S. State of the Union presidential address in 2010."}, {"color": "orange", "id": 616, "label": 616, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 616 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2010.5652931\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Lei Shi;Furu Wei;Shixia Liu;Li Tan;Xiaoxiao Lian;Michelle X. Zhou; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Understanding text corpora with multiple facets; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Text visualization becomes an increasingly more important research topic as the need to understand massive-scale textual information is proven to be imperative for many people and businesses. However, it is still very challenging to design effective visual metaphors to represent large corpora of text due to the unstructured and high-dimensional nature of text. In this paper, we propose a data model that can be used to represent most of the text corpora. Such a data model contains four basic types of facets: time, category, content (unstructured), and structured facet. To understand the corpus with such a data model, we develop a hybrid visualization by combining the trend graph with tag-clouds. We encode the four types of data facets with four separate visual dimensions. To help people discover evolutionary and correlation patterns, we also develop several visual interaction methods that allow people to interactively analyze text by one or more facets. Finally, we present two case studies to demonstrate the effectiveness of our solution in support of multi-faceted visual analysis of text corpora."}, {"color": "orange", "id": 617, "label": 617, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 617 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2010.5652932\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Haeyong Chung;Seungwon Yang;Naveed Massjouni;Christopher Andrews;Rahul Kanna;Chris North; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: VizCept: Supporting synchronous collaboration for constructing visualizations in intelligence analysis; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In this paper, we present a new web-based visual analytics system, VizCept, which is designed to support fluid, collaborative analysis of large textual intelligence datasets. The main approach of the design is to combine individual workspace and shared visualization in an integrated environment. Collaborating analysts will be able to identify concepts and relationships from the dataset based on keyword searches in their own workspace and collaborate visually with other analysts using visualization tools such as a concept map view and a timeline view. The system allows analysts to parallelize the work by dividing initial sets of concepts, investigating them on their own workspace, and then integrating individual findings automatically on shared visualizations with support for interaction and personal graph layout in real time, in order to develop a unified plot. We highlight several design considerations that promote communication and analytic performance in small team synchronous collaboration. We report the result of a pair of case study applications including collaboration and communication methods, analysis strategies, and user behaviors under a competition setting in the same location at the same time. The results of these demonstrate the tool\u0027s effectiveness for synchronous collaborative construction and use of visualizations in intelligence data analysis."}, {"color": "orange", "id": 624, "label": 624, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 624 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2010.5653598\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Heather Richter Lipford;Felesia Stukes;Wenwen Dou;Matthew E. Hawkins;Remco Chang; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Helping users recall their reasoning process; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The final product of an analyst\u0027s investigation using a visualization is often a report of the discovered knowledge, as well as the methods employed and reasoning behind the discovery. We believe that analysts may have difficulty keeping track of their knowledge discovery process and will require tools to assist in accurately recovering their reasoning. We first report on a study examining analysts\u0027 recall of their strategies and methods, demonstrating their lack of memory of the path of knowledge discovery. We then explore whether a tool visualizing the steps of the visual analysis can aid users in recalling their reasoning process. The results of our second study indicate that visualizations of interaction logs can serve as an effective memory aid, allowing analysts to recall additional details of their strategies and decisions."}, {"color": "blue", "id": 631, "label": 631, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 631 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2011.166\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Zhao Geng;ZhenMin Peng;Robert S.Laramee;Jonathan C. Roberts;Rick Walker; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Angular Histograms: Frequency-Based Visualizations for Large, High Dimensional Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Parallel coordinates is a popular and well-known multivariate data visualization technique. However, one of their inherent limitations has to do with the rendering of very large data sets. This often causes an overplotting problem and the goal of the visual information seeking mantra is hampered because of a cluttered overview and non-interactive update rates. In this paper, we propose two novel solutions, namely, angular histograms and attribute curves. These techniques are frequency-based approaches to large, high-dimensional data visualization. They are able to convey both the density of underlying polylines and their slopes. Angular histogram and attribute curves offer an intuitive way for the user to explore the clustering, linear correlations and outliers in large data sets without the over-plotting and clutter problems associated with traditional parallel coordinates. We demonstrate the results on a wide variety of data sets including real-world, high-dimensional biological data. Finally, we compare our methods with the other popular frequency-based algorithms."}, {"color": "blue", "id": 632, "label": 632, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 632 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2011.167\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Justin Talbot;John Gerth;Pat Hanrahan; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Arc Length-Based Aspect Ratio Selection; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The aspect ratio of a plot has a dramatic impact on our ability to perceive trends and patterns in the data. Previous approaches for automatically selecting the aspect ratio have been based on adjusting the orientations or angles of the line segments in the plot. In contrast, we recommend a simple, effective method for selecting the aspect ratio: minimize the arc length of the data curve while keeping the area of the plot constant. The approach is parameterization invariant, robust to a wide range of inputs, preserves visual symmetries in the data, and is a compromise between previously proposed techniques. Further, we demonstrate that it can be effectively used to select the aspect ratio of contour plots. We believe arc length should become the default aspect ratio selection method."}, {"color": "blue", "id": 635, "label": 635, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 635 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2011.175\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jessica Hullman;Eytan Adar;Priti Shah; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Benefitting InfoVis with Visual Difficulties; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Many well-cited theories for visualization design state that a visual representation should be optimized for quick and immediate interpretation by a user. Distracting elements like decorative \"chartjunk\" or extraneous information are avoided so as not to slow comprehension. Yet several recent studies in visualization research provide evidence that non-efficient visual elements may benefit comprehension and recall on the part of users. Similarly, findings from studies related to learning from visual displays in various subfields of psychology suggest that introducing cognitive difficulties to visualization interaction can improve a user\u0027s understanding of important information. In this paper, we synthesize empirical results from cross-disciplinary research on visual information representations, providing a counterpoint to efficiency-based design theory with guidelines that describe how visual difficulties can be introduced to benefit comprehension and recall. We identify conditions under which the application of visual difficulties is appropriate based on underlying factors in visualization interaction like active processing and engagement. We characterize effective graph design as a trade-off between efficiency and learning difficulties in order to provide Information Visualization (InfoVis) researchers and practitioners with a framework for organizing explorations of graphs for which comprehension and recall are crucial. We identify implications of this view for the design and evaluation of information visualizations."}, {"color": "blue", "id": 637, "label": 637, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 637 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2011.178\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Cagatay Turkay;Peter Filzmoser;Helwig Hauser; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Brushing Dimensions - A Dual Visual Analysis Model for High-Dimensional Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In many application fields, data analysts have to deal with datasets that contain many expressions per item. The effective analysis of such multivariate datasets is dependent on the user\u0027s ability to understand both the intrinsic dimensionality of the dataset as well as the distribution of the dependent values with respect to the dimensions. In this paper, we propose a visualization model that enables the joint interactive visual analysis of multivariate datasets with respect to their dimensions as well as with respect to the actual data values. We describe a dual setting of visualization and interaction in items space and in dimensions space. The visualization of items is linked to the visualization of dimensions with brushing and focus+context visualization. With this approach, the user is able to jointly study the structure of the dimensions space as well as the distribution of data items with respect to the dimensions. Even though the proposed visualization model is general, we demonstrate its application in the context of a DNA microarray data analysis."}, {"color": "blue", "id": 638, "label": 638, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 638 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2011.179\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Milos Krstajic;Enrico Bertini;Daniel Keim; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: CloudLines: Compact Display of Event Episodes in Multiple Time-Series; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We propose incremental logarithmic time-series technique as a way to deal with time-based representations of large and dynamic event data sets in limited space. Modern data visualization problems in the domains of news analysis, network security and financial applications, require visual analysis of incremental data, which poses specific challenges that are normally not solved by static visualizations. The incremental nature of the data implies that visualizations have to necessarily change their content and still provide comprehensible representations. In particular, in this paper we deal with the need to keep an eye on recent events together with providing a context on the past and to make relevant patterns accessible at any scale. Our technique adapts to the incoming data by taking care of the rate at which data items occur and by using a decay function to let the items fade away according to their relevance. Since access to details is also important, we also provide a novel distortion magnifying lens technique which takes into account the distortions introduced by the logarithmic time scale to augment readability in selected areas of interest. We demonstrate the validity of our techniques by applying them on incremental data coming from online news streams in different time frames."}, {"color": "blue", "id": 639, "label": 639, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 639 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2011.181\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Roeland Scheepens;Niels Willems;Huub van de Wetering;Gennady Andrienko;Natalia Andrienko;Jarke J. van Wijk; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Composite Density Maps for Multivariate Trajectories; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We consider moving objects as multivariate time-series. By visually analyzing the attributes, patterns may appear that explain why certain movements have occurred. Density maps as proposed by Scheepens et al. [25] are a way to reveal these patterns by means of aggregations of filtered subsets of trajectories. Since filtering is often not sufficient for analysts to express their domain knowledge, we propose to use expressions instead. We present a flexible architecture for density maps to enable custom, versatile exploration using multiple density fields. The flexibility comes from a script, depicted in this paper as a block diagram, which defines an advanced computation of a density field. We define six different types of blocks to create, compose, and enhance trajectories or density fields. Blocks are customized by means of expressions that allow the analyst to model domain knowledge. The versatility of our architecture is demonstrated with several maritime use cases developed with domain experts. Our approach is expected to be useful for the analysis of objects in other domains."}, {"color": "blue", "id": 640, "label": 640, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 640 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2011.183\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Markus Steinberger;Manuela Waldner;Marc Streit;Alexander Lex;Dieter Schmalstieg; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Context-Preserving Visual Links; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Evaluating, comparing, and interpreting related pieces of information are tasks that are commonly performed during visual data analysis and in many kinds of information-intensive work. Synchronized visual highlighting of related elements is a well-known technique used to assist this task. An alternative approach, which is more invasive but also more expressive is visual linking in which line connections are rendered between related elements. In this work, we present context-preserving visual links as a new method for generating visual links. The method specifically aims to fulfill the following two goals: first, visual links should minimize the occlusion of important information; second, links should visually stand out from surrounding information by minimizing visual interference. We employ an image-based analysis of visual saliency to determine the important regions in the original representation. A consequence of the image-based approach is that our technique is application-independent and can be employed in a large number of visual data analysis scenarios in which the underlying content cannot or should not be altered. We conducted a controlled experiment that indicates that users can find linked elements in complex visualizations more quickly and with greater subjective satisfaction than in complex visualizations in which plain highlighting is used. Context-preserving visual links were perceived as visually more attractive than traditional visual links that do not account for the context information."}, {"color": "blue", "id": 641, "label": 641, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 641 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2011.185\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Michael Bostock;Vadim Ogievetsky;Jeffrey Heer; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: D\u00b3 Data-Driven Documents; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Data-Driven Documents (D3) is a novel representation-transparent approach to visualization for the web. Rather than hide the underlying scenegraph within a toolkit-specific abstraction, D3 enables direct inspection and manipulation of a native representation: the standard document object model (DOM). With D3, designers selectively bind input data to arbitrary document elements, applying dynamic transforms to both generate and modify content. We show how representational transparency improves expressiveness and better integrates with developer tools than prior approaches, while offering comparable notational efficiency and retaining powerful declarative components. Immediate evaluation of operators further simplifies debugging and allows iterative development. Additionally, we demonstrate how D3 transforms naturally enable animation and interaction with dramatic performance improvements over intermediate representations."}, {"color": "blue", "id": 642, "label": 642, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 642 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2011.186\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Basak Alper;Nathalie Riche;Gonzalo Ramos;Mary Czerwinski; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Design Study of LineSets, a Novel Set Visualization Technique; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Computing and visualizing sets of elements and their relationships is one of the most common tasks one performs when analyzing and organizing large amounts of data. Common representations of sets such as convex or concave geometries can become cluttered and difficult to parse when these sets overlap in multiple or complex ways, e.g., when multiple elements belong to multiple sets. In this paper, we present a design study of a novel set visual representation, LineSets, consisting of a curve connecting all of the set\u0027s elements. Our approach to design the visualization differs from traditional methodology used by the InfoVis community. We first explored the potential of the visualization concept by running a controlled experiment comparing our design sketches to results from the state-of-the-art technique. Our results demonstrated that LineSets are advantageous for certain tasks when compared to concave shapes. We discuss an implementation of LineSets based on simple heuristics and present a study demonstrating that our generated curves do as well as human-drawn ones. Finally, we present two applications of our technique in the context of search tasks on a map and community analysis tasks in social networks."}, {"color": "blue", "id": 644, "label": 644, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 644 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2011.188\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Nan Cao;David Gotz;Jimeng Sun;Huamin Qu; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: DICON: Interactive Visual Analysis of Multidimensional Clusters; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Clustering as a fundamental data analysis technique has been widely used in many analytic applications. However, it is often difficult for users to understand and evaluate multidimensional clustering results, especially the quality of clusters and their semantics. For large and complex data, high-level statistical information about the clusters is often needed for users to evaluate cluster quality while a detailed display of multidimensional attributes of the data is necessary to understand the meaning of clusters. In this paper, we introduce DICON, an icon-based cluster visualization that embeds statistical information into a multi-attribute display to facilitate cluster interpretation, evaluation, and comparison. We design a treemap-like icon to represent a multidimensional cluster, and the quality of the cluster can be conveniently evaluated with the embedded statistical information. We further develop a novel layout algorithm which can generate similar icons for similar clusters, making comparisons of clusters easier. User interaction and clutter reduction are integrated into the system to help users more effectively analyze and refine clustering results for large datasets. We demonstrate the power of DICON through a user study and a case study in the healthcare domain. Our evaluation shows the benefits of the technique, especially in support of complex multidimensional cluster analysis."}, {"color": "blue", "id": 645, "label": 645, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 645 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2011.190\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: David Selassie;Brandon Heller;Jeffrey Heer; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Divided Edge Bundling for Directional Network Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The node-link diagram is an intuitive and venerable way to depict a graph. To reduce clutter and improve the readability of node-link views, Holten \u0026amp;amp; van Wijk\u0027s force-directed edge bundling employs a physical simulation to spatially group graph edges. While both useful and aesthetic, this technique has shortcomings: it bundles spatially proximal edges regardless of direction, weight, or graph connectivity. As a result, high-level directional edge patterns are obscured. We present divided edge bundling to tackle these shortcomings. By modifying the forces in the physical simulation, directional lanes appear as an emergent property of edge direction. By considering graph topology, we only bundle edges related by graph structure. Finally, we aggregate edge weights in bundles to enable more accurate visualization of total bundle weights. We compare visualizations created using our technique to standard force-directed edge bundling, matrix diagrams, and clustered graphs; we find that divided edge bundling leads to visualizations that are easier to interpret and reveal both familiar and previously obscured patterns."}, {"color": "blue", "id": 649, "label": 649, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 649 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2011.195\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jian Zhao;Fanny Chevalier;Emmanuel Pietriga;Ravin Balakrishnan; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Exploratory Analysis of Time-Series with ChronoLenses; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Visual representations of time-series are useful for tasks such as identifying trends, patterns and anomalies in the data. Many techniques have been devised to make these visual representations more scalable, enabling the simultaneous display of multiple variables, as well as the multi-scale display of time-series of very high resolution or that span long time periods. There has been comparatively little research on how to support the more elaborate tasks associated with the exploratory visual analysis of timeseries, e.g., visualizing derived values, identifying correlations, or discovering anomalies beyond obvious outliers. Such tasks typically require deriving new time-series from the original data, trying different functions and parameters in an iterative manner. We introduce a novel visualization technique called ChronoLenses, aimed at supporting users in such exploratory tasks. ChronoLenses perform on-the-fly transformation of the data points in their focus area, tightly integrating visual analysis with user actions, and enabling the progressive construction of advanced visual analysis pipelines."}, {"color": "blue", "id": 652, "label": 652, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 652 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2011.201\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jarry H.T. Claessen;Jarke J. van Wijk; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Flexible Linked Axes for Multivariate Data Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Multivariate data visualization is a classic topic, for which many solutions have been proposed, each with its own strengths and weaknesses. In standard solutions the structure of the visualization is fixed, we explore how to give the user more freedom to define visualizations. Our new approach is based on the usage of Flexible Linked Axes: The user is enabled to define a visualization by drawing and linking axes on a canvas. Each axis has an associated attribute and range, which can be adapted. Links between pairs of axes are used to show data in either scatter plot- or Parallel Coordinates Plot-style. Flexible Linked Axes enable users to define a wide variety of different visualizations. These include standard methods, such as scatter plot matrices, radar charts, and PCPs [11]; less well known approaches, such as Hyperboxes [1], TimeWheels [17], and many-to-many relational parallel coordinate displays [14]; and also custom visualizations, consisting of combinations of scatter plots and PCPs. Furthermore, our method allows users to define composite visualizations that automatically support brushing and linking. We have discussed our approach with ten prospective users, who found the concept easy to understand and highly promising."}, {"color": "blue", "id": 653, "label": 653, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 653 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2011.202\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Kevin Buchin;Bettina Speckmann;Kevin Verbeek; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Flow Map Layout via Spiral Trees; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Flow maps are thematic maps that visualize the movement of objects, such as people or goods, between geographic regions. One or more sources are connected to several targets by lines whose thickness corresponds to the amount of flow between a source and a target. Good flow maps reduce visual clutter by merging (bundling) lines smoothly and by avoiding self-intersections. Most flow maps are still drawn by hand and only few automated methods exist. Some of the known algorithms do not support edge-bundling and those that do, cannot guarantee crossing-free flows. We present a new algorithmic method that uses edge-bundling and computes crossing-free flows of high visual quality. Our method is based on so-called spiral trees, a novel type of Steiner tree which uses logarithmic spirals. Spiral trees naturally induce a clustering on the targets and smoothly bundle lines. Our flows can also avoid obstacles, such as map features, region outlines, or even the targets. We demonstrate our approach with extensive experiments."}, {"color": "blue", "id": 655, "label": 655, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 655 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2011.209\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: David Lloyd;Jason Dykes; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Human-Centered Approaches in Geovisualization Design: Investigating Multiple Methods Through a Long-Term Case Study; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Working with three domain specialists we investigate human-centered approaches to geovisualization following an ISO13407 taxonomy covering context of use, requirements and early stages of design. Our case study, undertaken over three years, draws attention to repeating trends: that generic approaches fail to elicit adequate requirements for geovis application design; that the use of real data is key to understanding needs and possibilities; that trust and knowledge must be built and developed with collaborators. These processes take time but modified human-centred approaches can be effective. A scenario developed through contextual inquiry but supplemented with domain data and graphics is useful to geovis designers. Wireframe, paper and digital prototypes enable successful communication between specialist and geovis domains when incorporating real and interesting data, prompting exploratory behaviour and eliciting previously unconsidered requirements. Paper prototypes are particularly successful at eliciting suggestions, especially for novel visualization. Enabling specialists to explore their data freely with a digital prototype is as effective as using a structured task protocol and is easier to administer. Autoethnography has potential for framing the design process. We conclude that a common understanding of context of use, domain data and visualization possibilities are essential to successful geovis design and develop as this progresses. HC approaches can make a significant contribution here. However, modified approaches, applied with flexibility, are most promising. We advise early, collaborative engagement with data - through simple, transient visual artefacts supported by data sketches and existing designs - before moving to successively more sophisticated data wireframes and data prototypes."}, {"color": "blue", "id": 657, "label": 657, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 657 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2011.213\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Steffen Hadlak;Hans-Jorg Schulz;Heidrun Schumann; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: In Situ Exploration of Large Dynamic Networks; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The analysis of large dynamic networks poses a challenge in many fields, ranging from large bot-nets to social networks. As dynamic networks exhibit different characteristics, e.g., being of sparse or dense structure, or having a continuous or discrete time line, a variety of visualization techniques have been specifically designed to handle these different aspects of network structure and time. This wide range of existing techniques is well justified, as rarely a single visualization is suitable to cover the entire visual analysis. Instead, visual representations are often switched in the course of the exploration of dynamic graphs as the focus of analysis shifts between the temporal and the structural aspects of the data. To support such a switching in a seamless and intuitive manner, we introduce the concept of in situ visualization- a novel strategy that tightly integrates existing visualization techniques for dynamic networks. It does so by allowing the user to interactively select in a base visualization a region for which a different visualization technique is then applied and embedded in the selection made. This permits to change the way a locally selected group of data items, such as nodes or time points, are shown - right in the place where they are positioned, thus supporting the user\u0027s overall mental map. Using this approach, a user can switch seamlessly between different visual representations to adapt a region of a base visualization to the specifics of the data within it or to the current analysis focus. This paper presents and discusses the in situ visualization strategy and its implications for dynamic graph visualization. Furthermore, it illustrates its usefulness by employing it for the visual exploration of dynamic networks from two different fields: model versioning and wireless mesh networks."}, {"color": "blue", "id": 658, "label": 658, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 658 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2011.220\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Paulo Joia;Danilo Coimbra;Jose A. Cuminato;Fernando V. Paulovich;Luis G. Nonato; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Local Affine Multidimensional Projection; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Multidimensional projection techniques have experienced many improvements lately, mainly regarding computational times and accuracy. However, existing methods do not yet provide flexible enough mechanisms for visualization-oriented fully interactive applications. This work presents a new multidimensional projection technique designed to be more flexible and versatile than other methods. This novel approach, called Local Affine Multidimensional Projection (LAMP), relies on orthogonal mapping theory to build accurate local transformations that can be dynamically modified according to user knowledge. The accuracy, flexibility and computational efficiency of LAMP is confirmed by a comprehensive set of comparisons. LAMP\u0027s versatility is exploited in an application which seeks to correlate data that, in principle, has no connection as well as in visual exploration of textual documents."}, {"color": "blue", "id": 659, "label": 659, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 659 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2011.223\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Christophe Hurter;Alexandru Telea;Ozan Ersoy; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: MoleView: An Attribute and Structure-Based Semantic Lens for Large Element-Based Plots; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present MoleView, a novel technique for interactive exploration of multivariate relational data. Given a spatial embedding of the data, in terms of a scatter plot or graph layout, we propose a semantic lens which selects a specific spatial and attribute-related data range. The lens keeps the selected data in focus unchanged and continuously deforms the data out of the selection range in order to maintain the context around the focus. Specific deformations include distance-based repulsion of scatter plot points, deforming straight-line node-link graph drawings, and as varying the simplification degree of bundled edge graph layouts. Using a brushing-based technique, we further show the applicability of our semantic lens for scenarios requiring a complex selection of the zones of interest. Our technique is simple to implement and provides real-time performance on large datasets. We demonstrate our technique with actual data from air and road traffic control, medical imaging, and software comprehension applications."}, {"color": "blue", "id": 660, "label": 660, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 660 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2011.226\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Michael Burch;Corinna Vehlow;Fabian Beck;Stephan Diehl;Daniel Weiskopf; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Parallel Edge Splatting for Scalable Dynamic Graph Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present a novel dynamic graph visualization technique based on node-link diagrams. The graphs are drawn side-byside from left to right as a sequence of narrow stripes that are placed perpendicular to the horizontal time line. The hierarchically organized vertices of the graphs are arranged on vertical, parallel lines that bound the stripes; directed edges connect these vertices from left to right. To address massive overplotting of edges in huge graphs, we employ a splatting approach that transforms the edges to a pixel-based scalar field. This field represents the edge densities in a scalable way and is depicted by non-linear color mapping. The visualization method is complemented by interaction techniques that support data exploration by aggregation, filtering, brushing, and selective data zooming. Furthermore, we formalize graph patterns so that they can be interactively highlighted on demand. A case study on software releases explores the evolution of call graphs extracted from the JUnit open source software project. In a second application, we demonstrate the scalability of our approach by applying it to a bibliography dataset containing more than 1.5 million paper titles from 60 years of research history producing a vast amount of relations between title words."}, {"color": "blue", "id": 661, "label": 661, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 661 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2011.227\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Hadley Wickham;Heike Hofmann; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Product Plots; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We propose a new framework for visualising tables of counts, proportions and probabilities. We call our framework product plots, alluding to the computation of area as a product of height and width, and the statistical concept of generating a joint distribution from the product of conditional and marginal distributions. The framework, with extensions, is sufficient to encompass over 20 visualisations previously described in fields of statistical graphics and infovis, including bar charts, mosaic plots, treemaps, equal area plots and fluctuation diagrams."}, {"color": "blue", "id": 662, "label": 662, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 662 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2011.229\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Enrico Bertini;Andrada Tatu;Daniel Keim; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Quality Metrics in High-Dimensional Data Visualization: An Overview and Systematization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In this paper, we present a systematization of techniques that use quality metrics to help in the visual exploration of meaningful patterns in high-dimensional data. In a number of recent papers, different quality metrics are proposed to automate the demanding search through large spaces of alternative visualizations (e.g., alternative projections or ordering), allowing the user to concentrate on the most promising visualizations suggested by the quality metrics. Over the last decade, this approach has witnessed a remarkable development but few reflections exist on how these methods are related to each other and how the approach can be developed further. For this purpose, we provide an overview of approaches that use quality metrics in high-dimensional data visualization and propose a systematization based on a thorough literature review. We carefully analyze the papers and derive a set of factors for discriminating the quality metrics, visualization techniques, and the process itself. The process is described through a reworked version of the well-known information visualization pipeline. We demonstrate the usefulness of our model by applying it to several existing approaches that use quality metrics, and we provide reflections on implications of our model for future research."}, {"color": "blue", "id": 664, "label": 664, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 664 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2011.233\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Ozan Ersoy;Christophe Hurter;Fernando Paulovich;Gabriel Cantareiro;Alex Telea; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Skeleton-Based Edge Bundling for Graph Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In this paper, we present a novel approach for constructing bundled layouts of general graphs. As layout cues for bundles, we use medial axes, or skeletons, of edges which are similar in terms of position information. We combine edge clustering, distance fields, and 2D skeletonization to construct progressively bundled layouts for general graphs by iteratively attracting edges towards the centerlines of level sets of their distance fields. Apart from clustering, our entire pipeline is image-based with an efficient implementation in graphics hardware. Besides speed and implementation simplicity, our method allows explicit control of the emphasis on structure of the bundled layout, i.e. the creation of strongly branching (organic-like) or smooth bundles. We demonstrate our method on several large real-world graphs."}, {"color": "blue", "id": 666, "label": 666, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 666 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2011.237\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Georgia Albuquerque;Thomas Lowe;Marcus Magnor; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Synthetic Generation of High-Dimensional Datasets; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Generation of synthetic datasets is a common practice in many research areas. Such data is often generated to meet specific needs or certain conditions that may not be easily found in the original, real data. The nature of the data varies according to the application area and includes text, graphs, social or weather data, among many others. The common process to create such synthetic datasets is to implement small scripts or programs, restricted to small problems or to a specific application. In this paper we propose a framework designed to generate high dimensional datasets. Users can interactively create and navigate through multi dimensional datasets using a suitable graphical user-interface. The data creation is driven by statistical distributions based on a few user-defined parameters. First, a grounding dataset is created according to given inputs, and then structures and trends are included in selected dimensions and orthogonal projection planes. Furthermore, our framework supports the creation of complex non-orthogonal trends and classified datasets. It can successfully be used to create synthetic datasets simulating important trends as multidimensional clusters, correlations and outliers."}, {"color": "blue", "id": 667, "label": 667, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 667 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2011.239\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Weiwei Cui;Shixia Liu;Li Tan;Conglei Shi;Yangqiu Song;Zekai Gao;Huamin Qu;Xin Tong; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: TextFlow: Towards Better Understanding of Evolving Topics in Text; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Understanding how topics evolve in text data is an important and challenging task. Although much work has been devoted to topic analysis, the study of topic evolution has largely been limited to individual topics. In this paper, we introduce TextFlow, a seamless integration of visualization and topic mining techniques, for analyzing various evolution patterns that emerge from multiple topics. We first extend an existing analysis technique to extract three-level features: the topic evolution trend, the critical event, and the keyword correlation. Then a coherent visualization that consists of three new visual components is designed to convey complex relationships between them. Through interaction, the topic mining model and visualization can communicate with each other to help users refine the analysis result and gain insights into the data progressively. Finally, two case studies are conducted to demonstrate the effectiveness and usefulness of TextFlow in helping users understand the major topic evolution patterns in time-varying text data."}, {"color": "blue", "id": 668, "label": 668, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 668 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2011.247\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Liang Gou;Xiaolong Luke Zhang; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: TreeNetViz: Revealing Patterns of Networks over Tree Structures; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Network data often contain important attributes from various dimensions such as social affiliations and areas of expertise in a social network. If such attributes exhibit a tree structure, visualizing a compound graph consisting of tree and network structures becomes complicated. How to visually reveal patterns of a network over a tree has not been fully studied. In this paper, we propose a compound graph model, TreeNet, to support visualization and analysis of a network at multiple levels of aggregation over a tree. We also present a visualization design, TreeNetViz, to offer the multiscale and cross-scale exploration and interaction of a TreeNet graph. TreeNetViz uses a Radial, Space-Filling (RSF) visualization to represent the tree structure, a circle layout with novel optimization to show aggregated networks derived from TreeNet, and an edge bundling technique to reduce visual complexity. Our circular layout algorithm reduces both total edge-crossings and edge length and also considers hierarchical structure constraints and edge weight in a TreeNet graph. These experiments illustrate that the algorithm can reduce visual cluttering in TreeNet graphs. Our case study also shows that TreeNetViz has the potential to support the analysis of a compound graph by revealing multiscale and cross-scale network patterns."}, {"color": "blue", "id": 669, "label": 669, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 669 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2011.250\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Alexander Lex;Hans-Jorg Schulz;Marc Streit;Christian Partl;Dieter Schmalstieg; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: VisBricks: Multiform Visualization of Large, Inhomogeneous Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Large volumes of real-world data often exhibit inhomogeneities: vertically in the form of correlated or independent dimensions and horizontally in the form of clustered or scattered data items. In essence, these inhomogeneities form the patterns in the data that researchers are trying to find and understand. Sophisticated statistical methods are available to reveal these patterns, however, the visualization of their outcomes is mostly still performed in a one-view-fits-all manner, In contrast, our novel visualization approach, VisBricks, acknowledges the inhomogeneity of the data and the need for different visualizations that suit the individual characteristics of the different data subsets. The overall visualization of the entire data set is patched together from smaller visualizations, there is one VisBrick for each cluster in each group of interdependent dimensions. Whereas the total impression of all VisBricks together gives a comprehensive high-level overview of the different groups of data, each VisBrick independently shows the details of the group of data it represents, State-of-the-art brushing and visual linking between all VisBricks furthermore allows the comparison of the groupings and the distribution of data items among them. In this paper, we introduce the VisBricks visualization concept, discuss its design rationale and implementation, and demonstrate its usefulness by applying it to a use case from the field of biomedicine."}, {"color": "blue", "id": 670, "label": 670, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 670 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2011.251\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jagoda Walny;Sheelagh Carpendale;Nathalie Henry Riche;Gina Venolia;Philip Fawcett; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visual Thinking In Action: Visualizations As Used On Whiteboards; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: While it is still most common for information visualization researchers to develop new visualizations from a data-or taskdriven perspective, there is growing interest in understanding the types of visualizations people create by themselves for personal use. As part of this recent direction, we have studied a large collection of whiteboards in a research institution, where people make active use of combinations of words, diagrams and various types of visuals to help them further their thought processes. Our goal is to arrive at a better understanding of the nature of visuals that are created spontaneously during brainstorming, thinking, communicating, and general problem solving on whiteboards. We use the qualitative approaches of open coding, interviewing, and affinity diagramming to explore the use of recognizable and novel visuals, and the interplay between visualization and diagrammatic elements with words, numbers and labels. We discuss the potential implications of our findings on information visualization design."}, {"color": "blue", "id": 671, "label": 671, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 671 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2011.253\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: A. Johannes Pretorius;Mark-Anthony Bray;Anne E. Carpenter;Roy A. Ruddle; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visualization of Parameter Space for Image Analysis; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Image analysis algorithms are often highly parameterized and much human input is needed to optimize parameter settings. This incurs a time cost of up to several days. We analyze and characterize the conventional parameter optimization process for image analysis and formulate user requirements. With this as input, we propose a change in paradigm by optimizing parameters based on parameter sampling and interactive visual exploration. To save time and reduce memory load, users are only involved in the first step - initialization of sampling - and the last step - visual analysis of output. This helps users to more thoroughly explore the parameter space and produce higher quality results. We describe a custom sampling plug-in we developed for CellProfiler - a popular biomedical image analysis framework. Our main focus is the development of an interactive visualization technique that enables users to analyze the relationships between sampled input parameters and corresponding output. We implemented this in a prototype called Paramorama. It provides users with a visual overview of parameters and their sampled values. User-defined areas of interest are presented in a structured way that includes image-based output and a novel layout algorithm. To find optimal parameter settings, users can tag high- and low-quality results to refine their search. We include two case studies to illustrate the utility of this approach."}, {"color": "blue", "id": 672, "label": 672, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 672 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2011.255\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jessica Hullman;Nick Diakopoulos; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visualization Rhetoric: Framing Effects in Narrative Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Narrative visualizations combine conventions of communicative and exploratory information visualization to convey an intended story. We demonstrate visualization rhetoric as an analytical framework for understanding how design techniques that prioritize particular interpretations in visualizations that \"tell a story\" can significantly affect end-user interpretation. We draw a parallel between narrative visualization interpretation and evidence from framing studies in political messaging, decision-making, and literary studies. Devices for understanding the rhetorical nature of narrative information visualizations are presented, informed by the rigorous application of concepts from critical theory, semiotics, journalism, and political theory. We draw attention to how design tactics represent additions or omissions of information at various levels-the data, visual representation, textual annotations, and interactivity-and how visualizations denote and connote phenomena with reference to unstated viewing conventions and codes. Classes of rhetorical techniques identified via a systematic analysis of recent narrative visualizations are presented, and characterized according to their rhetorical contribution to the visualization. We describe how designers and researchers can benefit from the potentially positive aspects of visualization rhetoric in designing engaging, layered narrative visualizations and how our framework can shed light on how a visualization design prioritizes specific interpretations. We identify areas where future inquiry into visualization rhetoric can improve understanding of visualization interpretation."}, {"color": "orange", "id": 673, "label": 673, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 673 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2011.6102435\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Bum chul Kwon;Brian Fisher;Ji Soo Yi; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visual analytic roadblocks for novice investigators; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We have observed increasing interest in visual analytics tools and their applications in investigative analysis. Despite the growing interest and substantial studies regarding the topic, understanding the major roadblocks of using such tools from novice users\u0027 perspectives is still limited. Therefore, we attempted to identify such \u201cvisual analytic roadblocks\u201d for novice users in an investigative analysis scenario. To achieve this goal, we reviewed the existing models, theories, and frameworks that could explain the cognitive processes of human-visualization interaction in investigative analysis. Then, we conducted a qualitative experiment with six novice participants, using a slightly modified version of pair analytics, and analyzed the results through the open-coding method. As a result, we came up with four visual analytic roadblocks and explained these roadblocks using existing cognitive models and theories. We also provided design suggestions to overcome these roadblocks."}, {"color": "orange", "id": 674, "label": 674, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 674 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2011.6102437\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Georgia Albuquerque;Martin Eisemann;Marcus Magnor; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Perception-based visual quality measures; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In recent years diverse quality measures to support the exploration of high-dimensional data sets have been proposed. Such measures can be very useful to rank and select information-bearing projections of very high dimensional data, when the visual exploration of all possible projections becomes unfeasible. But even though a ranking of the low dimensional projections may support the user in the visual exploration task, different measures deliver different distances between the views that do not necessarily match the expectations of human perception. As an alternative solution, we propose a perception-based approach that, similar to the existing measures, can be used to select information bearing projections of the data. Specifically, we construct a perceptual embedding for the different projections based on the data from a psychophysics study and multi-dimensional scaling. This embedding together with a ranking function is then used to estimate the value of the projections for a specific user task in a perceptual sense."}, {"color": "orange", "id": 675, "label": 675, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 675 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2011.6102438\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Youn-ah Kang;John Stasko; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Characterizing the intelligence analysis process: Informing visual analytics design through a longitudinal field study; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: While intelligence analysis has been a primary target domain for visual analytics system development, relatively little user and task analysis has been conducted within this area. Our research community\u0027s understanding of the work processes and practices of intelligence analysts is not deep enough to adequately address their needs. Without a better understanding of the analysts and their problems, we cannot build visual analytics systems that integrate well with their work processes and truly provide benefit to them. In order to close this knowledge gap, we conducted a longitudinal, observational field study of intelligence analysts in training within the intelligence program at Mercyhurst College. We observed three teams of analysts, each working on an intelligence problem for a ten-week period. Based upon study findings, we describe and characterize processes and methods of intelligence analysis that we observed, make clarifications regarding the processes and practices, and suggest design implications for visual analytics systems for intelligence analysis."}, {"color": "orange", "id": 676, "label": 676, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 676 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2011.6102439\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Sebastian Bremm;Tatiana von Landesberger;Martin He\u00df;Tobias Schreck;Philipp Weil;Kay Hamacherk; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Interactive visual comparison of multiple trees; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Traditionally, the visual analysis of hierarchies, respectively, trees, is conducted by focusing on one given hierarchy. However, in many research areas multiple, differing hierarchies need to be analyzed simultaneously in a comparative way - in particular to highlight differences between them, which sometimes can be subtle. A prominent example is the analysis of so-called phylogenetic trees in biology, reflecting hierarchical evolutionary relationships among a set of organisms. Typically, the analysis considers multiple phylogenetic trees, either to account for statistical significance or for differences in derivation of such evolutionary hierarchies; for example, based on different input data, such as the 16S ribosomal RNA and protein sequences of highly conserved enzymes. The simultaneous analysis of a collection of such trees leads to more insight into the evolutionary process. We introduce a novel visual analytics approach for the comparison of multiple hierarchies focusing on both global and local structures. A new tree comparison score has been elaborated for the identification of interesting patterns. We developed a set of linked hierarchy views showing the results of automatic tree comparison on various levels of details. This combined approach offers detailed assessment of local and global tree similarities. The approach was developed in close cooperation with experts from the evolutionary biology domain. We apply it to a phylogenetic data set on bacterial ancestry, demonstrating its application benefit."}, {"color": "orange", "id": 677, "label": 677, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 677 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2011.6102440\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Zhicheng Liu;Shamkant B. Navathe;John T. Stasko; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Network-based visual analysis of tabular data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Tabular data are pervasive. Although tables often describe multivariate data without explicit network semantics, it may be advantageous to explore the data modeled as a graph or network for analysis. Even when a given table design conveys some static network semantics, analysts may want to look at multiple networks from different perspectives, at different levels of abstraction, and with different edge semantics. We present a system called Ploceus that offers a general approach for performing multi-dimensional and multi-level network-based visual analysis on multivariate tabular data. Powered by an underlying relational algebraic framework, Ploceus supports flexible construction and transformation of networks through a direct manipulation interface, and integrates dynamic network manipulation with visual exploration for a seamless analytic experience."}, {"color": "orange", "id": 678, "label": 678, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 678 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2011.6102441\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jeffrey Heer;Adam Perer; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Orion: A system for modeling, transformation and visualization of multidimensional heterogeneous networks; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The study of complex activities such as scientific production and software development often require modeling connections among heterogeneous entities including people, institutions and artifacts. Despite numerous advances in algorithms and visualization techniques for understanding such social networks, the process of constructing network models and performing exploratory analysis remains difficult and time-consuming. In this paper we present Orion, a system for interactive modeling, transformation and visualization of network data. Orion\u0027s interface enables the rapid manipulation of large graphs-including the specification of complex linking relationships-using simple drag-and-drop operations with desired node types. Orion maps these user interactions to statements in a declarative workflow language that incorporates both relational operators (e.g., selection, aggregation and joins) and network analytics (e.g., centrality measures). We demonstrate how these features enable analysts to flexibly construct and compare networks in domains such as online health communities, academic collaboration and distributed software development."}, {"color": "orange", "id": 680, "label": 680, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 680 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2011.6102443\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Adam Perer;Ido Guy;Erel Uziel;Inbal Ronen;Michal Jacovi; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visual social network analytics for relationship discovery in the enterprise; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: As people continue to author and share increasing amounts of information in social media, the opportunity to leverage such information for relationship discovery tasks increases. In this paper, we describe a set of systems that mine, aggregate, and infer a social graph from social media inside an enterprise, resulting in over 73 million relationships between 450,000 people. We then describe SaNDVis, a novel visual analytics tool that supports people-centric tasks like expertise location, team building, and team coordination in the enterprise. We also provide details of a 12-month-long, large-scale deployment to almost 1,800 users from which we extract dominant use cases from log and interview data. By integrating social position, evidence, and facets into SaNDVis, we demonstrate how users can use a visual analytics tool to reflect on existing relationships as well as build new relationships in an enterprise setting."}, {"color": "orange", "id": 682, "label": 682, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 682 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2011.6102446\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jean-Daniel Fekete;Pierre-Luc H\u00e9mery;Thomas Baudel;Jo Wood; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Obvious: A meta-toolkit to encapsulate information visualization toolkits - One toolkit to bind them all; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: This article describes \u201cObvious\u201d: a meta-toolkit that abstracts and encapsulates information visualization toolkits implemented in the Java language. It intends to unify their use and postpone the choice of which concrete toolkit(s) to use later-on in the development of visual analytics applications. We also report on the lessons we have learned when wrapping popular toolkits with Obvious, namely Prefuse, the InfoVis Toolkit, partly Improvise, JUNG and other data management libraries. We show several examples on the uses of Obvious, how the different toolkits can be combined, for instance sharing their data models. We also show how Weka and Rapid-Miner, two popular machine-learning toolkits, have been wrapped with Obvious and can be used directly with all the other wrapped toolkits. We expect Obvious to start a co-evolution process: Obvious is meant to evolve when more components of Information Visualization systems will become consensual. It is also designed to help information visualization systems adhere to the best practices to provide a higher level of interoperability and leverage the domain of visual analytics."}, {"color": "orange", "id": 683, "label": 683, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 683 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2011.6102447\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Yang Chen;Jamal Alsakran;Scott Barlowe;Jing Yang;Ye Zhao; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Supporting effective common ground construction in Asynchronous Collaborative Visual Analytics; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Asynchronous Collaborative Visual Analytics (ACVA) leverages group sensemaking by releasing the constraints on when, where, and who works collaboratively. A significant task to be addressed before ACVA can reach its full potential is effective common ground construction, namely the process in which users evaluate insights from individual work to develop a shared understanding of insights and collectively pool them. This is challenging due to the lack of instant communication and scale of collaboration in ACVA. We propose a novel visual analytics approach that automatically gathers, organizes, and summarizes insights to form common ground with reduced human effort. The rich set of visualization and interaction techniques provided in our approach allows users to effectively and flexibly control the common ground construction and review, explore, and compare insights in detail. A working prototype of the approach has been implemented. We have conducted a case study and a user study to demonstrate its effectiveness."}, {"color": "orange", "id": 684, "label": 684, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 684 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2011.6102448\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Thorsten May;Andreas Bannach;James Davey;Tobias Ruppert;J\u00f6rn Kohlhammer; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Guiding feature subset selection with an interactive visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We propose a method for the semi-automated refinement of the results of feature subset selection algorithms. Feature subset selection is a preliminary step in data analysis which identifies the most useful subset of features (columns) in a data table. So-called filter techniques use statistical ranking measures for the correlation of features. Usually a measure is applied to all entities (rows) of a data table. However, the differing contributions of subsets of data entities are masked by statistical aggregation. Feature and entity subset selection are, thus, highly interdependent. Due to the difficulty in visualizing a high-dimensional data table, most feature subset selection algorithms are applied as a black box at the outset of an analysis. Our visualization technique, SmartStripes, allows users to step into the feature subset selection process. It enables the investigation of dependencies and interdependencies between different feature and entity subsets. A user may even choose to control the iterations manually, taking into account the ranking measures, the contributions of different entity subsets, as well as the semantics of the features."}, {"color": "orange", "id": 685, "label": 685, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 685 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2011.6102449\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Alex Endert;Chao Han;Dipayan Maiti;Leanna House;Scotland Leman;Chris North; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Observation-level interaction with statistical models for visual analytics; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In visual analytics, sensemaking is facilitated through interactive visual exploration of data. Throughout this dynamic process, users combine their domain knowledge with the dataset to create insight. Therefore, visual analytic tools exist that aid sensemaking by providing various interaction techniques that focus on allowing users to change the visual representation through adjusting parameters of the underlying statistical model. However, we postulate that the process of sensemaking is not focused on a series of parameter adjustments, but instead, a series of perceived connections and patterns within the data. Thus, how can models for visual analytic tools be designed, so that users can express their reasoning on observations (the data), instead of directly on the model or tunable parameters? Observation level (and thus \u201cobservation\u201d) in this paper refers to the data points within a visualization. In this paper, we explore two possible observation-level interactions, namely exploratory and expressive, within the context of three statistical methods, Probabilistic Principal Component Analysis (PPCA), Multidimensional Scaling (MDS), and Generative Topographic Mapping (GTM). We discuss the importance of these two types of observation level interactions, in terms of how they occur within the sensemaking process. Further, we present use cases for GTM, MDS, and PPCA, illustrating how observation level interaction can be incorporated into visual analytic tools."}, {"color": "orange", "id": 686, "label": 686, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 686 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2011.6102450\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Zhenyu Guo;Matthew O. Ward;Elke A. Rundensteiner;Carolina Ruiz; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Pointwise local pattern exploration for sensitivity analysis; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Sensitivity analysis is a powerful method for discovering the significant factors that contribute to targets and understanding the interaction between variables in multivariate datasets. A number of sensitivity analysis methods fall into the class of local analysis, in which the sensitivity is defined as the partial derivatives of a target variable with respect to a group of independent variables. Incorporating sensitivity analysis in visual analytic tools is essential for multivariate phenomena analysis. However, most current multivariate visualization techniques do not allow users to explore local patterns individually for understanding the sensitivity from a pointwise view. In this paper, we present a novel pointwise local pattern exploration system for visual sensitivity analysis. Using this system, analysts are able to explore local patterns and the sensitivity at individual data points, which reveals the relationships between a focal point and its neighbors. During exploration, users are able to interactively change the derivative coefficients to perform sensitivity analysis based on different requirements as well as their domain knowledge. Each local pattern is assigned an outlier factor, so that users can quickly identify anomalous local patterns that do not conform with the global pattern. Users can also compare the local pattern with the global pattern both visually and statistically. Finally, the local pattern is integrated into the original attribute space using color mapping and jittering, which reveals the distribution of the partial derivatives. Case studies with real datasets are used to investigate the effectiveness of the visualizations and interactions."}, {"color": "orange", "id": 687, "label": 687, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 687 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2011.6102451\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: M.A. Migut;J.C. van Gemert;M. Worring; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Interactive decision making using dissimilarity to visually represented prototypes; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: To make informed decisions, an expert has to reason with multi-dimensional, heterogeneous data and analysis results of these. Items in such datasets are typically represented by features. However, as argued in cognitive science, features do not yield an optimal space for human reasoning. In fact, humans tend to organize complex information in terms of prototypes or known cases rather than in absolute terms. When confronted with unknown data items, humans assess them in terms of similarity to these prototypical elements. Interestingly, an analogues similarity-to-prototype approach, where prototypes are taken from the data, has been successfully applied in machine learning. Combining such a machine learning approach with human prototypical reasoning in a Visual Analytics context requires to integrate similarity-based classification with interactive visualizations. To that end, the data prototypes should be visually represented to trigger direct associations to cases familiar to the domain experts. In this paper, we propose a set of highly interactive visualizations to explore data and classification results in terms of dissimilarities to visually represented prototypes. We argue that this approach not only supports human reasoning processes, but is also suitable to enhance understanding of heterogeneous data. The proposed framework is applied to a risk assessment case study in Forensic Psychiatry."}, {"color": "orange", "id": 688, "label": 688, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 688 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2011.6102453\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Stef van den Elzen;Jarke J. van Wijk; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: BaobabView: Interactive construction and analysis of decision trees; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present a system for the interactive construction and analysis of decision trees that enables domain experts to bring in domain specific knowledge. We identify different user tasks and corresponding requirements, and develop a system incorporating a tight integration of visualization, interaction and algorithmic support. Domain experts are supported in growing, pruning, optimizing and analysing decision trees. Furthermore, we present a scalable decision tree visualization optimized for exploration. We show the effectiveness of our approach by applying the methods to two use cases. The first case illustrates the advantages of interactive construction, the second case demonstrates the effectiveness of analysis of decision trees and exploration of the structure of the data."}, {"color": "orange", "id": 689, "label": 689, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 689 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2011.6102454\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Gennady Andrienko;Natalia Andrienko;Christophe Hurter;Salvatore Rinzivillo;Stefan Wrobel; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: From movement tracks through events to places: Extracting and characterizing significant places from mobility data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We propose a visual analytics procedure for analyzing movement data, i.e., recorded tracks of moving objects. It is oriented to a class of problems where it is required to determine significant places on the basis of certain types of events occurring repeatedly in movement data. The procedure consists of four major steps: (1) event extraction from trajectories; (2) event clustering and extraction of relevant places; (3) spatio-temporal aggregation of events or trajectories; (4) analysis of the aggregated data. All steps are scalable with respect to the amount of the data under analysis. We demonstrate the use of the procedure by example of two real-world problems requiring analysis at different spatial scales."}, {"color": "orange", "id": 690, "label": 690, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 690 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2011.6102455\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: He Liu;Yuan Gao;Lu Lu;Siyuan Liu;Huamin Qu;Lionel M. Ni; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visual analysis of route diversity; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Route suggestion is an important feature of GPS navigation systems. Recently, Microsoft T-drive has been enabled to suggest routes chosen by experienced taxi drivers for given source/destination pairs in given time periods, which often take less time than the routes calculated according to distance. However, in real environments, taxi drivers may use different routes to reach the same destination, which we call route diversity. In this paper we first propose a trajectory visualization method that examines the regions where the diversity exists and then develop several novel visualization techniques to display the high dimensional attributes and statistics associated with different routes to help users analyze diversity patterns. Our techniques have been applied to the real trajectory data of thousands of taxis and some interesting findings about route diversity have been obtained. We further demonstrate that our system can be used not only to suggest better routes for drivers but also to analyze traffic bottlenecks for transportation management."}, {"color": "orange", "id": 691, "label": 691, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 691 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2011.6102456\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Alan M. MacEachren;Anuj Jaiswal;Anthony C. Robinson;Scott Pezanowski;Alexander Savelyev;Prasenjit Mitra;Xiao Zhang;Justine Blanford; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: SensePlace2: GeoTwitter analytics support for situational awareness; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Geographically-grounded situational awareness (SA) is critical to crisis management and is essential in many other decision making domains that range from infectious disease monitoring, through regional planning, to political campaigning. Social media are becoming an important information input to support situational assessment (to produce awareness) in all domains. Here, we present a geovisual analytics approach to supporting SA for crisis events using one source of social media, Twitter. Specifically, we focus on leveraging explicit and implicit geographic information for tweets, on developing place-time-theme indexing schemes that support overview+detail methods and that scale analytical capabilities to relatively large tweet volumes, and on providing visual interface methods to enable understanding of place, time, and theme components of evolving situations. Our approach is user-centered, using scenario-based design methods that include formal scenarios to guide design and validate implementation as well as a systematic claims analysis to justify design choices and provide a framework for future testing. The work is informed by a structured survey of practitioners and the end product of Phase-I development is demonstrated / validated through implementation in SensePlace2, a map-based, web application initially focused on tweets but extensible to other media."}, {"color": "orange", "id": 696, "label": 696, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 696 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2011.6102461\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Wenwen Dou;Xiaoyu Wang;Remco Chang;William Ribarsky; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: ParallelTopics: A probabilistic approach to exploring document collections; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Scalable and effective analysis of large text corpora remains a challenging problem as our ability to collect textual data continues to increase at an exponential rate. To help users make sense of large text corpora, we present a novel visual analytics system, Parallel-Topics, which integrates a state-of-the-art probabilistic topic model Latent Dirichlet Allocation (LDA) with interactive visualization. To describe a corpus of documents, ParallelTopics first extracts a set of semantically meaningful topics using LDA. Unlike most traditional clustering techniques in which a document is assigned to a specific cluster, the LDA model accounts for different topical aspects of each individual document. This permits effective full text analysis of larger documents that may contain multiple topics. To highlight this property of the model, ParallelTopics utilizes the parallel coordinate metaphor to present the probabilistic distribution of a document across topics. Such representation allows the users to discover single-topic vs. multi-topic documents and the relative importance of each topic to a document of interest. In addition, since most text corpora are inherently temporal, ParallelTopics also depicts the topic evolution over time. We have applied ParallelTopics to exploring and analyzing several text corpora, including the scientific proposals awarded by the National Science Foundation and the publications in the VAST community over the years. To demonstrate the efficacy of ParallelTopics, we conducted several expert evaluations, the results of which are reported in this paper."}, {"color": "orange", "id": 698, "label": 698, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 698 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2011.6102463\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Xiaoyu Wang;Wenwen Dou;Thomas Butkiewicz;Eric A. Bier;William Ribarsky; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: A two-stage framework for designing visual analytics system in organizational environments; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: A perennially interesting research topic in the field of visual analytics is how to effectively develop systems that support organizational users\u0027 decision-making and reasoning processes. The problem is, however, most domain analytical practices generally vary from organization to organization. This leads to diverse designs of visual analytics systems in incorporating domain analytical processes, making it difficult to generalize the success from one domain to another. Exacerbating this problem is the dearth of general models of analytical workflows available to enable such timely and effective designs. To alleviate these problems, we present a two-stage framework for informing the design of a visual analytics system. This design framework builds upon and extends current practices pertaining to analytical workflow and focuses, in particular, on incorporating both general domain analysis processes as well as individual\u0027s analytical activities. We illustrate both stages and their design components through examples, and hope this framework will be useful for designing future visual analytics systems. We validate the soundness of our framework with two visual analytics systems, namely Entity Workspace [8] and PatViz [37]."}, {"color": "blue", "id": 732, "label": 732, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 732 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2012.189\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Kai Xu;Chris Rooney;Peter Passmore;Dong-Han Ham;Phong H. Nguyen; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: A User Study on Curved Edges in Graph Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Recently there has been increasing research interest in displaying graphs with curved edges to produce more readable visualizations. While there are several automatic techniques, little has been done to evaluate their effectiveness empirically. In this paper we present two experiments studying the impact of edge curvature on graph readability. The goal is to understand the advantages and disadvantages of using curved edges for common graph tasks compared to straight line segments, which are the conventional choice for showing edges in node-link diagrams. We included several edge variations: straight edges, edges with different curvature levels, and mixed straight and curved edges. During the experiments, participants were asked to complete network tasks including determination of connectivity, shortest path, node degree, and common neighbors. We also asked the participants to provide subjective ratings of the aesthetics of different edge types. The results show significant performance differences between the straight and curved edges and clear distinctions between variations of curved edges."}, {"color": "orange", "id": 738, "label": 738, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 738 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2012.195\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: R. Jordon Crouser;Remco Chang; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: An Affordance-Based Framework for Human Computation and Human-Computer Collaboration; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Visual Analytics is \u201cthe science of analytical reasoning facilitated by visual interactive interfaces\u201d [70]. The goal of this field is to develop tools and methodologies for approaching problems whose size and complexity render them intractable without the close coupling of both human and machine analysis. Researchers have explored this coupling in many venues: VAST, Vis, InfoVis, CHI, KDD, IUI, and more. While there have been myriad promising examples of human-computer collaboration, there exists no common language for comparing systems or describing the benefits afforded by designing for such collaboration. We argue that this area would benefit significantly from consensus about the design attributes that define and distinguish existing techniques. In this work, we have reviewed 1,271 papers from many of the top-ranking conferences in visual analytics, human-computer interaction, and visualization. From these, we have identified 49 papers that are representative of the study of human-computer collaborative problem-solving, and provide a thorough overview of the current state-of-the-art. Our analysis has uncovered key patterns of design hinging on humanand machine-intelligence affordances, and also indicates unexplored avenues in the study of this area. The results of this analysis provide a common framework for understanding these seemingly disparate branches of inquiry, which we hope will motivate future work in the field."}, {"color": "blue", "id": 739, "label": 739, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 739 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2012.196\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Justin Talbot;John Gerth;Pat Hanrahan; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: An Empirical Model of Slope Ratio Comparisons; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Comparing slopes is a fundamental graph reading task and the aspect ratio chosen for a plot influences how easy these comparisons are to make. According to Banking to 45\u00b0, a classic design guideline first proposed and studied by Cleveland et al., aspect ratios that center slopes around 45\u00b0 minimize errors in visual judgments of slope ratios. This paper revisits this earlier work. Through exploratory pilot studies that expand Cleveland et al.\u0027s experimental design, we develop an empirical model of slope ratio estimation that fits more extreme slope ratio judgments and two common slope ratio estimation strategies. We then run two experiments to validate our model. In the first, we show that our model fits more generally than the one proposed by Cleveland et al. and we find that, in general, slope ratio errors are not minimized around 45\u00b0. In the second experiment, we explore a novel hypothesis raised by our model: that visible baselines can substantially mitigate errors made in slope judgments. We conclude with an application of our model to aspect ratio selection."}, {"color": "blue", "id": 740, "label": 740, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 740 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2012.197\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Rita Borgo;Alfie Abdul-Rahman;Farhan Mohamed;Philip W. Grant;Irene Reppa;Luciano Floridi;Min Chen; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: An Empirical Study on Using Visual Embellishments in Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In written and spoken communications, figures of speech (e.g., metaphors and synecdoche) are often used as an aid to help convey abstract or less tangible concepts. However, the benefits of using rhetorical illustrations or embellishments in visualization have so far been inconclusive. In this work, we report an empirical study to evaluate hypotheses that visual embellishments may aid memorization, visual search and concept comprehension. One major departure from related experiments in the literature is that we make use of a dual-task methodology in our experiment. This design offers an abstraction of typical situations where viewers do not have their full attention focused on visualization (e.g., in meetings and lectures). The secondary task introduces \u201cdivided attention\u201d, and makes the effects of visual embellishments more observable. In addition, it also serves as additional masking in memory-based trials. The results of this study show that visual embellishments can help participants better remember the information depicted in visualization. On the other hand, visual embellishments can have a negative impact on the speed of visual search. The results show a complex pattern as to the benefits of visual embellishments in helping participants grasp key concepts from visualization."}, {"color": "blue", "id": 746, "label": 746, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 746 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2012.204\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Bongshin Lee;Petra Isenberg;Nathalie Henry Riche;Sheelagh Carpendale; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Beyond Mouse and Keyboard: Expanding Design Considerations for Information Visualization Interactions; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The importance of interaction to Information Visualization (InfoVis) and, in particular, of the interplay between interactivity and cognition is widely recognized [12, 15, 32, 55, 70]. This interplay, combined with the demands from increasingly large and complex datasets, is driving the increased significance of interaction in InfoVis. In parallel, there have been rapid advances in many facets of interaction technologies. However, InfoVis interactions have yet to take full advantage of these new possibilities in interaction technologies, as they largely still employ the traditional desktop, mouse, and keyboard setup of WIMP (Windows, Icons, Menus, and a Pointer) interfaces. In this paper, we reflect more broadly about the role of more \u201cnatural\u201d interactions for InfoVis and provide opportunities for future research. We discuss and relate general HCI interaction models to existing InfoVis interaction classifications by looking at interactions from a novel angle, taking into account the entire spectrum of interactions. Our discussion of InfoVis-specific interaction design considerations helps us identify a series of underexplored attributes of interaction that can lead to new, more \u201cnatural,\u201d interaction techniques for InfoVis."}, {"color": "blue", "id": 747, "label": 747, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 747 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2012.205\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Thomas Baudel;Bertjan Broeksema; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Capturing the Design Space of Sequential Space-filling Layouts; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We characterize the design space of the algorithms that sequentially tile a rectangular area with smaller, fixed-surface, rectangles. This space consist of five independent dimensions: Order, Size, Score, Recurse and Phrase. Each of these dimensions describe a particular aspect of such layout tasks. This class of layouts is interesting, because, beyond encompassing simple grids, tables and trees, it also includes all kinds of treemaps involving the placement of rectangles. For instance, Slice and dice, Squarified, Strip and Pivot layouts are various points in this five dimensional space. Many classic statistics visualizations, such as 100% stacked bar charts, mosaic plots and dimensional stacking, are also instances of this class. A few new and potentially interesting points in this space are introduced, such as spiral treemaps and variations on the strip layout. The core algorithm is implemented as a JavaScript prototype that can be used as a layout component in a variety of InfoViz toolkits."}, {"color": "blue", "id": 750, "label": 750, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 750 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2012.208\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Kasper Dinkla;Michel A. Westenberg;Jarke J. van Wijk; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Compressed Adjacency Matrices: Untangling Gene Regulatory Networks; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present a novel technique-Compressed Adjacency Matrices-for visualizing gene regulatory networks. These directed networks have strong structural characteristics: out-degrees with a scale-free distribution, in-degrees bound by a low maximum, and few and small cycles. Standard visualization techniques, such as node-link diagrams and adjacency matrices, are impeded by these network characteristics. The scale-free distribution of out-degrees causes a high number of intersecting edges in node-link diagrams. Adjacency matrices become space-inefficient due to the low in-degrees and the resulting sparse network. Compressed adjacency matrices, however, exploit these structural characteristics. By cutting open and rearranging an adjacency matrix, we achieve a compact and neatly-arranged visualization. Compressed adjacency matrices allow for easy detection of subnetworks with a specific structure, so-called motifs, which provide important knowledge about gene regulatory networks to domain experts. We summarize motifs commonly referred to in the literature, and relate them to network analysis tasks common to the visualization domain. We show that a user can easily find the important motifs in compressed adjacency matrices, and that this is hard in standard adjacency matrix and node-link diagrams. We also demonstrate that interaction techniques for standard adjacency matrices can be used for our compressed variant. These techniques include rearrangement clustering, highlighting, and filtering."}, {"color": "blue", "id": 754, "label": 754, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 754 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2012.212\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Yuzuru Tanahashi;Kwan-Liu Ma; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Design Considerations for Optimizing Storyline Visualizations; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Storyline visualization is a technique used to depict the temporal dynamics of social interactions. This visualization technique was first introduced as a hand-drawn illustration in XKCD\u0027s \u201cMovie Narrative Charts\u201d [21]. If properly constructed, the visualization can convey both global trends and local interactions in the data. However, previous methods for automating storyline visualizations are overly simple, failing to achieve some of the essential principles practiced by professional illustrators. This paper presents a set of design considerations for generating aesthetically pleasing and legible storyline visualizations. Our layout algorithm is based on evolutionary computation, allowing us to effectively incorporate multiple objective functions. We show that the resulting visualizations have significantly improved aesthetics and legibility compared to existing techniques."}, {"color": "blue", "id": 755, "label": 755, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 755 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2012.213\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Michael Sedlmair;Miriah Meyer;Tamara Munzner; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Design Study Methodology: Reflections from the Trenches and the Stacks; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Design studies are an increasingly popular form of problem-driven visualization research, yet there is little guidance available about how to do them effectively. In this paper we reflect on our combined experience of conducting twenty-one design studies, as well as reading and reviewing many more, and on an extensive literature review of other field work methods and methodologies. Based on this foundation we provide definitions, propose a methodological framework, and provide practical guidance for conducting design studies. We define a design study as a project in which visualization researchers analyze a specific real-world problem faced by domain experts, design a visualization system that supports solving this problem, validate the design, and reflect about lessons learned in order to refine visualization design guidelines. We characterize two axes - a task clarity axis from fuzzy to crisp and an information location axis from the domain expert\u0027s head to the computer - and use these axes to reason about design study contributions, their suitability, and uniqueness from other approaches. The proposed methodological framework consists of 9 stages: learn, winnow, cast, discover, design, implement, deploy, reflect, and write. For each stage we provide practical guidance and outline potential pitfalls. We also conducted an extensive literature survey of related methodological approaches that involve a significant amount of qualitative field work, and compare design study methodology to that of ethnography, grounded theory, and action research."}, {"color": "orange", "id": 761, "label": 761, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 761 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2012.219\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Sean Kandel;Andreas Paepcke;Joseph M. Hellerstein;Jeffrey Heer; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Enterprise Data Analysis and Visualization: An Interview Study; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Organizations rely on data analysts to model customer engagement, streamline operations, improve production, inform business decisions, and combat fraud. Though numerous analysis and visualization tools have been built to improve the scale and efficiency at which analysts can work, there has been little research on how analysis takes place within the social and organizational context of companies. To better understand the enterprise analysts\u0027 ecosystem, we conducted semi-structured interviews with 35 data analysts from 25 organizations across a variety of sectors, including healthcare, retail, marketing and finance. Based on our interview data, we characterize the process of industrial data analysis and document how organizational features of an enterprise impact it. We describe recurring pain points, outstanding challenges, and barriers to adoption for visual analytic tools. Finally, we discuss design implications and opportunities for visual analysis research."}, {"color": "blue", "id": 762, "label": 762, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 762 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2012.220\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Nadia Boukhelifa;Anastasia Bezerianos;Tobias Isenberg;Jean-Daniel Fekete; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Evaluating Sketchiness as a Visual Variable for the Depiction of Qualitative Uncertainty; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We report on results of a series of user studies on the perception of four visual variables that are commonly used in the literature to depict uncertainty. To the best of our knowledge, we provide the first formal evaluation of the use of these variables to facilitate an easier reading of uncertainty in visualizations that rely on line graphical primitives. In addition to blur, dashing and grayscale, we investigate the use of `sketchiness\u0027 as a visual variable because it conveys visual impreciseness that may be associated with data quality. Inspired by work in non-photorealistic rendering and by the features of hand-drawn lines, we generate line trajectories that resemble hand-drawn strokes of various levels of proficiency-ranging from child to adult strokes-where the amount of perturbations in the line corresponds to the level of uncertainty in the data. Our results show that sketchiness is a viable alternative for the visualization of uncertainty in lines and is as intuitive as blur; although people subjectively prefer dashing style over blur, grayscale and sketchiness. We discuss advantages and limitations of each technique and conclude with design considerations on how to deploy these visual variables to effectively depict various levels of uncertainty for line marks."}, {"color": "blue", "id": 763, "label": 763, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 763 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2012.221\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Andrew Vande Moere;Martin Tomitsch;Christoph Wimmer;Boesch Christoph;Thomas Grechenig; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Evaluating the Effect of Style in Information Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: This paper reports on a between-subject, comparative online study of three information visualization demonstrators that each displayed the same dataset by way of an identical scatterplot technique, yet were different in style in terms of visual and interactive embellishment. We validated stylistic adherence and integrity through a separate experiment in which a small cohort of participants assigned our three demonstrators to predefined groups of stylistic examples, after which they described the styles with their own words. From the online study, we discovered significant differences in how participants execute specific interaction operations, and the types of insights that followed from them. However, in spite of significant differences in apparent usability, enjoyability and usefulness between the style demonstrators, no variation was found on the self-reported depth, expert-rated depth, confidence or difficulty of the resulting insights. Three different methods of insight analysis have been applied, revealing how style impacts the creation of insights, ranging from higher-level pattern seeking to a more reflective and interpretative engagement with content, which is what underlies the patterns. As this study only forms the first step in determining how the impact of style in information visualization could be best evaluated, we propose several guidelines and tips on how to gather, compare and categorize insights through an online evaluation study, particularly in terms of analyzing the concise, yet wide variety of insights and observations in a trustworthy and reproducable manner."}, {"color": "orange", "id": 766, "label": 766, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 766 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2012.224\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Youn-ah Kang;John Stasko; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Examining the Use of a Visual Analytics System for Sensemaking Tasks: Case Studies with Domain Experts; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: While the formal evaluation of systems in visual analytics is still relatively uncommon, particularly rare are case studies of prolonged system use by domain analysts working with their own data. Conducting case studies can be challenging, but it can be a particularly effective way to examine whether visual analytics systems are truly helping expert users to accomplish their goals. We studied the use of a visual analytics system for sensemaking tasks on documents by six analysts from a variety of domains. We describe their application of the system along with the benefits, issues, and problems that we uncovered. Findings from the studies identify features that visual analytics systems should emphasize as well as missing capabilities that should be addressed. These findings inform design implications for future systems."}, {"color": "blue", "id": 767, "label": 767, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 767 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2012.225\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Krist Wongsuphasawat;David Gotz; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Exploring Flow, Factors, and Outcomes of Temporal Event Sequences with the Outflow Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Event sequence data is common in many domains, ranging from electronic medical records (EMRs) to sports events. Moreover, such sequences often result in measurable outcomes (e.g., life or death, win or loss). Collections of event sequences can be aggregated together to form event progression pathways. These pathways can then be connected with outcomes to model how alternative chains of events may lead to different results. This paper describes the Outflow visualization technique, designed to (1) aggregate multiple event sequences, (2) display the aggregate pathways through different event states with timing and cardinality, (3) summarize the pathways\u0027 corresponding outcomes, and (4) allow users to explore external factors that correlate with specific pathway state transitions. Results from a user study with twelve participants show that users were able to learn how to use Outflow easily with limited training and perform a range of tasks both accurately and rapidly."}, {"color": "blue", "id": 771, "label": 771, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 771 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2012.229\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Nicholas Kong;Maneesh Agrawala; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Graphical Overlays: Using Layered Elements to Aid Chart Reading; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Reading a visualization can involve a number of tasks such as extracting, comparing or aggregating numerical values. Yet, most of the charts that are published in newspapers, reports, books, and on the Web only support a subset of these tasks. In this paper we introduce graphical overlays-visual elements that are layered onto charts to facilitate a larger set of chart reading tasks. These overlays directly support the lower-level perceptual and cognitive processes that viewers must perform to read a chart. We identify five main types of overlays that support these processes; the overlays can provide (1) reference structures such as gridlines, (2) highlights such as outlines around important marks, (3) redundant encodings such as numerical data labels, (4) summary statistics such as the mean or max and (5) annotations such as descriptive text for context. We then present an automated system that applies user-chosen graphical overlays to existing chart bitmaps. Our approach is based on the insight that generating most of these graphical overlays only requires knowing the properties of the visual marks and axes that encode the data, but does not require access to the underlying data values. Thus, our system analyzes the chart bitmap to extract only the properties necessary to generate the desired overlay. We also discuss techniques for generating interactive overlays that provide additional controls to viewers. We demonstrate several examples of each overlay type for bar, pie and line charts."}, {"color": "blue", "id": 778, "label": 778, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 778 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2012.237\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Christian Tominski;Camilla Forsell;Jimmy Johansson; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Interaction Support for Visual Comparison Inspired by Natural Behavior; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Visual comparison is an intrinsic part of interactive data exploration and analysis. The literature provides a large body of existing solutions that help users accomplish comparison tasks. These solutions are mostly of visual nature and custom-made for specific data. We ask the question if a more general support is possible by focusing on the interaction aspect of comparison tasks. As an answer to this question, we propose a novel interaction concept that is inspired by real-world behavior of people comparing information printed on paper. In line with real-world interaction, our approach supports users (1) in interactively specifying pieces of graphical information to be compared, (2) in flexibly arranging these pieces on the screen, and (3) in performing the actual comparison of side-by-side and overlapping arrangements of the graphical information. Complementary visual cues and add-ons further assist users in carrying out comparison tasks. Our concept and the integrated interaction techniques are generally applicable and can be coupled with different visualization techniques. We implemented an interactive prototype and conducted a qualitative user study to assess the concept\u0027s usefulness in the context of three different visualization techniques. The obtained feedback indicates that our interaction techniques mimic the natural behavior quite well, can be learned quickly, and are easy to apply to visual comparison tasks."}, {"color": "blue", "id": 779, "label": 779, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 779 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2012.238\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Michael Zinsmaier;Ulrik Brandes;Oliver Deussen;Hendrik Strobelt; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Interactive Level-of-Detail Rendering of Large Graphs; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We propose a technique that allows straight-line graph drawings to be rendered interactively with adjustable level of detail. The approach consists of a novel combination of edge cumulation with density-based node aggregation and is designed to exploit common graphics hardware for speed. It operates directly on graph data and does not require precomputed hierarchies or meshes. As proof of concept, we present an implementation that scales to graphs with millions of nodes and edges, and discuss several example applications."}, {"color": "red", "id": 781, "label": 781, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 781 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2012.240\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Markus Hadwiger;Johanna Beyer;Won-Ki Jeong;Hanspeter Pfister; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Interactive Volume Exploration of Petascale Microscopy Data Streams Using a Visualization-Driven Virtual Memory Approach; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: This paper presents the first volume visualization system that scales to petascale volumes imaged as a continuous stream of high-resolution electron microscopy images. Our architecture scales to dense, anisotropic petascale volumes because it: (1) decouples construction of the 3D multi-resolution representation required for visualization from data acquisition, and (2) decouples sample access time during ray-casting from the size of the multi-resolution hierarchy. Our system is designed around a scalable multi-resolution virtual memory architecture that handles missing data naturally, does not pre-compute any 3D multi-resolution representation such as an octree, and can accept a constant stream of 2D image tiles from the microscopes. A novelty of our system design is that it is visualization-driven: we restrict most computations to the visible volume data. Leveraging the virtual memory architecture, missing data are detected during volume ray-casting as cache misses, which are propagated backwards for on-demand out-of-core processing. 3D blocks of volume data are only constructed from 2D microscope image tiles when they have actually been accessed during ray-casting. We extensively evaluate our system design choices with respect to scalability and performance, compare to previous best-of-breed systems, and illustrate the effectiveness of our system for real microscopy data from neuroscience."}, {"color": "red", "id": 787, "label": 787, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 787 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2012.249\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Steven Schlegel;Nico Korn;Gerik Scheuermann; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: On the Interpolation of Data with Normally Distributed Uncertainty for Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In many fields of science or engineering, we are confronted with uncertain data. For that reason, the visualization of uncertainty received a lot of attention, especially in recent years. In the majority of cases, Gaussian distributions are used to describe uncertain behavior, because they are able to model many phenomena encountered in science. Therefore, in most applications uncertain data is (or is assumed to be) Gaussian distributed. If such uncertain data is given on fixed positions, the question of interpolation arises for many visualization approaches. In this paper, we analyze the effects of the usual linear interpolation schemes for visualization of Gaussian distributed data. In addition, we demonstrate that methods known in geostatistics and machine learning have favorable properties for visualization purposes in this case."}, {"color": "blue", "id": 790, "label": 790, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 790 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2012.252\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Marian D\u00f6rk;Nathalie Henry Riche;Gonzalo Ramos;Susan Dumais; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: PivotPaths: Strolling through Faceted Information Spaces; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present PivotPaths, an interactive visualization for exploring faceted information resources. During both work and leisure, we increasingly interact with information spaces that contain multiple facets and relations, such as authors, keywords, and citations of academic publications, or actors and genres of movies. To navigate these interlinked resources today, one typically selects items from facet lists resulting in abrupt changes from one subset of data to another. While filtering is useful to retrieve results matching specific criteria, it can be difficult to see how facets and items relate and to comprehend the effect of filter operations. In contrast, the PivotPaths interface exposes faceted relations as visual paths in arrangements that invite the viewer to `take a stroll\u0027 through an information space. PivotPaths supports pivot operations as lightweight interaction techniques that trigger gradual transitions between views. We designed the interface to allow for casual traversal of large collections in an aesthetically pleasing manner that encourages exploration and serendipitous discoveries. This paper shares the findings from our iterative design-and-evaluation process that included semi-structured interviews and a two-week deployment of PivotPaths applied to a large database of academic publications."}, {"color": "blue", "id": 791, "label": 791, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 791 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2012.253\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Conglei Shi;Weiwei Cui;Shixia Liu;Panpan Xu;Wei Chen;Huamin Qu; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: RankExplorer: Visualization of Ranking Changes in Large Time Series Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: For many applications involving time series data, people are often interested in the changes of item values over time as well as their ranking changes. For example, people search many words via search engines like Google and Bing every day. Analysts are interested in both the absolute searching number for each word as well as their relative rankings. Both sets of statistics may change over time. For very large time series data with thousands of items, how to visually present ranking changes is an interesting challenge. In this paper, we propose RankExplorer, a novel visualization method based on ThemeRiver to reveal the ranking changes. Our method consists of four major components: 1) a segmentation method which partitions a large set of time series curves into a manageable number of ranking categories; 2) an extended ThemeRiver view with embedded color bars and changing glyphs to show the evolution of aggregation values related to each ranking category over time as well as the content changes in each ranking category; 3) a trend curve to show the degree of ranking changes over time; 4) rich user interactions to support interactive exploration of ranking changes. We have applied our method to some real time series data and the case studies demonstrate that our method can reveal the underlying patterns related to ranking changes which might otherwise be obscured in traditional visualizations."}, {"color": "blue", "id": 793, "label": 793, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 793 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2012.255\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Michael Sedlmair;Annika Frank;Tamara Munzner;Andreas Butz; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: RelEx: Visualization for Actively Changing Overlay Network Specifications; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present a network visualization design study focused on supporting automotive engineers who need to specify and optimize traffic patterns for in-car communication networks. The task and data abstractions that we derived support actively making changes to an overlay network, where logical communication specifications must be mapped to an underlying physical network. These abstractions are very different from the dominant use case in visual network analysis, namely identifying clusters and central nodes, that stems from the domain of social network analysis. Our visualization tool RelEx was created and iteratively refined through a full user-centered design process that included a full problem characterization phase before tool design began, paper prototyping, iterative refinement in close collaboration with expert users for formative evaluation, deployment in the field with real analysts using their own data, usability testing with non-expert users, and summative evaluation at the end of the deployment. In the summative post-deployment study, which entailed domain experts using the tool over several weeks in their daily practice, we documented many examples where the use of RelEx simplified or sped up their work compared to previous practices."}, {"color": "blue", "id": 794, "label": 794, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 794 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2012.256\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Cagatay Turkay;Arvid Lundervold;Astri Johansen Lundervold;Helwig Hauser; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Representative Factor Generation for the Interactive Visual Analysis of High-Dimensional Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Datasets with a large number of dimensions per data item (hundreds or more) are challenging both for computational and visual analysis. Moreover, these dimensions have different characteristics and relations that result in sub-groups and/or hierarchies over the set of dimensions. Such structures lead to heterogeneity within the dimensions. Although the consideration of these structures is crucial for the analysis, most of the available analysis methods discard the heterogeneous relations among the dimensions. In this paper, we introduce the construction and utilization of representative factors for the interactive visual analysis of structures in high-dimensional datasets. First, we present a selection of methods to investigate the sub-groups in the dimension set and associate representative factors with those groups of dimensions. Second, we introduce how these factors are included in the interactive visual analysis cycle together with the original dimensions. We then provide the steps of an analytical procedure that iteratively analyzes the datasets through the use of representative factors. We discuss how our methods improve the reliability and interpretability of the analysis process by enabling more informed selections of computational tools. Finally, we demonstrate our techniques on the analysis of brain imaging study results that are performed over a large group of subjects."}, {"color": "orange", "id": 797, "label": 797, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 797 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2012.260\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Alex Endert;Patrick Fiaux;Chris North; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Semantic Interaction for Sensemaking: Inferring Analytical Reasoning for Model Steering; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Visual analytic tools aim to support the cognitively demanding task of sensemaking. Their success often depends on the ability to leverage capabilities of mathematical models, visualization, and human intuition through flexible, usable, and expressive interactions. Spatially clustering data is one effective metaphor for users to explore similarity and relationships between information, adjusting the weighting of dimensions or characteristics of the dataset to observe the change in the spatial layout. Semantic interaction is an approach to user interaction in such spatializations that couples these parametric modifications of the clustering model with users\u0027 analytic operations on the data (e.g., direct document movement in the spatialization, highlighting text, search, etc.). In this paper, we present results of a user study exploring the ability of semantic interaction in a visual analytic prototype, ForceSPIRE, to support sensemaking. We found that semantic interaction captures the analytical reasoning of the user through keyword weighting, and aids the user in co-creating a spatialization based on the user\u0027s reasoning and intuition."}, {"color": "blue", "id": 800, "label": 800, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 800 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2012.263\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Hannah Pileggi;Charles D. Stolper;J. Michael Boyle;John T. Stasko; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: SnapShot: Visualization to Propel Ice Hockey Analytics; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Sports analysts live in a world of dynamic games flattened into tables of numbers, divorced from the rinks, pitches, and courts where they were generated. Currently, these professional analysts use R, Stata, SAS, and other statistical software packages for uncovering insights from game data. Quantitative sports consultants seek a competitive advantage both for their clients and for themselves as analytics becomes increasingly valued by teams, clubs, and squads. In order for the information visualization community to support the members of this blossoming industry, it must recognize where and how visualization can enhance the existing analytical workflow. In this paper, we identify three primary stages of today\u0027s sports analyst\u0027s routine where visualization can be beneficially integrated: 1) exploring a dataspace; 2) sharing hypotheses with internal colleagues; and 3) communicating findings to stakeholders.Working closely with professional ice hockey analysts, we designed and built SnapShot, a system to integrate visualization into the hockey intelligence gathering process. SnapShot employs a variety of information visualization techniques to display shot data, yet given the importance of a specific hockey statistic, shot length, we introduce a technique, the radial heat map. Through a user study, we received encouraging feedback from several professional analysts, both independent consultants and professional team personnel."}, {"color": "blue", "id": 802, "label": 802, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 802 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2012.265\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Christian Tominski;Heidrun Schumann;Gennady Andrienko;Natalia Andrienko; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Stacking-Based Visualization of Trajectory Attribute Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Visualizing trajectory attribute data is challenging because it involves showing the trajectories in their spatio-temporal context as well as the attribute values associated with the individual points of trajectories. Previous work on trajectory visualization addresses selected aspects of this problem, but not all of them. We present a novel approach to visualizing trajectory attribute data. Our solution covers space, time, and attribute values. Based on an analysis of relevant visualization tasks, we designed the visualization solution around the principle of stacking trajectory bands. The core of our approach is a hybrid 2D/3D display. A 2D map serves as a reference for the spatial context, and the trajectories are visualized as stacked 3D trajectory bands along which attribute values are encoded by color. Time is integrated through appropriate ordering of bands and through a dynamic query mechanism that feeds temporally aggregated information to a circular time display. An additional 2D time graph shows temporal information in full detail by stacking 2D trajectory bands. Our solution is equipped with analytical and interactive mechanisms for selecting and ordering of trajectories, and adjusting the color mapping, as well as coordinated highlighting and dedicated 3D navigation. We demonstrate the usefulness of our novel visualization by three examples related to radiation surveillance, traffic analysis, and maritime navigation. User feedback obtained in a small experiment indicates that our hybrid 2D/3D solution can be operated quite well."}, {"color": "blue", "id": 806, "label": 806, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 806 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2012.272\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Florian Block;Michael S. Horn;Brenda Caldwell Phillips;Judy Diamond;E. Margaret Evans;Chia Shen; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: The DeepTree Exhibit: Visualizing the Tree of Life to Facilitate Informal Learning; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In this paper, we present the DeepTree exhibit, a multi-user, multi-touch interactive visualization of the Tree of Life. We developed DeepTree to facilitate collaborative learning of evolutionary concepts. We will describe an iterative process in which a team of computer scientists, learning scientists, biologists, and museum curators worked together throughout design, development, and evaluation. We present the importance of designing the interactions and the visualization hand-in-hand in order to facilitate active learning. The outcome of this process is a fractal-based tree layout that reduces visual complexity while being able to capture all life on earth; a custom rendering and navigation engine that prioritizes visual appeal and smooth fly-through; and a multi-user interface that encourages collaborative exploration while offering guided discovery. We present an evaluation showing that the large dataset encouraged free exploration, triggers emotional responses, and facilitates visitor engagement and informal learning."}, {"color": "orange", "id": 807, "label": 807, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 807 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2012.273\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Margit Pohl;Michael Smuc;Eva Mayr; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: The User Puzzle---Explaining the Interaction with Visual Analytics Systems; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Visual analytics emphasizes the interplay between visualization, analytical procedures performed by computers and human perceptual and cognitive activities. Human reasoning is an important element in this context. There are several theories in psychology and HCI explaining open-ended and exploratory reasoning. Five of these theories (sensemaking theories, gestalt theories, distributed cognition, graph comprehension theories and skill-rule-knowledge models) are described in this paper. We discuss their relevance for visual analytics. In order to do this more systematically, we developed a schema of categories relevant for visual analytics research and evaluation. All these theories have strengths but also weaknesses in explaining interaction with visual analytics systems. A possibility to overcome the weaknesses would be to combine two or more of these theories."}, {"color": "blue", "id": 809, "label": 809, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 809 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2012.275\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jagoda Walny;Bongshin Lee;Paul Johns;Nathalie Henry Riche;Sheelagh Carpendale; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Understanding Pen and Touch Interaction for Data Exploration on Interactive Whiteboards; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Current interfaces for common information visualizations such as bar graphs, line graphs, and scatterplots usually make use of the WIMP (Windows, Icons, Menus and a Pointer) interface paradigm with its frequently discussed problems of multiple levels of indirection via cascading menus, dialog boxes, and control panels. Recent advances in interface capabilities such as the availability of pen and touch interaction challenge us to re-think this and investigate more direct access to both the visualizations and the data they portray. We conducted a Wizard of Oz study to explore applying pen and touch interaction to the creation of information visualization interfaces on interactive whiteboards without implementing a plethora of recognizers. Our wizard acted as a robust and flexible pen and touch recognizer, giving participants maximum freedom in how they interacted with the system. Based on our qualitative analysis of the interactions our participants used, we discuss our insights about pen and touch interactions in the context of learnability and the interplay between pen and touch gestures. We conclude with suggestions for designing pen and touch enabled interactive visualization interfaces."}, {"color": "orange", "id": 811, "label": 811, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 811 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2012.277\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Florian Heimerl;Steffen Koch;Harald Bosch;Thomas Ertl; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visual Classifier Training for Text Document Retrieval; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Performing exhaustive searches over a large number of text documents can be tedious, since it is very hard to formulate search queries or define filter criteria that capture an analyst\u0027s information need adequately. Classification through machine learning has the potential to improve search and filter tasks encompassing either complex or very specific information needs, individually. Unfortunately, analysts who are knowledgeable in their field are typically not machine learning specialists. Most classification methods, however, require a certain expertise regarding their parametrization to achieve good results. Supervised machine learning algorithms, in contrast, rely on labeled data, which can be provided by analysts. However, the effort for labeling can be very high, which shifts the problem from composing complex queries or defining accurate filters to another laborious task, in addition to the need for judging the trained classifier\u0027s quality. We therefore compare three approaches for interactive classifier training in a user study. All of the approaches are potential candidates for the integration into a larger retrieval system. They incorporate active learning to various degrees in order to reduce the labeling effort as well as to increase effectiveness. Two of them encompass interactive visualization for letting users explore the status of the classifier in context of the labeled documents, as well as for judging the quality of the classifier in iterative feedback loops. We see our work as a step towards introducing user controlled classification methods in addition to text search and filtering for increasing recall in analytics scenarios involving large corpora."}, {"color": "red", "id": 814, "label": 814, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 814 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2012.280\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Daniel Engel;Klaus Greff;Christoph Garth;Keith Bein;Anthony Wexler;Bernd Hamann;Hans Hagen; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visual Steering and Verification of Mass Spectrometry Data Factorization in Air Quality Research; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The study of aerosol composition for air quality research involves the analysis of high-dimensional single particle mass spectrometry data. We describe, apply, and evaluate a novel interactive visual framework for dimensionality reduction of such data. Our framework is based on non-negative matrix factorization with specifically defined regularization terms that aid in resolving mass spectrum ambiguity. Thereby, visualization assumes a key role in providing insight into and allowing to actively control a heretofore elusive data processing step, and thus enabling rapid analysis meaningful to domain scientists. In extending existing black box schemes, we explore design choices for visualizing, interacting with, and steering the factorization process to produce physically meaningful results. A domain-expert evaluation of our system performed by the air quality research experts involved in this effort has shown that our method and prototype admits the finding of unambiguous and physically correct lower-dimensional basis transformations of mass spectrometry data at significantly increased speed and a higher degree of ease."}, {"color": "blue", "id": 823, "label": 823, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 823 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2012.291\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Nan Cao;Yu-Ru Lin;Xiaohua Sun;David Lazer;Shixia Liu;Huamin Qu; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Whisper: Tracing the Spatiotemporal Process of Information Diffusion in Real Time; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: When and where is an idea dispersed? Social media, like Twitter, has been increasingly used for exchanging information, opinions and emotions about events that are happening across the world. Here we propose a novel visualization design, \u201cWhisper\u201d, for tracing the process of information diffusion in social media in real time. Our design highlights three major characteristics of diffusion processes in social media: the temporal trend, social-spatial extent, and community response of a topic of interest. Such social, spatiotemporal processes are conveyed based on a sunflower metaphor whose seeds are often dispersed far away. In Whisper, we summarize the collective responses of communities on a given topic based on how tweets were retweeted by groups of users, through representing the sentiments extracted from the tweets, and tracing the pathways of retweets on a spatial hierarchical layout. We use an efficient flux line-drawing algorithm to trace multiple pathways so the temporal and spatial patterns can be identified even for a bursty event. A focused diffusion series highlights key roles such as opinion leaders in the diffusion process. We demonstrate how our design facilitates the understanding of when and where a piece of information is dispersed and what are the social responses of the crowd, for large-scale events including political campaigns and natural disasters. Initial feedback from domain experts suggests promising use for today\u0027s information consumption and dispersion in the wild."}, {"color": "orange", "id": 826, "label": 826, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 826 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2012.6400485\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Wenwen Dou;Xiaoyu Wang;Drew Skau;William Ribarsky;Michelle X. Zhou; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: LeadLine: Interactive visual analysis of text data through event identification and exploration; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Text data such as online news and microblogs bear valuable insights regarding important events and responses to such events. Events are inherently temporal, evolving over time. Existing visual text analysis systems have provided temporal views of changes based on topical themes extracted from text data. But few have associated topical themes with events that cause the changes. In this paper, we propose an interactive visual analytics system, LeadLine, to automatically identify meaningful events in news and social media data and support exploration of the events. To characterize events, LeadLine integrates topic modeling, event detection, and named entity recognition techniques to automatically extract information regarding the investigative 4 Ws: who, what, when, and where for each event. To further support analysis of the text corpora through events, LeadLine allows users to interactively examine meaningful events using the 4 Ws to develop an understanding of how and why. Through representing large-scale text corpora in the form of meaningful events, LeadLine provides a concise summary of the corpora. LeadLine also supports the construction of simple narratives through the exploration of events. To demonstrate the efficacy of LeadLine in identifying events and supporting exploration, two case studies were conducted using news and social media data."}, {"color": "orange", "id": 827, "label": 827, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 827 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2012.6400486\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Eli T. Brown;Jingjing Liu;Carla E. Brodley;Remco Chang; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Dis-function: Learning distance functions interactively; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The world\u0027s corpora of data grow in size and complexity every day, making it increasingly difficult for experts to make sense out of their data. Although machine learning offers algorithms for finding patterns in data automatically, they often require algorithm-specific parameters, such as an appropriate distance function, which are outside the purview of a domain expert. We present a system that allows an expert to interact directly with a visual representation of the data to define an appropriate distance function, thus avoiding direct manipulation of obtuse model parameters. Adopting an iterative approach, our system first assumes a uniformly weighted Euclidean distance function and projects the data into a two-dimensional scatterplot view. The user can then move incorrectly-positioned data points to locations that reflect his or her understanding of the similarity of those data points relative to the other data points. Based on this input, the system performs an optimization to learn a new distance function and then re-projects the data to redraw the scatter-plot. We illustrate empirically that with only a few iterations of interaction and optimization, a user can achieve a scatterplot view and its corresponding distance function that reflect the user\u0027s knowledge of the data. In addition, we evaluate our system to assess scalability in data size and data dimension, and show that our system is computationally efficient and can provide an interactive or near-interactive user experience."}, {"color": "orange", "id": 828, "label": 828, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 828 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2012.6400487\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Eser Kandogan; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Just-in-time annotation of clusters, outliers, and trends in point-based data visualizations; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We introduce the concept of just-in-time descriptive analytics as a novel application of computational and statistical techniques performed at interaction-time to help users easily understand the structure of data as seen in visualizations. Fundamental to just-intime descriptive analytics is (a) identifying visual features, such as clusters, outliers, and trends, user might observe in visualizations automatically, (b) determining the semantics of such features by performing statistical analysis as the user is interacting, and (c) enriching visualizations with annotations that not only describe semantics of visual features but also facilitate interaction to support high-level understanding of data. In this paper, we demonstrate just-in-time descriptive analytics applied to a point-based multi-dimensional visualization technique to identify and describe clusters, outliers, and trends. We argue that it provides a novel user experience of computational techniques working alongside of users allowing them to build faster qualitative mental models of data by demonstrating its application on a few use-cases. Techniques used to facilitate just-in-time descriptive analytics are described in detail along with their runtime performance characteristics. We believe this is just a starting point and much remains to be researched, as we discuss open issues and opportunities in improving accessibility and collaboration."}, {"color": "orange", "id": 829, "label": 829, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 829 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2012.6400488\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Andrada Tatu;Fabian Maa\u00df;Ines F\u00e4rber;Enrico Bertini;Tobias Schreck;Thomas Seidl;Daniel Keim; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Subspace search and visualization to make sense of alternative clusterings in high-dimensional data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In explorative data analysis, the data under consideration often resides in a high-dimensional (HD) data space. Currently many methods are available to analyze this type of data. So far, proposed automatic approaches include dimensionality reduction and cluster analysis, whereby visual-interactive methods aim to provide effective visual mappings to show, relate, and navigate HD data. Furthermore, almost all of these methods conduct the analysis from a singular perspective, meaning that they consider the data in either the original HD data space, or a reduced version thereof. Additionally, HD data spaces often consist of combined features that measure different properties, in which case the particular relationships between the various properties may not be clear to the analysts a priori since it can only be revealed if appropriate feature combinations (subspaces) of the data are taken into consideration. Considering just a single subspace is, however, often not sufficient since different subspaces may show complementary, conjointly, or contradicting relations between data items. Useful information may consequently remain embedded in sets of subspaces of a given HD input data space. Relying on the notion of subspaces, we propose a novel method for the visual analysis of HD data in which we employ an interestingness-guided subspace search algorithm to detect a candidate set of subspaces. Based on appropriately defined subspace similarity functions, we visualize the subspaces and provide navigation facilities to interactively explore large sets of subspaces. Our approach allows users to effectively compare and relate subspaces with respect to involved dimensions and clusters of objects. We apply our approach to synthetic and real data sets. We thereby demonstrate its support for understanding HD data from different perspectives, effectively yielding a more complete view on HD data."}, {"color": "orange", "id": 830, "label": 830, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 830 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2012.6400489\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Elisa Portes dos Santos Amorim;Emilio Vital Brazil;Joel Daniels;Paulo Joia;Luis Gustavo Nonato;Mario Costa Sousa; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: iLAMP: Exploring high-dimensional spacing through backward multidimensional projection; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Ever improving computing power and technological advances are greatly augmenting data collection and scientific observation. This has directly contributed to increased data complexity and dimensionality, motivating research of exploration techniques for multidimensional data. Consequently, a recent influx of work dedicated to techniques and tools that aid in understanding multidimensional datasets can be observed in many research fields, including biology, engineering, physics and scientific computing. While the effectiveness of existing techniques to analyze the structure and relationships of multidimensional data varies greatly, few techniques provide flexible mechanisms to simultaneously visualize and actively explore high-dimensional spaces. In this paper, we present an inverse linear affine multidimensional projection, coined iLAMP, that enables a novel interactive exploration technique for multidimensional data. iLAMP operates in reverse to traditional projection methods by mapping low-dimensional information into a high-dimensional space. This allows users to extrapolate instances of a multidimensional dataset while exploring a projection of the data to the planar domain. We present experimental results that validate iLAMP, measuring the quality and coherence of the extrapolated data; as well as demonstrate the utility of iLAMP to hypothesize the unexplored regions of a high-dimensional space."}, {"color": "orange", "id": 831, "label": 831, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 831 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2012.6400490\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Anushka Anand;Leland Wilkinson;Tuan Nhon Dang; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visual pattern discovery using random projections; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: An essential element of exploratory data analysis is the use of revealing low-dimensional projections of high-dimensional data. Projection Pursuit has been an effective method for finding interesting low-dimensional projections of multidimensional spaces by optimizing a score function called a projection pursuit index. However, the technique is not scalable to high-dimensional spaces. Here, we introduce a novel method for discovering noteworthy views of high-dimensional data spaces by using binning and random projections. We define score functions, akin to projection pursuit indices, that characterize visual patterns of the low-dimensional projections that constitute feature subspaces. We also describe an analytic, multivariate visualization platform based on this algorithm that is scalable to extremely large problems."}, {"color": "orange", "id": 832, "label": 832, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 832 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2012.6400491\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Abish Malik;Ross Maciejewski;Niklas Elmqvist;Yun Jang;David S. Ebert;Whitney Huang; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: A correlative analysis process in a visual analytics environment; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Finding patterns and trends in spatial and temporal datasets has been a long studied problem in statistics and different domains of science. This paper presents a visual analytics approach for the interactive exploration and analysis of spatiotemporal correlations among multivariate datasets. Our approach enables users to discover correlations and explore potentially causal or predictive links at different spatiotemporal aggregation levels among the datasets, and allows them to understand the underlying statistical foundations that precede the analysis. Our technique utilizes the Pearson\u0027s product-moment correlation coefficient and factors in the lead or lag between different datasets to detect trends and periodic patterns amongst them."}, {"color": "orange", "id": 833, "label": 833, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 833 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2012.6400492\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Benjamin H\u00f6ferlin;Rudolf Netzel;Markus H\u00f6ferlin;Daniel Weiskopf;Gunther Heidemann; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Inter-active learning of ad-hoc classifiers for video visual analytics; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Learning of classifiers to be used as filters within the analytical reasoning process leads to new and aggravates existing challenges. Such classifiers are typically trained ad-hoc, with tight time constraints that affect the amount and the quality of annotation data and, thus, also the users\u0027 trust in the classifier trained. We approach the challenges of ad-hoc training by inter-active learning, which extends active learning by integrating human experts\u0027 background knowledge to greater extent. In contrast to active learning, not only does inter-active learning include the users\u0027 expertise by posing queries of data instances for labeling, but it also supports the users in comprehending the classifier model by visualization. Besides the annotation of manually or automatically selected data instances, users are empowered to directly adjust complex classifier models. Therefore, our model visualization facilitates the detection and correction of inconsistencies between the classifier model trained by examples and the user\u0027s mental model of the class definition. Visual feedback of the training process helps the users assess the performance of the classifier and, thus, build up trust in the filter created. We demonstrate the capabilities of inter-active learning in the domain of video visual analytics and compare its performance with the results of random sampling and uncertainty sampling of training sets."}, {"color": "orange", "id": 862, "label": 862, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 862 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2012.6400556\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Harald Piringer;Matthias Buchetics;Rudolf Benedik; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: AlVis: Situation awareness in the surveillance of road tunnels; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In the surveillance of road tunnels, video data plays an important role for a detailed inspection and as an input to systems for an automated detection of incidents. In disaster scenarios like major accidents, however, the increased amount of detected incidents may lead to situations where human operators lose a sense of the overall meaning of that data, a problem commonly known as a lack of situation awareness. The primary contribution of this paper is a design study of AlVis, a system designed to increase situation awareness in the surveillance of road tunnels. The design of AlVis is based on a simplified tunnel model which enables an overview of the spatiotemporal development of scenarios in real-time. The visualization explicitly represents the present state, the history, and predictions of potential future developments. Concepts for situation-sensitive prioritization of information ensure scalability from normal operation to major disaster scenarios. The visualization enables an intuitive access to live and historic video for any point in time and space. We illustrate AlVis by means of a scenario and report qualitative feedback by tunnel experts and operators. This feedback suggests that AlVis is suitable to save time in recognizing dangerous situations and helps to maintain an overview in complex disaster scenarios."}, {"color": "orange", "id": 863, "label": 863, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 863 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2012.6400557\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Junghoon Chae;Dennis Thom;Harald Bosch;Yun Jang;Ross Maciejewski;David S. Ebert;Thomas Ertl; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Spatiotemporal social media analytics for abnormal event detection and examination using seasonal-trend decomposition; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Recent advances in technology have enabled social media services to support space-time indexed data, and internet users from all over the world have created a large volume of time-stamped, geo-located data. Such spatiotemporal data has immense value for increasing situational awareness of local events, providing insights for investigations and understanding the extent of incidents, their severity, and consequences, as well as their time-evolving nature. In analyzing social media data, researchers have mainly focused on finding temporal trends according to volume-based importance. Hence, a relatively small volume of relevant messages may easily be obscured by a huge data set indicating normal situations. In this paper, we present a visual analytics approach that provides users with scalable and interactive social media data analysis and visualization including the exploration and examination of abnormal topics and events within various social media data sources, such as Twitter, Flickr and YouTube. In order to find and understand abnormal events, the analyst can first extract major topics from a set of selected messages and rank them probabilistically using Latent Dirichlet Allocation. He can then apply seasonal trend decomposition together with traditional control chart methods to find unusual peaks and outliers within topic time series. Our case studies show that situational awareness can be improved by incorporating the anomaly and trend examination techniques into a highly interactive visual analysis process."}, {"color": "orange", "id": 864, "label": 864, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 864 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2012.6400558\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Liang Gou;Xiaolong Zhang;Airong Luo;Patricia F. Anderson; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: SocialNetSense: Supporting sensemaking of social and structural features in networks with interactive visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Increasingly, social network datasets contain social attribute information about actors and their relationship. Analyzing such network with social attributes requires making sense of not only its structural features, but also the relationship between social features in attributes and network structures. Existing social network analysis tools are usually weak in supporting complex analytical tasks involving both structural and social features, and often overlook users\u0027 needs for sensemaking tools that help to gather, synthesize, and organize information of these features. To address these challenges, we propose a sensemaking framework of social-network visual analytics in this paper. This framework considers both bottom-up processes, which are about constructing new understandings based on collected information, and top-down processes, which concern using prior knowledge to guide information collection, in analyzing social networks from both social and structural perspectives. The framework also emphasizes the externalization of sensemaking processes through interactive visualization. Guided by the framework, we develop a system, SocialNetSense, to support the sensemaking in visual analytics of social networks with social attributes. The example of using our system to analyze a scholar collaboration network shows that our approach can help users gain insight into social networks both structurally and socially, and enhance their process awareness in visual analytics."}, {"color": "orange", "id": 865, "label": 865, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 865 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2012.6400559\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Christopher Andrews;Chris North; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Analyst\u0027s Workspace: An embodied sensemaking environment for large, high-resolution displays; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Distributed cognition and embodiment provide compelling models for how humans think and interact with the environment. Our examination of the use of large, high-resolution displays from an embodied perspective has lead directly to the development of a new sensemaking environment called Analyst\u0027s Workspace (AW). AW leverages the embodied resources made more accessible through the physical nature of the display to create a spatial workspace. By combining spatial layout of documents and other artifacts with an entity-centric, explorative investigative approach, AW aims to allow the analyst to externalize elements of the sensemaking process as a part of the investigation, integrated into the visual representations of the data itself. In this paper, we describe the various capabilities of AW and discuss the key principles and concepts underlying its design, emphasizing unique design principles for designing visual analytic tools for large, high-resolution displays."}, {"color": "blue", "id": 867, "label": 867, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 867 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.119\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jessica Hullman;Steven Drucker;Nathalie Henry Riche;Bongshin Lee;Danyel Fisher;Eytan Adar; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: A Deeper Understanding of Sequence in Narrative Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Conveying a narrative with visualizations often requires choosing an order in which to present visualizations. While evidence exists that narrative sequencing in traditional stories can affect comprehension and memory, little is known about how sequencing choices affect narrative visualization. We consider the forms and reactions to sequencing in narrative visualization presentations to provide a deeper understanding with a focus on linear, \u0027slideshow-style\u0027 presentations. We conduct a qualitative analysis of 42 professional narrative visualizations to gain empirical knowledge on the forms that structure and sequence take. Based on the results of this study we propose a graph-driven approach for automatically identifying effective sequences in a set of visualizations to be presented linearly. Our approach identifies possible transitions in a visualization set and prioritizes local (visualization-to-visualization) transitions based on an objective function that minimizes the cost of transitions from the audience perspective. We conduct two studies to validate this function. We also expand the approach with additional knowledge of user preferences for different types of local transitions and the effects of global sequencing strategies on memory, preference, and comprehension. Our results include a relative ranking of types of visualization transitions by the audience perspective and support for memory and subjective rating benefits of visualization sequences that use parallelism as a structural device. We discuss how these insights can guide the design of narrative visualization and systems that support optimization of visualization sequence."}, {"color": "blue", "id": 868, "label": 868, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 868 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.120\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Hans-J\u00f6rg Schulz;Thomas Nocke;Magnus Heitzler;Heidrun Schumann; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: A Design Space of Visualization Tasks; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Knowledge about visualization tasks plays an important role in choosing or building suitable visual representations to pursue them. Yet, tasks are a multi-faceted concept and it is thus not surprising that the many existing task taxonomies and models all describe different aspects of tasks, depending on what these task descriptions aim to capture. This results in a clear need to bring these different aspects together under the common hood of a general design space of visualization tasks, which we propose in this paper. Our design space consists of five design dimensions that characterize the main aspects of tasks and that have so far been distributed across different task descriptions. We exemplify its concrete use by applying our design space in the domain of climate impact research. To this end, we propose interfaces to our design space for different user roles (developers, authors, and end users) that allow users of different levels of expertise to work with it."}, {"color": "blue", "id": 872, "label": 872, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 872 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.124\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Matthew Brehmer;Tamara Munzner; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: A Multi-Level Typology of Abstract Visualization Tasks; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The considerable previous work characterizing visualization usage has focused on low-level tasks or interactions and high-level tasks, leaving a gap between them that is not addressed. This gap leads to a lack of distinction between the ends and means of a task, limiting the potential for rigorous analysis. We contribute a multi-level typology of visualization tasks to address this gap, distinguishing why and how a visualization task is performed, as well as what the task inputs and outputs are. Our typology allows complex tasks to be expressed as sequences of interdependent simpler tasks, resulting in concise and flexible descriptions for tasks of varying complexity and scope. It provides abstract rather than domain-specific descriptions of tasks, so that useful comparisons can be made between visualization systems targeted at different application domains. This descriptive power supports a level of analysis required for the generation of new designs, by guiding the translation of domain-specific problems into abstract tasks, and for the qualitative evaluation of visualization usage. We demonstrate the benefits of our approach in a detailed case study, comparing task descriptions from our typology to those derived from related work. We also discuss the similarities and differences between our typology and over two dozen extant classification systems and theoretical frameworks from the literatures of visualization, human-computer interaction, information retrieval, communications, and cartography."}, {"color": "orange", "id": 873, "label": 873, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 873 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.125\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Thomas M\u00fchlbacher;Harald Piringer; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: A Partition-Based Framework for Building and Validating Regression Models; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Regression models play a key role in many application domains for analyzing or predicting a quantitative dependent variable based on one or more independent variables. Automated approaches for building regression models are typically limited with respect to incorporating domain knowledge in the process of selecting input variables (also known as feature subset selection). Other limitations include the identification of local structures, transformations, and interactions between variables. The contribution of this paper is a framework for building regression models addressing these limitations. The framework combines a qualitative analysis of relationship structures by visualization and a quantification of relevance for ranking any number of features and pairs of features which may be categorical or continuous. A central aspect is the local approximation of the conditional target distribution by partitioning 1D and 2D feature domains into disjoint regions. This enables a visual investigation of local patterns and largely avoids structural assumptions for the quantitative ranking. We describe how the framework supports different tasks in model building (e.g., validation and comparison), and we present an interactive workflow for feature subset selection. A real-world case study illustrates the step-wise identification of a five-dimensional model for natural gas consumption. We also report feedback from domain experts after two months of deployment in the energy sector, indicating a significant effort reduction for building and improving regression models."}, {"color": "red", "id": 874, "label": 874, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 874 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.126\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Tobias Isenberg;Petra Isenberg;Jian Chen;Michael Sedlmair;Torsten M\u00f6ller; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: A Systematic Review on the Practice of Evaluating Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present an assessment of the state and historic development of evaluation practices as reported in papers published at the IEEE Visualization conference. Our goal is to reflect on a meta-level about evaluation in our community through a systematic understanding of the characteristics and goals of presented evaluations. For this purpose we conducted a systematic review of ten years of evaluations in the published papers using and extending a coding scheme previously established by Lam et al. [2012]. The results of our review include an overview of the most common evaluation goals in the community, how they evolved over time, and how they contrast or align to those of the IEEE Information Visualization conference. In particular, we found that evaluations specific to assessing resulting images and algorithm performance are the most prevalent (with consistently 80-90% of all papers since 1997). However, especially over the last six years there is a steady increase in evaluation methods that include participants, either by evaluating their performances and subjective feedback or by evaluating their work practices and their improved analysis and reasoning capabilities using visual tools. Up to 2010, this trend in the IEEE Visualization conference was much more pronounced than in the IEEE Information Visualization conference which only showed an increasing percentage of evaluation through user performance and experience testing. Since 2011, however, also papers in IEEE Information Visualization show such an increase of evaluations of work practices and analysis as well as reasoning using visual tools. Further, we found that generally the studies reporting requirements analyses and domain-specific work practices are too informally reported which hinders cross-comparison and lowers external validity."}, {"color": "blue", "id": 878, "label": 878, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 878 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.130\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Robert E. Roth; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: An Empirically-Derived Taxonomy of Interaction Primitives for Interactive Cartography and Geovisualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Proposals to establish a \u0027science of interaction\u0027 have been forwarded from Information Visualization and Visual Analytics, as well as Cartography, Geovisualization, and GIScience. This paper reports on two studies to contribute to this call for an interaction science, with the goal of developing a functional taxonomy of interaction primitives for map-based visualization. A semi-structured interview study first was conducted with 21 expert interactive map users to understand the way in which map-based visualizations currently are employed. The interviews were transcribed and coded to identify statements representative of either the task the user wished to accomplish (i.e., objective primitives) or the interactive functionality included in the visualization to achieve this task (i.e., operator primitives). A card sorting study then was conducted with 15 expert interactive map designers to organize these example statements into logical structures based on their experience translating client requests into interaction designs. Example statements were supplemented with primitive definitions in the literature and were separated into two sorting exercises: objectives and operators. The objective sort suggested five objectives that increase in cognitive sophistication (identify, compare, rank, associate, \u0026amp; delineate), but exhibited a large amount of variation across participants due to consideration of broader user goals (procure, predict, \u0026amp; prescribe) and interaction operands (space-alone, attributes-in-space, \u0026amp; space-in-time; elementary \u0026amp; general). The operator sort suggested five enabling operators (import, export, save, edit, \u0026amp; annotate) and twelve work operators (reexpress, arrange, sequence, resymbolize, overlay, pan, zoom, reproject, search, filter, retrieve, \u0026amp; calculate). This taxonomy offers an empirically-derived and ecologically-valid structure to inform future research and design on interaction."}, {"color": "orange", "id": 880, "label": 880, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 880 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.132\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Rick Walker;Aiden Slingsby;Jason Dykes;Kai Xu;Jo Wood;Phong H. Nguyen;Derek Stephens;B.L. William Wong;Yongjun Zheng; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: An Extensible Framework for Provenance in Human Terrain Visual Analytics; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We describe and demonstrate an extensible framework that supports data exploration and provenance in the context of Human Terrain Analysis (HTA). Working closely with defence analysts we extract requirements and a list of features that characterise data analysed at the end of the HTA chain. From these, we select an appropriate non-classified data source with analogous features, and model it as a set of facets. We develop ProveML, an XML-based extension of the Open Provenance Model, using these facets and augment it with the structures necessary to record the provenance of data, analytical process and interpretations. Through an iterative process, we develop and refine a prototype system for Human Terrain Visual Analytics (HTVA), and demonstrate means of storing, browsing and recalling analytical provenance and process through analytic bookmarks in ProveML. We show how these bookmarks can be combined to form narratives that link back to the live data. Throughout the process, we demonstrate that through structured workshops, rapid prototyping and structured communication with intelligence analysts we are able to establish requirements, and design schema, techniques and tools that meet the requirements of the intelligence community. We use the needs and reactions of defence analysts in defining and steering the methods to validate the framework."}, {"color": "blue", "id": 882, "label": 882, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 882 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.134\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Yvonne Jansen;Pierre Dragicevic; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: An Interaction Model for Visualizations Beyond The Desktop; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present an interaction model for beyond-desktop visualizations that combines the visualization reference model with the instrumental interaction paradigm. Beyond-desktop visualizations involve a wide range of emerging technologies such as wall-sized displays, 3D and shape-changing displays, touch and tangible input, and physical information visualizations. While these technologies allow for new forms of interaction, they are often studied in isolation. New conceptual models are needed to build a coherent picture of what has been done and what is possible. We describe a modified pipeline model where raw data is processed into a visualization and then rendered into the physical world. Users can explore or change data by directly manipulating visualizations or through the use of instruments. Interactions can also take place in the physical world outside the visualization system, such as when using locomotion to inspect a large scale visualization. Through case studies we illustrate how this model can be used to describe both conventional and unconventional interactive visualization systems, and compare different design alternatives."}, {"color": "blue", "id": 887, "label": 887, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 887 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.140\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Heike Hofmann;Marie Vendettuoli; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Common Angle Plots as Perception-True Visualizations of Categorical Associations; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Visualizations are great tools of communications-they summarize findings and quickly convey main messages to our audience. As designers of charts we have to make sure that information is shown with a minimum of distortion. We have to also consider illusions and other perceptual limitations of our audience. In this paper we discuss the effect and strength of the line width illusion, a Muller-Lyer type illusion, on designs related to displaying associations between categorical variables. Parallel sets and hammock plots are both affected by line width illusions. We introduce the common-angle plot as an alternative method for displaying categorical data in a manner that minimizes the effect from perceptual illusions. Results from user studies both highlight the need for addressing line-width illusions in displays and provide evidence that common angle charts successfully resolve this issue."}, {"color": "red", "id": 888, "label": 888, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 888 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.141\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Mathias Hummel;Harald Obermaier;Christoph Garth;Kenneth I. Joy; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Comparative Visual Analysis of Lagrangian Transport in CFD Ensembles; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Sets of simulation runs based on parameter and model variation, so-called ensembles, are increasingly used to model physical behaviors whose parameter space is too large or complex to be explored automatically. Visualization plays a key role in conveying important properties in ensembles, such as the degree to which members of the ensemble agree or disagree in their behavior. For ensembles of time-varying vector fields, there are numerous challenges for providing an expressive comparative visualization, among which is the requirement to relate the effect of individual flow divergence to joint transport characteristics of the ensemble. Yet, techniques developed for scalar ensembles are of little use in this context, as the notion of transport induced by a vector field cannot be modeled using such tools. We develop a Lagrangian framework for the comparison of flow fields in an ensemble. Our techniques evaluate individual and joint transport variance and introduce a classification space that facilitates incorporation of these properties into a common ensemble visualization. Variances of Lagrangian neighborhoods are computed using pathline integration and Principal Components Analysis. This allows for an inclusion of uncertainty measurements into the visualization and analysis approach. Our results demonstrate the usefulness and expressiveness of the presented method on several practical examples."}, {"color": "red", "id": 889, "label": 889, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 889 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.142\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Johanna Beyer;Ali Al-Awami;Narayanan Kasthuri;Jeff W. Lichtman;Hanspeter Pfister;Markus Hadwiger; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: ConnectomeExplorer: Query-Guided Visual Analysis of Large Volumetric Neuroscience Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: This paper presents ConnectomeExplorer, an application for the interactive exploration and query-guided visual analysis of large volumetric electron microscopy (EM) data sets in connectomics research. Our system incorporates a knowledge-based query algebra that supports the interactive specification of dynamically evaluated queries, which enable neuroscientists to pose and answer domain-specific questions in an intuitive manner. Queries are built step by step in a visual query builder, building more complex queries from combinations of simpler queries. Our application is based on a scalable volume visualization framework that scales to multiple volumes of several teravoxels each, enabling the concurrent visualization and querying of the original EM volume, additional segmentation volumes, neuronal connectivity, and additional meta data comprising a variety of neuronal data attributes. We evaluate our application on a data set of roughly one terabyte of EM data and 750 GB of segmentation data, containing over 4,000 segmented structures and 1,000 synapses. We demonstrate typical use-case scenarios of our collaborators in neuroscience, where our system has enabled them to answer specific scientific questions using interactive querying and analysis on the full-size data for the first time."}, {"color": "red", "id": 890, "label": 890, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 890 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.143\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Ross T. Whitaker;Mahsa Mirzargar;Robert M. Kirby; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Contour Boxplots: A Method for Characterizing Uncertainty in Feature Sets from Simulation Ensembles; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Ensembles of numerical simulations are used in a variety of applications, such as meteorology or computational solid mechanics, in order to quantify the uncertainty or possible error in a model or simulation. Deriving robust statistics and visualizing the variability of an ensemble is a challenging task and is usually accomplished through direct visualization of ensemble members or by providing aggregate representations such as an average or pointwise probabilities. In many cases, the interesting quantities in a simulation are not dense fields, but are sets of features that are often represented as thresholds on physical or derived quantities. In this paper, we introduce a generalization of boxplots, called contour boxplots, for visualization and exploration of ensembles of contours or level sets of functions. Conventional boxplots have been widely used as an exploratory or communicative tool for data analysis, and they typically show the median, mean, confidence intervals, and outliers of a population. The proposed contour boxplots are a generalization of functional boxplots, which build on the notion of data depth. Data depth approximates the extent to which a particular sample is centrally located within its density function. This produces a center-outward ordering that gives rise to the statistical quantities that are essential to boxplots. Here we present a generalization of functional data depth to contours and demonstrate methods for displaying the resulting boxplots for two-dimensional simulation data in weather forecasting and computational fluid dynamics."}, {"color": "blue", "id": 892, "label": 892, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 892 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.145\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Sarah Goodwin;Jason Dykes;Sara Jones;Iain Dillingham;Graham Dove;Alison Duffy;Alexander Kachkaev;Aidan Slingsby;Jo Wood; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Creative User-Centered Visualization Design for Energy Analysts and Modelers; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We enhance a user-centered design process with techniques that deliberately promote creativity to identify opportunities for the visualization of data generated by a major energy supplier. Visualization prototypes developed in this way prove effective in a situation whereby data sets are largely unknown and requirements open - enabling successful exploration of possibilities for visualization in Smart Home data analysis. The process gives rise to novel designs and design metaphors including data sculpting. It suggests: that the deliberate use of creativity techniques with data stakeholders is likely to contribute to successful, novel and effective solutions; that being explicit about creativity may contribute to designers developing creative solutions; that using creativity techniques early in the design process may result in a creative approach persisting throughout the process. The work constitutes the first systematic visualization design for a data rich source that will be increasingly important to energy suppliers and consumers as Smart Meter technology is widely deployed. It is novel in explicitly employing creativity techniques at the requirements stage of visualization design and development, paving the way for further use and study of creativity methods in visualization design."}, {"color": "red", "id": 894, "label": 894, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 894 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.147\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Dane Coffey;Chi-Lun Lin;Arthur G. Erdman;Daniel F. Keefe; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Design by Dragging: An Interface for Creative Forward and Inverse Design with Simulation Ensembles; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present an interface for exploring large design spaces as encountered in simulation-based engineering, design of visual effects, and other tasks that require tuning parameters of computationally-intensive simulations and visually evaluating results. The goal is to enable a style of design with simulations that feels as-direct-as-possible so users can concentrate on creative design tasks. The approach integrates forward design via direct manipulation of simulation inputs (e.g., geometric properties, applied forces) in the same visual space with inverse design via \u0027tugging\u0027 and reshaping simulation outputs (e.g., scalar fields from finite element analysis (FEA) or computational fluid dynamics (CFD)). The interface includes algorithms for interpreting the intent of users\u0027 drag operations relative to parameterized models, morphing arbitrary scalar fields output from FEA and CFD simulations, and in-place interactive ensemble visualization. The inverse design strategy can be extended to use multi-touch input in combination with an as-rigid-as-possible shape manipulation to support rich visual queries. The potential of this new design approach is confirmed via two applications: medical device engineering of a vacuum-assisted biopsy device and visual effects design using a physically based flame simulation."}, {"color": "blue", "id": 896, "label": 896, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 896 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.149\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: S\u00e9bastien Rufiange;Michael J. McGuffin; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: DiffAni: Visualizing Dynamic Graphs with a Hybrid of Difference Maps and Animation; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Visualization of dynamically changing networks (graphs) is a significant challenge for researchers. Previous work has experimentally compared animation, small multiples, and other techniques, and found trade-offs between these. One potential way to avoid such trade-offs is to combine previous techniques in a hybrid visualization. We present two taxonomies of visualizations of dynamic graphs: one of non-hybrid techniques, and one of hybrid techniques. We also describe a prototype, called DiffAni, that allows a graph to be visualized as a sequence of three kinds of tiles: diff tiles that show difference maps over some time interval, animation tiles that show the evolution of the graph over some time interval, and small multiple tiles that show the graph state at an individual time slice. This sequence of tiles is ordered by time and covers all time slices in the data. An experimental evaluation of DiffAni shows that our hybrid approach has advantages over non-hybrid techniques in certain cases."}, {"color": "blue", "id": 897, "label": 897, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 897 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.150\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Xiaoru Yuan;Donghao Ren;Zuchao Wang;Cong Guo; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Dimension Projection Matrix/Tree: Interactive Subspace Visual Exploration and Analysis of High Dimensional Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: For high-dimensional data, this work proposes two novel visual exploration methods to gain insights into the data aspect and the dimension aspect of the data. The first is a Dimension Projection Matrix, as an extension of a scatterplot matrix. In the matrix, each row or column represents a group of dimensions, and each cell shows a dimension projection (such as MDS) of the data with the corresponding dimensions. The second is a Dimension Projection Tree, where every node is either a dimension projection plot or a Dimension Projection Matrix. Nodes are connected with links and each child node in the tree covers a subset of the parent node\u0027s dimensions or a subset of the parent node\u0027s data items. While the tree nodes visualize the subspaces of dimensions or subsets of the data items under exploration, the matrix nodes enable cross-comparison between different combinations of subspaces. Both Dimension Projection Matrix and Dimension Project Tree can be constructed algorithmically through automation, or manually through user interaction. Our implementation enables interactions such as drilling down to explore different levels of the data, merging or splitting the subspaces to adjust the matrix, and applying brushing to select data clusters. Our method enables simultaneously exploring data correlation and dimension correlation for data with high dimensions."}, {"color": "blue", "id": 900, "label": 900, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 900 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.153\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Michael Sedlmair;Tamara Munzner;Melanie Tory; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Empirical Guidance on Scatterplot and Dimension Reduction Technique Choices; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: To verify cluster separation in high-dimensional data, analysts often reduce the data with a dimension reduction (DR) technique, and then visualize it with 2D Scatterplots, interactive 3D Scatterplots, or Scatterplot Matrices (SPLOMs). With the goal of providing guidance between these visual encoding choices, we conducted an empirical data study in which two human coders manually inspected a broad set of 816 scatterplots derived from 75 datasets, 4 DR techniques, and the 3 previously mentioned scatterplot techniques. Each coder scored all color-coded classes in each scatterplot in terms of their separability from other classes. We analyze the resulting quantitative data with a heatmap approach, and qualitatively discuss interesting scatterplot examples. Our findings reveal that 2D scatterplots are often \u0027good enough\u0027, that is, neither SPLOM nor interactive 3D adds notably more cluster separability with the chosen DR technique. If 2D is not good enough, the most promising approach is to use an alternative DR technique in 2D. Beyond that, SPLOM occasionally adds additional value, and interactive 3D rarely helps but often hurts in terms of poorer class separation and usability. We summarize these results as a workflow model and implications for design. Our results offer guidance to analysts during the DR exploration process."}, {"color": "orange", "id": 904, "label": 904, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 904 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.157\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Michael Gleicher; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Explainers: Expert Explorations with Crafted Projections; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: This paper introduces an approach to exploration and discovery in high-dimensional data that incorporates a user\u0027s knowledge and questions to craft sets of projection functions meaningful to them. Unlike most prior work that defines projections based on their statistical properties, our approach creates projection functions that align with user-specified annotations. Therefore, the resulting derived dimensions represent concepts defined by the user\u0027s examples. These especially crafted projection functions, or explainers, can help find and explain relationships between the data variables and user-designated concepts. They can organize the data according to these concepts. Sets of explainers can provide multiple perspectives on the data. Our approach considers tradeoffs in choosing these projection functions, including their simplicity, expressive power, alignment with prior knowledge, and diversity. We provide techniques for creating collections of explainers. The methods, based on machine learning optimization frameworks, allow exploring the tradeoffs. We demonstrate our approach on model problems and applications in text analysis."}, {"color": "blue", "id": 907, "label": 907, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 907 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.160\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jean-Fran\u00e7ois Im;Michael J. McGuffin;Rock Leung; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: GPLOM: The Generalized Plot Matrix for Visualizing Multidimensional Multivariate Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Scatterplot matrices (SPLOMs), parallel coordinates, and glyphs can all be used to visualize the multiple continuous variables (i.e., dependent variables or measures) in multidimensional multivariate data. However, these techniques are not well suited to visualizing many categorical variables (i.e., independent variables or dimensions). To visualize multiple categorical variables, \u0027hierarchical axes\u0027 that \u0027stack dimensions\u0027 have been used in systems like Polaris and Tableau. However, this approach does not scale well beyond a small number of categorical variables. Emerson et al. [8] extend the matrix paradigm of the SPLOM to simultaneously visualize several categorical and continuous variables, displaying many kinds of charts in the matrix depending on the kinds of variables involved. We propose a variant of their technique, called the Generalized Plot Matrix (GPLOM). The GPLOM restricts Emerson et al.\u0027s technique to only three kinds of charts (scatterplots for pairs of continuous variables, heatmaps for pairs of categorical variables, and barcharts for pairings of categorical and continuous variable), in an effort to make it easier to understand. At the same time, the GPLOM extends Emerson et al.\u0027s work by demonstrating interactive techniques suited to the matrix of charts. We discuss the visual design and interactive features of our GPLOM prototype, including a textual search feature allowing users to quickly locate values or variables by name. We also present a user study that compared performance with Tableau and our GPLOM prototype, that found that GPLOM is significantly faster in certain cases, and not significantly slower in other cases."}, {"color": "orange", "id": 909, "label": 909, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 909 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.162\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Wenwen Dou;Li Yu;Xiaoyu Wang;Zhiqiang Ma;William Ribarsky; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: HierarchicalTopics: Visually Exploring Large Text Collections Using Topic Hierarchies; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Analyzing large textual collections has become increasingly challenging given the size of the data available and the rate that more data is being generated. Topic-based text summarization methods coupled with interactive visualizations have presented promising approaches to address the challenge of analyzing large text corpora. As the text corpora and vocabulary grow larger, more topics need to be generated in order to capture the meaningful latent themes and nuances in the corpora. However, it is difficult for most of current topic-based visualizations to represent large number of topics without being cluttered or illegible. To facilitate the representation and navigation of a large number of topics, we propose a visual analytics system - HierarchicalTopic (HT). HT integrates a computational algorithm, Topic Rose Tree, with an interactive visual interface. The Topic Rose Tree constructs a topic hierarchy based on a list of topics. The interactive visual interface is designed to present the topic content as well as temporal evolution of topics in a hierarchical fashion. User interactions are provided for users to make changes to the topic hierarchy based on their mental model of the topic space. To qualitatively evaluate HT, we present a case study that showcases how HierarchicalTopics aid expert users in making sense of a large number of topics and discovering interesting patterns of topic groups. We have also conducted a user study to quantitatively evaluate the effect of hierarchical topic structure. The study results reveal that the HT leads to faster identification of large number of relevant topics. We have also solicited user feedback during the experiments and incorporated some suggestions into the current version of HierarchicalTopics."}, {"color": "blue", "id": 912, "label": 912, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 912 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.166\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Mikkel R. Jakobsen;Yonas Sahlemariam Haile;S\u00f8ren Knudsen;Kasper Hornb\u00e6k; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Information Visualization and Proxemics: Design Opportunities and Empirical findings; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: People typically interact with information visualizations using a mouse. Their physical movement, orientation, and distance to visualizations are rarely used as input. We explore how to use such spatial relations among people and visualizations (i.e., proxemics) to drive interaction with visualizations, focusing here on the spatial relations between a single user and visualizations on a large display. We implement interaction techniques that zoom and pan, query and relate, and adapt visualizations based on tracking of users\u0027 position in relation to a large high-resolution display. Alternative prototypes are tested in three user studies and compared with baseline conditions that use a mouse. Our aim is to gain empirical data on the usefulness of a range of design possibilities and to generate more ideas. Among other things, the results show promise for changing zoom level or visual representation with the user\u0027s physical distance to a large display. We discuss possible benefits and potential issues to avoid when designing information visualizations that use proxemics."}, {"color": "orange", "id": 913, "label": 913, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 913 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.167\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jian Zhao;Christopher Collins;Fanny Chevalier;Ravin Balakrishnan; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Interactive Exploration of Implicit and Explicit Relations in Faceted Datasets; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Many datasets, such as scientific literature collections, contain multiple heterogeneous facets which derive implicit relations, as well as explicit relational references between data items. The exploration of this data is challenging not only because of large data scales but also the complexity of resource structures and semantics. In this paper, we present PivotSlice, an interactive visualization technique which provides efficient faceted browsing as well as flexible capabilities to discover data relationships. With the metaphor of direct manipulation, PivotSlice allows the user to visually and logically construct a series of dynamic queries over the data, based on a multi-focus and multi-scale tabular view that subdivides the entire dataset into several meaningful parts with customized semantics. PivotSlice further facilitates the visual exploration and sensemaking process through features including live search and integration of online data, graphical interaction histories and smoothly animated visual state transitions. We evaluated PivotSlice through a qualitative lab study with university researchers and report the findings from our observations and interviews. We also demonstrate the effectiveness of PivotSlice using a scenario of exploring a repository of information visualization literature."}, {"color": "blue", "id": 918, "label": 918, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 918 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.173\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Samuel Gratzl;Alexander Lex;Nils Gehlenborg;Hanspeter Pfister;Marc Streit; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: LineUp: Visual Analysis of Multi-Attribute Rankings; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Rankings are a popular and universal approach to structuring otherwise unorganized collections of items by computing a rank for each item based on the value of one or more of its attributes. This allows us, for example, to prioritize tasks or to evaluate the performance of products relative to each other. While the visualization of a ranking itself is straightforward, its interpretation is not, because the rank of an item represents only a summary of a potentially complicated relationship between its attributes and those of the other items. It is also common that alternative rankings exist which need to be compared and analyzed to gain insight into how multiple heterogeneous attributes affect the rankings. Advanced visual exploration tools are needed to make this process efficient. In this paper we present a comprehensive analysis of requirements for the visualization of multi-attribute rankings. Based on these considerations, we propose LineUp - a novel and scalable visualization technique that uses bar charts. This interactive technique supports the ranking of items based on multiple heterogeneous attributes with different scales and semantics. It enables users to interactively combine attributes and flexibly refine parameters to explore the effect of changes in the attribute combination. This process can be employed to derive actionable insights as to which attributes of an item need to be modified in order for its rank to change. Additionally, through integration of slope graphs, LineUp can also be used to compare multiple alternative rankings on the same set of items, for example, over time or across different attribute combinations. We evaluate the effectiveness of the proposed multi-attribute visualization technique in a qualitative study. The study shows that users are able to successfully solve complex ranking tasks in a short period of time."}, {"color": "blue", "id": 922, "label": 922, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 922 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.179\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Lauro Lins;James T. Klosowski;Carlos Scheidegger; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Nanocubes for Real-Time Exploration of Spatiotemporal Datasets; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Consider real-time exploration of large multidimensional spatiotemporal datasets with billions of entries, each defined by a location, a time, and other attributes. Are certain attributes correlated spatially or temporally? Are there trends or outliers in the data? Answering these questions requires aggregation over arbitrary regions of the domain and attributes of the data. Many relational databases implement the well-known data cube aggregation operation, which in a sense precomputes every possible aggregate query over the database. Data cubes are sometimes assumed to take a prohibitively large amount of space, and to consequently require disk storage. In contrast, we show how to construct a data cube that fits in a modern laptop\u0027s main memory, even for billions of entries; we call this data structure a nanocube. We present algorithms to compute and query a nanocube, and show how it can be used to generate well-known visual encodings such as heatmaps, histograms, and parallel coordinate plots. When compared to exact visualizations created by scanning an entire dataset, nanocube plots have bounded screen error across a variety of scales, thanks to a hierarchical structure in space and time. We demonstrate the effectiveness of our technique on a variety of real-world datasets, and present memory, timing, and network bandwidth measurements. We find that the timings for the queries in our examples are dominated by network and user-interaction latencies."}, {"color": "blue", "id": 927, "label": 927, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 927 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.184\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Bilal Alsallakh;Wolfgang Aigner;Silvia Miksch;Helwig Hauser; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Radial Sets: Interactive Visual Analysis of Large Overlapping Sets; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In many applications, data tables contain multi-valued attributes that often store the memberships of the table entities to multiple sets such as which languages a person masters, which skills an applicant documents, or which features a product comes with. With a growing number of entities, the resulting element-set membership matrix becomes very rich of information about how these sets overlap. Many analysis tasks targeted at set-typed data are concerned with these overlaps as salient features of such data. This paper presents Radial Sets, a novel visual technique to analyze set memberships for a large number of elements. Our technique uses frequency-based representations to enable quickly finding and analyzing different kinds of overlaps between the sets, and relating these overlaps to other attributes of the table entities. Furthermore, it enables various interactions to select elements of interest, find out if they are over-represented in specific sets or overlaps, and if they exhibit a different distribution for a specific attribute compared to the rest of the elements. These interactions allow formulating highly-expressive visual queries on the elements in terms of their set memberships and attribute values. As we demonstrate via two usage scenarios, Radial Sets enable revealing and analyzing a multitude of overlapping patterns between large sets, beyond the limits of state-of-the-art techniques."}, {"color": "orange", "id": 928, "label": 928, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 928 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.186\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Harald Bosch;Dennis Thom;Florian Heimerl;Edwin P\u00fcttmann;Steffen Koch;Robert Kr\u00fcger;Michael W\u00f6rner;Thomas Ertl; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: ScatterBlogs2: Real-Time Monitoring of Microblog Messages through User-Guided filtering; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The number of microblog posts published daily has reached a level that hampers the effective retrieval of relevant messages, and the amount of information conveyed through services such as Twitter is still increasing. Analysts require new methods for monitoring their topic of interest, dealing with the data volume and its dynamic nature. It is of particular importance to provide situational awareness for decision making in time-critical tasks. Current tools for monitoring microblogs typically filter messages based on user-defined keyword queries and metadata restrictions. Used on their own, such methods can have drawbacks with respect to filter accuracy and adaptability to changes in trends and topic structure. We suggest ScatterBlogs2, a new approach to let analysts build task-tailored message filters in an interactive and visual manner based on recorded messages of well-understood previous events. These message filters include supervised classification and query creation backed by the statistical distribution of terms and their co-occurrences. The created filter methods can be orchestrated and adapted afterwards for interactive, visual real-time monitoring and analysis of microblog feeds. We demonstrate the feasibility of our approach for analyzing the Twitter stream in emergency management scenarios."}, {"color": "blue", "id": 929, "label": 929, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 929 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.187\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Martin Fink;Jan-Henrik Haunert;Joachim Spoerhase;Alexander Wolff; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Selecting the Aspect Ratio of a Scatter Plot Based on Its Delaunay Triangulation; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Scatter plots are diagrams that visualize two-dimensional data as sets of points in the plane. They allow users to detect correlations and clusters in the data. Whether or not a user can accomplish these tasks highly depends on the aspect ratio selected for the plot, i.e., the ratio between the horizontal and the vertical extent of the diagram. We argue that an aspect ratio is good if the Delaunay triangulation of the scatter plot at this aspect ratio has some nice geometric property, e.g., a large minimum angle or a small total edge length. More precisely, we consider the following optimization problem. Given a set Q of points in the plane, find a scale factor s such that scaling the x-coordinates of the points in Q by s and the y-coordinates by 1=s yields a point set P(s) that optimizes a property of the Delaunay triangulation of P(s), over all choices of s. We present an algorithm that solves this problem efficiently and demonstrate its usefulness on real-world instances. Moreover, we discuss an empirical test in which we asked 64 participants to choose the aspect ratios of 18 scatter plots. We tested six different quality measures that our algorithm can optimize. In conclusion, minimizing the total edge length and minimizing what we call the \u0027uncompactness\u0027 of the triangles of the Delaunay triangulation yielded the aspect ratios that were most similar to those chosen by the participants in the test."}, {"color": "orange", "id": 930, "label": 930, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 930 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.188\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Xinran Hu;Lauren Bradel;Dipayan Maiti;Leanna House;Chris North;Scotland Leman; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Semantics of Directly Manipulating Spatializations; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: When high-dimensional data is visualized in a 2D plane by using parametric projection algorithms, users may wish to manipulate the layout of the data points to better reflect their domain knowledge or to explore alternative structures. However, few users are well-versed in the algorithms behind the visualizations, making parameter tweaking more of a guessing game than a series of decisive interactions. Translating user interactions into algorithmic input is a key component of Visual to Parametric Interaction (V2PI) [13]. Instead of adjusting parameters, users directly move data points on the screen, which then updates the underlying statistical model. However, we have found that some data points that are not moved by the user are just as important in the interactions as the data points that are moved. Users frequently move some data points with respect to some other \u0027unmoved\u0027 data points that they consider as spatially contextual. However, in current V2PI interactions, these points are not explicitly identified when directly manipulating the moved points. We design a richer set of interactions that makes this context more explicit, and a new algorithm and sophisticated weighting scheme that incorporates the importance of these unmoved data points into V2PI."}, {"color": "blue", "id": 933, "label": 933, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 933 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.191\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Bongshin Lee;Rubaiat Habib Kazi;Greg Smith; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: SketchStory: Telling More Engaging Stories with Data through Freeform Sketching; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Presenting and communicating insights to an audience-telling a story-is one of the main goals of data exploration. Even though visualization as a storytelling medium has recently begun to gain attention, storytelling is still underexplored in information visualization and little research has been done to help people tell their stories with data. To create a new, more engaging form of storytelling with data, we leverage and extend the narrative storytelling attributes of whiteboard animation with pen and touch interactions. We present SketchStory, a data-enabled digital whiteboard that facilitates the creation of personalized and expressive data charts quickly and easily. SketchStory recognizes a small set of sketch gestures for chart invocation, and automatically completes charts by synthesizing the visuals from the presenter-provided example icon and binding them to the underlying data. Furthermore, SketchStory allows the presenter to move and resize the completed data charts with touch, and filter the underlying data to facilitate interactive exploration. We conducted a controlled experiment for both audiences and presenters to compare SketchStory with a traditional presentation system, Microsoft PowerPoint. Results show that the audience is more engaged by presentations done with SketchStory than PowerPoint. Eighteen out of 24 audience participants preferred SketchStory to PowerPoint. Four out of five presenter participants also favored SketchStory despite the extra effort required for presentation."}, {"color": "blue", "id": 934, "label": 934, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 934 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.192\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Charles Perin;Romain Vuillemot;Jean-Daniel Fekete; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: SoccerStories: A Kick-off for Visual Soccer Analysis; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: This article presents SoccerStories, a visualization interface to support analysts in exploring soccer data and communicating interesting insights. Currently, most analyses on such data relate to statistics on individual players or teams. However, soccer analysts we collaborated with consider that quantitative analysis alone does not convey the right picture of the game, as context, player positions and phases of player actions are the most relevant aspects. We designed SoccerStories to support the current practice of soccer analysts and to enrich it, both in the analysis and communication stages. Our system provides an overview+detail interface of game phases, and their aggregation into a series of connected visualizations, each visualization being tailored for actions such as a series of passes or a goal attempt. To evaluate our tool, we ran two qualitative user studies on recent games using SoccerStories with data from one of the world\u0027s leading live sports data providers. The first study resulted in a series of four articles on soccer tactics, by a tactics analyst, who said he would not have been able to write these otherwise. The second study consisted in an exploratory follow-up to investigate design alternatives for embedding soccer phases into word-sized graphics. For both experiments, we received a very enthusiastic feedback and participants consider further use of SoccerStories to enhance their current workflow."}, {"color": "orange", "id": 935, "label": 935, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 935 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.193\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Natalia Andrienko;Gennady Andrienko;Louise Barrett;Marcus Dostie;Peter Henzi; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Space Transformation for Understanding Group Movement; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We suggest a methodology for analyzing movement behaviors of individuals moving in a group. Group movement is analyzed at two levels of granularity: the group as a whole and the individuals it comprises. For analyzing the relative positions and movements of the individuals with respect to the rest of the group, we apply space transformation, in which the trajectories of the individuals are converted from geographical space to an abstract \u0027group space\u0027. The group space reference system is defined by both the position of the group center, which is taken as the coordinate origin, and the direction of the group\u0027s movement. Based on the individuals\u0027 positions mapped onto the group space, we can compare the behaviors of different individuals, determine their roles and/or ranks within the groups, and, possibly, understand how group movement is organized. The utility of the methodology has been evaluated by applying it to a set of real data concerning movements of wild social animals and discussing the results with experts in animal ethology."}, {"color": "blue", "id": 937, "label": 937, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 937 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.196\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Shixia Liu;Yingcai Wu;Enxun Wei;Mengchen Liu;Yang Liu; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: StoryFlow: Tracking the Evolution of Stories; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Storyline visualizations, which are useful in many applications, aim to illustrate the dynamic relationships between entities in a story. However, the growing complexity and scalability of stories pose great challenges for existing approaches. In this paper, we propose an efficient optimization approach to generating an aesthetically appealing storyline visualization, which effectively handles the hierarchical relationships between entities over time. The approach formulates the storyline layout as a novel hybrid optimization approach that combines discrete and continuous optimization. The discrete method generates an initial layout through the ordering and alignment of entities, and the continuous method optimizes the initial layout to produce the optimal one. The efficient approach makes real-time interactions (e.g., bundling and straightening) possible, thus enabling users to better understand and track how the story evolves. Experiments and case studies are conducted to demonstrate the effectiveness and usefulness of the optimization approach."}, {"color": "orange", "id": 938, "label": 938, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 938 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.197\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Amir Hossein Hajizadeh;Melanie Tory;Rock Leung; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Supporting Awareness through Collaborative Brushing and Linking of Tabular Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Maintaining an awareness of collaborators\u0027 actions is critical during collaborative work, including during collaborative visualization activities. Particularly when collaborators are located at a distance, it is important to know what everyone is working on in order to avoid duplication of effort, share relevant results in a timely manner and build upon each other\u0027s results. Can a person\u0027s brushing actions provide an indication of their queries and interests in a data set? Can these actions be revealed to a collaborator without substantially disrupting their own independent work? We designed a study to answer these questions in the context of distributed collaborative visualization of tabular data. Participants in our study worked independently to answer questions about a tabular data set, while simultaneously viewing brushing actions of a fictitious collaborator, shown directly within a shared workspace. We compared three methods of presenting the collaborator\u0027s actions: brushing \u0026amp;amp; linking (i.e. highlighting exactly what the collaborator would see), selection (i.e. showing only a selected item), and persistent selection (i.e. showing only selected items but having them persist for some time). Our results demonstrated that persistent selection enabled some awareness of the collaborator\u0027s activities while causing minimal interference with independent work. Other techniques were less effective at providing awareness, and brushing \u0026amp;amp; linking caused substantial interference. These findings suggest promise for the idea of exploiting natural brushing actions to provide awareness in collaborative work."}, {"color": "orange", "id": 939, "label": 939, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 939 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.198\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Steffen Hadlak;Heidrun Schumann;Clemens H. Cap;Till Wollenberg; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Supporting the Visual Analysis of Dynamic Networks by Clustering associated Temporal Attributes; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The visual analysis of dynamic networks is a challenging task. In this paper, we introduce a new approach supporting the discovery of substructures sharing a similar trend over time by combining computation, visualization and interaction. With existing techniques, their discovery would be a tedious endeavor because of the number of nodes, edges as well as time points to be compared. First, on the basis of the supergraph, we therefore group nodes and edges according to their associated attributes that are changing over time. Second, the supergraph is visualized to provide an overview of the groups of nodes and edges with similar behavior over time in terms of their associated attributes. Third, we provide specific interactions to explore and refine the temporal clustering, allowing the user to further steer the analysis of the dynamic network. We demonstrate our approach by the visual analysis of a large wireless mesh network."}, {"color": "orange", "id": 940, "label": 940, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 940 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.200\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Megan Monroe;Rongjian Lan;Hanseung Lee;Catherine Plaisant;Ben Shneiderman; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Temporal Event Sequence Simplification; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Electronic Health Records (EHRs) have emerged as a cost-effective data source for conducting medical research. The difficulty in using EHRs for research purposes, however, is that both patient selection and record analysis must be conducted across very large, and typically very noisy datasets. Our previous work introduced EventFlow, a visualization tool that transforms an entire dataset of temporal event records into an aggregated display, allowing researchers to analyze population-level patterns and trends. As datasets become larger and more varied, however, it becomes increasingly difficult to provide a succinct, summarizing display. This paper presents a series of user-driven data simplifications that allow researchers to pare event records down to their core elements. Furthermore, we present a novel metric for measuring visual complexity, and a language for codifying disjoint strategies into an overarching simplification framework. These simplifications were used by real-world researchers to gain new and valuable insights from initially overwhelming datasets."}, {"color": "orange", "id": 942, "label": 942, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 942 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.206\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Alexander Rind;Tim Lammarsch;Wolfgang Aigner;Bilal Alsallakh;Silvia Miksch; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: TimeBench: A Data Model and Software Library for Visual Analytics of Time-Oriented Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Time-oriented data play an essential role in many Visual Analytics scenarios such as extracting medical insights from collections of electronic health records or identifying emerging problems and vulnerabilities in network traffic. However, many software libraries for Visual Analytics treat time as a flat numerical data type and insufficiently tackle the complexity of the time domain such as calendar granularities and intervals. Therefore, developers of advanced Visual Analytics designs need to implement temporal foundations in their application code over and over again. We present TimeBench, a software library that provides foundational data structures and algorithms for time-oriented data in Visual Analytics. Its expressiveness and developer accessibility have been evaluated through application examples demonstrating a variety of challenges with time-oriented data and long-term developer studies conducted in the scope of research and student projects."}, {"color": "orange", "id": 943, "label": 943, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 943 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.207\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Philip A. Legg;David H.S. Chung;Matthew L. Parry;Rhodri Bown;Mark W. Jones;Iwan W. Griffiths;Min Chen; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Transformation of an Uncertain Video Search Pipeline to a Sketch-Based Visual Analytics Loop; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Traditional sketch-based image or video search systems rely on machine learning concepts as their core technology. However, in many applications, machine learning alone is impractical since videos may not be semantically annotated sufficiently, there may be a lack of suitable training data, and the search requirements of the user may frequently change for different tasks. In this work, we develop a visual analytics systems that overcomes the shortcomings of the traditional approach. We make use of a sketch-based interface to enable users to specify search requirement in a flexible manner without depending on semantic annotation. We employ active machine learning to train different analytical models for different types of search requirements. We use visualization to facilitate knowledge discovery at the different stages of visual analytics. This includes visualizing the parameter space of the trained model, visualizing the search space to support interactive browsing, visualizing candidature search results to support rapid interaction for active learning while minimizing watching videos, and visualizing aggregated information of the search results. We demonstrate the system for searching spatiotemporal attributes from sports video to identify key instances of the team and player performance."}, {"color": "red", "id": 944, "label": 944, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 944 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.208\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Tushar Athawale;Alireza Entezari; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Uncertainty Quantification in Linear Interpolation for Isosurface Extraction; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present a study of linear interpolation when applied to uncertain data. Linear interpolation is a key step for isosurface extraction algorithms, and the uncertainties in the data lead to non-linear variations in the geometry of the extracted isosurface. We present an approach for deriving the probability density function of a random variable modeling the positional uncertainty in the isosurface extraction. When the uncertainty is quantified by a uniform distribution, our approach provides a closed-form characterization of the mentioned random variable. This allows us to derive, in closed form, the expected value as well as the variance of the level-crossing position. While the former quantity is used for constructing a stable isosurface for uncertain data, the latter is used for visualizing the positional uncertainties in the expected isosurface level crossings on the underlying grid."}, {"color": "orange", "id": 948, "label": 948, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 948 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.212\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jaegul Choo;Changhyun Lee;Chandan K. Reddy;Haesun Park; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: UTOPIAN: User-Driven Topic Modeling Based on Interactive Nonnegative Matrix Factorization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Topic modeling has been widely used for analyzing text document collections. Recently, there have been significant advancements in various topic modeling techniques, particularly in the form of probabilistic graphical modeling. State-of-the-art techniques such as Latent Dirichlet Allocation (LDA) have been successfully applied in visual text analytics. However, most of the widely-used methods based on probabilistic modeling have drawbacks in terms of consistency from multiple runs and empirical convergence. Furthermore, due to the complicatedness in the formulation and the algorithm, LDA cannot easily incorporate various types of user feedback. To tackle this problem, we propose a reliable and flexible visual analytics system for topic modeling called UTOPIAN (User-driven Topic modeling based on Interactive Nonnegative Matrix Factorization). Centered around its semi-supervised formulation, UTOPIAN enables users to interact with the topic modeling method and steer the result in a user-driven manner. We demonstrate the capability of UTOPIAN via several usage scenarios with real-world document corpuses such as InfoVis/VAST paper data set and product review data sets."}, {"color": "blue", "id": 950, "label": 950, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 950 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.214\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Joel A. Ferstay;Cydney B. Nielsen;Tamara Munzner; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Variant View: Visualizing Sequence Variants in their Gene Context; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Scientists use DNA sequence differences between an individual\u0027s genome and a standard reference genome to study the genetic basis of disease. Such differences are called sequence variants, and determining their impact in the cell is difficult because it requires reasoning about both the type and location of the variant across several levels of biological context. In this design study, we worked with four analysts to design a visualization tool supporting variant impact assessment for three different tasks. We contribute data and task abstractions for the problem of variant impact assessment, and the carefully justified design and implementation of the Variant View tool. Variant View features an information-dense visual encoding that provides maximal information at the overview level, in contrast to the extensive navigation required by currently-prevalent genome browsers. We provide initial evidence that the tool simplified and accelerated workflows for these three tasks through three case studies. Finally, we reflect on the lessons learned in creating and refining data and task abstractions that allow for concise overviews of sprawling information spaces that can reduce or remove the need for the memory-intensive use of navigation."}, {"color": "orange", "id": 953, "label": 953, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 953 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.220\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Rachel Shadoan;Chris Weaver; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visual Analysis of Higher-Order Conjunctive Relationships in Multidimensional Data Using a Hypergraph Query System; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Visual exploration and analysis of multidimensional data becomes increasingly difficult with increasing dimensionality. We want to understand the relationships between dimensions of data, but lack flexible techniques for exploration beyond low-order relationships. Current visual techniques for multidimensional data analysis focus on binary conjunctive relationships between dimensions. Recent techniques, such as cross-filtering on an attribute relationship graph, facilitate the exploration of some higher-order conjunctive relationships, but require a great deal of care and precision to do so effectively. This paper provides a detailed analysis of the expressive power of existing visual querying systems and describes a more flexible approach in which users can explore n-ary conjunctive inter- and intra- dimensional relationships by interactively constructing queries as visual hypergraphs. In a hypergraph query, nodes represent subsets of values and hyperedges represent conjunctive relationships. Analysts can dynamically build and modify the query using sequences of simple interactions. The hypergraph serves not only as a query specification, but also as a compact visual representation of the interactive state. Using examples from several domains, focusing on the digital humanities, we describe the design considerations for developing the querying system and incorporating it into visual analysis tools. We analyze query expressiveness with regard to the kinds of questions it can and cannot pose, and describe how it simultaneously expands the expressiveness of and is complemented by cross-filtering."}, {"color": "orange", "id": 954, "label": 954, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 954 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.221\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Panpan Xu;Yingcai Wu;Enxun Wei;Tai-Quan Peng;Shixia Liu;Jonathan J.H. Zhu;Huamin Qu; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visual Analysis of Topic Competition on Social Media; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: How do various topics compete for public attention when they are spreading on social media? What roles do opinion leaders play in the rise and fall of competitiveness of various topics? In this study, we propose an expanded topic competition model to characterize the competition for public attention on multiple topics promoted by various opinion leaders on social media. To allow an intuitive understanding of the estimated measures, we present a timeline visualization through a metaphoric interpretation of the results. The visual design features both topical and social aspects of the information diffusion process by compositing ThemeRiver with storyline style visualization. ThemeRiver shows the increase and decrease of competitiveness of each topic. Opinion leaders are drawn as threads that converge or diverge with regard to their roles in influencing the public agenda change over time. To validate the effectiveness of the visual analysis techniques, we report the insights gained on two collections of Tweets: the 2012 United States presidential election and the Occupy Wall Street movement."}, {"color": "orange", "id": 956, "label": 956, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 956 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.223\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Sohaib Ghani;Bum Chul Kwon;Seungyoon Lee;Ji Soo Yi;Niklas Elmqvist; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visual Analytics for Multimodal Social Network Analysis: A Design Study with Social Scientists; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Social network analysis (SNA) is becoming increasingly concerned not only with actors and their relations, but also with distinguishing between different types of such entities. For example, social scientists may want to investigate asymmetric relations in organizations with strict chains of command, or incorporate non-actors such as conferences and projects when analyzing coauthorship patterns. Multimodal social networks are those where actors and relations belong to different types, or modes, and multimodal social network analysis (mSNA) is accordingly SNA for such networks. In this paper, we present a design study that we conducted with several social scientist collaborators on how to support mSNA using visual analytics tools. Based on an openended, formative design process, we devised a visual representation called parallel node-link bands (PNLBs) that splits modes into separate bands and renders connections between adjacent ones, similar to the list view in Jigsaw. We then used the tool in a qualitative evaluation involving five social scientists whose feedback informed a second design phase that incorporated additional network metrics. Finally, we conducted a second qualitative evaluation with our social scientist collaborators that provided further insights on the utility of the PNLBs representation and the potential of visual analytics for mSNA."}, {"color": "orange", "id": 957, "label": 957, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 957 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.224\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Eli Packer;Peter Bak;Mikko Nikkil\u00e4;Valentin Polishchuk;Harold J. Ship; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visual Analytics for Spatial Clustering: Using a Heuristic Approach for Guided Exploration; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We propose a novel approach of distance-based spatial clustering and contribute a heuristic computation of input parameters for guiding users in the search of interesting cluster constellations. We thereby combine computational geometry with interactive visualization into one coherent framework. Our approach entails displaying the results of the heuristics to users, as shown in Figure 1, providing a setting from which to start the exploration and data analysis. Addition interaction capabilities are available containing visual feedback for exploring further clustering options and is able to cope with noise in the data. We evaluate, and show the benefits of our approach on a sophisticated artificial dataset and demonstrate its usefulness on real-world data."}, {"color": "orange", "id": 959, "label": 959, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 959 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.226\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Nivan Ferreira;Jorge Poco;Huy T. Vo;Juliana Freire;Cl\u00e1udio T. Silva; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visual Exploration of Big Spatio-Temporal Urban Data: A Study of New York City Taxi Trips; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: As increasing volumes of urban data are captured and become available, new opportunities arise for data-driven analysis that can lead to improvements in the lives of citizens through evidence-based decision making and policies. In this paper, we focus on a particularly important urban data set: taxi trips. Taxis are valuable sensors and information associated with taxi trips can provide unprecedented insight into many different aspects of city life, from economic activity and human behavior to mobility patterns. But analyzing these data presents many challenges. The data are complex, containing geographical and temporal components in addition to multiple variables associated with each trip. Consequently, it is hard to specify exploratory queries and to perform comparative analyses (e.g., compare different regions over time). This problem is compounded due to the size of the data-there are on average 500,000 taxi trips each day in NYC. We propose a new model that allows users to visually query taxi trips. Besides standard analytics queries, the model supports origin-destination queries that enable the study of mobility across the city. We show that this model is able to express a wide range of spatio-temporal queries, and it is also flexible in that not only can queries be composed but also different aggregations and visual representations can be applied, allowing users to explore and compare results. We have built a scalable system that implements this model which supports interactive response times; makes use of an adaptive level-of-detail rendering strategy to generate clutter-free visualization for large results; and shows hidden details to the users in a summary through the use of overlay heat maps. We present a series of case studies motivated by traffic engineers and economists that show how our model and system enable domain experts to perform tasks that were previously unattainable for them."}, {"color": "blue", "id": 960, "label": 960, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 960 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.227\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Samuel Huron;Romain Vuillemot;Jean-Daniel Fekete; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visual Sedimentation; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We introduce Visual Sedimentation, a novel design metaphor for visualizing data streams directly inspired by the physical process of sedimentation. Visualizing data streams (e. g., Tweets, RSS, Emails) is challenging as incoming data arrive at unpredictable rates and have to remain readable. For data streams, clearly expressing chronological order while avoiding clutter, and keeping aging data visible, are important. The metaphor is drawn from the real-world sedimentation processes: objects fall due to gravity, and aggregate into strata over time. Inspired by this metaphor, data is visually depicted as falling objects using a force model to land on a surface, aggregating into strata over time. In this paper, we discuss how this metaphor addresses the specific challenge of smoothing the transition between incoming and aging data. We describe the metaphor\u0027s design space, a toolkit developed to facilitate its implementation, and example applications to a range of case studies. We then explore the generative capabilities of the design space through our toolkit. We finally illustrate creative extensions of the metaphor when applied to real streams of data."}, {"color": "orange", "id": 961, "label": 961, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 961 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.228\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Zuchao Wang;Min Lu;Xiaoru Yuan;Junping Zhang;Huub van de Wetering; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visual Traffic Jam Analysis Based on Trajectory Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In this work, we present an interactive system for visual analysis of urban traffic congestion based on GPS trajectories. For these trajectories we develop strategies to extract and derive traffic jam information. After cleaning the trajectories, they are matched to a road network. Subsequently, traffic speed on each road segment is computed and traffic jam events are automatically detected. Spatially and temporally related events are concatenated in, so-called, traffic jam propagation graphs. These graphs form a high-level description of a traffic jam and its propagation in time and space. Our system provides multiple views for visually exploring and analyzing the traffic condition of a large city as a whole, on the level of propagation graphs, and on road segment level. Case studies with 24 days of taxi GPS trajectories collected in Beijing demonstrate the effectiveness of our system."}, {"color": "blue", "id": 965, "label": 965, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 965 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.232\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Corinna Vehlow;Thomas Reinhardt;Daniel Weiskopf; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visualizing Fuzzy Overlapping Communities in Networks; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: An important feature of networks for many application domains is their community structure. This is because objects within the same community usually have at least one property in common. The investigation of community structure can therefore support the understanding of object attributes from the network topology alone. In real-world systems, objects may belong to several communities at the same time, i.e., communities can overlap. Analyzing fuzzy community memberships is essential to understand to what extent objects contribute to different communities and whether some communities are highly interconnected. We developed a visualization approach that is based on node-link diagrams and supports the investigation of fuzzy communities in weighted undirected graphs at different levels of detail. Starting with the network of communities, the user can continuously drill down to the network of individual nodes and finally analyze the membership distribution of nodes of interest. Our approach uses layout strategies and further visual mappings to graphically encode the fuzzy community memberships. The usefulness of our approach is illustrated by two case studies analyzing networks of different domains: social networking and biological interactions. The case studies showed that our layout and visualization approach helps investigate fuzzy overlapping communities. Fuzzy vertices as well as the different communities to which they belong can be easily identified based on node color and position."}, {"color": "blue", "id": 967, "label": 967, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 967 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2013.234\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Michelle A. Borkin;Azalea A. Vo;Zoya Bylinskii;Phillip Isola;Shashank Sunkavalli;Aude Oliva;Hanspeter Pfister; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: What Makes a Visualization Memorable?; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: An ongoing debate in the Visualization community concerns the role that visualization types play in data understanding. In human cognition, understanding and memorability are intertwined. As a first step towards being able to ask questions about impact and effectiveness, here we ask: \u0027What makes a visualization memorable?\u0027 We ran the largest scale visualization study to date using 2,070 single-panel visualizations, categorized with visualization type (e.g., bar chart, line graph, etc.), collected from news media sites, government reports, scientific journals, and infographic sources. Each visualization was annotated with additional attributes, including ratings for data-ink ratios and visual densities. Using Amazon\u0027s Mechanical Turk, we collected memorability scores for hundreds of these visualizations, and discovered that observers are consistent in which visualizations they find memorable and forgettable. We find intuitive results (e.g., attributes like color and the inclusion of a human recognizable object enhance memorability) and less intuitive results (e.g., common graphs are less memorable than unique visualization types). Altogether our findings suggest that quantifying memorability is a general metric of the utility of information, an essential step towards determining how to design effective visualizations."}, {"color": "blue", "id": 968, "label": 968, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 968 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346248\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Alexander Lex;Nils Gehlenborg;Hendrik Strobelt;Romain Vuillemot;Hanspeter Pfister; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: UpSet: Visualization of Intersecting Sets; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Understanding relationships between sets is an important analysis task that has received widespread attention in the visualization community. The major challenge in this context is the combinatorial explosion of the number of set intersections if the number of sets exceeds a trivial threshold. In this paper we introduce UpSet, a novel visualization technique for the quantitative analysis of sets, their intersections, and aggregates of intersections. UpSet is focused on creating task-driven aggregates, communicating the size and properties of aggregates and intersections, and a duality between the visualization of the elements in a dataset and their set membership. UpSet visualizes set intersections in a matrix layout and introduces aggregates based on groupings and queries. The matrix layout enables the effective representation of associated data, such as the number of elements in the aggregates and intersections, as well as additional summary statistics derived from subset or element attributes. Sorting according to various measures enables a task-driven analysis of relevant intersections and aggregates. The elements represented in the sets and their associated attributes are visualized in a separate view. Queries based on containment in specific intersections, aggregates or driven by attribute filters are propagated between both views. We also introduce several advanced visual encodings and interaction methods to overcome the problems of varying scales and to address scalability. UpSet is web-based and open source. We demonstrate its general utility in multiple use cases from various domains."}, {"color": "blue", "id": 969, "label": 969, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 969 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346249\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Ramik Sadana;Timothy Major;Alistair Dove;John Stasko; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: OnSet: A Visualization Technique for Large-scale Binary Set Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Visualizing sets to reveal relationships between constituent elements is a complex representational problem. Recent research presents several automated placement and grouping techniques to highlight connections between set elements. However, these techniques do not scale well for sets with cardinality greater than one hundred elements. We present OnSet, an interactive, scalable visualization technique for representing large-scale binary set data. The visualization technique defines a single, combined domain of elements for all sets, and models each set by the elements that it both contains and does not contain. OnSet employs direct manipulation interaction and visual highlighting to support easy identification of commonalities and differences as well as membership patterns across different sets of elements. We present case studies to illustrate how the technique can be successfully applied across different domains such as bio-chemical metabolomics and task and event scheduling."}, {"color": "blue", "id": 970, "label": 970, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 970 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346250\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Brittany Kondo;Christopher Collins; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: DimpVis: Exploring Time-varying Information Visualizations by Direct Manipulation; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We introduce a new direct manipulation technique, DimpVis, for interacting with visual items in information visualizations to enable exploration of the time dimension. DimpVis is guided by visual hint paths which indicate how a selected data item changes through the time dimension in a visualization. Temporal navigation is controlled by manipulating any data item along its hint path. All other items are updated to reflect the new time. We demonstrate how the DimpVis technique can be designed to directly manipulate position, colour, and size in familiar visualizations such as bar charts and scatter plots, as a means for temporal navigation. We present results from a comparative evaluation, showing that the DimpVis technique was subjectively preferred and quantitatively competitive with the traditional time slider, and significantly faster than small multiples for a variety of tasks."}, {"color": "blue", "id": 972, "label": 972, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 972 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346260\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Samuel Gratzl;Nils Gehlenborg;Alexander Lex;Hanspeter Pfister;Marc Streit; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Domino: Extracting, Comparing, and Manipulating Subsets Across Multiple Tabular Datasets; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Answering questions about complex issues often requires analysts to take into account information contained in multiple interconnected datasets. A common strategy in analyzing and visualizing large and heterogeneous data is dividing it into meaningful subsets. Interesting subsets can then be selected and the associated data and the relationships between the subsets visualized. However, neither the extraction and manipulation nor the comparison of subsets is well supported by state-of-the-art techniques. In this paper we present Domino, a novel multiform visualization technique for effectively representing subsets and the relationships between them. By providing comprehensive tools to arrange, combine, and extract subsets, Domino allows users to create both common visualization techniques and advanced visualizations tailored to specific use cases. In addition to the novel technique, we present an implementation that enables analysts to manage the wide range of options that our approach offers. Innovative interactive features such as placeholders and live previews support rapid creation of complex analysis setups. We introduce the technique and the implementation using a simple example and demonstrate scalability and effectiveness in a use case from the field of cancer genomics."}, {"color": "blue", "id": 973, "label": 973, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 973 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346265\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Cagatay Turkay;Aidan Slingsby;Helwig Hauser;Jo Wood;Jason Dykes; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Attribute Signatures: Dynamic Visual Summaries for Analyzing Multivariate Geographical Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The visual analysis of geographically referenced datasets with a large number of attributes is challenging due to the fact that the characteristics of the attributes are highly dependent upon the locations at which they are focussed, and the scale and time at which they are measured. Specialized interactive visual methods are required to help analysts in understanding the characteristics of the attributes when these multiple aspects are considered concurrently. Here, we develop attribute signatures-interactively crafted graphics that show the geographic variability of statistics of attributes through which the extent of dependency between the attributes and geography can be visually explored. We compute a number of statistical measures, which can also account for variations in time and scale, and use them as a basis for our visualizations. We then employ different graphical configurations to show and compare both continuous and discrete variation of location and scale. Our methods allow variation in multiple statistical summaries of multiple attributes to be considered concurrently and geographically, as evidenced by examples in which the census geography of London and the wider UK are explored."}, {"color": "blue", "id": 974, "label": 974, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 974 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346271\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Diansheng Guo;Xi Zhu; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Origin-Destination Flow Data Smoothing and Mapping; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: This paper presents a new approach to flow mapping that extracts inherent patterns from massive geographic mobility data and constructs effective visual representations of the data for the understanding of complex flow trends. This approach involves a new method for origin-destination flow density estimation and a new method for flow map generalization, which together can remove spurious data variance, normalize flows with control population, and detect high-level patterns that are not discernable with existing approaches. The approach achieves three main objectives in addressing the challenges for analyzing and mapping massive flow data. First, it removes the effect of size differences among spatial units via kernel-based density estimation, which produces a measurement of flow volume between each pair of origin and destination. Second, it extracts major flow patterns in massive flow data through a new flow sampling method, which filters out duplicate information in the smoothed flows. Third, it enables effective flow mapping and allows intuitive perception of flow patterns among origins and destinations without bundling or altering flow paths. The approach can work with both point-based flow data (such as taxi trips with GPS locations) and area-based flow data (such as county-to-county migration). Moreover, the approach can be used to detect and compare flow patterns at different scales or in relatively sparse flow datasets, such as migration for each age group. We evaluate and demonstrate the new approach with case studies of U.S. migration data and experiments with synthetic data."}, {"color": "blue", "id": 979, "label": 979, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 979 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346291\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Donghao Ren;Tobias H\u00f6llerer;Xiaoru Yuan; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: iVisDesigner: Expressive Interactive Design of Information Visualizations; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present the design, implementation and evaluation of iVisDesigner, a web-based system that enables users to design information visualizations for complex datasets interactively, without the need for textual programming. Our system achieves high interactive expressiveness through conceptual modularity, covering a broad information visualization design space. iVisDesigner supports the interactive design of interactive visualizations, such as provisioning for responsive graph layouts and different types of brushing and linking interactions. We present the system design and implementation, exemplify it through a variety of illustrative visualization designs and discuss its limitations. A performance analysis and an informal user study are presented to evaluate the system."}, {"color": "blue", "id": 980, "label": 980, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 980 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346292\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Samuel Huron;Yvonne Jansen;Sheelagh Carpendale; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Constructing Visual Representations: Investigating the Use of Tangible Tokens; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The accessibility of infovis authoring tools to a wide audience has been identified as a major research challenge. A key task in the authoring process is the development of visual mappings. While the infovis community has long been deeply interested in finding effective visual mappings, comparatively little attention has been placed on how people construct visual mappings. In this paper, we present the results of a study designed to shed light on how people transform data into visual representations. We asked people to create, update and explain their own information visualizations using only tangible building blocks. We learned that all participants, most of whom had little experience in visualization authoring, were readily able to create and talk about their own visualizations. Based on our observations, we discuss participants\u0027 actions during the development of their visual representations and during their analytic activities. We conclude by suggesting implications for tool design to enable broader support for infovis authoring."}, {"color": "blue", "id": 981, "label": 981, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 981 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346293\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Emanuel Zgraggen;Robert Zeleznik;Steven M. Drucker; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: PanoramicData: Data Analysis through Pen \u0026 Touch; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Interactively exploring multidimensional datasets requires frequent switching among a range of distinct but inter-related tasks (e.g., producing different visuals based on different column sets, calculating new variables, and observing the interactions between sets of data). Existing approaches either target specific different problem domains (e.g., data-transformation or data-presentation) or expose only limited aspects of the general exploratory process; in either case, users are forced to adopt coping strategies (e.g., arranging windows or using undo as a mechanism for comparison instead of using side-by-side displays) to compensate for the lack of an integrated suite of exploratory tools. PanoramicData (PD) addresses these problems by unifying a comprehensive set of tools for visual data exploration into a hybrid pen and touch system designed to exploit the visualization advantages of large interactive displays. PD goes beyond just familiar visualizations by including direct UI support for data transformation and aggregation, filtering and brushing. Leveraging an unbounded whiteboard metaphor, users can combine these tools like building blocks to create detailed interactive visual display networks in which each visualization can act as a filter for others. Further, by operating directly on relational-databases, PD provides an approachable visual language that exposes a broad set of the expressive power of SQL including functionally complete logic filtering, computation of aggregates and natural table joins. To understand the implications of this novel approach, we conducted a formative user study with both data and visualization experts. The results indicated that the system provided a fluid and natural user experience for probing multi-dimensional data and was able to cover the full range of queries that the users wanted to pose."}, {"color": "blue", "id": 983, "label": 983, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 983 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346298\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Michael Correll;Michael Gleicher; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Error Bars Considered Harmful: Exploring Alternate Encodings for Mean and Error; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: When making an inference or comparison with uncertain, noisy, or incomplete data, measurement error and confidence intervals can be as important for judgment as the actual mean values of different groups. These often misunderstood statistical quantities are frequently represented by bar charts with error bars. This paper investigates drawbacks with this standard encoding, and considers a set of alternatives designed to more effectively communicate the implications of mean and error data to a general audience, drawing from lessons learned from the use of visual statistics in the information visualization community. We present a series of crowd-sourced experiments that confirm that the encoding of mean and error significantly changes how viewers make decisions about uncertain data. Careful consideration of design tradeoffs in the visual presentation of data results in human reasoning that is more consistently aligned with statistical inferences. We suggest the use of gradient plots (which use transparency to encode uncertainty) and violin plots (which use width) as better alternatives for inferential tasks than bar charts with error bars."}, {"color": "blue", "id": 985, "label": 985, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 985 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346312\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Ali K. Al-Awami;Johanna Beyer;Hendrik Strobelt;Narayanan Kasthuri;Jeff W. Lichtman;Hanspeter Pfister;Markus Hadwiger; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: NeuroLines: A Subway Map Metaphor for Visualizing Nanoscale Neuronal Connectivity; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present NeuroLines, a novel visualization technique designed for scalable detailed analysis of neuronal connectivity at the nanoscale level. The topology of 3D brain tissue data is abstracted into a multi-scale, relative distance-preserving subway map visualization that allows domain scientists to conduct an interactive analysis of neurons and their connectivity. Nanoscale connectomics aims at reverse-engineering the wiring of the brain. Reconstructing and analyzing the detailed connectivity of neurons and neurites (axons, dendrites) will be crucial for understanding the brain and its development and diseases. However, the enormous scale and complexity of nanoscale neuronal connectivity pose big challenges to existing visualization techniques in terms of scalability. NeuroLines offers a scalable visualization framework that can interactively render thousands of neurites, and that supports the detailed analysis of neuronal structures and their connectivity. We describe and analyze the design of NeuroLines based on two real-world use-cases of our collaborators in developmental neuroscience, and investigate its scalability to large-scale neuronal connectivity data."}, {"color": "red", "id": 987, "label": 987, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 987 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346318\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Peter Rautek;Stefan Bruckner;M. Eduard Gr\u00f6ller;Markus Hadwiger; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: ViSlang: A System for Interpreted Domain-Specific Languages for Scientific Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Researchers from many domains use scientific visualization in their daily practice. Existing implementations of algorithms usually come with a graphical user interface (high-level interface), or as software library or source code (low-level interface). In this paper we present a system that integrates domain-specific languages (DSLs) and facilitates the creation of new DSLs. DSLs provide an effective interface for domain scientists avoiding the difficulties involved with low-level interfaces and at the same time offering more flexibility than high-level interfaces. We describe the design and implementation of ViSlang, an interpreted language specifically tailored for scientific visualization. A major contribution of our design is the extensibility of the ViSlang language. Novel DSLs that are tailored to the problems of the domain can be created and integrated into ViSlang. We show that our approach can be added to existing user interfaces to increase the flexibility for expert users on demand, but at the same time does not interfere with the user experience of novice users. To demonstrate the flexibility of our approach we present new DSLs for volume processing, querying and visualization. We report the implementation effort for new DSLs and compare our approach with Matlab and Python implementations in terms of run-time performance."}, {"color": "blue", "id": 990, "label": 990, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 990 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346321\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Michael Sedlmair;Christoph Heinzl;Stefan Bruckner;Harald Piringer;Torsten M\u00f6ller; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visual Parameter Space Analysis: A Conceptual Framework; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Various case studies in different application domains have shown the great potential of visual parameter space analysis to support validating and using simulation models. In order to guide and systematize research endeavors in this area, we provide a conceptual framework for visual parameter space analysis problems. The framework is based on our own experience and a structured analysis of the visualization literature. It contains three major components: (1) a data flow model that helps to abstractly describe visual parameter space analysis problems independent of their application domain; (2) a set of four navigation strategies of how parameter space analysis can be supported by visualization tools; and (3) a characterization of six analysis tasks. Based on our framework, we analyze and classify the current body of literature, and identify three open research gaps in visual parameter space analysis. The framework and its discussion are meant to support visualization designers and researchers in characterizing parameter space analysis problems and to guide their design and evaluation processes."}, {"color": "red", "id": 991, "label": 991, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 991 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346322\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Hyungsuk Choi;Woohyuk Choi;Tran Minh Quan;David G. C. Hildebrand;Hanspeter Pfister;Won-Ki Jeong; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Vivaldi: A Domain-Specific Language for Volume Processing and Visualization on Distributed Heterogeneous Systems; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: As the size of image data from microscopes and telescopes increases, the need for high-throughput processing and visualization of large volumetric data has become more pressing. At the same time, many-core processors and GPU accelerators are commonplace, making high-performance distributed heterogeneous computing systems affordable. However, effectively utilizing GPU clusters is difficult for novice programmers, and even experienced programmers often fail to fully leverage the computing power of new parallel architectures due to their steep learning curve and programming complexity. In this paper, we propose Vivaldi, a new domain-specific language for volume processing and visualization on distributed heterogeneous computing systems. Vivaldi\u0027s Python-like grammar and parallel processing abstractions provide flexible programming tools for non-experts to easily write high-performance parallel computing code. Vivaldi provides commonly used functions and numerical operators for customized visualization and high-throughput image processing applications. We demonstrate the performance and usability of Vivaldi on several examples ranging from volume rendering to image segmentation."}, {"color": "blue", "id": 992, "label": 992, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 992 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346323\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jo Wood;Roger Beecham;Jason Dykes; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Moving beyond sequential design: Reflections on a rich multi-channel approach to data visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We reflect on a four-year engagement with transport authorities and others involving a large dataset describing the use of a public bicycle-sharing scheme. We describe the role visualization of these data played in fostering engagement with policy makers, transport operators, the transport research community, the museum and gallery sector and the general public. We identify each of these as `channels\u0027-evolving relationships between producers and consumers of visualization-where traditional roles of the visualization expert and domain expert are blurred. In each case, we identify the different design decisions that were required to support each of these channels and the role played by the visualization process. Using chauffeured interaction with a flexible visual analytics system we demonstrate how insight was gained by policy makers into gendered spatio-temporal cycle behaviors, how this led to further insight into workplace commuting activity, group cycling behavior and explanations for street navigation choice. We demonstrate how this supported, and was supported by, the seemingly unrelated development of narrative-driven visualization via TEDx, of the creation and the setting of an art installation and the curating of digital and physical artefacts. We assert that existing models of visualization design, of tool/technique development and of insight generation do not adequately capture the richness of parallel engagement via these multiple channels of communication. We argue that developing multiple channels in parallel opens up opportunities for visualization design and analysis by building trust and authority and supporting creativity. This rich, non-sequential approach to visualization design is likely to foster serendipity, deepen insight and increase impact."}, {"color": "blue", "id": 994, "label": 994, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 994 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346325\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Gordon Kindlmann;Carlos Scheidegger; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: An Algebraic Process for Visualization Design; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present a model of visualization design based on algebraic considerations of the visualization process. The model helps characterize visual encodings, guide their design, evaluate their effectiveness, and highlight their shortcomings. The model has three components: the underlying mathematical structure of the data or object being visualized, the concrete representation of the data in a computer, and (to the extent possible) a mathematical description of how humans perceive the visualization. Because we believe the value of our model lies in its practical application, we propose three general principles for good visualization design. We work through a collection of examples where our model helps explain the known properties of existing visualizations methods, both good and not-so-good, as well as suggesting some novel methods. We describe how to use the model alongside experimental user studies, since it can help frame experiment outcomes in an actionable manner. Exploring the implications and applications of our model and its design principles should provide many directions for future visualization research."}, {"color": "blue", "id": 995, "label": 995, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 995 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346331\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Sean McKenna;Dominika Mazur;James Agutter;Miriah Meyer; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Design Activity Framework for Visualization Design; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: An important aspect in visualization design is the connection between what a designer does and the decisions the designer makes. Existing design process models, however, do not explicitly link back to models for visualization design decisions. We bridge this gap by introducing the design activity framework, a process model that explicitly connects to the nested model, a well-known visualization design decision model. The framework includes four overlapping activities that characterize the design process, with each activity explicating outcomes related to the nested model. Additionally, we describe and characterize a list of exemplar methods and how they overlap among these activities. The design activity framework is the result of reflective discussions from a collaboration on a visualization redesign project, the details of which we describe to ground the framework in a real-world design process. Lastly, from this redesign project we provide several research outcomes in the domain of cybersecurity, including an extended data abstraction and rich opportunities for future visualization research."}, {"color": "red", "id": 996, "label": 996, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 996 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346332\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Dilip Mathew Thomas;Vijay Natarajan; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Multiscale Symmetry Detection in Scalar Fields by Clustering Contours; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The complexity in visualizing volumetric data often limits the scope of direct exploration of scalar fields. Isocontour extraction is a popular method for exploring scalar fields because of its simplicity in presenting features in the data. In this paper, we present a novel representation of contours with the aim of studying the similarity relationship between the contours. The representation maps contours to points in a high-dimensional transformation-invariant descriptor space. We leverage the power of this representation to design a clustering based algorithm for detecting symmetric regions in a scalar field. Symmetry detection is a challenging problem because it demands both segmentation of the data and identification of transformation invariant segments. While the former task can be addressed using topological analysis of scalar fields, the latter requires geometry based solutions. Our approach combines the two by utilizing the contour tree for segmenting the data and the descriptor space for determining transformation invariance. We discuss two applications, query driven exploration and asymmetry visualization, that demonstrate the effectiveness of the approach."}, {"color": "blue", "id": 1012, "label": 1012, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1012 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346422\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Bahador Saket;Paolo Simonetto;Stephen Kobourov;Katy B\u00f6rner; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Node, Node-Link, and Node-Link-Group Diagrams: An Evaluation; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Effectively showing the relationships between objects in a dataset is one of the main tasks in information visualization. Typically there is a well-defined notion of distance between pairs of objects, and traditional approaches such as principal component analysis or multi-dimensional scaling are used to place the objects as points in 2D space, so that similar objects are close to each other. In another typical setting, the dataset is visualized as a network graph, where related nodes are connected by links. More recently, datasets are also visualized as maps, where in addition to nodes and links, there is an explicit representation of groups and clusters. We consider these three Techniques, characterized by a progressive increase of the amount of encoded information: node diagrams, node-link diagrams and node-link-group diagrams. We assess these three types of diagrams with a controlled experiment that covers nine different tasks falling broadly in three categories: node-based tasks, network-based tasks and group-based tasks. Our findings indicate that adding links, or links and group representations, does not negatively impact performance (time and accuracy) of node-based tasks. Similarly, adding group representations does not negatively impact the performance of network-based tasks. Node-link-group diagrams outperform the others on group-based tasks. These conclusions contradict results in other studies, in similar but subtly different settings. Taken together, however, such results can have significant implications for the design of standard and domain snecific visualizations tools."}, {"color": "blue", "id": 1014, "label": 1014, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1014 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346424\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Fanny Chevalier;Pierre Dragicevic;Steven Franconeri; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: The Not-so-Staggering Effect of Staggered Animated Transitions on Visual Tracking; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Interactive visual applications often rely on animation to transition from one display state to another. There are multiple animation techniques to choose from, and it is not always clear which should produce the best visual correspondences between display elements. One major factor is whether the animation relies on staggering-an incremental delay in start times across the moving elements. It has been suggested that staggering may reduce occlusion, while also reducing display complexity and producing less overwhelming animations, though no empirical evidence has demonstrated these advantages. Work in perceptual psychology does show that reducing occlusion, and reducing inter-object proximity (crowding) more generally, improves performance in multiple object tracking. We ran simulations confirming that staggering can in some cases reduce crowding in animated transitions involving dot clouds (as found in, e.g., animated 2D scatterplots). We empirically evaluated the effect of two staggering techniques on tracking tasks, focusing on cases that should most favour staggering. We found that introducing staggering has a negligible, or even negative, impact on multiple object tracking performance. The potential benefits of staggering may be outweighed by strong costs: a loss of common-motion grouping information about which objects travel in similar paths, and less predictability about when any specific object would begin to move. Staggering may be beneficial in some conditions, but they have yet to be demonstrated. The present results are a significant step toward a better understanding of animation pacing, and provide direction for further research."}, {"color": "blue", "id": 1018, "label": 1018, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1018 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346431\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Matthew Brehmer;Stephen Ingram;Jonathan Stray;Tamara Munzner; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Overview: The Design, Adoption, and Analysis of a Visual Document Mining Tool for Investigative Journalists; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: For an investigative journalist, a large collection of documents obtained from a Freedom of Information Act request or a leak is both a blessing and a curse: such material may contain multiple newsworthy stories, but it can be difficult and time consuming to find relevant documents. Standard text search is useful, but even if the search target is known it may not be possible to formulate an effective query. In addition, summarization is an important non-search task. We present Overview, an application for the systematic analysis of large document collections based on document clustering, visualization, and tagging. This work contributes to the small set of design studies which evaluate a visualization system \u201cin the wild\u201d, and we report on six case studies where Overview was voluntarily used by self-initiated journalists to produce published stories. We find that the frequently-used language of \u201cexploring\u201d a document collection is both too vague and too narrow to capture how journalists actually used our application. Our iterative process, including multiple rounds of deployment and observations of real world usage, led to a much more specific characterization of tasks. We analyze and justify the visual encoding and interaction techniques used in Overview\u0027s design with respect to our final task abstractions, and propose generalizable lessons for visualization design methodology."}, {"color": "blue", "id": 1020, "label": 1020, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1020 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346433\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Weiwei Cui;Shixia Liu;Zhuofeng Wu;Hao Wei; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: How Hierarchical Topics Evolve in Large Text Corpora; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Using a sequence of topic trees to organize documents is a popular way to represent hierarchical and evolving topics in text corpora. However, following evolving topics in the context of topic trees remains difficult for users. To address this issue, we present an interactive visual text analysis approach to allow users to progressively explore and analyze the complex evolutionary patterns of hierarchical topics. The key idea behind our approach is to exploit a tree cut to approximate each tree and allow users to interactively modify the tree cuts based on their interests. In particular, we propose an incremental evolutionary tree cut algorithm with the goal of balancing 1) the fitness of each tree cut and the smoothness between adjacent tree cuts; 2) the historical and new information related to user interests. A time-based visualization is designed to illustrate the evolving topics over time. To preserve the mental map, we develop a stable layout algorithm. As a result, our approach can quickly guide users to progressively gain profound insights into evolving hierarchical topics. We evaluate the effectiveness of the proposed method on Amazon\u0027s Mechanical Turk and real-world news data. The results show that users are able to successfully analyze evolving topics in text data."}, {"color": "blue", "id": 1022, "label": 1022, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1022 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346435\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Pascal Goffin;Wesley Willett;Jean-Daniel Fekete;Petra Isenberg; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Exploring the Placement and Design of Word-Scale Visualizations; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present an exploration and a design space that characterize the usage and placement of word-scale visualizations within text documents. Word-scale visualizations are a more general version of sparklines-small, word-sized data graphics that allow meta-information to be visually presented in-line with document text. In accordance with Edward Tufte\u0027s definition, sparklines are traditionally placed directly before or after words in the text. We describe alternative placements that permit a wider range of word-scale graphics and more flexible integration with text layouts. These alternative placements include positioning visualizations between lines, within additional vertical and horizontal space in the document, and as interactive overlays on top of the text. Each strategy changes the dimensions of the space available to display the visualizations, as well as the degree to which the text must be adjusted or reflowed to accommodate them. We provide an illustrated design space of placement options for word-scale visualizations and identify six important variables that control the placement of the graphics and the level of disruption of the source text. We also contribute a quantitative analysis that highlights the effect of different placements on readability and text disruption. Finally, we use this analysis to propose guidelines to support the design and placement of word-scale visualizations."}, {"color": "blue", "id": 1024, "label": 1024, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1024 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346441\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Stef van den Elzen;Jarke J. van Wijk; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Multivariate Network Exploration and Presentation: From Detail to Overview via Selections and Aggregations; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Network data is ubiquitous; e-mail traffic between persons, telecommunication, transport and financial networks are some examples. Often these networks are large and multivariate, besides the topological structure of the network, multivariate data on the nodes and links is available. Currently, exploration and analysis methods are focused on a single aspect; the network topology or the multivariate data. In addition, tools and techniques are highly domain specific and require expert knowledge. We focus on the non-expert user and propose a novel solution for multivariate network exploration and analysis that tightly couples structural and multivariate analysis. In short, we go from Detail to Overview via Selections and Aggregations (DOSA): users are enabled to gain insights through the creation of selections of interest (manually or automatically), and producing high-level, infographic-style overviews simultaneously. Finally, we present example explorations on real-world datasets that demonstrate the effectiveness of our method for the exploration and understanding of multivariate networks where presentation of findings comes for free."}, {"color": "blue", "id": 1026, "label": 1026, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1026 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346444\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Charles D. Stolper;Minsuk Kahng;Zhiyuan Lin;Florian Foerster;Aakash Goel;John Stasko;Duen Horng Chau; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: GLO-STIX: Graph-Level Operations for Specifying Techniques and Interactive eXploration; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The field of graph visualization has produced a wealth of visualization techniques for accomplishing a variety of analysis tasks. Therefore analysts often rely on a suite of different techniques, and visual graph analysis application builders strive to provide this breadth of techniques. To provide a holistic model for specifying network visualization techniques (as opposed to considering each technique in isolation) we present the Graph-Level Operations (GLO) model. We describe a method for identifying GLOs and apply it to identify five classes of GLOs, which can be flexibly combined to re-create six canonical graph visualization techniques. We discuss advantages of the GLO model, including potentially discovering new, effective network visualization techniques and easing the engineering challenges of building multi-technique graph visualization applications. Finally, we implement the GLOs that we identified into the GLO-STIX prototype system that enables an analyst to interactively explore a graph by applying GLOs."}, {"color": "blue", "id": 1027, "label": 1027, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1027 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346445\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Tom Polk;Jing Yang;Yueqi Hu;Ye Zhao; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: TenniVis: Visualization for Tennis Match Analysis; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Existing research efforts into tennis visualization have primarily focused on using ball and player tracking data to enhance professional tennis broadcasts and to aid coaches in helping their students. Gathering and analyzing this data typically requires the use of an array of synchronized cameras, which are expensive for non-professional tennis matches. In this paper, we propose TenniVis, a novel tennis match visualization system that relies entirely on data that can be easily collected, such as score, point outcomes, point lengths, service information, and match videos that can be captured by one consumer-level camera. It provides two new visualizations to allow tennis coaches and players to quickly gain insights into match performance. It also provides rich interactions to support ad hoc hypothesis development and testing. We first demonstrate the usefulness of the system by analyzing the 2007 Australian Open men\u0027s singles final. We then validate its usability by two pilot user studies where two college tennis coaches analyzed the matches of their own players. The results indicate that useful insights can quickly be discovered and ad hoc hypotheses based on these insights can conveniently be tested through linked match videos."}, {"color": "red", "id": 1030, "label": 1030, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1030 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346448\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Ismail Demir;Christian Dick;R\u00fcdiger Westermann; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Multi-Charts for Comparative 3D Ensemble Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: A comparative visualization of multiple volume data sets is challenging due to the inherent occlusion effects, yet it is important to effectively reveal uncertainties, correlations and reliable trends in 3D ensemble fields. In this paper we present bidirectional linking of multi-charts and volume visualization as a means to analyze visually 3D scalar ensemble fields at the data level. Multi-charts are an extension of conventional bar and line charts: They linearize the 3D data points along a space-filling curve and draw them as multiple charts in the same plot area. The bar charts encode statistical information on ensemble members, such as histograms and probability densities, and line charts are overlayed to allow comparing members against the ensemble. Alternative linearizations based on histogram similarities or ensemble variation allow clustering of spatial locations depending on data distribution. Multi-charts organize the data at multiple scales to quickly provide overviews and enable users to select regions exhibiting interesting behavior interactively. They are further put into a spatial context by allowing the user to brush or query value intervals and specific distributions, and to simultaneously visualize the corresponding spatial points via volume rendering. By providing a picking mechanism in 3D and instantly highlighting the corresponding data points in the chart, the user can go back and forth between the abstract and the 3D view to focus the analysis."}, {"color": "red", "id": 1031, "label": 1031, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1031 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346449\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Harish Doraiswamy;Nivan Ferreira;Theodoros Damoulas;Juliana Freire;Cl\u00e1udio T. Silva; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Using Topological Analysis to Support Event-Guided Exploration in Urban Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The explosion in the volume of data about urban environments has opened up opportunities to inform both policy and administration and thereby help governments improve the lives of their citizens, increase the efficiency of public services, and reduce the environmental harms of development. However, cities are complex systems and exploring the data they generate is challenging. The interaction between the various components in a city creates complex dynamics where interesting facts occur at multiple scales, requiring users to inspect a large number of data slices over time and space. Manual exploration of these slices is ineffective, time consuming, and in many cases impractical. In this paper, we propose a technique that supports event-guided exploration of large, spatio-temporal urban data. We model the data as time-varying scalar functions and use computational topology to automatically identify events in different data slices. To handle a potentially large number of events, we develop an algorithm to group and index them, thus allowing users to interactively explore and query event patterns on the fly. A visual exploration interface helps guide users towards data slices that display interesting events and trends. We demonstrate the effectiveness of our technique on two different data sets from New York City (NYC): data about taxi trips and subway service. We also report on the feedback we received from analysts at different NYC agencies."}, {"color": "blue", "id": 1033, "label": 1033, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1033 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346452\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Zhicheng Liu;Jeffrey Heer; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: The Effects of Interactive Latency on Exploratory Visual Analysis; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: To support effective exploration, it is often stated that interactive visualizations should provide rapid response times. However, the effects of interactive latency on the process and outcomes of exploratory visual analysis have not been systematically studied. We present an experiment measuring user behavior and knowledge discovery with interactive visualizations under varying latency conditions. We observe that an additional delay of 500ms incurs significant costs, decreasing user activity and data set coverage. Analyzing verbal data from think-aloud protocols, we find that increased latency reduces the rate at which users make observations, draw generalizations and generate hypotheses. Moreover, we note interaction effects in which initial exposure to higher latencies leads to subsequently reduced performance in a low-latency setting. Overall, increased latency causes users to shift exploration strategy, in turn affecting performance. We discuss how these results can inform the design of interactive analysis tools."}, {"color": "blue", "id": 1034, "label": 1034, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1034 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346454\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jaemin Jo;Jaeseok Huh;Jonghun Park;Bohyoung Kim;Jinwook Seo; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: LiveGantt: Interactively Visualizing a Large Manufacturing Schedule; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In this paper, we introduce LiveGantt as a novel interactive schedule visualization tool that helps users explore highly-concurrent large schedules from various perspectives. Although a Gantt chart is the most common approach to illustrate schedules, currently available Gantt chart visualization tools suffer from limited scalability and lack of interactions. LiveGantt is built with newly designed algorithms and interactions to improve conventional charts with better scalability, explorability, and reschedulability. It employs resource reordering and task aggregation to display the schedules in a scalable way. LiveGantt provides four coordinated views and filtering techniques to help users explore and interact with the schedules in more flexible ways. In addition, LiveGantt is equipped with an efficient rescheduler to allow users to instantaneously modify their schedules based on their scheduling experience in the fields. To assess the usefulness of the application of LiveGantt, we conducted a case study on manufacturing schedule data with four industrial engineering researchers. Participants not only grasped an overview of a schedule but also explored the schedule from multiple perspectives to make enhancements."}, {"color": "red", "id": 1035, "label": 1035, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1035 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346455\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Mahsa Mirzargar;Ross T. Whitaker;Robert M. Kirby; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Curve Boxplot: Generalization of Boxplot for Ensembles of Curves; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In simulation science, computational scientists often study the behavior of their simulations by repeated solutions with variations in parameters and/or boundary values or initial conditions. Through such simulation ensembles, one can try to understand or quantify the variability or uncertainty in a solution as a function of the various inputs or model assumptions. In response to a growing interest in simulation ensembles, the visualization community has developed a suite of methods for allowing users to observe and understand the properties of these ensembles in an efficient and effective manner. An important aspect of visualizing simulations is the analysis of derived features, often represented as points, surfaces, or curves. In this paper, we present a novel, nonparametric method for summarizing ensembles of 2D and 3D curves. We propose an extension of a method from descriptive statistics, data depth, to curves. We also demonstrate a set of rendering and visualization strategies for showing rank statistics of an ensemble of curves, which is a generalization of traditional whisker plots or boxplots to multidimensional curves. Results are presented for applications in neuroimaging, hurricane forecasting and fluid dynamics."}, {"color": "orange", "id": 1040, "label": 1040, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1040 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346481\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Dominik Sacha;Andreas Stoffel;Florian Stoffel;Bum Chul Kwon;Geoffrey Ellis;Daniel A. Keim; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Knowledge Generation Model for Visual Analytics; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Visual analytics enables us to analyze huge information spaces in order to support complex decision making and data exploration. Humans play a central role in generating knowledge from the snippets of evidence emerging from visual data analysis. Although prior research provides frameworks that generalize this process, their scope is often narrowly focused so they do not encompass different perspectives at different levels. This paper proposes a knowledge generation model for visual analytics that ties together these diverse frameworks, yet retains previously developed models (e.g., KDD process) to describe individual segments of the overall visual analytic processes. To test its utility, a real world visual analytics system is compared against the model, demonstrating that the knowledge generation process model provides a useful guideline when developing and evaluating such systems. The model is used to effectively compare different data analysis systems. Furthermore, the model provides a common language and description of visual analytic processes, which can be used for communication between researchers. At the end, our model reflects areas of research that future researchers can embark on."}, {"color": "orange", "id": 1041, "label": 1041, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1041 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346482\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Josua Krause;Adam Perer;Enrico Bertini; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: INFUSE: Interactive Feature Selection for Predictive Modeling of High Dimensional Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Predictive modeling techniques are increasingly being used by data scientists to understand the probability of predicted outcomes. However, for data that is high-dimensional, a critical step in predictive modeling is determining which features should be included in the models. Feature selection algorithms are often used to remove non-informative features from models. However, there are many different classes of feature selection algorithms. Deciding which one to use is problematic as the algorithmic output is often not amenable to user interpretation. This limits the ability for users to utilize their domain expertise during the modeling process. To improve on this limitation, we developed INFUSE, a novel visual analytics system designed to help analysts understand how predictive features are being ranked across feature selection algorithms, cross-validation folds, and classifiers. We demonstrate how our system can lead to important insights in a case study involving clinical researchers predicting patient outcomes from electronic medical records."}, {"color": "orange", "id": 1042, "label": 1042, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1042 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346572\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Tuan Nhon Dang;Leland Wilkinson; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Transforming Scagnostics to Reveal Hidden Features; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Scagnostics (Scatterplot Diagnostics) were developed by Wilkinson et al. based on an idea of Paul and John Tukey, in order to discern meaningful patterns in large collections of scatterplots. The Tukeys\u0027 original idea was intended to overcome the impediments involved in examining large scatterplot matrices (multiplicity of plots and lack of detail). Wilkinson\u0027s implementation enabled for the first time scagnostics computations on many points as well as many plots. Unfortunately, scagnostics are sensitive to scale transformations. We illustrate the extent of this sensitivity and show how it is possible to pair statistical transformations with scagnostics to enable discovery of hidden structures in data that are not discernible in untransformed visualizations."}, {"color": "orange", "id": 1043, "label": 1043, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1043 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346573\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Narges Mahyar;Melanie Tory; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Supporting Communication and Coordination in Collaborative Sensemaking; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: When people work together to analyze a data set, they need to organize their findings, hypotheses, and evidence, share that information with their collaborators, and coordinate activities amongst team members. Sharing externalizations (recorded information such as notes) could increase awareness and assist with team communication and coordination. However, we currently know little about how to provide tool support for this sort of sharing. We explore how linked common work (LCW) can be employed within a `collaborative thinking space\u0027, to facilitate synchronous collaborative sensemaking activities in Visual Analytics (VA). Collaborative thinking spaces provide an environment for analysts to record, organize, share and connect externalizations. Our tool, CLIP, extends earlier thinking spaces by integrating LCW features that reveal relationships between collaborators\u0027 findings. We conducted a user study comparing CLIP to a baseline version without LCW. Results demonstrated that LCW significantly improved analytic outcomes at a collaborative intelligence task. Groups using CLIP were also able to more effectively coordinate their work, and held more discussion of their findings and hypotheses. LCW enabled them to maintain awareness of each other\u0027s activities and findings and link those findings to their own work, preventing disruptive oral awareness notifications."}, {"color": "orange", "id": 1044, "label": 1044, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1044 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346574\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Charles D. Stolper;Adam Perer;David Gotz; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Progressive Visual Analytics: User-Driven Visual Exploration of In-Progress Analytics; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: As datasets grow and analytic algorithms become more complex, the typical workflow of analysts launching an analytic, waiting for it to complete, inspecting the results, and then re-Iaunching the computation with adjusted parameters is not realistic for many real-world tasks. This paper presents an alternative workflow, progressive visual analytics, which enables an analyst to inspect partial results of an algorithm as they become available and interact with the algorithm to prioritize subspaces of interest. Progressive visual analytics depends on adapting analytical algorithms to produce meaningful partial results and enable analyst intervention without sacrificing computational speed. The paradigm also depends on adapting information visualization techniques to incorporate the constantly refining results without overwhelming analysts and provide interactions to support an analyst directing the analytic. The contributions of this paper include: a description of the progressive visual analytics paradigm; design goals for both the algorithms and visualizations in progressive visual analytics systems; an example progressive visual analytics system (Progressive Insights) for analyzing common patterns in a collection of event sequences; and an evaluation of Progressive Insights and the progressive visual analytics paradigm by clinical researchers analyzing electronic medical records."}, {"color": "orange", "id": 1045, "label": 1045, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1045 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346575\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Eli T Brown;Alvitta Ottley;Helen Zhao;Quan Lin;Richard Souvenir;Alex Endert;Remco Chang; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Finding Waldo: Learning about Users from their Interactions; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Visual analytics is inherently a collaboration between human and computer. However, in current visual analytics systems, the computer has limited means of knowing about its users and their analysis processes. While existing research has shown that a user\u0027s interactions with a system reflect a large amount of the user\u0027s reasoning process, there has been limited advancement in developing automated, real-time techniques that mine interactions to learn about the user. In this paper, we demonstrate that we can accurately predict a user\u0027s task performance and infer some user personality traits by using machine learning techniques to analyze interaction data. Specifically, we conduct an experiment in which participants perform a visual search task, and apply well-known machine learning algorithms to three encodings of the users\u0027 interaction data. We achieve, depending on algorithm and encoding, between 62% and 83% accuracy at predicting whether each user will be fast or slow at completing the task. Beyond predicting performance, we demonstrate that using the same techniques, we can infer aspects of the user\u0027s personality factors, including locus of control, extraversion, and neuroticism. Further analyses show that strong results can be attained with limited observation time: in one case 95% of the final accuracy is gained after a quarter of the average task completion time. Overall, our findings show that interactions can provide information to the computer about its human collaborator, and establish a foundation for realizing mixed-initiative visual analytics systems."}, {"color": "orange", "id": 1046, "label": 1046, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1046 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346578\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Thomas M\u00fchlbacher;Harald Piringer;Samuel Gratzl;Michael Sedlmair;Marc Streit; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Opening the Black Box: Strategies for Increased User Involvement in Existing Algorithm Implementations; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: An increasing number of interactive visualization tools stress the integration with computational software like MATLAB and R to access a variety of proven algorithms. In many cases, however, the algorithms are used as black boxes that run to completion in isolation which contradicts the needs of interactive data exploration. This paper structures, formalizes, and discusses possibilities to enable user involvement in ongoing computations. Based on a structured characterization of needs regarding intermediate feedback and control, the main contribution is a formalization and comparison of strategies for achieving user involvement for algorithms with different characteristics. In the context of integration, we describe considerations for implementing these strategies either as part of the visualization tool or as part of the algorithm, and we identify requirements and guidelines for the design of algorithmic APIs. To assess the practical applicability, we provide a survey of frequently used algorithm implementations within R regarding the fulfillment of these guidelines. While echoing previous calls for analysis modules which support data exploration more directly, we conclude that a range of pragmatic options for enabling user involvement in ongoing computations exists on both the visualization and algorithm side and should be used."}, {"color": "orange", "id": 1048, "label": 1048, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1048 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346594\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Haidong Chen;Wei Chen;Honghui Mei;Zhiqi Liu;Kun Zhou;Weifeng Chen;Wentao Gu;Kwan-Liu Ma; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visual Abstraction and Exploration of Multi-class Scatterplots; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Scatterplots are widely used to visualize scatter dataset for exploring outliers, clusters, local trends, and correlations. Depicting multi-class scattered points within a single scatterplot view, however, may suffer from heavy overdraw, making it inefficient for data analysis. This paper presents a new visual abstraction scheme that employs a hierarchical multi-class sampling technique to show a feature-preserving simplification. To enhance the density contrast, the colors of multiple classes are optimized by taking the multi-class point distributions into account. We design a visual exploration system that supports visual inspection and quantitative analysis from different perspectives. We have applied our system to several challenging datasets, and the results demonstrate the efficiency of our approach."}, {"color": "orange", "id": 1050, "label": 1050, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1050 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346660\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Bilal Alsallakh;Allan Hanbury;Helwig Hauser;Silvia Miksch;Andreas Rauber; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visual Methods for Analyzing Probabilistic Classification Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Multi-class classifiers often compute scores for the classification samples describing probabilities to belong to different classes. In order to improve the performance of such classifiers, machine learning experts need to analyze classification results for a large number of labeled samples to find possible reasons for incorrect classification. Confusion matrices are widely used for this purpose. However, they provide no information about classification scores and features computed for the samples. We propose a set of integrated visual methods for analyzing the performance of probabilistic classifiers. Our methods provide insight into different aspects of the classification results for a large number of samples. One visualization emphasizes at which probabilities these samples were classified and how these probabilities correlate with classification error in terms of false positives and false negatives. Another view emphasizes the features of these samples and ranks them by their separation power between selected true and false classifications. We demonstrate the insight gained using our technique in a benchmarking classification dataset, and show how it enables improving classification performance by interactively defining and evaluating post-classification rules."}, {"color": "orange", "id": 1051, "label": 1051, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1051 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346665\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Maoyuan Sun;Chris North;Naren Ramakrishnan; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: A Five-Level Design Framework for Bicluster Visualizations; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Analysts often need to explore and identify coordinated relationships (e.g., four people who visited the same five cities on the same set of days) within some large datasets for sensemaking. Biclusters provide a potential solution to ease this process, because each computed bicluster bundles individual relationships into coordinated sets. By understanding such computed, structural, relations within biclusters, analysts can leverage their domain knowledge and intuition to determine the importance and relevance of the extracted relationships for making hypotheses. However, due to the lack of systematic design guidelines, it is still a challenge to design effective and usable visualizations of biclusters to enhance their perceptibility and interactivity for exploring coordinated relationships. In this paper, we present a five-level design framework for bicluster visualizations, with a survey of the state-of-the-art design considerations and applications that are related or that can be applied to bicluster visualizations. We summarize pros and cons of these design options to support user tasks at each of the five-level relationships. Finally, we discuss future research challenges for bicluster visualizations and their incorporation into visual analytics tools."}, {"color": "orange", "id": 1052, "label": 1052, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1052 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346677\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Steffen Koch;Markus John;Michael W\u00f6rner;Andreas M\u00fcller;Thomas Ertl; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: VarifocalReader -- In-Depth Visual Analysis of Large Text Documents; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Interactive visualization provides valuable support for exploring, analyzing, and understanding textual documents. Certain tasks, however, require that insights derived from visual abstractions are verified by a human expert perusing the source text. So far, this problem is typically solved by offering overview-detail techniques, which present different views with different levels of abstractions. This often leads to problems with visual continuity. Focus-context techniques, on the other hand, succeed in accentuating interesting subsections of large text documents but are normally not suited for integrating visual abstractions. With VarifocalReader we present a technique that helps to solve some of these approaches\u0027 problems by combining characteristics from both. In particular, our method simplifies working with large and potentially complex text documents by simultaneously offering abstract representations of varying detail, based on the inherent structure of the document, and access to the text itself. In addition, VarifocalReader supports intra-document exploration through advanced navigation concepts and facilitates visual analysis tasks. The approach enables users to apply machine learning techniques and search mechanisms as well as to assess and adapt these techniques. This helps to extract entities, concepts and other artifacts from texts. In combination with the automatic generation of intermediate text levels through topic segmentation for thematic orientation, users can test hypotheses or develop interesting new research questions. To illustrate the advantages of our approach, we provide usage examples from literature studies."}, {"color": "orange", "id": 1053, "label": 1053, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1053 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346682\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: David Gotz;Harry Stavropoulos; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: DecisionFlow: Visual Analytics for High-Dimensional Temporal Event Sequence Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Temporal event sequence data is increasingly commonplace, with applications ranging from electronic medical records to financial transactions to social media activity. Previously developed techniques have focused on low-dimensional datasets (e.g., with less than 20 distinct event types). Real-world datasets are often far more complex. This paper describes DecisionFlow, a visual analysis technique designed to support the analysis of high-dimensional temporal event sequence data (e.g., thousands of event types). DecisionFlow combines a scalable and dynamic temporal event data structure with interactive multi-view visualizations and ad hoc statistical analytics. We provide a detailed review of our methods, and present the results from a 12-person user study. The study results demonstrate that DecisionFlow enables the quick and accurate completion of a range of sequence analysis tasks for datasets containing thousands of event types and millions of individual events."}, {"color": "orange", "id": 1056, "label": 1056, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1056 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346746\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Zuchao Wang;Tangzhi Ye;Min Lu;Xiaoru Yuan;Huamin Qu;Jacky Yuan;Qianliang Wu; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visual Exploration of Sparse Traffic Trajectory Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In this paper, we present a visual analysis system to explore sparse traffic trajectory data recorded by transportation cells. Such data contains the movements of nearly all moving vehicles on the major roads of a city. Therefore it is very suitable for macro-traffic analysis. However, the vehicle movements are recorded only when they pass through the cells. The exact tracks between two consecutive cells are unknown. To deal with such uncertainties, we first design a local animation, showing the vehicle movements only in the vicinity of cells. Besides, we ignore the micro-behaviors of individual vehicles, and focus on the macro-traffic patterns. We apply existing trajectory aggregation techniques to the dataset, studying cell status pattern and inter-cell flow pattern. Beyond that, we propose to study the correlation between these two patterns with dynamic graph visualization techniques. It allows us to check how traffic congestion on one cell is correlated with traffic flows on neighbouring links, and with route selection in its neighbourhood. Case studies show the effectiveness of our system."}, {"color": "orange", "id": 1057, "label": 1057, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1057 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346747\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Krishna Madhavan;Niklas Elmqvist;Mihaela Vorvoreanu;Xin Chen;Yuetling Wong;Hanjun Xian;Zhihua Dong;Aditya Johri; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: DIA2: Web-based Cyberinfrastructure for Visual Analysis of Funding Portfolios; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present a design study of the Deep Insights Anywhere, Anytime (DIA2) platform, a web-based visual analytics system that allows program managers and academic staff at the U.S. National Science Foundation to search, view, and analyze their research funding portfolio. The goal of this system is to facilitate users\u0027 understanding of both past and currently active research awards in order to make more informed decisions of their future funding. This user group is characterized by high domain expertise yet not necessarily high literacy in visualization and visual analytics-they are essentially casual experts-and thus require careful visual and information design, including adhering to user experience standards, providing a self-instructive interface, and progressively refining visualizations to minimize complexity. We discuss the challenges of designing a system for casual experts and highlight how we addressed this issue by modeling the organizational structure and workflows of the NSF within our system. We discuss each stage of the design process, starting with formative interviews, prototypes, and finally live deployments and evaluation with stakeholders."}, {"color": "orange", "id": 1059, "label": 1059, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1059 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346752\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Christian Partl;Alexander Lex;Marc Streit;Hendrik Strobelt;Anne-Mai Wassermann;Hanspeter Pfister;Dieter Schmalstieg; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: ConTour: Data-Driven Exploration of Multi-Relational Datasets for Drug Discovery; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Large scale data analysis is nowadays a crucial part of drug discovery. Biologists and chemists need to quickly explore and evaluate potentially effective yet safe compounds based on many datasets that are in relationship with each other. However, there is a lack of tools that support them in these processes. To remedy this, we developed ConTour, an interactive visual analytics technique that enables the exploration of these complex, multi-relational datasets. At its core ConTour lists all items of each dataset in a column. Relationships between the columns are revealed through interaction: selecting one or multiple items in one column highlights and re-sorts the items in other columns. Filters based on relationships enable drilling down into the large data space. To identify interesting items in the first place, ConTour employs advanced sorting strategies, including strategies based on connectivity strength and uniqueness, as well as sorting based on item attributes. ConTour also introduces interactive nesting of columns, a powerful method to show the related items of a child column for each item in the parent column. Within the columns, ConTour shows rich attribute data about the items as well as information about the connection strengths to other datasets. Finally, ConTour provides a number of detail views, which can show items from multiple datasets and their associated data at the same time. We demonstrate the utility of our system in case studies conducted with a team of chemical biologists, who investigate the effects of chemical compounds on cells and need to understand the underlying mechanisms."}, {"color": "orange", "id": 1063, "label": 1063, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1063 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346893\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Wei Zeng;Chi-Wing Fu;Stefan M\u00fcller Arisona;Alexander Erath;Huamin Qu; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visualizing Mobility of Public Transportation System; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Public transportation systems (PTSs) play an important role in modern cities, providing shared/massive transportation services that are essential for the general public. However, due to their increasing complexity, designing effective methods to visualize and explore PTS is highly challenging. Most existing techniques employ network visualization methods and focus on showing the network topology across stops while ignoring various mobility-related factors such as riding time, transfer time, waiting time, and round-the-clock patterns. This work aims to visualize and explore passenger mobility in a PTS with a family of analytical tasks based on inputs from transportation researchers. After exploring different design alternatives, we come up with an integrated solution with three visualization modules: isochrone map view for geographical information, isotime flow map view for effective temporal information comparison and manipulation, and OD-pair journey view for detailed visual analysis of mobility factors along routes between specific origin-destination pairs. The isotime flow map linearizes a flow map into a parallel isoline representation, maximizing the visualization of mobility information along the horizontal time axis while presenting clear and smooth pathways from origin to destinations. Moreover, we devise several interactive visual query methods for users to easily explore the dynamics of PTS mobility over space and time. Lastly, we also construct a PTS mobility model from millions of real passenger trajectories, and evaluate our visualization techniques with assorted case studies with the transportation researchers."}, {"color": "orange", "id": 1064, "label": 1064, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1064 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346898\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jiawan Zhang;E Yanli;Jing Ma;Yahui Zhao;Binghan Xu;Liting Sun;Jinyan Chen;Xiaoru Yuan; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visual Analysis of Public Utility Service Problems in a Metropolis; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Issues about city utility services reported by citizens can provide unprecedented insights into the various aspects of such services. Analysis of these issues can improve living quality through evidence-based decision making. However, these issues are complex, because of the involvement of spatial and temporal components, in addition to having multi-dimensional and multivariate natures. Consequently, exploring utility service problems and creating visual representations are difficult. To analyze these issues, we propose a visual analytics process based on the main tasks of utility service management. We also propose an aggregate method that transforms numerous issues into legible events and provide visualizations for events. In addition, we provide a set of tools and interaction techniques to explore such issues. Our approach enables administrators to make more informed decisions."}, {"color": "orange", "id": 1066, "label": 1066, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1066 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346912\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Conglei Shi;Yingcai Wu;Shixia Liu;Hong Zhou;Huamin Qu; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: LoyalTracker: Visualizing Loyalty Dynamics in Search Engines; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The huge amount of user log data collected by search engine providers creates new opportunities to understand user loyalty and defection behavior at an unprecedented scale. However, this also poses a great challenge to analyze the behavior and glean insights into the complex, large data. In this paper, we introduce LoyalTracker, a visual analytics system to track user loyalty and switching behavior towards multiple search engines from the vast amount of user log data. We propose a new interactive visualization technique (flow view) based on a flow metaphor, which conveys a proper visual summary of the dynamics of user loyalty of thousands of users over time. Two other visualization techniques, a density map and a word cloud, are integrated to enable analysts to gain further insights into the patterns identified by the flow view. Case studies and the interview with domain experts are conducted to demonstrate the usefulness of our technique in understanding user loyalty and switching behavior in search engines."}, {"color": "orange", "id": 1068, "label": 1068, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1068 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346919\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Guodao Sun;Yingcai Wu;Shixia Liu;Tai-Quan Peng;Jonathan J. H. Zhu;Ronghua Liang; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: EvoRiver: Visual Analysis of Topic Coopetition on Social Media; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Cooperation and competition (jointly called \u201ccoopetition\u201d) are two modes of interactions among a set of concurrent topics on social media. How do topics cooperate or compete with each other to gain public attention? Which topics tend to cooperate or compete with one another? Who plays the key role in coopetition-related interactions? We answer these intricate questions by proposing a visual analytics system that facilitates the in-depth analysis of topic coopetition on social media. We model the complex interactions among topics as a combination of carry-over, coopetition recruitment, and coopetition distraction effects. This model provides a close functional approximation of the coopetition process by depicting how different groups of influential users (i.e., \u201ctopic leaders\u201d) affect coopetition. We also design EvoRiver, a time-based visualization, that allows users to explore coopetition-related interactions and to detect dynamically evolving patterns, as well as their major causes. We test our model and demonstrate the usefulness of our system based on two Twitter data sets (social topics data and business topics data)."}, {"color": "orange", "id": 1069, "label": 1069, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1069 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346920\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Yingcai Wu;Shixia Liu;Kai Yan;Mengchen Liu;Fangzhao Wu; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: OpinionFlow: Visual Analysis of Opinion Diffusion on Social Media; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: It is important for many different applications such as government and business intelligence to analyze and explore the diffusion of public opinions on social media. However, the rapid propagation and great diversity of public opinions on social media pose great challenges to effective analysis of opinion diffusion. In this paper, we introduce a visual analysis system called OpinionFlow to empower analysts to detect opinion propagation patterns and glean insights. Inspired by the information diffusion model and the theory of selective exposure, we develop an opinion diffusion model to approximate opinion propagation among Twitter users. Accordingly, we design an opinion flow visualization that combines a Sankey graph with a tailored density map in one view to visually convey diffusion of opinions among many users. A stacked tree is used to allow analysts to select topics of interest at different levels. The stacked tree is synchronized with the opinion flow visualization to help users examine and compare diffusion patterns across topics. Experiments and case studies on Twitter data demonstrate the effectiveness and usability of OpinionFlow."}, {"color": "orange", "id": 1070, "label": 1070, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1070 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346922\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jian Zhao;Nan Cao;Zhen Wen;Yale Song;Yu-Ru Lin;Christopher Collins; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: #FluxFlow: Visual Analysis of Anomalous Information Spreading on Social Media; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present FluxFlow, an interactive visual analysis system for revealing and analyzing anomalous information spreading in social media. Everyday, millions of messages are created, commented, and shared by people on social media websites, such as Twitter and Facebook. This provides valuable data for researchers and practitioners in many application domains, such as marketing, to inform decision-making. Distilling valuable social signals from the huge crowd\u0027s messages, however, is challenging, due to the heterogeneous and dynamic crowd behaviors. The challenge is rooted in data analysts\u0027 capability of discerning the anomalous information behaviors, such as the spreading of rumors or misinformation, from the rest that are more conventional patterns, such as popular topics and newsworthy events, in a timely fashion. FluxFlow incorporates advanced machine learning algorithms to detect anomalies, and offers a set of novel visualization designs for presenting the detected threads for deeper analysis. We evaluated FluxFlow with real datasets containing the Twitter feeds captured during significant events such as Hurricane Sandy. Through quantitative measurements of the algorithmic performance and qualitative interviews with domain experts, the results show that the back-end anomaly detection model is effective in identifying anomalous retweeting threads, and its front-end interactive visualizations are intuitive and useful for analysts to discover insights in data and comprehend the underlying analytical model."}, {"color": "blue", "id": 1074, "label": 1074, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1074 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346979\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Lane Harrison;Fumeng Yang;Steven Franconeri;Remco Chang; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Ranking Visualizations of Correlation Using Weber\u0027s Law; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Despite years of research yielding systems and guidelines to aid visualization design, practitioners still face the challenge of identifying the best visualization for a given dataset and task. One promising approach to circumvent this problem is to leverage perceptual laws to quantitatively evaluate the effectiveness of a visualization design. Following previously established methodologies, we conduct a large scale (n = 1687) crowdsourced experiment to investigate whether the perception of correlation in nine commonly used visualizations can be modeled using Weber\u0027s law. The results of this experiment contribute to our understanding of information visualization by establishing that: (1) for all tested visualizations, the precision of correlation judgment could be modeled by Weber\u0027s law, (2) correlation judgment precision showed striking variation between negatively and positively correlated data, and (3) Weber models provide a concise means to quantify, compare, and rank the perceptual precision afforded by a visualization."}, {"color": "blue", "id": 1076, "label": 1076, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1076 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2346984\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jeremy Boy;Ronald A. Rensink;Enrico Bertini;Jean-Daniel Fekete; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: A Principled Way of Assessing Visualization Literacy; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We describe a method for assessing the visualization literacy (VL) of a user. Assessing how well people understand visualizations has great value for research (e. g., to avoid confounds), for design (e. g., to best determine the capabilities of an audience), for teaching (e. g., to assess the level of new students), and for recruiting (e. g., to assess the level of interviewees). This paper proposes a method for assessing VL based on Item Response Theory. It describes the design and evaluation of two VL tests for line graphs, and presents the extension of the method to bar charts and scatterplots. Finally, it discusses the reimplementation of these tests for fast, effective, and scalable web-based use."}, {"color": "blue", "id": 1079, "label": 1079, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1079 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2014.2352953\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Simon Stusak;Aur\u00e9lien Tabard;Franziska Sauka;Rohit Ashok Khot;Andreas Butz; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Activity Sculptures: Exploring the Impact of Physical Visualizations on Running Activity; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Data sculptures are a promising type of visualizations in which data is given a physical form. In the past, they have mostly been used for artistic, communicative or educational purposes, and designers of data sculptures argue that in such situations, physical visualizations can be more enriching than pixel-based visualizations. We present the design of Activity Sculptures: data sculptures of running activity. In a three-week field study we investigated the impact of the sculptures on 14 participants\u0027 running activity, the personal and social behaviors generated by the sculptures, as well as participants\u0027 experiences when receiving these individual physical tokens generated from the specific data of their runs. The physical rewards generated curiosity and personal experimentation but also social dynamics such as discussion on runs or envy/competition. We argue that such passive (or calm) visualizations can complement nudging and other mechanisms of persuasion with a more playful and reflective look at ones\u0027 activity."}, {"color": "orange", "id": 1081, "label": 1081, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1081 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2014.7042477\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Halld\u0027or Janetzko;Dominik Sacha;Manuel Stein;Tobias Schreck;Daniel A. Keim;Oliver Deussen; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Feature-Driven Visual Analytics of Soccer Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Soccer is one the most popular sports today and also very interesting from an scientific point of view. We present a system for analyzing high-frequency position-based soccer data at various levels of detail, allowing to interactively explore and analyze for movement features and game events. Our Visual Analytics method covers single-player, multi-player and event-based analytical views. Depending on the task the most promising features are semi-automatically selected, processed, and visualized. Our aim is to help soccer analysts in finding the most important and interesting events in a match. We present a flexible, modular, and expandable layer-based system allowing in-depth analysis. The integration of Visual Analytics techniques into the analysis process enables the analyst to find interesting events based on classification and allows, by a set of custom views, to communicate the found results. The feedback loop in the Visual Analytics pipeline helps to further improve the classification results. We evaluate our approach by investigating real-world soccer matches and collecting additional expert feedback. Several use cases and findings illustrate the capabilities of our approach."}, {"color": "orange", "id": 1082, "label": 1082, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1082 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2014.7042478\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Carlos Dietrich;David Koop;Huy T. Vo;Cl\u00e1udio T. Silva; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Baseball4D: A Tool for Baseball Game Reconstruction \u0026 Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: While many sports use statistics and video to analyze and improve game play, baseball has led the charge throughout its history. With the advent of new technologies that allow all players and the ball to be tracked across the entire field, it is now possible to bring this understanding to another level. From discrete positions across time, we present techniques to reconstruct entire baseball games and visually explore each play. This provides opportunities to not only derive new metrics for the game, but also allow us to investigate existing measures with targeted visualizations. In addition, our techniques allow users to filter on demand so specific situations can be analyzed both in general and according to those situations. We show that gameplay can be accurately reconstructed from the raw position data and discuss how visualization and statistical methods can combine to better inform baseball analyses."}, {"color": "orange", "id": 1084, "label": 1084, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1084 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2014.7042480\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Michael Behrisch;Fatih Korkmaz;Lin Shao;Tobias Schreck; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Feedback-Driven Interactive Exploration of Large Multidimensional Data Supported by Visual Classifier; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The extraction of relevant and meaningful information from multivariate or high-dimensional data is a challenging problem. One reason for this is that the number of possible representations, which might contain relevant information, grows exponentially with the amount of data dimensions. Also, not all views from a possibly large view space, are potentially relevant to a given analysis task or user. Focus+Context or Semantic Zoom Interfaces can help to some extent to efficiently search for interesting views or data segments, yet they show scalability problems for very large data sets. Accordingly, users are confronted with the problem of identifying interesting views, yet the manual exploration of the entire view space becomes ineffective or even infeasible. While certain quality metrics have been proposed recently to identify potentially interesting views, these often are defined in a heuristic way and do not take into account the application or user context. We introduce a framework for a feedback-driven view exploration, inspired by relevance feedback approaches used in Information Retrieval. Our basic idea is that users iteratively express their notion of interestingness when presented with candidate views. From that expression, a model representing the user\u0027s preferences, is trained and used to recommend further interesting view candidates. A decision support system monitors the exploration process and assesses the relevance-driven search process for convergence and stability. We present an instantiation of our framework for exploration of Scatter Plot Spaces based on visual features. We demonstrate the effectiveness of this implementation by a case study on two real-world datasets. We also discuss our framework in light of design alternatives and point out its usefulness for development of user- and context-dependent visual exploration systems."}, {"color": "orange", "id": 1086, "label": 1086, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1086 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2014.7042482\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Steven R. Gomez;Hua Guo;Caroline Ziemkiewicz;David H. Laidlaw; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: An Insight- and Task-based Methodology for Evaluating Spatiotemporal Visual Analytics; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present a method for evaluating visualizations using both tasks and exploration, and demonstrate this method in a study of spatiotemporal network designs for a visual analytics system. The method is well suited for studying visual analytics applications in which users perform both targeted data searches and analyses of broader patterns. In such applications, an effective visualization design is one that helps users complete tasks accurately and efficiently, and supports hypothesis generation during open-ended exploration. To evaluate both of these aims in a single study, we developed an approach called layered insight- and task-based evaluation (LITE) that interposes several prompts for observations about the data model between sequences of predefined search tasks. We demonstrate the evaluation method in a user study of four network visualizations for spatiotemporal data in a visual analytics application. Results include findings that might have been difficult to obtain in a single experiment using a different methodology. For example, with one dataset we studied, we found that on average participants were faster on search tasks using a force-directed layout than using our other designs; at the same time, participants found this design least helpful in understanding the data. Our contributions include a novel evaluation method that combines well-defined tasks with exploration and observation, an evaluation of network visualization designs for spatiotemporal visual analytics, and guidelines for using this evaluation method."}, {"color": "orange", "id": 1090, "label": 1090, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1090 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2014.7042486\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Fei Wang;Wei Chen;Feiran Wu;Ye Zhao;Han Hong;Tianyu Gu;Long Wang;Ronghua Liang;Hujun Bao; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: A Visual Reasoning Approach for Data-driven Transport Assessment on Urban Roads; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Transport assessment plays a vital role in urban planning and traffic control, which are influenced by multi-faceted traffic factors involving road infrastructure and traffic flow. Conventional solutions can hardly meet the requirements and expectations of domain experts. In this paper we present a data-driven solution by leveraging a visual analysis system to evaluate the real traffic situations based on taxi trajectory data. A sketch-based visual interface is designed to support dynamic query and visual reasoning of traffic situations within multiple coordinated views. In particular, we propose a novel road-based query model for analysts to interactively conduct evaluation tasks. This model is supported by a bi-directional hash structure, TripHash, which enables real-time responses to the data queries over a huge amount of trajectory data. Case studies with a real taxi GPS trajectory dataset (\u0026amp;gt; 30GB) show that our system performs well for on-demand transport assessment and reasoning."}, {"color": "orange", "id": 1091, "label": 1091, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1091 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2014.7042487\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Krist Wongsuphasawat;Jimmy Lin; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Using Visualizations to Monitor Changes and Harvest Insights from a Global-Scale Logging Infrastructure at Twitter; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Logging user activities is essential to data analysis for internet products and services. Twitter has built a unified logging infrastructure that captures user activities across all clients it owns, making it one of the largest datasets in the organization. This paper describes challenges and opportunities in applying information visualization to log analysis at this massive scale, and shows how various visualization techniques can be adapted to help data scientists extract insights. In particular, we focus on two scenarios: (1) monitoring and exploring a large collection of log events, and (2) performing visual funnel analysis on log data with tens of thousands of event types. Two interactive visualizations were developed for these purposes: we discuss design choices and the implementation of these systems, along with case studies of how they are being used in day-to-day operations at Twitter."}, {"color": "orange", "id": 1094, "label": 1094, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1094 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2014.7042490\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Wenchao Wu;Yixian Zheng;Huamin Qu;Wei Chen;Eduard Gr\u00f6ller;Lionel M. Ni; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: BoundarySeer: Visual Analysis of 2D Boundary Changes; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Boundary changes exist ubiquitously in our daily life. From the Antarctic ozone hole to the land desertification, and from the territory of a country to the area within one-hour reach from a downtown location, boundaries change over time. With a large number of time-varying boundaries recorded, people often need to analyze the changes, detect their similarities or differences, and find out spatial and temporal patterns of the evolution for various applications. In this paper, we present a comprehensive visual analytics system, BoundarySeer, to help users gain insight into the changes of boundaries. Our system consists of four major viewers: 1) a global viewer to show boundary groups based on their similarity and the distribution of boundary attributes such as smoothness and perimeter; 2) a region viewer to display the regions encircled by the boundaries and how they are affected by boundary changes; 3) a trend viewer to reveal the temporal patterns in the boundary evolution and potential spatio-temporal correlations; 4) a directional change viewer to encode movements of boundary segments in different directions. Quantitative analyses of boundaries (e.g., similarity measurement and adaptive clustering) and intuitive visualizations (e.g., density map and ThemeRiver) are integrated into these viewers, which enable users to explore boundary changes from different aspects and at different scales. Case studies with two real-world datasets have been carried out to demonstrate the effectiveness of our system."}, {"color": "orange", "id": 1096, "label": 1096, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1096 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2014.7042492\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Lauren Bradel;Chris North;Leanna House;Scotland Leman; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Multi-Model Semantic Interaction for Text Analytics; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Semantic interaction offers an intuitive communication mechanism between human users and complex statistical models. By shielding the users from manipulating model parameters, they focus instead on directly manipulating the spatialization, thus remaining in their cognitive zone. However, this technique is not inherently scalable past hundreds of text documents. To remedy this, we present the concept of multi-model semantic interaction, where semantic interactions can be used to steer multiple models at multiple levels of data scale, enabling users to tackle larger data problems. We also present an updated visualization pipeline model for generalized multi-model semantic interaction. To demonstrate multi-model semantic interaction, we introduce StarSPIRE, a visual text analytics prototype that transforms user interactions on documents into both small-scale display layout updates as well as large-scale relevancy-based document selection."}, {"color": "orange", "id": 1097, "label": 1097, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1097 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2014.7042493\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Eric Alexander;Joe Kohlmann;Robin Valenza;Michael Witmore;Michael Gleicher; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Serendip: Topic Model-Driven Visual Exploration of Text Corpora; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Exploration and discovery in a large text corpus requires investigation at multiple levels of abstraction, from a zoomed-out view of the entire corpus down to close-ups of individual passages and words. At each of these levels, there is a wealth of information that can inform inquiry - from statistical models, to metadata, to the researcher\u0027s own knowledge and expertise. Joining all this information together can be a challenge, and there are issues of scale to be combatted along the way. In this paper, we describe an approach to text analysis that addresses these challenges of scale and multiple information sources, using probabilistic topic models to structure exploration through multiple levels of inquiry in a way that fosters serendipitous discovery. In implementing this approach into a tool called Serendip, we incorporate topic model data and metadata into a highly reorderable matrix to expose corpus level trends; extend encodings of tagged text to illustrate probabilistic information at a passage level; and introduce a technique for visualizing individual word rankings, along with interaction techniques and new statistical methods to create links between different levels and information types. We describe example uses from both the humanities and visualization research that illustrate the benefits of our approach."}, {"color": "orange", "id": 1098, "label": 1098, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1098 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2014.7042494\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Shixia Liu;Xiting Wang;Jianfei Chen;Jim Zhu;Baining Guo; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: TopicPanorama: A Full Picture of Relevant Topics; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present a visual analytics approach to developing a full picture of relevant topics discussed in multiple sources such as news, blogs, or micro-blogs. The full picture consists of a number of common topics among multiple sources as well as distinctive topics. The key idea behind our approach is to jointly match the topics extracted from each source together in order to interactively and effectively analyze common and distinctive topics. We start by modeling each textual corpus as a topic graph. These graphs are then matched together with a consistent graph matching method. Next, we develop an LOD-based visualization for better understanding and analysis of the matched graph. The major feature of this visualization is that it combines a radially stacked tree visualization with a density-based graph visualization to facilitate the examination of the matched topic graph from multiple perspectives. To compensate for the deficiency of the graph matching algorithm and meet different users\u0027 needs, we allow users to interactively modify the graph matching result. We have applied our approach to various data including news, tweets, and blog data. Qualitative evaluation and a real-world case study with domain experts demonstrate the promise of our approach, especially in support of analyzing a topic-graph-based full picture at different levels of detail."}, {"color": "orange", "id": 1099, "label": 1099, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1099 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2014.7042495\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Yafeng Lu;Robert Kr\u00fcger;Dennis Thom;Feng Wang;Steffen Koch;Thomas Ertl;Ross Maciejewski; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Integrating Predictive Analytics and Social Media; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: A key analytical task across many domains is model building and exploration for predictive analysis. Data is collected, parsed and analyzed for relationships, and features are selected and mapped to estimate the response of a system under exploration. As social media data has grown more abundant, data can be captured that may potentially represent behavioral patterns in society. In turn, this unstructured social media data can be parsed and integrated as a key factor for predictive intelligence. In this paper, we present a framework for the development of predictive models utilizing social media data. We combine feature selection mechanisms, similarity comparisons and model cross-validation through a variety of interactive visualizations to support analysts in model building and prediction. In order to explore how predictions might be performed in such a framework, we present results from a user study focusing on social media data as a predictor for movie box-office success."}, {"color": "orange", "id": 1100, "label": 1100, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1100 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2014.7042496\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jian Zhao;Liang Gou;Fei Wang;Michelle Zhou; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: PEARL: An Interactive Visual Analytic Tool for Understanding Personal Emotion Style Derived from Social Media; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Hundreds of millions of people leave digital footprints on social media (e.g., Twitter and Facebook). Such data not only disclose a person\u0027s demographics and opinions, but also reveal one\u0027s emotional style. Emotional style captures a person\u0027s patterns of emotions over time, including his overall emotional volatility and resilience. Understanding one\u0027s emotional style can provide great benefits for both individuals and businesses alike, including the support of self-reflection and delivery of individualized customer care. We present PEARL, a timeline-based visual analytic tool that allows users to interactively discover and examine a person\u0027s emotional style derived from this person\u0027s social media text. Compared to other visual text analytic systems, our work offers three unique contributions. First, it supports multi-dimensional emotion analysis from social media text to automatically detect a person\u0027s expressed emotions at different time points and summarize those emotions to reveal the person\u0027s emotional style. Second, it effectively visualizes complex, multi-dimensional emotion analysis results to create a visual emotional profile of an individual, which helps users browse and interpret one\u0027s emotional style. Third, it supports rich visual interactions that allow users to interactively explore and validate emotion analysis results. We have evaluated our work extensively through a series of studies. The results demonstrate the effectiveness of our tool both in emotion analysis from social media and in support of interactive visualization of the emotion analysis results."}, {"color": "red", "id": 1101, "label": 1101, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1101 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/SciVis.2015.7429485\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Bireswar Laha;Doug A. Bowman;David H. Laidlaw;John J. Socha; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: A Classification of User Tasks in Visual Analysis of Volume Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Empirical findings from studies in one scientific domain have very limited applicability to other domains, unless we formally establish deeper insights on the generalizability of task types. We present a domain-independent classification of visual analysis tasks with volume visualizations. This taxonomy will help researchers design experiments, ensure coverage, and generate hypotheses in empirical studies with volume datasets. To develop our taxonomy, we first interviewed scientists working with spatial data in disparate domains. We then ran a survey to evaluate the design participants in which were scientists and professionals from around the world, working with volume data in various scientific domains. Respondents agreed substantially with our taxonomy design, but also suggested important refinements. We report the results in the form of a goal-based generic categorization of visual analysis tasks with volume visualizations. Our taxonomy covers tasks performed with a wide variety of volume datasets."}, {"color": "red", "id": 1103, "label": 1103, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1103 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/SciVis.2015.7429487\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Alexander Bock;Asher Pembroke;M. Leila Mays;Lutz Rastaetter;Timo Ropinski;Anders Ynnerman; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visual Verification of Space Weather Ensemble Simulations; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We propose a system to analyze and contextualize simulations of coronal mass ejections. As current simulation techniques require manual input, uncertainty is introduced into the simulation pipeline leading to inaccurate predictions that can be mitigated through ensemble simulations. We provide the space weather analyst with a multi-view system providing visualizations to: 1. compare ensemble members against ground truth measurements, 2. inspect time-dependent information derived from optical flow analysis of satellite images, and 3. combine satellite images with a volumetric rendering of the simulations. This three-tier workflow provides experts with tools to discover correlations between errors in predictions and simulation parameters, thus increasing knowledge about the evolution and propagation of coronal mass ejections that pose a danger to Earth and interplanetary travel."}, {"color": "blue", "id": 1125, "label": 1125, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1125 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2466971\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Matthew Brehmer;Jocelyn Ng;Kevin Tate;Tamara Munzner; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Matches, Mismatches, and Methods: Multiple-View Workflows for Energy Portfolio Analysis; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The energy performance of large building portfolios is challenging to analyze and monitor, as current analysis tools are not scalable or they present derived and aggregated data at too coarse of a level. We conducted a visualization design study, beginning with a thorough work domain analysis and a characterization of data and task abstractions. We describe generalizable visual encoding design choices for time-oriented data framed in terms of matches and mismatches, as well as considerations for workflow design. Our designs address several research questions pertaining to scalability, view coordination, and the inappropriateness of line charts for derived and aggregated data due to a combination of data semantics and domain convention. We also present guidelines relating to familiarity and trust, as well as methodological considerations for visualization design studies. Our designs were adopted by our collaborators and incorporated into the design of an energy analysis software application that will be deployed to tens of thousands of energy workers in their client base."}, {"color": "blue", "id": 1126, "label": 1126, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1126 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2466992\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jimmy Johansson;Camilla Forsell; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Evaluation of Parallel Coordinates: Overview, Categorization and Guidelines for Future Research; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The parallel coordinates technique is widely used for the analysis of multivariate data. During recent decades significant research efforts have been devoted to exploring the applicability of the technique and to expand upon it, resulting in a variety of extensions. Of these many research activities, a surprisingly small number concerns user-centred evaluations investigating actual use and usability issues for different tasks, data and domains. The result is a clear lack of convincing evidence to support and guide uptake by users as well as future research directions. To address these issues this paper contributes a thorough literature survey of what has been done in the area of user-centred evaluation of parallel coordinates. These evaluations are divided into four categories based on characterization of use, derived from the survey. Based on the data from the survey and the categorization combined with the authors\u0027 experience of working with parallel coordinates, a set of guidelines for future research directions is proposed."}, {"color": "blue", "id": 1129, "label": 1129, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1129 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467051\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: M. Adil Yal\u00e7in;Niklas Elmqvist;Benjamin B. Bederson; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: AggreSet: Rich and Scalable Set Exploration using Visualizations of Element Aggregations; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Datasets commonly include multi-value (set-typed) attributes that describe set memberships over elements, such as genres per movie or courses taken per student. Set-typed attributes describe rich relations across elements, sets, and the set intersections. Increasing the number of sets results in a combinatorial growth of relations and creates scalability challenges. Exploratory tasks (e.g. selection, comparison) have commonly been designed in separation for set-typed attributes, which reduces interface consistency. To improve on scalability and to support rich, contextual exploration of set-typed data, we present AggreSet. AggreSet creates aggregations for each data dimension: sets, set-degrees, set-pair intersections, and other attributes. It visualizes the element count per aggregate using a matrix plot for set-pair intersections, and histograms for set lists, set-degrees and other attributes. Its non-overlapping visual design is scalable to numerous and large sets. AggreSet supports selection, filtering, and comparison as core exploratory tasks. It allows analysis of set relations inluding subsets, disjoint sets and set intersection strength, and also features perceptual set ordering for detecting patterns in set matrices. Its interaction is designed for rich and rapid data exploration. We demonstrate results on a wide range of datasets from different domains with varying characteristics, and report on expert reviews and a case study using student enrollment and degree data with assistant deans at a major public university."}, {"color": "blue", "id": 1130, "label": 1130, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1130 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467091\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Arvind Satyanarayan;Ryan Russell;Jane Hoffswell;Jeffrey Heer; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Reactive Vega: A Streaming Dataflow Architecture for Declarative Interactive Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present Reactive Vega, a system architecture that provides the first robust and comprehensive treatment of declarative visual and interaction design for data visualization. Starting from a single declarative specification, Reactive Vega constructs a dataflow graph in which input data, scene graph elements, and interaction events are all treated as first-class streaming data sources. To support expressive interactive visualizations that may involve time-varying scalar, relational, or hierarchical data, Reactive Vega\u0027s dataflow graph can dynamically re-write itself at runtime by extending or pruning branches in a data-driven fashion. We discuss both compile- and run-time optimizations applied within Reactive Vega, and share the results of benchmark studies that indicate superior interactive performance to both D3 and the original, non-reactive Vega system."}, {"color": "blue", "id": 1132, "label": 1132, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1132 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467132\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Dirk J. Lehmann;Holger Theisel; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Optimal Sets of Projections of High-Dimensional Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Finding good projections of n-dimensional datasets into a 2D visualization domain is one of the most important problems in Information Visualization. Users are interested in getting maximal insight into the data by exploring a minimal number of projections. However, if the number is too small or improper projections are used, then important data patterns might be overlooked. We propose a data-driven approach to find minimal sets of projections that uniquely show certain data patterns. For this we introduce a dissimilarity measure of data projections that discards affine transformations of projections and prevents repetitions of the same data patterns. Based on this, we provide complete data tours of at most n/2 projections. Furthermore, we propose optimal paths of projection matrices for an interactive data exploration. We illustrate our technique with a set of state-of-the-art real high-dimensional benchmark datasets."}, {"color": "red", "id": 1133, "label": 1133, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1133 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467153\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: David Schroeder;Daniel F. Keefe; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visualization-by-Sketching: An Artist\u0027s Interface for Creating Multivariate Time-Varying Data Visualizations; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present Visualization-by-Sketching, a direct-manipulation user interface for designing new data visualizations. The goals are twofold: First, make the process of creating real, animated, data-driven visualizations of complex information more accessible to artists, graphic designers, and other visual experts with traditional, non-technical training. Second, support and enhance the role of human creativity in visualization design, enabling visual experimentation and workflows similar to what is possible with traditional artistic media. The approach is to conceive of visualization design as a combination of processes that are already closely linked with visual creativity: sketching, digital painting, image editing, and reacting to exemplars. Rather than studying and tweaking low-level algorithms and their parameters, designers create new visualizations by painting directly on top of a digital data canvas, sketching data glyphs, and arranging and blending together multiple layers of animated 2D graphics. This requires new algorithms and techniques to interpret painterly user input relative to data \u201cunder\u201d the canvas, balance artistic freedom with the need to produce accurate data visualizations, and interactively explore large (e.g., terabyte-sized) multivariate datasets. Results demonstrate a variety of multivariate data visualization techniques can be rapidly recreated using the interface. More importantly, results and feedback from artists support the potential for interfaces in this style to attract new, creative users to the challenging task of designing more effective data visualizations and to help these users stay \u201cin the creative zone\u201d as they work."}, {"color": "blue", "id": 1134, "label": 1134, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1134 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467191\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Kanit Wongsuphasawat;Dominik Moritz;Anushka Anand;Jock Mackinlay;Bill Howe;Jeffrey Heer; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Voyager: Exploratory Analysis via Faceted Browsing of Visualization Recommendations; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: General visualization tools typically require manual specification of views: analysts must select data variables and then choose which transformations and visual encodings to apply. These decisions often involve both domain and visualization design expertise, and may impose a tedious specification process that impedes exploration. In this paper, we seek to complement manual chart construction with interactive navigation of a gallery of automatically-generated visualizations. We contribute Voyager, a mixed-initiative system that supports faceted browsing of recommended charts chosen according to statistical and perceptual measures. We describe Voyager\u0027s architecture, motivating design principles, and methods for generating and interacting with visualization recommendations. In a study comparing Voyager to a manual visualization specification tool, we find that Voyager facilitates exploration of previously unseen data and leads to increased data variable coverage. We then distill design implications for visualization tools, in particular the need to balance rapid exploration and targeted question-answering."}, {"color": "red", "id": 1135, "label": 1135, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1135 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467194\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Wenchao Wu;Jiayi Xu;Haipeng Zeng;Yixian Zheng;Huamin Qu;Bing Ni;Mingxuan Yuan;Lionel M. Ni; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: TelCoVis: Visual Exploration of Co-occurrence in Urban Human Mobility Based on Telco Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Understanding co-occurrence in urban human mobility (i.e. people from two regions visit an urban place during the same time span) is of great value in a variety of applications, such as urban planning, business intelligence, social behavior analysis, as well as containing contagious diseases. In recent years, the widespread use of mobile phones brings an unprecedented opportunity to capture large-scale and fine-grained data to study co-occurrence in human mobility. However, due to the lack of systematic and efficient methods, it is challenging for analysts to carry out in-depth analyses and extract valuable information. In this paper, we present TelCoVis, an interactive visual analytics system, which helps analysts leverage their domain knowledge to gain insight into the co-occurrence in urban human mobility based on telco data. Our system integrates visualization techniques with new designs and combines them in a novel way to enhance analysts\u0027 perception for a comprehensive exploration. In addition, we propose to study the correlations in co-occurrence (i.e. people from multiple regions visit different places during the same time span) by means of biclustering techniques that allow analysts to better explore coordinated relationships among different regions and identify interesting patterns. The case studies based on a real-world dataset and interviews with domain experts have demonstrated the effectiveness of our system in gaining insights into co-occurrence and facilitating various analytical tasks."}, {"color": "blue", "id": 1136, "label": 1136, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1136 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467195\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Sukwon Lee;Sung-Hee Kim;Ya-Hsin Hung;Heidi Lam;Youn-Ah Kang;Ji Soo Yi; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: How do People Make Sense of Unfamiliar Visualizations?: A Grounded Model of Novice\u0027s Information Visualization Sensemaking; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In this paper, we would like to investigate how people make sense of unfamiliar information visualizations. In order to achieve the research goal, we conducted a qualitative study by observing 13 participants when they endeavored to make sense of three unfamiliar visualizations (i.e., a parallel-coordinates plot, a chord diagram, and a treemap) that they encountered for the first time. We collected data including audio/video record of think-aloud sessions and semi-structured interview; and analyzed the data using the grounded theory method. The primary result of this study is a grounded model of NOvice\u0027s information VIsualization Sensemaking (NOVIS model), which consists of the five major cognitive activities: 1 encountering visualization, 2 constructing a frame, 3 exploring visualization, 4 questioning the frame, and 5 floundering on visualization. We introduce the NOVIS model by explaining the five activities with representative quotes from our participants. We also explore the dynamics in the model. Lastly, we compare with other existing models and share further research directions that arose from our observations."}, {"color": "blue", "id": 1139, "label": 1139, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1139 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467199\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Sarah Goodwin;Jason Dykes;Aidan Slingsby;Cagatay Turkay; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visualizing Multiple Variables Across Scale and Geography; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Comparing multiple variables to select those that effectively characterize complex entities is important in a wide variety of domains - geodemographics for example. Identifying variables that correlate is a common practice to remove redundancy, but correlation varies across space, with scale and over time, and the frequently used global statistics hide potentially important differentiating local variation. For more comprehensive and robust insights into multivariate relations, these local correlations need to be assessed through various means of defining locality. We explore the geography of this issue, and use novel interactive visualization to identify interdependencies in multivariate data sets to support geographically informed multivariate analysis. We offer terminology for considering scale and locality, visual techniques for establishing the effects of scale on correlation and a theoretical framework through which variation in geographic correlation with scale and locality are addressed explicitly. Prototype software demonstrates how these contributions act together. These techniques enable multiple variables and their geographic characteristics to be considered concurrently as we extend visual parameter space analysis (vPSA) to the spatial domain. We find variable correlations to be sensitive to scale and geography to varying degrees in the context of energy-based geodemographics. This sensitivity depends upon the calculation of locality as well as the geographical and statistical structure of the variable."}, {"color": "blue", "id": 1141, "label": 1141, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1141 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467201\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jeremy Boy;Louis Eveillard;Fran\u00e7oise Detienne;Jean-Daniel Fekete; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Suggested Interactivity: Seeking Perceived Affordances for Information Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In this article, we investigate methods for suggesting the interactivity of online visualizations embedded with text. We first assess the need for such methods by conducting three initial experiments on Amazon\u0027s Mechanical Turk. We then present a design space for Suggested Interactivity (i. e., visual cues used as perceived affordances-SI), based on a survey of 382 HTML5 and visualization websites. Finally, we assess the effectiveness of three SI cues we designed for suggesting the interactivity of bar charts embedded with text. Our results show that only one cue (SI3) was successful in inciting participants to interact with the visualizations, and we hypothesize this is because this particular cue provided feedforward."}, {"color": "red", "id": 1144, "label": 1144, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1144 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467204\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Florian Ferstl;Kai B\u00fcrger;R\u00fcdiger Westermann; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Streamline Variability Plots for Characterizing the Uncertainty in Vector Field Ensembles; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present a new method to visualize from an ensemble of flow fields the statistical properties of streamlines passing through a selected location. We use principal component analysis to transform the set of streamlines into a low-dimensional Euclidean space. In this space the streamlines are clustered into major trends, and each cluster is in turn approximated by a multivariate Gaussian distribution. This yields a probabilistic mixture model for the streamline distribution, from which confidence regions can be derived in which the streamlines are most likely to reside. This is achieved by transforming the Gaussian random distributions from the low-dimensional Euclidean space into a streamline distribution that follows the statistical model, and by visualizing confidence regions in this distribution via iso-contours. We further make use of the principal component representation to introduce a new concept of streamline-median, based on existing median concepts in multidimensional Euclidean spaces. We demonstrate the potential of our method in a number of real-world examples, and we compare our results to alternative clustering approaches for particle trajectories as well as curve boxplots."}, {"color": "blue", "id": 1145, "label": 1145, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1145 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467251\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Vahan Yoghourdjian;Tim Dwyer;Graeme Gange;Steve Kieffer;Karsten Klein;Kim Marriott; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: High-Quality Ultra-Compact Grid Layout of Grouped Networks; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Prior research into network layout has focused on fast heuristic techniques for layout of large networks, or complex multi-stage pipelines for higher quality layout of small graphs. Improvements to these pipeline techniques, especially for orthogonal-style layout, are difficult and practical results have been slight in recent years. Yet, as discussed in this paper, there remain significant issues in the quality of the layouts produced by these techniques, even for quite small networks. This is especially true when layout with additional grouping constraints is required. The first contribution of this paper is to investigate an ultra-compact, grid-like network layout aesthetic that is motivated by the grid arrangements that are used almost universally by designers in typographical layout. Since the time when these heuristic and pipeline-based graph-layout methods were conceived, generic technologies (MIP, CP and SAT) for solving combinatorial and mixed-integer optimization problems have improved massively. The second contribution of this paper is to reassess whether these techniques can be used for high-quality layout of small graphs. While they are fast enough for graphs of up to 50 nodes we found these methods do not scale up. Our third contribution is a large-neighborhood search meta-heuristic approach that is scalable to larger networks."}, {"color": "blue", "id": 1146, "label": 1146, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1146 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467271\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jonathan C. Roberts;Chris Headleand;Panagiotis D. Ritsos; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Sketching Designs Using the Five Design-Sheet Methodology; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Sketching designs has been shown to be a useful way of planning and considering alternative solutions. The use of lo-fidelity prototyping, especially paper-based sketching, can save time, money and converge to better solutions more quickly. However, this design process is often viewed to be too informal. Consequently users do not know how to manage their thoughts and ideas (to first think divergently, to then finally converge on a suitable solution). We present the Five Design Sheet (FdS) methodology. The methodology enables users to create information visualization interfaces through lo-fidelity methods. Users sketch and plan their ideas, helping them express different possibilities, think through these ideas to consider their potential effectiveness as solutions to the task (sheet 1); they create three principle designs (sheets 2,3 and 4); before converging on a final realization design that can then be implemented (sheet 5). In this article, we present (i) a review of the use of sketching as a planning method for visualization and the benefits of sketching, (ii) a detailed description of the Five Design Sheet (FdS) methodology, and (iii) an evaluation of the FdS using the System Usability Scale, along with a case-study of its use in industry and experience of its use in teaching."}, {"color": "blue", "id": 1153, "label": 1153, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1153 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467323\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Anushka Anand;Justin Talbot; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Automatic Selection of Partitioning Variables for Small Multiple Displays; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Effective small multiple displays are created by partitioning a visualization on variables that reveal interesting conditional structure in the data. We propose a method that automatically ranks partitioning variables, allowing analysts to focus on the most promising small multiple displays. Our approach is based on a randomized, non-parametric permutation test, which allows us to handle a wide range of quality measures for visual patterns defined on many different visualization types, while discounting spurious patterns. We demonstrate the effectiveness of our approach on scatterplots of real-world, multidimensional datasets."}, {"color": "blue", "id": 1155, "label": 1155, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1155 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467325\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Mona Hosseinkhani Loorak;Charles Perin;Noreen Kamal;Michael Hill;Sheelagh Carpendale; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: TimeSpan: Using Visualization to Explore Temporal Multi-dimensional Data of Stroke Patients; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present TimeSpan, an exploratory visualization tool designed to gain a better understanding of the temporal aspects of the stroke treatment process. Working with stroke experts, we seek to provide a tool to help improve outcomes for stroke victims. Time is of critical importance in the treatment of acute ischemic stroke patients. Every minute that the artery stays blocked, an estimated 1.9 million neurons and 12 km of myelinated axons are destroyed. Consequently, there is a critical need for efficiency of stroke treatment processes. Optimizing time to treatment requires a deep understanding of interval times. Stroke health care professionals must analyze the impact of procedures, events, and patient attributes on time-ultimately, to save lives and improve quality of life after stroke. First, we interviewed eight domain experts, and closely collaborated with two of them to inform the design of TimeSpan. We classify the analytical tasks which a visualization tool should support and extract design goals from the interviews and field observations. Based on these tasks and the understanding gained from the collaboration, we designed TimeSpan, a web-based tool for exploring multi-dimensional and temporal stroke data. We describe how TimeSpan incorporates factors from stacked bar graphs, line charts, histograms, and a matrix visualization to create an interactive hybrid view of temporal data. From feedback collected from domain experts in a focus group session, we reflect on the lessons we learned from abstracting the tasks and iteratively designing TimeSpan."}, {"color": "red", "id": 1165, "label": 1165, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1165 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467436\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Soumya Dutta;Han-Wei Shen; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Distribution Driven Extraction and Tracking of Features for Time-varying Data Analysis; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Effective analysis of features in time-varying data is essential in numerous scientific applications. Feature extraction and tracking are two important tasks scientists rely upon to get insights about the dynamic nature of the large scale time-varying data. However, often the complexity of the scientific phenomena only allows scientists to vaguely define their feature of interest. Furthermore, such features can have varying motion patterns and dynamic evolution over time. As a result, automatic extraction and tracking of features becomes a non-trivial task. In this work, we investigate these issues and propose a distribution driven approach which allows us to construct novel algorithms for reliable feature extraction and tracking with high confidence in the absence of accurate feature definition. We exploit two key properties of an object, motion and similarity to the target feature, and fuse the information gained from them to generate a robust feature-aware classification field at every time step. Tracking of features is done using such classified fields which enhances the accuracy and robustness of the proposed algorithm. The efficacy of our method is demonstrated by successfully applying it on several scientific data sets containing a wide range of dynamic time-varying features."}, {"color": "red", "id": 1166, "label": 1166, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1166 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467441\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Ali K. Ai-Awami;Johanna Beyer;Daniel Haehn;Narayanan Kasthuri;Jeff W. Lichtman;Hanspeter Pfister;Markus Hadwiger; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: NeuroBlocks - Visual Tracking of Segmentation and Proofreading for Large Connectomics Projects; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In the field of connectomics, neuroscientists acquire electron microscopy volumes at nanometer resolution in order to reconstruct a detailed wiring diagram of the neurons in the brain. The resulting image volumes, which often are hundreds of terabytes in size, need to be segmented to identify cell boundaries, synapses, and important cell organelles. However, the segmentation process of a single volume is very complex, time-intensive, and usually performed using a diverse set of tools and many users. To tackle the associated challenges, this paper presents NeuroBlocks, which is a novel visualization system for tracking the state, progress, and evolution of very large volumetric segmentation data in neuroscience. NeuroBlocks is a multi-user web-based application that seamlessly integrates the diverse set of tools that neuroscientists currently use for manual and semi-automatic segmentation, proofreading, visualization, and analysis. NeuroBlocks is the first system that integrates this heterogeneous tool set, providing crucial support for the management, provenance, accountability, and auditing of large-scale segmentations. We describe the design of NeuroBlocks, starting with an analysis of the domain-specific tasks, their inherent challenges, and our subsequent task abstraction and visual representation. We demonstrate the utility of our design based on two case studies that focus on different user roles and their respective requirements for performing and tracking the progress of segmentation and proofreading in a large real-world connectomics project."}, {"color": "red", "id": 1167, "label": 1167, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1167 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467449\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Gordon Kindlmann;Charisee Chiw;Nicholas Seltzer;Lamont Samuels;John Reppy; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Diderot: a Domain-Specific Language for Portable Parallel Scientific Visualization and Image Analysis; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Many algorithms for scientific visualization and image analysis are rooted in the world of continuous scalar, vector, and tensor fields, but are programmed in low-level languages and libraries that obscure their mathematical foundations. Diderot is a parallel domain-specific language that is designed to bridge this semantic gap by providing the programmer with a high-level, mathematical programming notation that allows direct expression of mathematical concepts in code. Furthermore, Diderot provides parallel performance that takes advantage of modern multicore processors and GPUs. The high-level notation allows a concise and natural expression of the algorithms and the parallelism allows efficient execution on real-world datasets."}, {"color": "blue", "id": 1168, "label": 1168, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1168 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467451\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Steve Kieffer;Tim Dwyer;Kim Marriott;Michael Wybrow; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: HOLA: Human-like Orthogonal Network Layout; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Over the last 50 years a wide variety of automatic network layout algorithms have been developed. Some are fast heuristic techniques suitable for networks with hundreds of thousands of nodes while others are multi-stage frameworks for higher-quality layout of smaller networks. However, despite decades of research currently no algorithm produces layout of comparable quality to that of a human. We give a new \u201chuman-centred\u201d methodology for automatic network layout algorithm design that is intended to overcome this deficiency. User studies are first used to identify the aesthetic criteria algorithms should encode, then an algorithm is developed that is informed by these criteria and finally, a follow-up study evaluates the algorithm output. We have used this new methodology to develop an automatic orthogonal network layout method, HOLA, that achieves measurably better (by user study) layout than the best available orthogonal layout algorithm and which produces layouts of comparable quality to those produced by hand."}, {"color": "blue", "id": 1169, "label": 1169, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1169 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467452\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Uta Hinrichs;Stefania Forlini;Bridget Moynihan; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Speculative Practices: Utilizing InfoVis to Explore Untapped Literary Collections; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In this paper we exemplify how information visualization supports speculative thinking, hypotheses testing, and preliminary interpretation processes as part of literary research. While InfoVis has become a buzz topic in the digital humanities, skepticism remains about how effectively it integrates into and expands on traditional humanities research approaches. From an InfoVis perspective, we lack case studies that show the specific design challenges that make literary studies and humanities research at large a unique application area for information visualization. We examine these questions through our case study of the Speculative W@nderverse, a visualization tool that was designed to enable the analysis and exploration of an untapped literary collection consisting of thousands of science fiction short stories. We present the results of two empirical studies that involved general-interest readers and literary scholars who used the evolving visualization prototype as part of their research for over a year. Our findings suggest a design space for visualizing literary collections that is defined by (1) their academic and public relevance, (2) the tension between qualitative vs. quantitative methods of interpretation, (3) result-vs. process-driven approaches to InfoVis, and (4) the unique material and visual qualities of cultural collections. Through the Speculative W@nderverse we demonstrate how visualization can bridge these sometimes contradictory perspectives by cultivating curiosity and providing entry points into literary collections while, at the same time, supporting multiple aspects of humanities research processes."}, {"color": "orange", "id": 1171, "label": 1171, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1171 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467531\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Johanna Fulda;Matthew Brehmel;Tamara Munzner; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: TimeLineCurator: Interactive Authoring of Visual Timelines from Unstructured Text; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present TimeLineCurator, a browser-based authoring tool that automatically extracts event data from temporal references in unstructured text documents using natural language processing and encodes them along a visual timeline. Our goal is to facilitate the timeline creation process for journalists and others who tell temporal stories online. Current solutions involve manually extracting and formatting event data from source documents, a process that tends to be tedious and error prone. With TimeLineCurator, a prospective timeline author can quickly identify the extent of time encompassed by a document, as well as the distribution of events occurring along this timeline. Authors can speculatively browse possible documents to quickly determine whether they are appropriate sources of timeline material. TimeLineCurator provides controls for curating and editing events on a timeline, the ability to combine timelines from multiple source documents, and export curated timelines for online deployment. We evaluate TimeLineCurator through a benchmark comparison of entity extraction error against a manual timeline curation process, a preliminary evaluation of the user experience of timeline authoring, a brief qualitative analysis of its visual output, and a discussion of prospective use cases suggested by members of the target author communities following its deployment."}, {"color": "orange", "id": 1172, "label": 1172, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1172 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467551\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Eric D. Ragan;Alex Endert;Jibonananda Sanyal;Jian Chen; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Characterizing Provenance in Visualization and Data Analysis: An Organizational Framework of Provenance Types and Purposes; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: While the primary goal of visual analytics research is to improve the quality of insights and findings, a substantial amount of research in provenance has focused on the history of changes and advances throughout the analysis process. The term, provenance, has been used in a variety of ways to describe different types of records and histories related to visualization. The existing body of provenance research has grown to a point where the consolidation of design knowledge requires cross-referencing a variety of projects and studies spanning multiple domain areas. We present an organizational framework of the different types of provenance information and purposes for why they are desired in the field of visual analytics. Our organization is intended to serve as a framework to help researchers specify types of provenance and coordinate design knowledge across projects. We also discuss the relationships between these factors and the methods used to capture provenance information. In addition, our organization can be used to guide the selection of evaluation methodology and the comparison of study outcomes in provenance research."}, {"color": "orange", "id": 1175, "label": 1175, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1175 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467554\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Mengchen Liu;Shixia Liu;Xizhou Zhu;Qinying Liao;Furu Wei;Shimei Pan; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: An Uncertainty-Aware Approach for Exploratory Microblog Retrieval; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Although there has been a great deal of interest in analyzing customer opinions and breaking news in microblogs, progress has been hampered by the lack of an effective mechanism to discover and retrieve data of interest from microblogs. To address this problem, we have developed an uncertainty-aware visual analytics approach to retrieve salient posts, users, and hashtags. We extend an existing ranking technique to compute a multifaceted retrieval result: the mutual reinforcement rank of a graph node, the uncertainty of each rank, and the propagation of uncertainty among different graph nodes. To illustrate the three facets, we have also designed a composite visualization with three visual components: a graph visualization, an uncertainty glyph, and a flow map. The graph visualization with glyphs, the flow map, and the uncertainty analysis together enable analysts to effectively find the most uncertain results and interactively refine them. We have applied our approach to several Twitter datasets. Qualitative evaluation and two real-world case studies demonstrate the promise of our approach for retrieving high-quality microblog data."}, {"color": "orange", "id": 1176, "label": 1176, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1176 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467555\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Bum Chul Kwon;Sung-Hee Kim;Sukwon Lee;Jaegul Choo;Jina Huh;Ji Soo Yi; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: VisOHC: Designing Visual Analytics for Online Health Communities; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Through online health communities (OHCs), patients and caregivers exchange their illness experiences and strategies for overcoming the illness, and provide emotional support. To facilitate healthy and lively conversations in these communities, their members should be continuously monitored and nurtured by OHC administrators. The main challenge of OHC administrators\u0027 tasks lies in understanding the diverse dimensions of conversation threads that lead to productive discussions in their communities. In this paper, we present a design study in which three domain expert groups participated, an OHC researcher and two OHC administrators of online health communities, which was conducted to find with a visual analytic solution. Through our design study, we characterized the domain goals of OHC administrators and derived tasks to achieve these goals. As a result of this study, we propose a system called VisOHC, which visualizes individual OHC conversation threads as collapsed boxes-a visual metaphor of conversation threads. In addition, we augmented the posters\u0027 reply authorship network with marks and/or beams to show conversation dynamics within threads. We also developed unique measures tailored to the characteristics of OHCs, which can be encoded for thread visualizations at the users\u0027 requests. Our observation of the two administrators while using VisOHC showed that it supports their tasks and reveals interesting insights into online health communities. Finally, we share our methodological lessons on probing visual designs together with domain experts by allowing them to freely encode measurements into visual variables."}, {"color": "orange", "id": 1179, "label": 1179, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1179 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467611\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Phong H. Nguyen;Kai Xu;Ashley Wheat;B.L. William Wong;Simon Attfield;Bob Fields; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: SensePath: Understanding the Sensemaking Process Through Analytic Provenance; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Sensemaking is described as the process of comprehension, finding meaning and gaining insight from information, producing new knowledge and informing further action. Understanding the sensemaking process allows building effective visual analytics tools to make sense of large and complex datasets. Currently, it is often a manual and time-consuming undertaking to comprehend this: researchers collect observation data, transcribe screen capture videos and think-aloud recordings, identify recurring patterns, and eventually abstract the sensemaking process into a general model. In this paper, we propose a general approach to facilitate such a qualitative analysis process, and introduce a prototype, SensePath, to demonstrate the application of this approach with a focus on browser-based online sensemaking. The approach is based on a study of a number of qualitative research sessions including observations of users performing sensemaking tasks and post hoc analyses to uncover their sensemaking processes. Based on the study results and a follow-up participatory design session with HCI researchers, we decided to focus on the transcription and coding stages of thematic analysis. SensePath automatically captures user\u0027s sensemaking actions, i.e., analytic provenance, and provides multi-linked views to support their further analysis. A number of other requirements elicited from the design session are also implemented in SensePath, such as easy integration with existing qualitative analysis workflow and non-intrusive for participants. The tool was used by an experienced HCI researcher to analyze two sensemaking sessions. The researcher found the tool intuitive and considerably reduced analysis time, allowing better understanding of the sensemaking process."}, {"color": "orange", "id": 1181, "label": 1181, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1181 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467613\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Hua Guo;Steven R. Gomez;Caroline Ziemkiewicz;David H. Laidlaw; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: A Case Study Using Visualization Interaction Logs and Insight Metrics to Understand How Analysts Arrive at Insights; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present results from an experiment aimed at using logs of interactions with a visual analytics application to better understand how interactions lead to insight generation. We performed an insight-based user study of a visual analytics application and ran post hoc quantitative analyses of participants\u0027 measured insight metrics and interaction logs. The quantitative analyses identified features of interaction that were correlated with insight characteristics, and we confirmed these findings using a qualitative analysis of video captured during the user study. Results of the experiment include design guidelines for the visual analytics application aimed at supporting insight generation. Furthermore, we demonstrated an analysis method using interaction logs that identified which interaction patterns led to insights, going beyond insight-based evaluations that only quantify insight characteristics. We also discuss choices and pitfalls encountered when applying this analysis method, such as the benefits and costs of applying an abstraction framework to application-specific actions before further analysis. Our method can be applied to evaluations of other visualization tools to inform the design of insight-promoting interactions and to better understand analyst behaviors."}, {"color": "orange", "id": 1182, "label": 1182, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1182 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467615\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Hannah Kim;Jaegul Choo;Haesun Park;Alex Endert; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: InterAxis: Steering Scatterplot Axes via Observation-Level Interaction; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Scatterplots are effective visualization techniques for multidimensional data that use two (or three) axes to visualize data items as a point at its corresponding x and y Cartesian coordinates. Typically, each axis is bound to a single data attribute. Interactive exploration occurs by changing the data attributes bound to each of these axes. In the case of using scatterplots to visualize the outputs of dimension reduction techniques, the x and y axes are combinations of the true, high-dimensional data. For these spatializations, the axes present usability challenges in terms of interpretability and interactivity. That is, understanding the axes and interacting with them to make adjustments can be challenging. In this paper, we present InterAxis, a visual analytics technique to properly interpret, define, and change an axis in a user-driven manner. Users are given the ability to define and modify axes by dragging data items to either side of the x or y axes, from which the system computes a linear combination of data attributes and binds it to the axis. Further, users can directly tune the positive and negative contribution to these complex axes by using the visualization of data attributes that correspond to each axis. We describe the details of our technique and demonstrate the intended usage through two scenarios."}, {"color": "orange", "id": 1183, "label": 1183, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1183 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467618\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Eric Alexander;Michael Gleicher; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Task-Driven Comparison of Topic Models; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Topic modeling, a method of statistically extracting thematic content from a large collection of texts, is used for a wide variety of tasks within text analysis. Though there are a growing number of tools and techniques for exploring single models, comparisons between models are generally reduced to a small set of numerical metrics. These metrics may or may not reflect a model\u0027s performance on the analyst\u0027s intended task, and can therefore be insufficient to diagnose what causes differences between models. In this paper, we explore task-centric topic model comparison, considering how we can both provide detail for a more nuanced understanding of differences and address the wealth of tasks for which topic models are used. We derive comparison tasks from single-model uses of topic models, which predominantly fall into the categories of understanding topics, understanding similarity, and understanding change. Finally, we provide several visualization techniques that facilitate these tasks, including buddy plots, which combine color and position encodings to allow analysts to readily view changes in document similarity."}, {"color": "orange", "id": 1184, "label": 1184, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1184 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467619\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Siming Chen;Xiaoru Yuan;Zhenhuang Wang;Cong Guo;Jie Liang;Zuchao Wang;Xiaolong Luke Zhang;Jiawan Zhang; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Interactive Visual Discovering of Movement Patterns from Sparsely Sampled Geo-tagged Social Media Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Social media data with geotags can be used to track people\u0027s movements in their daily lives. By providing both rich text and movement information, visual analysis on social media data can be both interesting and challenging. In contrast to traditional movement data, the sparseness and irregularity of social media data increase the difficulty of extracting movement patterns. To facilitate the understanding of people\u0027s movements, we present an interactive visual analytics system to support the exploration of sparsely sampled trajectory data from social media. We propose a heuristic model to reduce the uncertainty caused by the nature of social media data. In the proposed system, users can filter and select reliable data from each derived movement category, based on the guidance of uncertainty model and interactive selection tools. By iteratively analyzing filtered movements, users can explore the semantics of movements, including the transportation methods, frequent visiting sequences and keyword descriptions. We provide two cases to demonstrate how our system can help users to explore the movement patterns."}, {"color": "orange", "id": 1185, "label": 1185, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1185 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467620\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Stefan J\u00e4nicke;Josef Focht;Gerik Scheuermann; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Interactive Visual Profiling of Musicians; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Determining similar objects based upon the features of an object of interest is a common task for visual analytics systems. This process is called profiling, if the object of interest is a person with individual attributes. The profiling of musicians similar to a musician of interest with the aid of visual means became an interesting research question for musicologists working with the Bavarian Musicians Encyclopedia Online. This paper illustrates the development of a visual analytics profiling system that is used to address such research questions. Taking musicological knowledge into account, we outline various steps of our collaborative digital humanities project, priority (1) the definition of various measures to determine the similarity of musicians\u0027 attributes, and (2) the design of an interactive profiling system that supports musicologists in iteratively determining similar musicians. The utility of the profiling system is emphasized by various usage scenarios illustrating current research questions in musicology."}, {"color": "orange", "id": 1186, "label": 1186, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1186 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467621\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Florian Heimerl;Qi Han;Steffen Koch;Thomas Ertl; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: CiteRivers: Visual Analytics of Citation Patterns; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The exploration and analysis of scientific literature collections is an important task for effective knowledge management. Past interest in such document sets has spurred the development of numerous visualization approaches for their interactive analysis. They either focus on the textual content of publications, or on document metadata including authors and citations. Previously presented approaches for citation analysis aim primarily at the visualization of the structure of citation networks and their exploration. We extend the state-of-the-art by presenting an approach for the interactive visual analysis of the contents of scientific documents, and combine it with a new and flexible technique to analyze their citations. This technique facilitates user-steered aggregation of citations which are linked to the content of the citing publications using a highly interactive visualization approach. Through enriching the approach with additional interactive views of other important aspects of the data, we support the exploration of the dataset over time and enable users to analyze citation patterns, spot trends, and track long-term developments. We demonstrate the strengths of our approach through a use case and discuss it based on expert user feedback."}, {"color": "orange", "id": 1187, "label": 1187, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1187 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467622\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Josua Krause;Adam Perer;Harry Stavropoulos; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Supporting Iterative Cohort Construction with Visual Temporal Queries; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Many researchers across diverse disciplines aim to analyze the behavior of cohorts whose behaviors are recorded in large event databases. However, extracting cohorts from databases is a difficult yet important step, often overlooked in many analytical solutions. This is especially true when researchers wish to restrict their cohorts to exhibit a particular temporal pattern of interest. In order to fill this gap, we designed COQUITO, a visual interface that assists users defining cohorts with temporal constraints. COQUITO was designed to be comprehensible to domain experts with no preknowledge of database queries and also to encourage exploration. We then demonstrate the utility of COQUITO via two case studies, involving medical and social media researchers."}, {"color": "blue", "id": 1189, "label": 1189, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1189 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467691\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Yong Wang;Qiaomu Shen;Daniel Archambault;Zhiguang Zhou;Min Zhu;Sixiao Yang;Huamin Qu; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: AmbiguityVis: Visualization of Ambiguity in Graph Layouts; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Node-link diagrams provide an intuitive way to explore networks and have inspired a large number of automated graph layout strategies that optimize aesthetic criteria. However, any particular drawing approach cannot fully satisfy all these criteria simultaneously, producing drawings with visual ambiguities that can impede the understanding of network structure. To bring attention to these potentially problematic areas present in the drawing, this paper presents a technique that highlights common types of visual ambiguities: ambiguous spatial relationships between nodes and edges, visual overlap between community structures, and ambiguity in edge bundling and metanodes. Metrics, including newly proposed metrics for abnormal edge lengths, visual overlap in community structures and node/edge aggregation, are proposed to quantify areas of ambiguity in the drawing. These metrics and others are then displayed using a heatmap-based visualization that provides visual feedback to developers of graph drawing and visualization approaches, allowing them to quickly identify misleading areas. The novel metrics and the heatmap-based visualization allow a user to explore ambiguities in graph layouts from multiple perspectives in order to make reasonable graph layout choices. The effectiveness of the technique is demonstrated through case studies and expert reviews."}, {"color": "blue", "id": 1190, "label": 1190, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1190 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467717\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Julian Stahnke;Marian D\u00f6rk;Boris M\u00fcller;Andreas Thom; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Probing Projections: Interaction Techniques for Interpreting Arrangements and Errors of Dimensionality Reductions; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We introduce a set of integrated interaction techniques to interpret and interrogate dimensionality-reduced data. Projection techniques generally aim to make a high-dimensional information space visible in form of a planar layout. However, the meaning of the resulting data projections can be hard to grasp. It is seldom clear why elements are placed far apart or close together and the inevitable approximation errors of any projection technique are not exposed to the viewer. Previous research on dimensionality reduction focuses on the efficient generation of data projections, interactive customisation of the model, and comparison of different projection techniques. There has been only little research on how the visualization resulting from data projection is interacted with. We contribute the concept of probing as an integrated approach to interpreting the meaning and quality of visualizations and propose a set of interactive methods to examine dimensionality-reduced data as well as the projection itself. The methods let viewers see approximation errors, question the positioning of elements, compare them to each other, and visualize the influence of data dimensions on the projection space. We created a web-based system implementing these methods, and report on findings from an evaluation with data analysts using the prototype to examine multidimensional datasets."}, {"color": "blue", "id": 1191, "label": 1191, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1191 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467732\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Michelle A. Borkin;Zoya Bylinskii;Nam Wook Kim;Constance May Bainbridge;Chelsea S. Yeh;Daniel Borkin;Hanspeter Pfister;Aude Oliva; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Beyond Memorability: Visualization Recognition and Recall; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In this paper we move beyond memorability and investigate how visualizations are recognized and recalled. For this study we labeled a dataset of 393 visualizations and analyzed the eye movements of 33 participants as well as thousands of participant-generated text descriptions of the visualizations. This allowed us to determine what components of a visualization attract people\u0027s attention, and what information is encoded into memory. Our findings quantitatively support many conventional qualitative design guidelines, including that (1) titles and supporting text should convey the message of a visualization, (2) if used appropriately, pictograms do not interfere with understanding and can improve recognition, and (3) redundancy helps effectively communicate the message. Importantly, we show that visualizations memorable \u201cat-a-glance\u201d are also capable of effectively conveying the message of the visualization. Thus, a memorable visualization is often also an effective one."}, {"color": "orange", "id": 1192, "label": 1192, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1192 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467733\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Michael Glueck;Peter Hamilton;Fanny Chevalier;Simon Breslav;Azam Khan;Daniel Wigdor;Michael Brudno; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: PhenoBlocks: Phenotype Comparison Visualizations; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The differential diagnosis of hereditary disorders is a challenging task for clinicians due to the heterogeneity of phenotypes that can be observed in patients. Existing clinical tools are often text-based and do not emphasize consistency, completeness, or granularity of phenotype reporting. This can impede clinical diagnosis and limit their utility to genetics researchers. Herein, we present PhenoBlocks, a novel visual analytics tool that supports the comparison of phenotypes between patients, or between a patient and the hallmark features of a disorder. An informal evaluation of PhenoBlocks with expert clinicians suggested that the visualization effectively guides the process of differential diagnosis and could reinforce the importance of complete, granular phenotypic reporting."}, {"color": "blue", "id": 1193, "label": 1193, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1193 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467751\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: James Walker;Rita Borgo;Mark W. Jones; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: TimeNotes: A Study on Effective Chart Visualization and Interaction Techniques for Time-Series Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Collecting sensor data results in large temporal data sets which need to be visualized, analyzed, and presented. One-dimensional time-series charts are used, but these present problems when screen resolution is small in comparison to the data. This can result in severe over-plotting, giving rise for the requirement to provide effective rendering and methods to allow interaction with the detailed data. Common solutions can be categorized as multi-scale representations, frequency based, and lens based interaction techniques. In this paper, we comparatively evaluate existing methods, such as Stack Zoom [15] and ChronoLenses [38], giving a graphical overview of each and classifying their ability to explore and interact with data. We propose new visualizations and other extensions to the existing approaches. We undertake and report an empirical study and a field study using these techniques."}, {"color": "blue", "id": 1194, "label": 1194, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1194 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467752\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Theresia Gschwandtnei;Markus B\u00f6gl;Paolo Federico;Silvia Miksch; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visual Encodings of Temporal Uncertainty: A Comparative User Study; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: A number of studies have investigated different ways of visualizing uncertainty. However, in the temporal dimension, it is still an open question how to best represent uncertainty, since the special characteristics of time require special visual encodings and may provoke different interpretations. Thus, we have conducted a comprehensive study comparing alternative visual encodings of intervals with uncertain start and end times: gradient plots, violin plots, accumulated probability plots, error bars, centered error bars, and ambiguation. Our results reveal significant differences in error rates and completion time for these different visualization types and different tasks. We recommend using ambiguation - using a lighter color value to represent uncertain regions - or error bars for judging durations and temporal bounds, and gradient plots - using fading color or transparency - for judging probability values."}, {"color": "blue", "id": 1195, "label": 1195, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1195 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467754\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: P. Samuel Quinan;Miriah Meyer; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visually Comparing Weather Features in Forecasts; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Meteorologists process and analyze weather forecasts using visualization in order to examine the behaviors of and relationships among weather features. In this design study conducted with meteorologists in decision support roles, we identified and attempted to address two significant common challenges in weather visualization: the employment of inconsistent and often ineffective visual encoding practices across a wide range of visualizations, and a lack of support for directly visualizing how different weather features relate across an ensemble of possible forecast outcomes. In this work, we present a characterization of the problems and data associated with meteorological forecasting, we propose a set of informed default encoding choices that integrate existing meteorological conventions with effective visualization practice, and we extend a set of techniques as an initial step toward directly visualizing the interactions of multiple features over an ensemble forecast. We discuss the integration of these contributions into a functional prototype tool, and also reflect on the many practical challenges that arise when working with weather data."}, {"color": "orange", "id": 1199, "label": 1199, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1199 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467771\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Xiaoke Huang;Ye Zhao;Chao Ma;Jing Yang;Xinyue Ye;Chong Zhang; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: TrajGraph: A Graph-Based Visual Analytics Approach to Studying Urban Network Centralities Using Taxi Trajectory Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We propose TrajGraph, a new visual analytics method, for studying urban mobility patterns by integrating graph modeling and visual analysis with taxi trajectory data. A special graph is created to store and manifest real traffic information recorded by taxi trajectories over city streets. It conveys urban transportation dynamics which can be discovered by applying graph analysis algorithms. To support interactive, multiscale visual analytics, a graph partitioning algorithm is applied to create region-level graphs which have smaller size than the original street-level graph. Graph centralities, including Pagerank and betweenness, are computed to characterize the time-varying importance of different urban regions. The centralities are visualized by three coordinated views including a node-link graph view, a map view and a temporal information view. Users can interactively examine the importance of streets to discover and assess city traffic patterns. We have implemented a fully working prototype of this approach and evaluated it using massive taxi trajectories of Shenzhen, China. TrajGraph\u0027s capability in revealing the importance of city streets was evaluated by comparing the calculated centralities with the subjective evaluations from a group of drivers in Shenzhen. Feedback from a domain expert was collected. The effectiveness of the visual interface was evaluated through a formal user study. We also present several examples and a case study to demonstrate the usefulness of TrajGraph in urban transportation analysis."}, {"color": "blue", "id": 1200, "label": 1200, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1200 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467811\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Nina McCurdy;Julie Lein;Katharine Coles;Miriah Meyer; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Poemage: Visualizing the Sonic Topology of a Poem; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The digital humanities have experienced tremendous growth within the last decade, mostly in the context of developing computational tools that support what is called distant reading - collecting and analyzing huge amounts of textual data for synoptic evaluation. On the other end of the spectrum is a practice at the heart of the traditional humanities, close reading - the careful, in-depth analysis of a single text in order to extract, engage, and even generate as much productive meaning as possible. The true value of computation to close reading is still very much an open question. During a two-year design study, we explored this question with several poetry scholars, focusing on an investigation of sound and linguistic devices in poetry. The contributions of our design study include a problem characterization and data abstraction of the use of sound in poetry as well as Poemage, a visualization tool for interactively exploring the sonic topology of a poem. The design of Poemage is grounded in the evaluation of a series of technology probes we deployed to our poetry collaborators, and we validate the final design with several case studies that illustrate the disruptive impact technology can have on poetry scholarship. Finally, we also contribute a reflection on the challenges we faced conducting visualization research in literary studies."}, {"color": "orange", "id": 1201, "label": 1201, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1201 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467813\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Maoyuan Sun;Peng Mi;Chris North;Naren Ramakrishnan; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: BiSet: Semantic Edge Bundling with Biclusters for Sensemaking; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Identifying coordinated relationships is an important task in data analytics. For example, an intelligence analyst might want to discover three suspicious people who all visited the same four cities. Existing techniques that display individual relationships, such as between lists of entities, require repetitious manual selection and significant mental aggregation in cluttered visualizations to find coordinated relationships. In this paper, we present BiSet, a visual analytics technique to support interactive exploration of coordinated relationships. In BiSet, we model coordinated relationships as biclusters and algorithmically mine them from a dataset. Then, we visualize the biclusters in context as bundled edges between sets of related entities. Thus, bundles enable analysts to infer task-oriented semantic insights about potentially coordinated activities. We make bundles as first class objects and add a new layer, \u201cin-between\u201d, to contain these bundle objects. Based on this, bundles serve to organize entities represented in lists and visually reveal their membership. Users can interact with edge bundles to organize related entities, and vice versa, for sensemaking purposes. With a usage scenario, we demonstrate how BiSet supports the exploration of coordinated relationships in text analytics."}, {"color": "blue", "id": 1205, "label": 1205, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1205 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467872\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Renata Georgia Raidou;Martin Eisemann;Marcel Breeuwer;Elmar Eisemann;Anna Vilanova; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Orientation-Enhanced Parallel Coordinate Plots; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Parallel Coordinate Plots (PCPs) is one of the most powerful techniques for the visualization of multivariate data. However, for large datasets, the representation suffers from clutter due to overplotting. In this case, discerning the underlying data information and selecting specific interesting patterns can become difficult. We propose a new and simple technique to improve the display of PCPs by emphasizing the underlying data structure. Our Orientation-enhanced Parallel Coordinate Plots (OPCPs) improve pattern and outlier discernibility by visually enhancing parts of each PCP polyline with respect to its slope. This enhancement also allows us to introduce a novel and efficient selection method, the Orientation-enhanced Brushing (O-Brushing). Our solution is particularly useful when multiple patterns are present or when the view on certain patterns is obstructed by noise. We present the results of our approach with several synthetic and real-world datasets. Finally, we conducted a user evaluation, which verifies the advantages of the OPCPs in terms of discernibility of information in complex data. It also confirms that O-Brushing eases the selection of data patterns in PCPs and reduces the amount of necessary user interactions compared to state-of-the-art brushing techniques."}, {"color": "red", "id": 1211, "label": 1211, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1211 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467958\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Tushar Athawale;Elham Sakhaee;Alireza Entezari; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Isosurface Visualization of Data with Nonparametric Models for Uncertainty; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The problem of isosurface extraction in uncertain data is an important research problem and may be approached in two ways. One can extract statistics (e.g., mean) from uncertain data points and visualize the extracted field. Alternatively, data uncertainty, characterized by probability distributions, can be propagated through the isosurface extraction process. We analyze the impact of data uncertainty on topology and geometry extraction algorithms. A novel, edge-crossing probability based approach is proposed to predict underlying isosurface topology for uncertain data. We derive a probabilistic version of the midpoint decider that resolves ambiguities that arise in identifying topological configurations. Moreover, the probability density function characterizing positional uncertainty in isosurfaces is derived analytically for a broad class of nonparametric distributions. This analytic characterization can be used for efficient closed-form computation of the expected value and variation in geometry. Our experiments show the computational advantages of our analytic approach over Monte-Carlo sampling for characterizing positional uncertainty. We also show the advantage of modeling underlying error densities in a nonparametric statistical framework as opposed to a parametric statistical framework through our experiments on ensemble datasets and uncertain scalar fields."}, {"color": "orange", "id": 1215, "label": 1215, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1215 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467971\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Isaac Cho;Wewnen Dou;Derek Xiaoyu Wang;Eric Sauda;William Ribarsky; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: VAiRoma: A Visual Analytics System for Making Sense of Places, Times, and Events in Roman History; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Learning and gaining knowledge of Roman history is an area of interest for students and citizens at large. This is an example of a subject with great sweep (with many interrelated sub-topics over, in this case, a 3,000 year history) that is hard to grasp by any individual and, in its full detail, is not available as a coherent story. In this paper, we propose a visual analytics approach to construct a data driven view of Roman history based on a large collection of Wikipedia articles. Extracting and enabling the discovery of useful knowledge on events, places, times, and their connections from large amounts of textual data has always been a challenging task. To this aim, we introduce VAiRoma, a visual analytics system that couples state-of-the-art text analysis methods with an intuitive visual interface to help users make sense of events, places, times, and more importantly, the relationships between them. VAiRoma goes beyond textual content exploration, as it permits users to compare, make connections, and externalize the findings all within the visual interface. As a result, VAiRoma allows users to learn and create new knowledge regarding Roman history in an informed way. We evaluated VAiRoma with 16 participants through a user study, with the task being to learn about roman piazzas through finding relevant articles and new relationships. Our study results showed that the VAiRoma system enables the participants to find more relevant articles and connections compared to Web searches and literature search conducted in a roman library. Subjective feedback on VAiRoma was also very positive. In addition, we ran two case studies that demonstrate how VAiRoma can be used for deeper analysis, permitting the rapid discovery and analysis of a small number of key documents even when the original collection contains hundreds of thousands of documents."}, {"color": "orange", "id": 1216, "label": 1216, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1216 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467991\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Yafeng Lu;Michael Steptoe;Sarah Burke;Hong Wang;Jiun-Yi Tsai;Hasan Davulcu;Douglas Montgomery;Steven R. Corman;Ross Maciejewski; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Exploring Evolving Media Discourse Through Event Cueing; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Online news, microblogs and other media documents all contain valuable insight regarding events and responses to events. Underlying these documents is the concept of framing, a process in which communicators act (consciously or unconsciously) to construct a point of view that encourages facts to be interpreted by others in a particular manner. As media discourse evolves, how topics and documents are framed can undergo change, shifting the discussion to different viewpoints or rhetoric. What causes these shifts can be difficult to determine directly; however, by linking secondary datasets and enabling visual exploration, we can enhance the hypothesis generation process. In this paper, we present a visual analytics framework for event cueing using media data. As discourse develops over time, our framework applies a time series intervention model which tests to see if the level of framing is different before or after a given date. If the model indicates that the times before and after are statistically significantly different, this cues an analyst to explore related datasets to help enhance their understanding of what (if any) events may have triggered these changes in discourse. Our framework consists of entity extraction and sentiment analysis as lenses for data exploration and uses two different models for intervention analysis. To demonstrate the usage of our framework, we present a case study on exploring potential relationships between climate change framing and conflicts in Africa."}, {"color": "blue", "id": 1217, "label": 1217, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1217 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2467992\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Paolo Simonetto;Daniel Archambault;Carlos Scheidegger; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: A Simple Approach for Boundary Improvement of Euler Diagrams; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: General methods for drawing Euler diagrams tend to generate irregular polygons. Yet, empirical evidence indicates that smoother contours make these diagrams easier to read. In this paper, we present a simple method to smooth the boundaries of any Euler diagram drawing. When refining the diagram, the method must ensure that set elements remain inside their appropriate boundaries and that no region is removed or created in the diagram. Our approach uses a force system that improves the diagram while at the same time ensuring its topological structure does not change. We demonstrate the effectiveness of the approach through case studies and quantitative evaluations."}, {"color": "orange", "id": 1218, "label": 1218, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1218 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2468011\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Johannes Sorger;Thomas Ortner;Christian Luksch;Michael Schw\u00e4rzler;Eduard Gr\u00f6ller;Harald Piringer; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: LiteVis: Integrated Visualization for Simulation-Based Decision Support in Lighting Design; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: State-of-the-art lighting design is based on physically accurate lighting simulations of scenes such as offices. The simulation results support lighting designers in the creation of lighting configurations, which must meet contradicting customer objectives regarding quality and price while conforming to industry standards. However, current tools for lighting design impede rapid feedback cycles. On the one side, they decouple analysis and simulation specification. On the other side, they lack capabilities for a detailed comparison of multiple configurations. The primary contribution of this paper is a design study of LiteVis, a system for efficient decision support in lighting design. LiteVis tightly integrates global illumination-based lighting simulation, a spatial representation of the scene, and non-spatial visualizations of parameters and result indicators. This enables an efficient iterative cycle of simulation parametrization and analysis. Specifically, a novel visualization supports decision making by ranking simulated lighting configurations with regard to a weight-based prioritization of objectives that considers both spatial and non-spatial characteristics. In the spatial domain, novel concepts support a detailed comparison of illumination scenarios. We demonstrate LiteVis using a real-world use case and report qualitative feedback of lighting designers. This feedback indicates that LiteVis successfully supports lighting designers to achieve key tasks more efficiently and with greater certainty."}, {"color": "orange", "id": 1220, "label": 1220, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1220 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2468078\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Stef van den Elzen;Danny Holten;Jorik Blaas;Jarke J. van Wijk; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Reducing Snapshots to Points: A Visual Analytics Approach to Dynamic Network Exploration; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We propose a visual analytics approach for the exploration and analysis of dynamic networks. We consider snapshots of the network as points in high-dimensional space and project these to two dimensions for visualization and interaction using two juxtaposed views: one for showing a snapshot and one for showing the evolution of the network. With this approach users are enabled to detect stable states, recurring states, outlier topologies, and gain knowledge about the transitions between states and the network evolution in general. The components of our approach are discretization, vectorization and normalization, dimensionality reduction, and visualization and interaction, which are discussed in detail. The effectiveness of the approach is shown by applying it to artificial and real-world dynamic networks."}, {"color": "red", "id": 1222, "label": 1222, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1222 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2468093\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Lihua Hao;Christopher G. Healey;Steffen A. Bass; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Effective Visualization of Temporal Ensembles; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: An ensemble is a collection of related datasets, called members, built from a series of runs of a simulation or an experiment. Ensembles are large, temporal, multidimensional, and multivariate, making them difficult to analyze. Another important challenge is visualizing ensembles that vary both in space and time. Initial visualization techniques displayed ensembles with a small number of members, or presented an overview of an entire ensemble, but without potentially important details. Recently, researchers have suggested combining these two directions, allowing users to choose subsets of members to visualization. This manual selection process places the burden on the user to identify which members to explore. We first introduce a static ensemble visualization system that automatically helps users locate interesting subsets of members to visualize. We next extend the system to support analysis and visualization of temporal ensembles. We employ 3D shape comparison, cluster tree visualization, and glyph based visualization to represent different levels of detail within an ensemble. This strategy is used to provide two approaches for temporal ensemble analysis: (1) segment based ensemble analysis, to capture important shape transition time-steps, clusters groups of similar members, and identify common shape changes over time across multiple members; and (2) time-step based ensemble analysis, which assumes ensemble members are aligned in time by combining similar shapes at common time-steps. Both approaches enable users to interactively visualize and analyze a temporal ensemble from different perspectives at different levels of detail. We demonstrate our techniques on an ensemble studying matter transition from hadronic gas to quark-gluon plasma during gold-on-gold particle collisions."}, {"color": "orange", "id": 1223, "label": 1223, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1223 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2468111\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Tatiana von Landesberger;Felix Brodkorb;Philipp Roskosch;Natalia Andrienko;Gennady Andrienko;Andreas Kerren; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: MobilityGraphs: Visual Analysis of Mass Mobility Dynamics via Spatio-Temporal Graphs and Clustering; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Learning more about people mobility is an important task for official decision makers and urban planners. Mobility data sets characterize the variation of the presence of people in different places over time as well as movements (or flows) of people between the places. The analysis of mobility data is challenging due to the need to analyze and compare spatial situations (i.e., presence and flows of people at certain time moments) and to gain an understanding of the spatio-temporal changes (variations of situations over time). Traditional flow visualizations usually fail due to massive clutter. Modern approaches offer limited support for investigating the complex variation of the movements over longer time periods. We propose a visual analytics methodology that solves these issues by combined spatial and temporal simplifications. We have developed a graph-based method, called MobilityGraphs, which reveals movement patterns that were occluded in flow maps. Our method enables the visual representation of the spatio-temporal variation of movements for long time series of spatial situations originally containing a large number of intersecting flows. The interactive system supports data exploration from various perspectives and at various levels of detail by interactive setting of clustering parameters. The feasibility our approach was tested on aggregated mobility data derived from a set of geolocated Twitter posts within the Greater London city area and mobile phone call data records in Abidjan, Ivory Coast. We could show that MobilityGraphs support the identification of regular daily and weekly movement patterns of resident population."}, {"color": "orange", "id": 1226, "label": 1226, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1226 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2015.2468292\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Sujin Jang;Niklas Elmqvist;Karthik Ramani; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: MotionFlow: Visual Abstraction and Aggregation of Sequential Patterns in Human Motion Tracking Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Pattern analysis of human motions, which is useful in many research areas, requires understanding and comparison of different styles of motion patterns. However, working with human motion tracking data to support such analysis poses great challenges. In this paper, we propose MotionFlow, a visual analytics system that provides an effective overview of various motion patterns based on an interactive flow visualization. This visualization formulates a motion sequence as transitions between static poses, and aggregates these sequences into a tree diagram to construct a set of motion patterns. The system also allows the users to directly reflect the context of data and their perception of pose similarities in generating representative pose states. We provide local and global controls over the partition-based clustering process. To support the users in organizing unstructured motion data into pattern groups, we designed a set of interactions that enables searching for similar motion sequences from the data, detailed exploration of data subsets, and creating and modifying the group of motion patterns. To evaluate the usability of MotionFlow, we conducted a user study with six researchers with expertise in gesture-based interaction design. They used MotionFlow to explore and organize unstructured motion tracking data. Results show that the researchers were able to easily learn how to use MotionFlow, and the system effectively supported their pattern analysis activities, including leveraging their perception and domain knowledge."}, {"color": "orange", "id": 1229, "label": 1229, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1229 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2015.7347625\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Kristin Cook;Nick Cramer;David Israel;Michael Wolverton;Joe Bruce;Russ Burtner;Alex Endert; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Mixed-initiative visual analytics using task-driven recommendations; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Visual data analysis is composed of a collection of cognitive actions and tasks to decompose, internalize, and recombine data to produce knowledge and insight. Visual analytic tools provide interactive visual interfaces to data to support discovery and sensemaking tasks, including forming hypotheses, asking questions, and evaluating and organizing evidence. Myriad analytic models can be incorporated into visual analytic systems at the cost of increasing complexity in the analytic discourse between user and system. Techniques exist to increase the usability of interacting with analytic models, such as inferring data models from user interactions to steer the underlying models of the system via semantic interaction, shielding users from having to do so explicitly. Such approaches are often also referred to as mixed-initiative systems. Sensemaking researchers have called for development of tools that facilitate analytic sensemaking through a combination of human and automated activities. However, design guidelines do not exist for mixed-initiative visual analytic systems to support iterative sensemaking. In this paper, we present candidate design guidelines and introduce the Active Data Environment (ADE) prototype, a spatial workspace supporting the analytic process via task recommendations invoked by inferences about user interactions within the workspace. ADE recommends data and relationships based on a task model, enabling users to co-reason with the system about their data in a single, spatial workspace. This paper provides an illustrative use case, a technical description of ADE, and a discussion of the strengths and limitations of the approach."}, {"color": "orange", "id": 1235, "label": 1235, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1235 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2015.7347631\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Wenwen Dou;Isaac Cho;Omar ElTayeby;Jaegul Choo;Xiaoyu Wang;William Ribarsky; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: DemographicVis: Analyzing demographic information based on user generated content; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The wide-spread of social media provides unprecedented sources of written language that can be used to model and infer online demographics. In this paper, we introduce a novel visual text analytics system, DemographicVis, to aid interactive analysis of such demographic information based on user-generated content. Our approach connects categorical data (demographic information) with textual data, allowing users to understand the characteristics of different demographic groups in a transparent and exploratory manner. The modeling and visualization are based on ground truth demographic information collected via a survey conducted on Reddit.com. Detailed user information is taken into our modeling process that connects the demographic groups with features that best describe the distinguishing characteristics of each group. Features including topical and linguistic are generated from the user-generated contents. Such features are then analyzed and ranked based on their ability to predict the users\u0027 demographic information. To enable interactive demographic analysis, we introduce a web-based visual interface that presents the relationship of the demographic groups, their topic interests, as well as the predictive power of various features. We present multiple case studies to showcase the utility of our visual analytics approach in exploring and understanding the interests of different demographic groups. We also report results from a comparative evaluation, showing that the DemographicVis is quantitatively superior or competitive and subjectively preferred when compared to a commercial text analysis tool."}, {"color": "orange", "id": 1238, "label": 1238, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1238 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2015.7347634\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Mihaela Jarema;Ismail Demir;Johannes Kehrer;R\u00fcdiger Westermann; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Comparative visual analysis of vector field ensembles; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present a new visual analysis approach to support the comparative exploration of 2D vector-valued ensemble fields. Our approach enables the user to quickly identify the most similar groups of ensemble members, as well as the locations where the variation among the members is high. We further provide means to visualize the main features of the potentially multimodal directional distributions at user-selected locations. For this purpose, directional data is modelled using mixtures of probability density functions (pdfs), which allows us to characterize and classify complex distributions with relatively few parameters. The resulting mixture models are used to determine the degree of similarity between ensemble members, and to construct glyphs showing the direction, spread, and strength of the principal modes of the directional distributions. We also propose several similarity measures, based on which we compute pairwise member similarities in the spatial domain and form clusters of similar members. The hierarchical clustering is shown using dendrograms and similarity matrices, which can be used to select particular members and visualize their variations. A user interface providing multiple linked views enables the simultaneous visualization of aggregated global and detailed local variations, as well as the selection of members for a detailed comparison."}, {"color": "orange", "id": 1240, "label": 1240, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1240 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2015.7347636\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Nivan Ferreira;Marcos Lage;Harish Doraiswamy;Huy Vo;Luc Wilson;Heidi Werner;Muchan Park;Cl\u00e1udio Silva; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Urbane: A 3D framework to support data driven decision making in urban development; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Architects working with developers and city planners typically rely on experience, precedent and data analyzed in isolation when making decisions that impact the character of a city. These decisions are critical in enabling vibrant, sustainable environments but must also negotiate a range of complex political and social forces. This requires those shaping the built environment to balance maximizing the value of a new development with its impact on the character of a neighborhood. As a result architects are focused on two issues throughout the decision making process: a) what defines the character of a neighborhood? and b) how will a new development change its neighborhood? In the first, character can be influenced by a variety of factors and understanding the interplay between diverse data sets is crucial; including safety, transportation access, school quality and access to entertainment. In the second, the impact of a new development is measured, for example, by how it impacts the view from the buildings that surround it. In this paper, we work in collaboration with architects to design Urbane, a 3-dimensional multi-resolution framework that enables a data-driven approach for decision making in the design of new urban development. This is accomplished by integrating multiple data layers and impact analysis techniques facilitating architects to explore and assess the effect of these attributes on the character and value of a neighborhood. Several of these data layers, as well as impact analysis, involve working in 3-dimensions and operating in real time. Efficient computation and visualization is accomplished through the use of techniques from computer graphics. We demonstrate the effectiveness of Urbane through a case study of development in Manhattan depicting how a data-driven understanding of the value and impact of speculative buildings can benefit the design-development process between architects, planners and developers."}, {"color": "orange", "id": 1241, "label": 1241, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1241 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2015.7347637\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Michael Brooks;Saleema Amershi;Bongshin Lee;Steven M. Drucker;Ashish Kapoor;Patrice Simard; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: FeatureInsight: Visual support for error-driven feature ideation in text classification; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Machine learning requires an effective combination of data, features, and algorithms. While many tools exist for working with machine learning data and algorithms, support for thinking of new features, or feature ideation, remains poor. In this paper, we investigate two general approaches to support feature ideation: visual summaries and sets of errors. We present FeatureInsight, an interactive visual analytics tool for building new dictionary features (semantically related groups of words) for text classification problems. FeatureInsight supports an error-driven feature ideation process and provides interactive visual summaries of sets of misclassified documents. We conducted a controlled experiment evaluating both visual summaries and sets of errors in FeatureInsight. Our results show that visual summaries significantly improve feature ideation, especially in combination with sets of errors. Users preferred visual summaries over viewing raw data, and only preferred examining sets when visual summaries were provided. We discuss extensions of both approaches to data types other than text, and point to areas for future research."}, {"color": "orange", "id": 1261, "label": 1261, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1261 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2598415\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Quan Li;Peng Xu;Yeuk Yin Chan;Yun Wang;Zhipeng Wang;Huamin Qu;Xiaojuan Ma; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: A Visual Analytics Approach for Understanding Reasons behind Snowballing and Comeback in MOBA Games; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: To design a successful Multiplayer Online Battle Arena (MOBA) game, the ratio of snowballing and comeback occurrences to all matches played must be maintained at a certain level to ensure its fairness and engagement. Although it is easy to identify these two types of occurrences, game developers often find it difficult to determine their causes and triggers with so many game design choices and game parameters involved. In addition, the huge amounts of MOBA game data are often heterogeneous, multi-dimensional and highly dynamic in terms of space and time, which poses special challenges for analysts. In this paper, we present a visual analytics system to help game designers find key events and game parameters resulting in snowballing or comeback occurrences in MOBA game data. We follow a user-centered design process developing the system with game analysts and testing with real data of a trial version MOBA game from NetEase Inc. We apply novel visualization techniques in conjunction with well-established ones to depict the evolution of players\u0027 positions, status and the occurrences of events. Our system can reveal players\u0027 strategies and performance throughout a single match and suggest patterns, e.g., specific player\u0027 actions and game events, that have led to the final occurrences. We further demonstrate a workflow of leveraging human analyzed patterns to improve the scalability and generality of match data analysis. Finally, we validate the usability of our system by proving the identified patterns are representative in snowballing or comeback matches in a one-month-long MOBA tournament dataset."}, {"color": "orange", "id": 1262, "label": 1262, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1262 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2598416\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Shamal Al-Dohuki;Yingyu Wu;Farah Kamw;Jing Yang;Xin Li;Ye Zhao;Xinyue Ye;Wei Chen;Chao Ma;Fei Wang; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: SemanticTraj: A New Approach to Interacting with Massive Taxi Trajectories; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Massive taxi trajectory data is exploited for knowledge discovery in transportation and urban planning. Existing tools typically require users to select and brush geospatial regions on a map when retrieving and exploring taxi trajectories and passenger trips. To answer seemingly simple questions such as \u201cWhat were the taxi trips starting from Main Street and ending at Wall Street in the morning?\u201d or \u201cWhere are the taxis arriving at the Art Museum at noon typically coming from?\u201d, tedious and time consuming interactions are usually needed since the numeric GPS points of trajectories are not directly linked to the keywords such as \u201cMain Street\u201d, \u201cWall Street\u201d, and \u201cArt Museum\u201d. In this paper, we present SemanticTraj, a new method for managing and visualizing taxi trajectory data in an intuitive, semantic rich, and efficient means. With SemanticTraj, domain and public users can find answers to the aforementioned questions easily through direct queries based on the terms. They can also interactively explore the retrieved data in visualizations enhanced by semantic information of the trajectories and trips. In particular, taxi trajectories are converted into taxi documents through a textualization transformation process. This process maps GPS points into a series of street/POI names and pick-up/drop-off locations. It also converts vehicle speeds into user-defined descriptive terms. Then, a corpus of taxi documents is formed and indexed to enable flexible semantic queries over a text search engine. Semantic labels and meta-summaries of the results are integrated with a set of visualizations in a SemanticTraj prototype, which helps users study taxi trajectories quickly and easily. A set of usage scenarios are presented to show the usability of the system. We also collected feedback from domain experts and conducted a preliminary user study to evaluate the visual system."}, {"color": "orange", "id": 1264, "label": 1264, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1264 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2598432\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Dongyu Liu;Di Weng;Yuhong Li;Jie Bao;Yu Zheng;Huamin Qu;Yingcai Wu; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: SmartAdP: Visual Analytics of Large-scale Taxi Trajectories for Selecting Billboard Locations; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The problem of formulating solutions immediately and comparing them rapidly for billboard placements has plagued advertising planners for a long time, owing to the lack of efficient tools for in-depth analyses to make informed decisions. In this study, we attempt to employ visual analytics that combines the state-of-the-art mining and visualization techniques to tackle this problem using large-scale GPS trajectory data. In particular, we present SmartAdP, an interactive visual analytics system that deals with the two major challenges including finding good solutions in a huge solution space and comparing the solutions in a visual and intuitive manner. An interactive framework that integrates a novel visualization-driven data mining model enables advertising planners to effectively and efficiently formulate good candidate solutions. In addition, we propose a set of coupled visualizations: a solution view with metaphor-based glyphs to visualize the correlation between different solutions; a location view to display billboard locations in a compact manner; and a ranking view to present multi-typed rankings of the solutions. This system has been demonstrated using case studies with a real-world dataset and domain-expert interviews. Our approach can be adapted for other location selection problems such as selecting locations of retail stores or restaurants using trajectory data."}, {"color": "orange", "id": 1266, "label": 1266, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1266 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2598445\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Minjeong Kim;Kyeongpil Kang;Deokgun Park;Jaegul Choo;Niklas Elmqvist; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: TopicLens: Efficient Multi-Level Visual Topic Exploration of Large-Scale Document Collections; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Topic modeling, which reveals underlying topics of a document corpus, has been actively adopted in visual analytics for large-scale document collections. However, due to its significant processing time and non-interactive nature, topic modeling has so far not been tightly integrated into a visual analytics workflow. Instead, most such systems are limited to utilizing a fixed, initial set of topics. Motivated by this gap in the literature, we propose a novel interaction technique called TopicLens that allows a user to dynamically explore data through a lens interface where topic modeling and the corresponding 2D embedding are efficiently computed on the fly. To support this interaction in real time while maintaining view consistency, we propose a novel efficient topic modeling method and a semi-supervised 2D embedding algorithm. Our work is based on improving state-of-the-art methods such as nonnegative matrix factorization and t-distributed stochastic neighbor embedding. Furthermore, we have built a web-based visual analytics system integrated with TopicLens. We use this system to measure the performance and the visualization quality of our proposed methods. We provide several scenarios showcasing the capability of TopicLens using real-world datasets."}, {"color": "orange", "id": 1267, "label": 1267, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1267 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2598446\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Bum Chul Kwon;Hannah Kim;Emily Wall;Jaegul Choo;Haesun Park;Alex Endert; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: AxiSketcher: Interactive Nonlinear Axis Mapping of Visualizations through User Drawings; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Visual analytics techniques help users explore high-dimensional data. However, it is often challenging for users to express their domain knowledge in order to steer the underlying data model, especially when they have little attribute-level knowledge. Furthermore, users\u0027 complex, high-level domain knowledge, compared to low-level attributes, posits even greater challenges. To overcome these challenges, we introduce a technique to interpret a user\u0027s drawings with an interactive, nonlinear axis mapping approach called AxiSketcher. This technique enables users to impose their domain knowledge on a visualization by allowing interaction with data entries rather than with data attributes. The proposed interaction is performed through directly sketching lines over the visualization. Using this technique, users can draw lines over selected data points, and the system forms the axes that represent a nonlinear, weighted combination of multidimensional attributes. In this paper, we describe our techniques in three areas: 1) the design space of sketching methods for eliciting users\u0027 nonlinear domain knowledge; 2) the underlying model that translates users\u0027 input, extracts patterns behind the selected data points, and results in nonlinear axes reflecting users\u0027 complex intent; and 3) the interactive visualization for viewing, assessing, and reconstructing the newly formed, nonlinear axes."}, {"color": "orange", "id": 1271, "label": 1271, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1271 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2598463\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Ievgeniia Gutenko;Konstantin Dmitriev;Arie E. Kaufman;Matthew A. Barish; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: AnaFe: Visual Analytics of Image-derived Temporal Features Focusing on the Spleen; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present a novel visualization framework, AnaFe, targeted at observing changes in the spleen over time through multiple image-derived features. Accurate monitoring of progressive changes is crucial for diseases that result in enlargement of the organ. Our system is comprised of multiple linked views combining visualization of temporal 3D organ data, related measurements, and features. Thus it enables the observation of progression and allows for simultaneous comparison within and between the subjects. AnaFe offers insights into the overall distribution of robustly extracted and reproducible quantitative imaging features and their changes within the population, and also enables detailed analysis of individual cases. It performs similarity comparison of temporal series of one subject to all other series in both sick and healthy groups. We demonstrate our system through two use case scenarios on a population of 189 spleen datasets from 68 subjects with various conditions observed over time."}, {"color": "orange", "id": 1273, "label": 1273, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1273 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2598466\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Ali Sarvghad;Melanie Tory;Narges Mahyar; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visualizing Dimension Coverage to Support Exploratory Analysis; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Data analysis involves constantly formulating and testing new hypotheses and questions about data. When dealing with a new dataset, especially one with many dimensions, it can be cumbersome for the analyst to clearly remember which aspects of the data have been investigated (i.e., visually examined for patterns, trends, outliers etc.) and which combinations have not. Yet this information is critical to help the analyst formulate new questions that they have not already answered. We observe that for tabular data, questions are typically comprised of varying combinations of data dimensions (e.g., what are the trends of Sales and Profit for different Regions?). We propose representing analysis history from the angle of dimension coverage (i.e., which data dimensions have been investigated and in which combinations). We use scented widgets to incorporate dimension coverage of the analysts\u0027 past work into interaction widgets of a visualization tool. We demonstrate how this approach can assist analysts with the question formation process. Our approach extends the concept of scented widgets to reveal aspects of one\u0027s own analysis history, and offers a different perspective on one\u0027s past work than typical visualization history tools. Results of our empirical study showed that participants with access to embedded dimension coverage information relied on this information when formulating questions, asked more questions about the data, generated more top-level findings, and showed greater breadth of their analysis without sacrificing depth."}, {"color": "orange", "id": 1274, "label": 1274, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1274 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2598467\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Michael Behrisch;Benjamin Bach;Michael Hund;Michael Delz;Laura Von R\u00fcden;Jean-Daniel Fekete;Tobias Schreck; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Magnostics: Image-Based Search of Interesting Matrix Views for Guided Network Exploration; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In this work we address the problem of retrieving potentially interesting matrix views to support the exploration of networks. We introduce Matrix Diagnostics (or Magnostics), following in spirit related approaches for rating and ranking other visualization techniques, such as Scagnostics for scatter plots. Our approach ranks matrix views according to the appearance of specific visual patterns, such as blocks and lines, indicating the existence of topological motifs in the data, such as clusters, bi-graphs, or central nodes. Magnostics can be used to analyze, query, or search for visually similar matrices in large collections, or to assess the quality of matrix reordering algorithms. While many feature descriptors for image analyzes exist, there is no evidence how they perform for detecting patterns in matrices. In order to make an informed choice of feature descriptors for matrix diagnostics, we evaluate 30 feature descriptors-27 existing ones and three new descriptors that we designed specifically for MAGNOSTICS-with respect to four criteria: pattern response, pattern variability, pattern sensibility, and pattern discrimination. We conclude with an informed set of six descriptors as most appropriate for Magnostics and demonstrate their application in two scenarios; exploring a large collection of matrices and analyzing temporal networks."}, {"color": "orange", "id": 1276, "label": 1276, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1276 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2598469\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Michael Glueck;Alina Gvozdik;Fanny Chevalier;Azam Khan;Michael Brudno;Daniel Wigdor; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: PhenoStacks: Cross-Sectional Cohort Phenotype Comparison Visualizations; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Cross-sectional phenotype studies are used by genetics researchers to better understand how phenotypes vary across patients with genetic diseases, both within and between cohorts. Analyses within cohorts identify patterns between phenotypes and patients (e.g., co-occurrence) and isolate special cases (e.g., potential outliers). Comparing the variation of phenotypes between two cohorts can help distinguish how different factors affect disease manifestation (e.g., causal genes, age of onset, etc.). PhenoStacks is a novel visual analytics tool that supports the exploration of phenotype variation within and between cross-sectional patient cohorts. By leveraging the semantic hierarchy of the Human Phenotype Ontology, phenotypes are presented in context, can be grouped and clustered, and are summarized via overviews to support the exploration of phenotype distributions. The design of PhenoStacks was motivated by formative interviews with genetics researchers: we distil high-level tasks, present an algorithm for simplifying ontology topologies for visualization, and report the results of a deployment evaluation with four expert genetics researchers. The results suggest that PhenoStacks can help identify phenotype patterns, investigate data quality issues, and inform data collection design."}, {"color": "orange", "id": 1277, "label": 1277, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1277 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2598470\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Cagatay Turkay;Erdem Kaya;Selim Balcisoy;Helwig Hauser; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Designing Progressive and Interactive Analytics Processes for High-Dimensional Data Analysis; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In interactive data analysis processes, the dialogue between the human and the computer is the enabling mechanism that can lead to actionable observations about the phenomena being investigated. It is of paramount importance that this dialogue is not interrupted by slow computational mechanisms that do not consider any known temporal human-computer interaction characteristics that prioritize the perceptual and cognitive capabilities of the users. In cases where the analysis involves an integrated computational method, for instance to reduce the dimensionality of the data or to perform clustering, such non-optimal processes are often likely. To remedy this, progressive computations, where results are iteratively improved, are getting increasing interest in visual analytics. In this paper, we present techniques and design considerations to incorporate progressive methods within interactive analysis processes that involve high-dimensional data. We define methodologies to facilitate processes that adhere to the perceptual characteristics of users and describe how online algorithms can be incorporated within these. A set of design recommendations and according methods to support analysts in accomplishing high-dimensional data analysis tasks are then presented. Our arguments and decisions here are informed by observations gathered over a series of analysis sessions with analysts from finance. We document observations and recommendations from this study and present evidence on how our approach contribute to the efficiency and productivity of interactive visual analysis sessions involving high-dimensional data."}, {"color": "orange", "id": 1278, "label": 1278, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1278 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2598471\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Filip Dabek;Jesus J Caban; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: A Grammar-based Approach for Modeling User Interactions and Generating Suggestions During the Data Exploration Process; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Despite the recent popularity of visual analytics focusing on big data, little is known about how to support users that use visualization techniques to explore multi-dimensional datasets and accomplish specific tasks. Our lack of models that can assist end-users during the data exploration process has made it challenging to learn from the user\u0027s interactive and analytical process. The ability to model how a user interacts with a specific visualization technique and what difficulties they face are paramount in supporting individuals with discovering new patterns within their complex datasets. This paper introduces the notion of visualization systems understanding and modeling user interactions with the intent of guiding a user through a task thereby enhancing visual data exploration. The challenges faced and the necessary future steps to take are discussed; and to provide a working example, a grammar-based model is presented that can learn from user interactions, determine the common patterns among a number of subjects using a K-Reversible algorithm, build a set of rules, and apply those rules in the form of suggestions to new users with the goal of guiding them along their visual analytic process. A formal evaluation study with 300 subjects was performed showing that our grammar-based model is effective at capturing the interactive process followed by users and that further research in this area has the potential to positively impact how users interact with a visualization system."}, {"color": "orange", "id": 1281, "label": 1281, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1281 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2598495\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Dominik Sacha;Leishi Zhang;Michael Sedlmair;John A. Lee;Jaakko Peltonen;Daniel Weiskopf;Stephen C. North;Daniel A. Keim; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visual Interaction with Dimensionality Reduction: A Structured Literature Analysis; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Dimensionality Reduction (DR) is a core building block in visualizing multidimensional data. For DR techniques to be useful in exploratory data analysis, they need to be adapted to human needs and domain-specific problems, ideally, interactively, and on-the-fly. Many visual analytics systems have already demonstrated the benefits of tightly integrating DR with interactive visualizations. Nevertheless, a general, structured understanding of this integration is missing. To address this, we systematically studied the visual analytics and visualization literature to investigate how analysts interact with automatic DR techniques. The results reveal seven common interaction scenarios that are amenable to interactive control such as specifying algorithmic constraints, selecting relevant features, or choosing among several DR algorithms. We investigate specific implementations of visual analysis systems integrating DR, and analyze ways that other machine learning methods have been combined with DR. Summarizing the results in a \u201chuman in the loop\u201d process model provides a general lens for the evaluation of visual interactive DR systems. We apply the proposed model to study and classify several systems previously described in the literature, and to derive future research opportunities."}, {"color": "blue", "id": 1282, "label": 1282, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1282 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2598496\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Bilal Alsallakh;Liu Ren; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: PowerSet: A Comprehensive Visualization of Set Intersections; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: When analyzing a large amount of data, analysts often define groups over data elements that share certain properties. Using these groups as the unit of analysis not only reduces the data volume, but also allows detecting various patterns in the data. This involves analyzing intersection relations between these groups, and how the element attributes vary between these intersections. This kind of set-based analysis has various applications in a variety of domains, due to the generic and powerful notion of sets. However, visualizing intersections relations is challenging because their number grows exponentially with the number of sets. We present a novel technique based on Treemaps to provide a comprehensive overview of non-empty intersections in a set system in a scalable way. It enables gaining insight about how elements are distributed across these intersections as well as performing fine-grained analysis to explore and compare their attributes both in overview and in detail. Interaction allows querying and filtering these elements based on their set memberships. We demonstrate how our technique supports various use cases in data exploration and analysis by providing insights into set-based data, beyond the limits of state-of-the-art techniques."}, {"color": "orange", "id": 1288, "label": 1288, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1288 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2598543\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jian Zhao;Michael Glueck;Simon Breslav;Fanny Chevalier;Azam Khan; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Annotation Graphs: A Graph-Based Visualization for Meta-Analysis of Data Based on User-Authored Annotations; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: User-authored annotations of data can support analysts in the activity of hypothesis generation and sensemaking, where it is not only critical to document key observations, but also to communicate insights between analysts. We present annotation graphs, a dynamic graph visualization that enables meta-analysis of data based on user-authored annotations. The annotation graph topology encodes annotation semantics, which describe the content of and relations between data selections, comments, and tags. We present a mixed-initiative approach to graph layout that integrates an analyst\u0027s manual manipulations with an automatic method based on similarity inferred from the annotation semantics. Various visual graph layout styles reveal different perspectives on the annotation semantics. Annotation graphs are implemented within C8, a system that supports authoring annotations during exploratory analysis of a dataset. We apply principles of Exploratory Sequential Data Analysis (ESDA) in designing C8, and further link these to an existing task typology in the visualization literature. We develop and evaluate the system through an iterative user-centered design process with three experts, situated in the domain of analyzing HCI experiment data. The results suggest that annotation graphs are effective as a method of visually extending user-authored annotations to data meta-analysis for discovery and organization of ideas."}, {"color": "orange", "id": 1289, "label": 1289, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1289 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2598544\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Aritra Dasgupta;Joon-Yong Lee;Ryan Wilson;Robert A. Lafrance;Nick Cramer;Kristin Cook;Samuel Payne; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Familiarity Vs Trust: A Comparative Study of Domain Scientists\u0027 Trust in Visual Analytics and Conventional Analysis Methods; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Combining interactive visualization with automated analytical methods like statistics and data mining facilitates data-driven discovery. These visual analytic methods are beginning to be instantiated within mixed-initiative systems, where humans and machines collaboratively influence evidence-gathering and decision-making. But an open research question is that, when domain experts analyze their data, can they completely trust the outputs and operations on the machine-side? Visualization potentially leads to a transparent analysis process, but do domain experts always trust what they see? To address these questions, we present results from the design and evaluation of a mixed-initiative, visual analytics system for biologists, focusing on analyzing the relationships between familiarity of an analysis medium and domain experts\u0027 trust. We propose a trust-augmented design of the visual analytics system, that explicitly takes into account domain-specific tasks, conventions, and preferences. For evaluating the system, we present the results of a controlled user study with 34 biologists where we compare the variation of the level of trust across conventional and visual analytic mediums and explore the influence of familiarity and task complexity on trust. We find that despite being unfamiliar with a visual analytic medium, scientists seem to have an average level of trust that is comparable with the same in conventional analysis medium. In fact, for complex sense-making tasks, we find that the visual analytic system is able to inspire greater trust than other mediums. We summarize the implications of our findings with directions for future research on trustworthiness of visual analytic systems."}, {"color": "red", "id": 1291, "label": 1291, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1291 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2598585\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Fabio Miranda;Harish Doraiswamy;Marcos Lage;Kai Zhao;Bruno Gon\u00e7alves;Luc Wilson;Mondrian Hsieh;Cl\u00e1udio T. Silva; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Urban Pulse: Capturing the Rhythm of Cities; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Cities are inherently dynamic. Interesting patterns of behavior typically manifest at several key areas of a city over multiple temporal resolutions. Studying these patterns can greatly help a variety of experts ranging from city planners and architects to human behavioral experts. Recent technological innovations have enabled the collection of enormous amounts of data that can help in these studies. However, techniques using these data sets typically focus on understanding the data in the context of the city, thus failing to capture the dynamic aspects of the city. The goal of this work is to instead understand the city in the context of multiple urban data sets. To do so, we define the concept of an \u201curban pulse\u201d which captures the spatio-temporal activity in a city across multiple temporal resolutions. The prominent pulses in a city are obtained using the topology of the data sets, and are characterized as a set of beats. The beats are then used to analyze and compare different pulses. We also design a visual exploration framework that allows users to explore the pulses within and across multiple cities under different conditions. Finally, we present three case studies carried out by experts from two different domains that demonstrate the utility of our framework."}, {"color": "blue", "id": 1292, "label": 1292, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1292 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2598586\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Mona Hosseinkhani Loorak;Charles Perin;Christopher Collins;Sheelagh Carpendale; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Exploring the Possibilities of Embedding Heterogeneous Data Attributes in Familiar Visualizations; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Heterogeneous multi-dimensional data are now sufficiently common that they can be referred to as ubiquitous. The most frequent approach to visualizing these data has been to propose new visualizations for representing these data. These new solutions are often inventive but tend to be unfamiliar. We take a different approach. We explore the possibility of extending well-known and familiar visualizations through including Heterogeneous Embedded Data Attributes (HEDA) in order to make familiar visualizations more powerful. We demonstrate how HEDA is a generic, interactive visualization component that can extend common visualization techniques while respecting the structure of the familiar layout. HEDA is a tabular visualization building block that enables individuals to visually observe, explore, and query their familiar visualizations through manipulation of embedded multivariate data. We describe the design space of HEDA by exploring its application to familiar visualizations in the D3 gallery. We characterize these familiar visualizations by the extent to which HEDA can facilitate data queries based on attribute reordering."}, {"color": "blue", "id": 1295, "label": 1295, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1295 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2598589\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Stephan Pajer;Marc Streit;Thomas Torsney-Weir;Florian Spechtenhauser;Torsten M\u00f6ller;Harald Piringer; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: WeightLifter: Visual Weight Space Exploration for Multi-Criteria Decision Making; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: A common strategy in Multi-Criteria Decision Making (MCDM) is to rank alternative solutions by weighted summary scores. Weights, however, are often abstract to the decision maker and can only be set by vague intuition. While previous work supports a point-wise exploration of weight spaces, we argue that MCDM can benefit from a regional and global visual analysis of weight spaces. Our main contribution is WeightLifter, a novel interactive visualization technique for weight-based MCDM that facilitates the exploration of weight spaces with up to ten criteria. Our technique enables users to better understand the sensitivity of a decision to changes of weights, to efficiently localize weight regions where a given solution ranks high, and to filter out solutions which do not rank high enough for any plausible combination of weights. We provide a comprehensive requirement analysis for weight-based MCDM and describe an interactive workflow that meets these requirements. For evaluation, we describe a usage scenario of WeightLifter in automotive engineering and report qualitative feedback from users of a deployed version as well as preliminary feedback from decision makers in multiple domains. This feedback confirms that WeightLifter increases both the efficiency of weight-based MCDM and the awareness of uncertainty in the ultimate decisions."}, {"color": "blue", "id": 1296, "label": 1296, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1296 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2598590\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Mengdie Hu;Krist Wongsuphasawat;John Stasko; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visualizing Social Media Content with SentenTree; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We introduce SentenTree, a novel technique for visualizing the content of unstructured social media text. SentenTree displays frequent sentence patterns abstracted from a corpus of social media posts. The technique employs design ideas from word clouds and the Word Tree, but overcomes a number of limitations of both those visualizations. SentenTree displays a node-link diagram where nodes are words and links indicate word co-occurrence within the same sentence. The spatial arrangement of nodes gives cues to the syntactic ordering of words while the size of nodes gives cues to their frequency of occurrence. SentenTree can help people gain a rapid understanding of key concepts and opinions in a large social media text collection. It is implemented as a lightweight application that runs in the browser."}, {"color": "blue", "id": 1299, "label": 1299, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1299 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2598594\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Evanthia Dimara;Anastasia Bezerianos;Pierre Dragicevic; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: The Attraction Effect in Information Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The attraction effect is a well-studied cognitive bias in decision making research, where one\u0027s choice between two alternatives is influenced by the presence of an irrelevant (dominated) third alternative. We examine whether this cognitive bias, so far only tested with three alternatives and simple presentation formats such as numerical tables, text and pictures, also appears in visualizations. Since visualizations can be used to support decision making - e.g., when choosing a house to buy or an employee to hire - a systematic bias could have important implications. In a first crowdsource experiment, we indeed partially replicated the attraction effect with three alternatives presented as a numerical table, and observed similar effects when they were presented as a scatterplot. In a second experiment, we investigated if the effect extends to larger sets of alternatives, where the number of alternatives is too large for numerical tables to be practical. Our findings indicate that the bias persists for larger sets of alternatives presented as scatterplots. We discuss implications for future research on how to further study and possibly alleviate the attraction effect."}, {"color": "red", "id": 1302, "label": 1302, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1302 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2598604\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Soumya Dutta;Chun-Ming Chen;Gregory Heinlein;Han-Wei Shen;Jen-Ping Chen; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: In Situ Distribution Guided Analysis and Visualization of Transonic Jet Engine Simulations; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Study of flow instability in turbine engine compressors is crucial to understand the inception and evolution of engine stall. Aerodynamics experts have been working on detecting the early signs of stall in order to devise novel stall suppression technologies. A state-of-the-art Navier-Stokes based, time-accurate computational fluid dynamics simulator, TURBO, has been developed in NASA to enhance the understanding of flow phenomena undergoing rotating stall. Despite the proven high modeling accuracy of TURBO, the excessive simulation data prohibits post-hoc analysis in both storage and I/O time. To address these issues and allow the expert to perform scalable stall analysis, we have designed an in situ distribution guided stall analysis technique. Our method summarizes statistics of important properties of the simulation data in situ using a probabilistic data modeling scheme. This data summarization enables statistical anomaly detection for flow instability in post analysis, which reveals the spatiotemporal trends of rotating stall for the expert to conceive new hypotheses. Furthermore, the verification of the hypotheses and exploratory visualization using the summarized data are realized using probabilistic visualization techniques such as uncertain isocontouring. Positive feedback from the domain scientist has indicated the efficacy of our system in exploratory stall analysis."}, {"color": "blue", "id": 1304, "label": 1304, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1304 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2598609\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Alex Bigelow;Steven Drucker;Danyel Fisher;Miriah Meyer; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Iterating between Tools to Create and Edit Visualizations; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: A common workflow for visualization designers begins with a generative tool, like D3 or Processing, to create the initial visualization; and proceeds to a drawing tool, like Adobe Illustrator or Inkscape, for editing and cleaning. Unfortunately, this is typically a one-way process: once a visualization is exported from the generative tool into a drawing tool, it is difficult to make further, data-driven changes. In this paper, we propose a bridge model to allow designers to bring their work back from the drawing tool to re-edit in the generative tool. Our key insight is to recast this iteration challenge as a merge problem - similar to when two people are editing a document and changes between them need to reconciled. We also present a specific instantiation of this model, a tool called Hanpuku, which bridges between D3 scripts and Illustrator. We show several examples of visualizations that are iteratively created using Hanpuku in order to illustrate the flexibility of the approach. We further describe several hypothetical tools that bridge between other visualization tools to emphasize the generality of the model."}, {"color": "blue", "id": 1307, "label": 1307, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1307 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2598620\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Nam Wook Kim;Eston Schweickart;Zhicheng Liu;Mira Dontcheva;Wilmot Li;Jovan Popovic;Hanspeter Pfister; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Data-Driven Guides: Supporting Expressive Design for Information Graphics; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In recent years, there is a growing need for communicating complex data in an accessible graphical form. Existing visualization creation tools support automatic visual encoding, but lack flexibility for creating custom design; on the other hand, freeform illustration tools require manual visual encoding, making the design process time-consuming and error-prone. In this paper, we present Data-Driven Guides (DDG), a technique for designing expressive information graphics in a graphic design environment. Instead of being confined by predefined templates or marks, designers can generate guides from data and use the guides to draw, place and measure custom shapes. We provide guides to encode data using three fundamental visual encoding channels: length, area, and position. Users can combine more than one guide to construct complex visual structures and map these structures to data. When underlying data is changed, we use a deformation technique to transform custom shapes using the guides as the backbone of the shapes. Our evaluation shows that data-driven guides allow users to create expressive and more accurate custom data-driven graphics."}, {"color": "blue", "id": 1309, "label": 1309, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1309 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2598647\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Fereshteh Amini;Nathalie Henry Riche;Bongshin Lee;Andres Monroy-Hernandez;Pourang Irani; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Authoring Data-Driven Videos with DataClips; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Data videos, or short data-driven motion graphics, are an increasingly popular medium for storytelling. However, creating data videos is difficult as it involves pulling together a unique combination of skills. We introduce DataClips, an authoring tool aimed at lowering the barriers to crafting data videos. DataClips allows non-experts to assemble data-driven \u201cclips\u201d together to form longer sequences. We constructed the library of data clips by analyzing the composition of over 70 data videos produced by reputable sources such as The New York Times and The Guardian. We demonstrate that DataClips can reproduce over 90% of our data videos corpus. We also report on a qualitative study comparing the authoring process and outcome achieved by (1) non-experts using DataClips, and (2) experts using Adobe Illustrator and After Effects to create data-driven clips. Results indicated that non-experts are able to learn and use DataClips with a short training period. In the span of one hour, they were able to produce more videos than experts using a professional editing tool, and their clips were rated similarly by an independent audience."}, {"color": "orange", "id": 1310, "label": 1310, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1310 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2598664\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Panpan Xu;Honghui Mei;Liu Ren;Wei Chen; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: ViDX: Visual Diagnostics of Assembly Line Performance in Smart Factories; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Visual analytics plays a key role in the era of connected industry (or industry 4.0, industrial internet) as modern machines and assembly lines generate large amounts of data and effective visual exploration techniques are needed for troubleshooting, process optimization, and decision making. However, developing effective visual analytics solutions for this application domain is a challenging task due to the sheer volume and the complexity of the data collected in the manufacturing processes. We report the design and implementation of a comprehensive visual analytics system, ViDX. It supports both real-time tracking of assembly line performance and historical data exploration to identify inefficiencies, locate anomalies, and form hypotheses about their causes and effects. The system is designed based on a set of requirements gathered through discussions with the managers and operators from manufacturing sites. It features interlinked views displaying data at different levels of detail. In particular, we apply and extend the Marey\u0027s graph by introducing a time-aware outlier-preserving visual aggregation technique to support effective troubleshooting in manufacturing processes. We also introduce two novel interaction techniques, namely the quantiles brush and samples brush, for the users to interactively steer the outlier detection algorithms. We evaluate the system with example use cases and an in-depth user interview, both conducted together with the managers and operators from manufacturing plants. The result demonstrates its effectiveness and reports a successful pilot application of visual analytics for manufacturing in smart factories."}, {"color": "blue", "id": 1311, "label": 1311, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1311 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2598667\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Matthew Berger;Katherine McDonough;Lee M. Seversky; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: cite2vec: Citation-Driven Document Exploration via Word Embeddings; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Effectively exploring and browsing document collections is a fundamental problem in visualization. Traditionally, document visualization is based on a data model that represents each document as the set of its comprised words, effectively characterizing what the document is. In this paper we take an alternative perspective: motivated by the manner in which users search documents in the research process, we aim to visualize documents via their usage, or how documents tend to be used. We present a new visualization scheme - cite2vec - that allows the user to dynamically explore and browse documents via how other documents use them, information that we capture through citation contexts in a document collection. Starting from a usage-oriented word-document 2D projection, the user can dynamically steer document projections by prescribing semantic concepts, both in the form of phrase/document compositions and document:phrase analogies, enabling the exploration and comparison of documents by their use. The user interactions are enabled by a joint representation of words and documents in a common high-dimensional embedding space where user-specified concepts correspond to linear operations of word and document vectors. Our case studies, centered around a large document corpus of computer vision research papers, highlight the potential for usage-based document visualization."}, {"color": "orange", "id": 1319, "label": 1319, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1319 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2598797\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Zhicheng Liu;Yang Wang;Mira Dontcheva;Matthew Hoffman;Seth Walker;Alan Wilson; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Patterns and Sequences: Interactive Exploration of Clickstreams to Understand Common Visitor Paths; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Modern web clickstream data consists of long, high-dimensional sequences of multivariate events, making it difficult to analyze. Following the overarching principle that the visual interface should provide information about the dataset at multiple levels of granularity and allow users to easily navigate across these levels, we identify four levels of granularity in clickstream analysis: patterns, segments, sequences and events. We present an analytic pipeline consisting of three stages: pattern mining, pattern pruning and coordinated exploration between patterns and sequences. Based on this approach, we discuss properties of maximal sequential patterns, propose methods to reduce the number of patterns and describe design considerations for visualizing the extracted sequential patterns and the corresponding raw sequences. We demonstrate the viability of our approach through an analysis scenario and discuss the strengths and limitations of the methods based on user feedback."}, {"color": "red", "id": 1323, "label": 1323, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1323 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2598827\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Petra Isenberg;Tobias Isenberg;Michael Sedlmair;Jian Chen;Torsten M\u00f6ller; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visualization as Seen through its Research Paper Keywords; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present the results of a comprehensive multi-pass analysis of visualization paper keywords supplied by authors for their papers published in the IEEE Visualization conference series (now called IEEE VIS) between 1990-2015. From this analysis we derived a set of visualization topics that we discuss in the context of the current taxonomy that is used to categorize papers and assign reviewers in the IEEE VIS reviewing process. We point out missing and overemphasized topics in the current taxonomy and start a discussion on the importance of establishing common visualization terminology. Our analysis of research topics in visualization can, thus, serve as a starting point to (a) help create a common vocabulary to improve communication among different visualization sub-groups, (b) facilitate the process of understanding differences and commonalities of the various research sub-fields in visualization, (c) provide an understanding of emerging new research trends, (d) facilitate the crucial step of finding the right reviewers for research submissions, and (e) it can eventually lead to a comprehensive taxonomy of visualization research. One additional tangible outcome of our work is an online query tool (http://keyvis.org/) that allows visualization researchers to easily browse the 3952 keywords used for IEEE VIS papers since 1990 to find related work or make informed keyword choices."}, {"color": "orange", "id": 1324, "label": 1324, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1324 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2598828\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Donghao Ren;Saleema Amershi;Bongshin Lee;Jina Suh;Jason D. Williams; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Squares: Supporting Interactive Performance Analysis for Multiclass Classifiers; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Performance analysis is critical in applied machine learning because it influences the models practitioners produce. Current performance analysis tools suffer from issues including obscuring important characteristics of model behavior and dissociating performance from data. In this work, we present Squares, a performance visualization for multiclass classification problems. Squares supports estimating common performance metrics while displaying instance-level distribution information necessary for helping practitioners prioritize efforts and access data. Our controlled study shows that practitioners can assess performance significantly faster and more accurately with Squares than a confusion matrix, a common performance analysis tool in machine learning."}, {"color": "orange", "id": 1325, "label": 1325, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1325 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2598829\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Gary K. L. Tam;Vivek Kothari;Min Chen; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: An Analysis of Machine- and Human-Analytics in Classification; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In this work, we present a study that traces the technical and cognitive processes in two visual analytics applications to a common theoretic model of soft knowledge that may be added into a visual analytics process for constructing a decision-tree model. Both case studies involved the development of classification models based on the \u201cbag of features\u201d approach. Both compared a visual analytics approach using parallel coordinates with a machine-learning approach using information theory. Both found that the visual analytics approach had some advantages over the machine learning approach, especially when sparse datasets were used as the ground truth. We examine various possible factors that may have contributed to such advantages, and collect empirical evidence for supporting the observation and reasoning of these factors. We propose an information-theoretic model as a common theoretic basis to explain the phenomena exhibited in these two case studies. Together we provide interconnected empirical and theoretical evidence to support the usefulness of visual analytics."}, {"color": "orange", "id": 1326, "label": 1326, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1326 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2598830\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Junpeng Wang;Xiaotong Liu;Han-Wei Shen;Guang Lin; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Multi-Resolution Climate Ensemble Parameter Analysis with Nested Parallel Coordinates Plots; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Due to the uncertain nature of weather prediction, climate simulations are usually performed multiple times with different spatial resolutions. The outputs of simulations are multi-resolution spatial temporal ensembles. Each simulation run uses a unique set of values for multiple convective parameters. Distinct parameter settings from different simulation runs in different resolutions constitute a multi-resolution high-dimensional parameter space. Understanding the correlation between the different convective parameters, and establishing a connection between the parameter settings and the ensemble outputs are crucial to domain scientists. The multi-resolution high-dimensional parameter space, however, presents a unique challenge to the existing correlation visualization techniques. We present Nested Parallel Coordinates Plot (NPCP), a new type of parallel coordinates plots that enables visualization of intra-resolution and inter-resolution parameter correlations. With flexible user control, NPCP integrates superimposition, juxtaposition and explicit encodings in a single view for comparative data visualization and analysis. We develop an integrated visual analytics system to help domain scientists understand the connection between multi-resolution convective parameters and the large spatial temporal ensembles. Our system presents intricate climate ensembles with a comprehensive overview and on-demand geographic details. We demonstrate NPCP, along with the climate ensemble visualization system, based on real-world use-cases from our collaborators in computational and predictive science."}, {"color": "orange", "id": 1327, "label": 1327, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1327 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2598831\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Mengchen Liu;Jiaxin Shi;Zhen Li;Chongxuan Li;Jun Zhu;Shixia Liu; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Towards Better Analysis of Deep Convolutional Neural Networks; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Deep convolutional neural networks (CNNs) have achieved breakthrough performance in many pattern recognition tasks such as image classification. However, the development of high-quality deep models typically relies on a substantial amount of trial-and-error, as there is still no clear understanding of when and why a deep model works. In this paper, we present a visual analytics approach for better understanding, diagnosing, and refining deep CNNs. We formulate a deep CNN as a directed acyclic graph. Based on this formulation, a hybrid visualization is developed to disclose the multiple facets of each neuron and the interactions between them. In particular, we introduce a hierarchical rectangle packing algorithm and a matrix reordering algorithm to show the derived features of a neuron cluster. We also propose a biclustering-based edge bundling method to reduce visual clutter caused by a large number of connections between neurons. We evaluated our method on a set of CNNs and the results are generally favorable."}, {"color": "orange", "id": 1328, "label": 1328, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1328 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2598838\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Paulo E. Rauber;Samuel G. Fadel;Alexandre X. Falc\u00e3o;Alexandru C. Telea; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visualizing the Hidden Activity of Artificial Neural Networks; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In machine learning, pattern classification assigns high-dimensional vectors (observations) to classes based on generalization from examples. Artificial neural networks currently achieve state-of-the-art results in this task. Although such networks are typically used as black-boxes, they are also widely believed to learn (high-dimensional) higher-level representations of the original observations. In this paper, we propose using dimensionality reduction for two tasks: visualizing the relationships between learned representations of observations, and visualizing the relationships between artificial neurons. Through experiments conducted in three traditional image classification benchmark datasets, we show how visualization can provide highly valuable feedback for network designers. For instance, our discoveries in one of these datasets (SVHN) include the presence of interpretable clusters of learned representations, and the partitioning of artificial neurons into groups with apparently related discriminative roles."}, {"color": "blue", "id": 1329, "label": 1329, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1329 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2598839\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Bahador Saket;Hannah Kim;Eli T. Brown;Alex Endert; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visualization by Demonstration: An Interaction Paradigm for Visual Data Exploration; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Although data visualization tools continue to improve, during the data exploration process many of them require users to manually specify visualization techniques, mappings, and parameters. In response, we present the Visualization by Demonstration paradigm, a novel interaction method for visual data exploration. A system which adopts this paradigm allows users to provide visual demonstrations of incremental changes to the visual representation. The system then recommends potential transformations (Visual Representation, Data Mapping, Axes, and View Specification transformations) from the given demonstrations. The user and the system continue to collaborate, incrementally producing more demonstrations and refining the transformations, until the most effective possible visualization is created. As a proof of concept, we present VisExemplar, a mixed-initiative prototype that allows users to explore their data by recommending appropriate transformations in response to the given demonstrations."}, {"color": "blue", "id": 1332, "label": 1332, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1332 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2598867\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Yanhong Wu;Nan Cao;Daniel Archambault;Qiaomu Shen;Huamin Qu;Weiwei Cui; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Evaluation of Graph Sampling: A Visualization Perspective; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Graph sampling is frequently used to address scalability issues when analyzing large graphs. Many algorithms have been proposed to sample graphs, and the performance of these algorithms has been quantified through metrics based on graph structural properties preserved by the sampling: degree distribution, clustering coefficient, and others. However, a perspective that is missing is the impact of these sampling strategies on the resultant visualizations. In this paper, we present the results of three user studies that investigate how sampling strategies influence node-link visualizations of graphs. In particular, five sampling strategies widely used in the graph mining literature are tested to determine how well they preserve visual features in node-link diagrams. Our results show that depending on the sampling strategy used different visual features are preserved. These results provide a complimentary view to metric evaluations conducted in the graph mining literature and provide an impetus to conduct future visualization studies."}, {"color": "red", "id": 1333, "label": 1333, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1333 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2598868\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Florian Ferstl;Mathias Kanzler;Marc Rautenhaus;R\u00fcdiger Westermann; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Time-Hierarchical Clustering and Visualization of Weather Forecast Ensembles; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We propose a new approach for analyzing the temporal growth of the uncertainty in ensembles of weather forecasts which are started from perturbed but similar initial conditions. As an alternative to traditional approaches in meteorology, which use juxtaposition and animation of spaghetti plots of iso-contours, we make use of contour clustering and provide means to encode forecast dynamics and spread in one single visualization. Based on a given ensemble clustering in a specified time window, we merge clusters in time-reversed order to indicate when and where forecast trajectories start to diverge. We present and compare different visualizations of the resulting time-hierarchical grouping, including space-time surfaces built by connecting cluster representatives over time, and stacked contour variability plots. We demonstrate the effectiveness of our visual encodings with forecast examples of the European Centre for Medium-Range Weather Forecasts, which convey the evolution of specific features in the data as well as the temporally increasing spatial variability."}, {"color": "red", "id": 1334, "label": 1334, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1334 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2598869\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Ayan Biswas;Guang Lin;Xiaotong Liu;Han-Wei Shen; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visualization of Time-Varying Weather Ensembles across Multiple Resolutions; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Uncertainty quantification in climate ensembles is an important topic for the domain scientists, especially for decision making in the real-world scenarios. With powerful computers, simulations now produce time-varying and multi-resolution ensemble data sets. It is of extreme importance to understand the model sensitivity given the input parameters such that more computation power can be allocated to the parameters with higher influence on the output. Also, when ensemble data is produced at different resolutions, understanding the accuracy of different resolutions helps the total time required to produce a desired quality solution with improved storage and computation cost. In this work, we propose to tackle these non-trivial problems on the Weather Research and Forecasting (WRF) model output. We employ a moment independent sensitivity measure to quantify and analyze parameter sensitivity across spatial regions and time domain. A comparison of clustering structures across three resolutions enables the users to investigate the sensitivity variation over the spatial regions of the five input parameters. The temporal trend in the sensitivity values is explored via an MDS view linked with a line chart for interactive brushing. The spatial and temporal views are connected to provide a full exploration system for complete spatio-temporal sensitivity analysis. To analyze the accuracy across varying resolutions, we formulate a Bayesian approach to identify which regions are better predicted at which resolutions compared to the observed precipitation. This information is aggregated over the time domain and finally encoded in an output image through a custom color map that guides the domain experts towards an adaptive grid implementation given a cost model. Users can select and further analyze the spatial and temporal error patterns for multi-resolution accuracy analysis via brushing and linking on the produced image. In this work, we collaborate with a domain expert whose feedback shows the effectiveness of our proposed exploration work-flow."}, {"color": "blue", "id": 1336, "label": 1336, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1336 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2598876\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Chris Bryan;Kwan-Liu Ma;Jonathan Woodring; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Temporal Summary Images: An Approach to Narrative Visualization via Interactive Annotation Generation and Placement; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Visualization is a powerful technique for analysis and communication of complex, multidimensional, and time-varying data. However, it can be difficult to manually synthesize a coherent narrative in a chart or graph due to the quantity of visualized attributes, a variety of salient features, and the awareness required to interpret points of interest (POls). We present Temporal Summary Images (TSIs) as an approach for both exploring this data and creating stories from it. As a visualization, a TSI is composed of three common components: (1) a temporal layout, (2) comic strip-style data snapshots, and (3) textual annotations. To augment user analysis and exploration, we have developed a number of interactive techniques that recommend relevant data features and design choices, including an automatic annotations workflow. As the analysis and visual design processes converge, the resultant image becomes appropriate for data storytelling. For validation, we use a prototype implementation for TSIs to conduct two case studies with large-scale, scientific simulation datasets."}, {"color": "blue", "id": 1337, "label": 1337, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1337 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2598885\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Yalong Yang;Tim Dwyer;Sarah Goodwin;Kim Marriott; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Many-to-Many Geographically-Embedded Flow Visualisation: An Evaluation; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Showing flows of people and resources between multiple geographic locations is a challenging visualisation problem. We conducted two quantitative user studies to evaluate different visual representations for such dense many-to-many flows. In our first study we compared a bundled node-link flow map representation and OD Maps [37] with a new visualisation we call MapTrix. Like OD Maps, MapTrix overcomes the clutter associated with a traditional flow map while providing geographic embedding that is missing in standard OD matrix representations. We found that OD Maps and MapTrix had similar performance while bundled node-link flow map representations did not scale at all well. Our second study compared participant performance with OD Maps and MapTrix on larger data sets. Again performance was remarkably similar."}, {"color": "blue", "id": 1341, "label": 1341, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1341 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2598920\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Sukwon Lee;Sung-Hee Kim;Bum Chul Kwon; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: VLAT: Development of a Visualization Literacy Assessment Test; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The Information Visualization community has begun to pay attention to visualization literacy; however, researchers still lack instruments for measuring the visualization literacy of users. In order to address this gap, we systematically developed a visualization literacy assessment test (VLAT), especially for non-expert users in data visualization, by following the established procedure of test development in Psychological and Educational Measurement: (1) Test Blueprint Construction, (2) Test Item Generation, (3) Content Validity Evaluation, (4) Test Tryout and Item Analysis, (5) Test Item Selection, and (6) Reliability Evaluation. The VLAT consists of 12 data visualizations and 53 multiple-choice test items that cover eight data visualization tasks. The test items in the VLAT were evaluated with respect to their essentialness by five domain experts in Information Visualization and Visual Analytics (average content validity ratio = 0.66). The VLAT was also tried out on a sample of 191 test takers and showed high reliability (reliability coefficient omega = 0.76). In addition, we demonstrated the relationship between users\u0027 visualization literacy and aptitude for learning an unfamiliar visualization and showed that they had a fairly high positive relationship (correlation coefficient = 0.64). Finally, we discuss evidence for the validity of the VLAT and potential research areas that are related to the instrument."}, {"color": "blue", "id": 1342, "label": 1342, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1342 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2598958\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Benjamin Bach;Nathalie Henry Riche;Christophe Hurter;Kim Marriott;Tim Dwyer; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Towards Unambiguous Edge Bundling: Investigating Confluent Drawings for Network Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In this paper, we investigate Confluent Drawings (CD), a technique for bundling edges in node-link diagrams based on network connectivity. Edge-bundling techniques are designed to reduce edge clutter in node-link diagrams by coalescing lines into common paths or bundles. Unfortunately, traditional bundling techniques introduce ambiguity since edges are only bundled by spatial proximity, rather than network connectivity; following an edge from its source to its target can lead to the perception of incorrect connectivity if edges are not clearly separated within the bundles. Contrary, CDs bundle edges based on common sources or targets. Thus, a smooth path along a confluent bundle indicates precise connectivity. While CDs have been described in theory, practical investigation and application to real-world networks (i.e., networks beyond those with certain planarity restrictions) is currently lacking. Here, we provide the first algorithm for constructing CDs from arbitrary directed and undirected networks and present a simple layout method, embedded in a sand box environment providing techniques for interactive exploration. We then investigate patterns and artifacts in CDs, which we compare to other common edge-bundling techniques. Finally, we present the first user study that compares edge-compression techniques, including CD, power graphs, metro-style, and common edge bundling. We found that users without particular expertise in visualization or network analysis are able to read small CDs without difficulty. Compared to existing bundling techniques, CDs are more likely to allow people to correctly perceive connectivity."}, {"color": "blue", "id": 1347, "label": 1347, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1347 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2599030\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Arvind Satyanarayan;Dominik Moritz;Kanit Wongsuphasawat;Jeffrey Heer; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Vega-Lite: A Grammar of Interactive Graphics; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present Vega-Lite, a high-level grammar that enables rapid specification of interactive data visualizations. Vega-Lite combines a traditional grammar of graphics, providing visual encoding rules and a composition algebra for layered and multi-view displays, with a novel grammar of interaction. Users specify interactive semantics by composing selections. In Vega-Lite, a selection is an abstraction that defines input event processing, points of interest, and a predicate function for inclusion testing. Selections parameterize visual encodings by serving as input data, defining scale extents, or by driving conditional logic. The Vega-Lite compiler automatically synthesizes requisite data flow and event handling logic, which users can override for further customization. In contrast to existing reactive specifications, Vega-Lite selections decompose an interaction design into concise, enumerable semantic units. We evaluate Vega-Lite through a range of examples, demonstrating succinct specification of both customized interaction methods and common techniques such as panning, zooming, and linked selection."}, {"color": "blue", "id": 1353, "label": 1353, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1353 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2599058\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Mi Feng;Cheng Deng;Evan M. Peck;Lane Harrison; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: HindSight: Encouraging Exploration through Direct Encoding of Personal Interaction History; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Physical and digital objects often leave markers of our use. Website links turn purple after we visit them, for example, showing us information we have yet to explore. These \u201cfootprints\u201d of interaction offer substantial benefits in information saturated environments - they enable us to easily revisit old information, systematically explore new information, and quickly resume tasks after interruption. While applying these design principles have been successful in HCI contexts, direct encodings of personal interaction history have received scarce attention in data visualization. One reason is that there is little guidance for integrating history into visualizations where many visual channels are already occupied by data. More importantly, there is not firm evidence that making users aware of their interaction history results in benefits with regards to exploration or insights. Following these observations, we propose HindSight - an umbrella term for the design space of representing interaction history directly in existing data visualizations. In this paper, we examine the value of HindSight principles by augmenting existing visualizations with visual indicators of user interaction history (e.g. How the Recession Shaped the Economy in 255 Charts, NYTimes). In controlled experiments of over 400 participants, we found that HindSight designs generally encouraged people to visit more data and recall different insights after interaction. The results of our experiments suggest that simple additions to visualizations can make users aware of their interaction history, and that these additions significantly impact users\u0027 exploration and insights."}, {"color": "blue", "id": 1359, "label": 1359, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1359 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2016.2599338\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Shiqing He;Eytan Adar; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: VizItCards: A Card-Based Toolkit for Infovis Design Education; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Shifts in information visualization practice are forcing a reconsideration of how infovis is taught. Traditional curricula that focused on conveying research-derived knowledge are slowly integrating design thinking as a key learning objective. In part, this is motivated by the realization that infovis is a wicked design problem, requiring a different kind of design work. In this paper we describe, VizItCards, a card-driven workshop developed for our graduate infovis class. The workshop is intended to provide practice with good design techniques and to simultaneously reinforce key concepts. VizItCards relies on principles of collaborative-learning and research on parallel design to generate positive collaborations and high-quality designs. From our experience of simulating a realistic design scenario in a classroom setting, we find that our students were able to meet key learning objectives and their design performance improved during the class. We describe variants of the workshop, discussing which techniques we think match to which learning goals."}, {"color": "orange", "id": 1362, "label": 1362, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1362 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2016.7883507\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Florian Heimerl;Markus John;Qi Han;Steffen Koch;Thomas Ertl; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: DocuCompass: Effective exploration of document landscapes; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The creation of interactive visualization to analyze text documents has gained an impressive momentum in recent years. This is not surprising in the light of massive and still increasing amounts of available digitized texts. Websites, social media, news wire, and digital libraries are just few examples of the diverse text sources whose visual analysis and exploration offers new opportunities to effectively mine and manage the information and knowledge hidden within them. A popular visualization method for large text collections is to represent each document by a glyph in 2D space. These landscapes can be the result of optimizing pairwise distances in 2D to represent document similarities, or they are provided directly as meta data, such as geo-locations. For well-defined information needs, suitable interaction methods are available for these spatializations. However, free exploration and navigation on a level of abstraction between a labeled document spatialization and reading single documents is largely unsupported. As a result, vital foraging steps for task-tailored actions, such as selecting subgroups of documents for detailed inspection, or subsequent sense-making steps are hampered. To fill in this gap, we propose DocuCompass, a focus+context approach based on the lens metaphor. It comprises multiple methods to characterize local groups of documents, and to efficiently guide exploration based on users\u0027 requirements. DocuCompass thus allows for effective interactive exploration of document landscapes without disrupting the mental map of users by changing the layout itself. We discuss the suitability of multiple navigation and characterization methods for different spatializations and texts. Finally, we provide insights generated through user feedback and discuss the effectiveness of our approach."}, {"color": "orange", "id": 1365, "label": 1365, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1365 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2016.7883510\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Siming Chen;Shuai Chen;Zhenhuang Wang;Jie Liang;Xiaoru Yuan;Nan Cao;Yadong Wu; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: D-Map: Visual Analysis of Ego-centric Information Diffusion Patterns in Social Media; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Popular social media platforms could rapidly propagate vital information over social networks among a significant number of people. In this work we present D-Map (Diffusion Map), a novel visualization method to support exploration and analysis of social behaviors during such information diffusion and propagation on typical social media through a map metaphor. In D-Map, users who participated in reposting (i.e., resending a message initially posted by others) one central user\u0027s posts (i.e., a series of original tweets) are collected and mapped to a hexagonal grid based on their behavior similarities and in chronological order of the repostings. With additional interaction and linking, D-Map is capable of providing visual portraits of the influential users and describing their social behaviors. A comprehensive visual analysis system is developed to support interactive exploration with D-Map. We evaluate our work with real world social media data and find interesting patterns among users. Key players, important information diffusion paths, and interactions among social communities can be identified."}, {"color": "orange", "id": 1366, "label": 1366, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1366 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2016.7883511\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Xiting Wang;Shixia Liu;Yang Chen;Tai-Quan Peng;Jing Su;Jing Yang;Baining Guo; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: How ideas flow across multiple social groups; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Tracking how correlated ideas flow within and across multiple social groups facilitates the understanding of the transfer of information, opinions, and thoughts on social media. In this paper, we present IdeaFlow, a visual analytics system for analyzing the lead-lag changes within and across pre-defined social groups regarding a specific set of correlated ideas, each of which is described by a set of words. To model idea flows accurately, we develop a random-walk-based correlation model and integrate it with Bayesian conditional cointegration and a tensor-based technique. To convey complex lead-lag relationships over time, IdeaFlow combines the strengths of a bubble tree, a flow map, and a timeline. In particular, we develop a Voronoi-treemap-based bubble tree to help users get an overview of a set of ideas quickly. A correlated-clustering-based layout algorithm is used to simultaneously generate multiple flow maps with less ambiguity. We also introduce a focus+context timeline to explore huge amounts of temporal data at different levels of time granularity. Quantitative evaluation and case studies demonstrate the accuracy and effectiveness of IdeaFlow."}, {"color": "orange", "id": 1367, "label": 1367, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1367 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2016.7883512\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Fan Du;Catherine Plaisant;Neil Spring;Ben Shneiderman; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: EventAction: Visual analytics for temporal event sequence recommendation; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Recommender systems are being widely used to assist people in making decisions, for example, recommending films to watch or books to buy. Despite its ubiquity, the problem of presenting the recommendations of temporal event sequences has not been studied. We propose EventAction, which to our knowledge, is the first attempt at a prescriptive analytics interface designed to present and explain recommendations of temporal event sequences. EventAction provides a visual analytics approach to (1) identify similar records, (2) explore potential outcomes, (3) review recommended temporal event sequences that might help achieve the users\u0027 goals, and (4) interactively assist users as they define a personalized action plan associated with a probability of success. Following the design study framework, we designed and deployed EventAction in the context of student advising and reported on the evaluation with a student review manager and three graduate students."}, {"color": "orange", "id": 1368, "label": 1368, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1368 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2016.7883513\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Xiaotong Liu;Anbang Xu;Liang Gou;Haibin Liu;Rama Akkiraju;Han-Wei Shen; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: SocialBrands: Visual analysis of public perceptions of brands on social media; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Public perceptions of a brand is critical to its performance. While social media has demonstrated a huge potential to shape public perceptions of brands, existing tools are not intuitive and explanatory for domain users to use as they fail to provide a comprehensive analysis framework for perceptions of brands. In this paper, we present SocialBrands, a novel visual analysis tool for brand managers to understand public perceptions of brands on social media. Social-Brands leverages brand personality framework in marketing literature and social computing approaches to compute the personality of brands from three driving factors (user imagery, employee imagery, and official announcement) on social media, and construct an evidence network explaining the association between brand personality and driving factors. These computational results are then integrated with new interactive visualizations to help brand managers understand personality traits and their driving factors. We demonstrate the usefulness and effectiveness of SocialBrands through a series of user studies with brand managers in an enterprise context. Design lessons are also derived from our studies."}, {"color": "orange", "id": 1369, "label": 1369, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1369 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2016.7883514\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jing Xia;Wei Chen;Yumeng Hou;Wanqi Hu;Xinxin Huang;David S. Ebertk; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: DimScanner: A Relation-based Visual Exploration Approach Towards Data Dimension Inspection; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Exploring multi-dimensional datasets can be cumbersome if data analysts have little knowledge about the data. Various dimension relation inspection tools and dimension exploration tools have been proposed for efficient data examining and understanding. However, the needed workload varies largely with respect to data complexity and user expertise, which can only be reduced with rich background knowledge over the data. In this paper we address the workload challenge with a data structuring and exploration scheme that affords dimension relation detection and that serves as the background knowledge for further investigation. We contribute a novel data structuring scheme that leverages an information-theoretic view structuring algorithm to uncover information-aware relations among different data views, and thereby discloses redundancy and other relation patterns among dimensions. The integrated system, DimScanner, empowers analysts with rich user controls and assistance widgets to interactively detect the relations of multi-dimensional data."}, {"color": "orange", "id": 1370, "label": 1370, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1370 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2016.7883515\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Phong H. Nguyen;Kai Xu;Andy Bardill;Betul Salman;Kate Herd;B.L. William Wong; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: SenseMap: Supporting browser-based online sensemaking through analytic provenance; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Sensemaking is described as the process in which people collect, organize and create representations of information, all centered around some problem they need to understand. People often get lost when solving complicated tasks using big datasets over long periods of exploration and analysis. They may forget what they have done, are unaware of where they are in the context of the overall task, and are unsure where to continue. In this paper, we introduce a tool, SenseMap, to address these issues in the context of browser-based online sensemaking. We conducted a semi-structured interview with nine participants to explore their behaviors in online sensemaking with existing browser functionality. A simplified sensemaking model based on Pirolli and Card\u0027s model is derived to better represent the behaviors we found: users iteratively collect information sources relevant to the task, curate them in a way that makes sense, and finally communicate their findings to others. SenseMap automatically captures provenance of user sensemaking actions and provides multi-linked views to visualize the collected information and enable users to curate and communicate their findings. To explore how SenseMap is used, we conducted a user study in a naturalistic work setting with five participants completing the same sensemaking task related to their daily work activities. All participants found the visual representation and interaction of the tool intuitive to use. Three of them engaged with the tool and produced successful outcomes. It helped them to organize information sources, to quickly find and navigate to the sources they wanted, and to effectively communicate their findings."}, {"color": "orange", "id": 1372, "label": 1372, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1372 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2016.7883517\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Yuanzhe Chen;Qing Chen;Mingqian Zhao;Sebastien Boyer;Kalyan Veeramachaneni;Huamin Qu; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: DropoutSeer: Visualizing learning patterns in Massive Open Online Courses for dropout reasoning and prediction; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Aiming at massive participation and open access education, Massive Open Online Courses (MOOCs) have attracted millions of learners over the past few years. However, the high dropout rate of learners is considered to be one of the most crucial factors that may hinder the development of MOOCs. To tackle this problem, statistical models have been developed to predict dropout behavior based on learner activity logs. Although predictive models can foresee the dropout behavior, it is still difficult for users to understand the reasons behind the predicted results and further design interventions to prevent dropout. In addition, with a better understanding of dropout, researchers in the area of predictive modeling in turn can improve the models. In this paper, we introduce DropoutSeer, a visual analytics system which not only helps instructors and education experts understand the reasons for dropout, but also allows researchers to identify crucial features which can further improve the performance of the models. Both the heterogeneous data extracted from three different kinds of learner activity logs (i.e., clickstream, forum posts and assignment records) and the predicted results are visualized in the proposed system. Case studies and expert interviews have been conducted to demonstrate the usefulness and effectiveness of DropoutSeer."}, {"color": "orange", "id": 1375, "label": 1375, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1375 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2016.7883520\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Tanja Blascheck;Fabian Beck;Sebastian Baltes;Thomas Ertl;Daniel Weiskopf; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visual analysis and coding of data-rich user behavior; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Investigating user behavior involves abstracting low-level events to higher-level concepts. This requires an analyst to study individual user activities, assign codes which categorize behavior, and develop a consistent classification scheme. To better support this reasoning process of an analyst, we suggest a novel visual analytics approach which integrates rich user data including transcripts, videos, eye movement data, and interaction logs. Word-sized visualizations embedded into a tabular representation provide a space-efficient and detailed overview of user activities. An analyst assigns codes, grouped into code categories, as part of an interactive process. Filtering and searching helps to select specific activities and focus an analysis. A comparison visualization summarizes results of coding and reveals relationships between codes. Editing features support efficient assignment, refinement, and aggregation of codes. We demonstrate the practical applicability and usefulness of our approach in a case study and describe expert feedback."}, {"color": "blue", "id": 1377, "label": 1377, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1377 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2743859\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Philipp Koytek;Charles Perin;Jo Vermeulen;Elisabeth Andr\u00e9;Sheelagh Carpendale; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: MyBrush: Brushing and Linking with Personal Agency; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We extend the popular brushing and linking technique by incorporating personal agency in the interaction. We map existing research related to brushing and linking into a design space that deconstructs the interaction technique into three components: source (what is being brushed), link (the expression of relationship between source and target), and target (what is revealed as related to the source). Using this design space, we created MyBrush, a unified interface that offers personal agency over brushing and linking by giving people the flexibility to configure the source, link, and target of multiple brushes. The results of three focus groups demonstrate that people with different backgrounds leveraged personal agency in different ways, including performing complex tasks and showing links explicitly. We reflect on these results, paving the way for future research on the role of personal agency in information visualization."}, {"color": "blue", "id": 1379, "label": 1379, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1379 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2743918\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Charles Perin;Tiffany Wun;Richard Pusch;Sheelagh Carpendale; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Assessing the Graphical Perception of Time and Speed on 2D+Time Trajectories; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We empirically evaluate the extent to which people perceive non-constant time and speed encoded on 2D paths. In our graphical perception study, we evaluate nine encodings from the literature for both straight and curved paths. Visualizing time and speed information is a challenge when the x and y axes already encode other data dimensions, for example when plotting a trip on a map. This is particularly true in disciplines such as time-geography and movement analytics that often require visualizing spatio-temporal trajectories. A common approach is to use 2D+time trajectories, which are 2D paths for which time is an additional dimension. However, there are currently no guidelines regarding how to represent time and speed on such paths. Our study results provide InfoVis designers with clear guidance regarding which encodings to use and which ones to avoid; in particular, we suggest using color value to encode speed and segment length to encode time whenever possible."}, {"color": "red", "id": 1380, "label": 1380, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1380 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2743938\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Julien Tierny;Guillaume Favelier;Joshua A. Levine;Charles Gueunet;Michael Michaux; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: The Topology ToolKit; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: This system paper presents the Topology ToolKit (TTK), a software platform designed for the topological analysis of scalar data in scientific visualization. While topological data analysis has gained in popularity over the last two decades, it has not yet been widely adopted as a standard data analysis tool for end users or developers. TTK aims at addressing this problem by providing a unified, generic, efficient, and robust implementation of key algorithms for the topological analysis of scalar data, including: critical points, integral lines, persistence diagrams, persistence curves, merge trees, contour trees, Morse-Smale complexes, fiber surfaces, continuous scatterplots, Jacobi sets, Reeb spaces, and more. TTK is easily accessible to end users due to a tight integration with ParaView. It is also easily accessible to developers through a variety of bindings (Python, VTK/C++) for fast prototyping or through direct, dependency-free, C++, to ease integration into pre-existing complex systems. While developing TTK, we faced several algorithmic and software engineering challenges, which we document in this paper. In particular, we present an algorithm for the construction of a discrete gradient that complies to the critical points extracted in the piecewise-linear setting. This algorithm guarantees a combinatorial consistency across the topological abstractions supported by TTK, and importantly, a unified implementation of topological data simplification for multi-scale exploration and analysis. We also present a cached triangulation data structure, that supports time efficient and generic traversals, which self-adjusts its memory usage on demand for input simplicial meshes and which implicitly emulates a triangulation for regular grids with no memory overhead. Finally, we describe an original software architecture, which guarantees memory efficient and direct accesses to TTK features, while still allowing for researchers powerful and easy bindings and extensions. TTK is open source (BSD license) and its code. online documentation and video tutorials are available on TTK\u0027s website [108]."}, {"color": "blue", "id": 1383, "label": 1383, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1383 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2743959\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jochen G\u00f6rtler;Christoph Schulz;Daniel Weiskopf;Oliver Deussen; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Bubble Treemaps for Uncertainty Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present a novel type of circular treemap, where we intentionally allocate extra space for additional visual variables. With this extended visual design space, we encode hierarchically structured data along with their uncertainties in a combined diagram. We introduce a hierarchical and force-based circle-packing algorithm to compute Bubble Treemaps, where each node is visualized using nested contour arcs. Bubble Treemaps do not require any color or shading, which offers additional design choices. We explore uncertainty visualization as an application of our treemaps using standard error and Monte Carlo-based statistical models. To this end, we discuss how uncertainty propagates within hierarchies. Furthermore, we show the effectiveness of our visualization using three different examples: the package structure of Flare, the S\u0026amp;P 500 index, and the US consumer expenditure survey."}, {"color": "orange", "id": 1389, "label": 1389, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1389 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2743990\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Andrea Batch;Niklas Elmqvist; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: The Interactive Visualization Gap in Initial Exploratory Data Analysis; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Data scientists and other analytic professionals often use interactive visualization in the dissemination phase at the end of a workflow during which findings are communicated to a wider audience. Visualization scientists, however, hold that interactive representation of data can also be used during exploratory analysis itself. Since the use of interactive visualization is optional rather than mandatory, this leaves a \u201cvisualization gap\u201d during initial exploratory analysis that is the onus of visualization researchers to fill. In this paper, we explore areas where visualization would be beneficial in applied research by conducting a design study using a novel variation on contextual inquiry conducted with professional data analysts. Based on these interviews and experiments, we propose a set of interactive initial exploratory visualization guidelines which we believe will promote adoption by this type of user."}, {"color": "blue", "id": 1390, "label": 1390, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1390 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2743998\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Romain Vuillemot;Jeremy Boy; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Structuring Visualization Mock-Ups at the Graphical Level by Dividing the Display Space; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Mock-ups are rapid, low fidelity prototypes, that are used in many design-related fields to generate and share ideas. While their creation is supported by many mature methods and tools, surprisingly few are suited for the needs of information visualization. In this article, we introduce a novel approach to creating visualizations mock-ups, based on a dialogue between graphic design and parametric toolkit explorations. Our approach consists in iteratively subdividing the display space, while progressively informing each division with realistic data. We show that a wealth of mock-ups can easily be created using only temporary data attributes, as we wait for more realistic data to become available. We describe the implementation of this approach in a D3-based toolkit, which we use to highlight its generative power, and we discuss the potential for transitioning towards higher fidelity prototypes."}, {"color": "blue", "id": 1392, "label": 1392, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1392 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2744019\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Ricardo Langner;Tom Horak;Raimund Dachselt; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: VisTiles: Coordinating and Combining Co-located Mobile Devices for Visual Data Exploration; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present VisTiles, a conceptual framework that uses a set of mobile devices to distribute and coordinate visualization views for the exploration of multivariate data. In contrast to desktop-based interfaces for information visualization, mobile devices offer the potential to provide a dynamic and user-defined interface supporting co-located collaborative data exploration with different individual workflows. As part of our framework, we contribute concepts that enable users to interact with coordinated \u0026amp; multiple views (CMV) that are distributed across several mobile devices. The major components of the framework are: (i) dynamic and flexible layouts for CMV focusing on the distribution of views and (ii) an interaction concept for smart adaptations and combinations of visualizations utilizing explicit side-by-side arrangements of devices. As a result, users can benefit from the possibility to combine devices and organize them in meaningful spatial layouts. Furthermore, we present a web-based prototype implementation as a specific instance of our concepts. This implementation provides a practical application case enabling users to explore a multivariate data collection. We also illustrate the design process including feedback from a preliminary user study, which informed the design of both the concepts and the final prototype."}, {"color": "orange", "id": 1399, "label": 1399, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1399 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2744098\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jiazhi Xia;Fenjin Ye;Wei Chen;Yusi Wang;Weifeng Chen;Yuxin Ma;Anthony K.H. Tung; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: LDSScanner: Exploratory Analysis of Low-Dimensional Structures in High-Dimensional Datasets; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Many approaches for analyzing a high-dimensional dataset assume that the dataset contains specific structures, e.g., clusters in linear subspaces or non-linear manifolds. This yields a trial-and-error process to verify the appropriate model and parameters. This paper contributes an exploratory interface that supports visual identification of low-dimensional structures in a high-dimensional dataset, and facilitates the optimized selection of data models and configurations. Our key idea is to abstract a set of global and local feature descriptors from the neighborhood graph-based representation of the latent low-dimensional structure, such as pairwise geodesic distance (GD) among points and pairwise local tangent space divergence (LTSD) among pointwise local tangent spaces (LTS). We propose a new LTSD-GD view, which is constructed by mapping LTSD and GD to the\u003cinline-formula\u003e\u003ctex-math notation=\"LaTeX\"\u003e$x$\u003c/tex-math\u003e\u003calternatives\u003e\u003cinline-graphic xlink:href=\"24tvcg01-xia-2744098-ieq-1-source.tif\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"/\u003e\u003c/alternatives\u003e\u003c/inline-formula\u003eaxis and\u003cinline-formula\u003e\u003ctex-math notation=\"LaTeX\"\u003e$y$\u003c/tex-math\u003e\u003calternatives\u003e\u003cinline-graphic xlink:href=\"24tvcg01-xia-2744098-ieq-2-source.tif\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"/\u003e\u003c/alternatives\u003e\u003c/inline-formula\u003eaxis using 1D multidimensional scaling, respectively. Unlike traditional dimensionality reduction methods that preserve various kinds of distances among points, the LTSD-GD view presents the distribution of pointwise LTS (\u003cinline-formula\u003e\u003ctex-math notation=\"LaTeX\"\u003e$x$\u003c/tex-math\u003e\u003calternatives\u003e\u003cinline-graphic xlink:href=\"24tvcg01-xia-2744098-ieq-3-source.tif\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"/\u003e\u003c/alternatives\u003e\u003c/inline-formula\u003eaxis) and the variation of LTS in structures (the combination of\u003cinline-formula\u003e\u003ctex-math notation=\"LaTeX\"\u003e$x$\u003c/tex-math\u003e\u003calternatives\u003e\u003cinline-graphic xlink:href=\"24tvcg01-xia-2744098-ieq-4-source.tif\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"/\u003e\u003c/alternatives\u003e\u003c/inline-formula\u003eaxis and\u003cinline-formula\u003e\u003ctex-math notation=\"LaTeX\"\u003e$y$\u003c/tex-math\u003e\u003calternatives\u003e\u003cinline-graphic xlink:href=\"24tvcg01-xia-2744098-ieq-5-source.tif\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"/\u003e\u003c/alternatives\u003e\u003c/inline-formula\u003eaxis). We design and implement a suite of visual tools for navigating and reasoning about intrinsic structures of a high-dimensional dataset. Three case studies verify the effectiveness of our approach."}, {"color": "red", "id": 1400, "label": 1400, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1400 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2744099\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Subhashis Hazarika;Ayan Biswas;Han-Wei Shen; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Uncertainty Visualization Using Copula-Based Analysis in Mixed Distribution Models; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Distributions are often used to model uncertainty in many scientific datasets. To preserve the correlation among the spatially sampled grid locations in the dataset, various standard multivariate distribution models have been proposed in visualization literature. These models treat each grid location as a univariate random variable which models the uncertainty at that location. Standard multivariate distributions (both parametric and nonparametric) assume that all the univariate marginals are of the same type/family of distribution. But in reality, different grid locations show different statistical behavior which may not be modeled best by the same type of distribution. In this paper, we propose a new multivariate uncertainty modeling strategy to address the needs of uncertainty modeling in scientific datasets. Our proposed method is based on a statistically sound multivariate technique called Copula, which makes it possible to separate the process of estimating the univariate marginals and the process of modeling dependency, unlike the standard multivariate distributions. The modeling flexibility offered by our proposed method makes it possible to design distribution fields which can have different types of distribution (Gaussian, Histogram, KDE etc.) at the grid locations, while maintaining the correlation structure at the same time. Depending on the results of various standard statistical tests, we can choose an optimal distribution representation at each location, resulting in a more cost efficient modeling without significantly sacrificing on the analysis quality. To demonstrate the efficacy of our proposed modeling strategy, we extract and visualize uncertain features like isocontours and vortices in various real world datasets. We also study various modeling criterion to help users in the task of univariate model selection."}, {"color": "blue", "id": 1402, "label": 1402, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1402 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2744138\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Andr\u00e9 Calero Valdez;Martina Ziefle;Michael Sedlmair; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Priming and Anchoring Effects in Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We investigate priming and anchoring effects on perceptual tasks in visualization. Priming or anchoring effects depict the phenomena that a stimulus might influence subsequent human judgments on a perceptual level, or on a cognitive level by providing a frame of reference. Using visual class separability in scatterplots as an example task, we performed a set of five studies to investigate the potential existence of priming and anchoring effects. Our findings show that - under certain circumstances - such effects indeed exist. In other words, humans judge class separability of the same scatterplot differently depending on the scatterplot(s) they have seen before. These findings inform future work on better understanding and more accurately modeling human perception of visual patterns."}, {"color": "blue", "id": 1403, "label": 1403, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1403 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2744158\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Hendrik Strobelt;Sebastian Gehrmann;Hanspeter Pfister;Alexander M. Rush; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: LSTMVis: A Tool for Visual Analysis of Hidden State Dynamics in Recurrent Neural Networks; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Recurrent neural networks, and in particular long short-term memory (LSTM) networks, are a remarkably effective tool for sequence modeling that learn a dense black-box hidden representation of their sequential input. Researchers interested in better understanding these models have studied the changes in hidden state representations over time and noticed some interpretable patterns but also significant noise. In this work, we present LSTMVis, a visual analysis tool for recurrent neural networks with a focus on understanding these hidden state dynamics. The tool allows users to select a hypothesis input range to focus on local state changes, to match these states changes to similar patterns in a large data set, and to align these results with structural annotations from their domain. We show several use cases of the tool for analyzing specific hidden state properties on dataset containing nesting, phrase structure, and chord progressions, and demonstrate how the tool can be used to isolate patterns for further statistical analysis. We characterize the domain, the different stakeholders, and their goals and tasks. Long-term usage data after putting the tool online revealed great interest in the machine learning community."}, {"color": "red", "id": 1404, "label": 1404, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1404 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2744159\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Qiaomu Shen;Wei Zeng;Yu Ye;Stefan M\u00fcller Arisona;Simon Schubiger;Remo Burkhard;Huamin Qu; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: StreetVizor: Visual Exploration of Human-Scale Urban Forms Based on Street Views; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Urban forms at human-scale, i.e., urban environments that individuals can sense (e.g., sight, smell, and touch) in their daily lives, can provide unprecedented insights on a variety of applications, such as urban planning and environment auditing. The analysis of urban forms can help planners develop high-quality urban spaces through evidence-based design. However, such analysis is complex because of the involvement of spatial, multi-scale (i.e., city, region, and street), and multivariate (e.g., greenery and sky ratios) natures of urban forms. In addition, current methods either lack quantitative measurements or are limited to a small area. The primary contribution of this work is the design of StreetVizor, an interactive visual analytics system that helps planners leverage their domain knowledge in exploring human-scale urban forms based on street view images. Our system presents two-stage visual exploration: 1) an AOI Explorer for the visual comparison of spatial distributions and quantitative measurements in two areas-of-interest (AOIs) at city- and region-scales; 2) and a Street Explorer with a novel parallel coordinate plot for the exploration of the fine-grained details of the urban forms at the street-scale. We integrate visualization techniques with machine learning models to facilitate the detection of street view patterns. We illustrate the applicability of our approach with case studies on the real-world datasets of four cities, i.e., Hong Kong, Singapore, Greater London and New York City. Interviews with domain experts demonstrate the effectiveness of our system in facilitating various analytical tasks."}, {"color": "blue", "id": 1405, "label": 1405, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1405 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2744184\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Alper Sarikaya;Michael Gleicher; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Scatterplots: Tasks, Data, and Designs; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Traditional scatterplots fail to scale as the complexity and amount of data increases. In response, there exist many design options that modify or expand the traditional scatterplot design to meet these larger scales. This breadth of design options creates challenges for designers and practitioners who must select appropriate designs for particular analysis goals. In this paper, we help designers in making design choices for scatterplot visualizations. We survey the literature to catalog scatterplot-specific analysis tasks. We look at how data characteristics influence design decisions. We then survey scatterplot-like designs to understand the range of design options. Building upon these three organizations, we connect data characteristics, analysis tasks, and design choices in order to generate challenges, open questions, and example best practices for the effective design of scatterplots."}, {"color": "blue", "id": 1406, "label": 1406, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1406 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2744198\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Zening Qu;Jessica Hullman; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Keeping Multiple Views Consistent: Constraints, Validations, and Exceptions in Visualization Authoring; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Visualizations often appear in multiples, either in a single display (e.g., small multiples, dashboard) or across time or space (e.g., slideshow, set of dashboards). However, existing visualization design guidelines typically focus on single rather than multiple views. Solely following these guidelines can lead to effective yet inconsistent views (e.g., the same field has different axes domains across charts), making interpretation slow and error-prone. Moreover, little is known how consistency balances with other design considerations, making it difficult to incorporate consistency mechanisms in visualization authoring software. We present a wizard-of-oz study in which we observed how Tableau users achieve and sacrifice consistency in an exploration-to-presentation visualization design scenario. We extend (from our prior work) a set of encoding-specific constraints defining consistency across multiple views. Using the constraints as a checklist in our study, we observed cases where participants spontaneously maintained consistent encodings and warned cases where consistency was overlooked. In response to the warnings, participants either revised views for consistency or stated why they thought consistency should be overwritten. We categorize participants\u0027 actions and responses as constraint validations and exceptions, depicting the relative importance of consistency and other design considerations under various circumstances (e.g., data cardinality, available encoding resources, chart layout). We discuss automatic consistency checking as a constraint-satisfaction problem and provide design implications for communicating inconsistencies to users."}, {"color": "blue", "id": 1407, "label": 1407, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1407 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2744199\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Michael Gleicher; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Considerations for Visualizing Comparison; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Supporting comparison is a common and diverse challenge in visualization. Such support is difficult to design because solutions must address both the specifics of their scenario as well as the general issues of comparison. This paper aids designers by providing a strategy for considering those general issues. It presents four considerations that abstract comparison. These considerations identify issues and categorize solutions in a domain independent manner. The first considers how the common elements of comparison-a target set of items that are related and an action the user wants to perform on that relationship-are present in an analysis problem. The second considers why these elements lead to challenges because of their scale, in number of items, complexity of items, or complexity of relationship. The third considers what strategies address the identified scaling challenges, grouping solutions into three broad categories. The fourth considers which visual designs map to these strategies to provide solutions for a comparison analysis problem. In sequence, these considerations provide a process for developers to consider support for comparison in the design of visualization tools. Case studies show how these considerations can help in the design and evaluation of visualization solutions for comparison problems."}, {"color": "blue", "id": 1408, "label": 1408, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1408 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2744218\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Yingcai Wu;Ji Lan;Xinhuan Shu;Chenyang Ji;Kejian Zhao;Jiachen Wang;Hui Zhang; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: iTTVis: Interactive Visualization of Table Tennis Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The rapid development of information technology paved the way for the recording of fine-grained data, such as stroke techniques and stroke placements, during a table tennis match. This data recording creates opportunities to analyze and evaluate matches from new perspectives. Nevertheless, the increasingly complex data poses a significant challenge to make sense of and gain insights into. Analysts usually employ tedious and cumbersome methods which are limited to watching videos and reading statistical tables. However, existing sports visualization methods cannot be applied to visualizing table tennis competitions due to different competition rules and particular data attributes. In this work, we collaborate with data analysts to understand and characterize the sophisticated domain problem of analysis of table tennis data. We propose iTTVis, a novel interactive table tennis visualization system, which to our knowledge, is the first visual analysis system for analyzing and exploring table tennis data. iTTVis provides a holistic visualization of an entire match from three main perspectives, namely, time-oriented, statistical, and tactical analyses. The proposed system with several well-coordinated views not only supports correlation identification through statistics and pattern detection of tactics with a score timeline but also allows cross analysis to gain insights. Data analysts have obtained several new insights by using iTTVis. The effectiveness and usability of the proposed system are demonstrated with four case studies."}, {"color": "blue", "id": 1415, "label": 1415, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1415 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2744319\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Heidi Lam;Melanie Tory;Tamara Munzner; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Bridging from Goals to Tasks with Design Study Analysis Reports; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Visualization researchers and practitioners engaged in generating or evaluating designs are faced with the difficult problem of transforming the questions asked and actions taken by target users from domain-specific language and context into more abstract forms. Existing abstract task classifications aim to provide support for this endeavour by providing a carefully delineated suite of actions. Our experience is that this bottom-up approach is part of the challenge: low-level actions are difficult to interpret without a higher-level context of analysis goals and the analysis process. To bridge this gap, we propose a framework based on analysis reports derived from open-coding 20 design study papers published at IEEE InfoVis 2009-2015, to build on the previous work of abstractions that collectively encompass a broad variety of domains. The framework is organized in two axes illustrated by nine analysis goals. It helps situate the analysis goals by placing each goal under axes of specificity (Explore, Describe, Explain, Confirm) and number of data populations (Single, Multiple). The single-population types are Discover Observation, Describe Observation, Identify Main Cause, and Collect Evidence. The multiple-population types are Compare Entities, Explain Differences, and Evaluate Hypothesis. Each analysis goal is scoped by an input and an output and is characterized by analysis steps reported in the design study papers. We provide examples of how we and others have used the framework in a top-down approach to abstracting domain problems: visualization designers or researchers first identify the analysis goals of each unit of analysis in an analysis stream, and then encode the individual steps using existing task classifications with the context of the goal, the level of specificity, and the number of populations involved in the analysis."}, {"color": "blue", "id": 1419, "label": 1419, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1419 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2744338\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Christophe Hurter;St\u00e9phane Puechmorel;Florence Nicol;Alexandru Telea; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Functional Decomposition for Bundled Simplification of Trail Sets; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Bundling visually aggregates curves to reduce clutter and help finding important patterns in trail-sets or graph drawings. We propose a new approach to bundling based on functional decomposition of the underling dataset. We recover the functional nature of the curves by representing them as linear combinations of piecewise-polynomial basis functions with associated expansion coefficients. Next, we express all curves in a given cluster in terms of a centroid curve and a complementary term, via a set of so-called principal component functions. Based on the above, we propose a two-fold contribution: First, we use cluster centroids to design a new bundling method for 2D and 3D curve-sets. Secondly, we deform the cluster centroids and generate new curves along them, which enables us to modify the underlying data in a statistically-controlled way via its simplified (bundled) view. We demonstrate our method by applications on real-world 2D and 3D datasets for graph bundling, trajectory analysis, and vector field and tensor field visualization."}, {"color": "orange", "id": 1421, "label": 1421, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1421 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2744358\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Nicola Pezzotti;Thomas H\u00f6llt;Jan Van Gemert;Boudewijn P.F. Lelieveldt;Elmar Eisemann;Anna Vilanova; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: DeepEyes: Progressive Visual Analytics for Designing Deep Neural Networks; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Deep neural networks are now rivaling human accuracy in several pattern recognition problems. Compared to traditional classifiers, where features are handcrafted, neural networks learn increasingly complex features directly from the data. Instead of handcrafting the features, it is now the network architecture that is manually engineered. The network architecture parameters such as the number of layers or the number of filters per layer and their interconnections are essential for good performance. Even though basic design guidelines exist, designing a neural network is an iterative trial-and-error process that takes days or even weeks to perform due to the large datasets used for training. In this paper, we present DeepEyes, a Progressive Visual Analytics system that supports the design of neural networks during training. We present novel visualizations, supporting the identification of layers that learned a stable set of patterns and, therefore, are of interest for a detailed analysis. The system facilitates the identification of problems, such as superfluous filters or layers, and information that is not being captured by the network. We demonstrate the effectiveness of our system through multiple use cases, showing how a trained network can be compressed, reshaped and adapted to different problems."}, {"color": "blue", "id": 1422, "label": 1422, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1422 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2744359\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Danielle Albers Szafir; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Modeling Color Difference for Visualization Design; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Color is frequently used to encode values in visualizations. For color encodings to be effective, the mapping between colors and values must preserve important differences in the data. However, most guidelines for effective color choice in visualization are based on either color perceptions measured using large, uniform fields in optimal viewing environments or on qualitative intuitions. These limitations may cause data misinterpretation in visualizations, which frequently use small, elongated marks. Our goal is to develop quantitative metrics to help people use color more effectively in visualizations. We present a series of crowdsourced studies measuring color difference perceptions for three common mark types: points, bars, and lines. Our results indicate that peoples\u0027 abilities to perceive color differences varies significantly across mark types. Probabilistic models constructed from the resulting data can provide objective guidance for designers, allowing them to anticipate viewer perceptions in order to inform effective encoding design."}, {"color": "orange", "id": 1423, "label": 1423, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1423 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2744378\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Shixia Liu;Jiannan Xiao;Junlin Liu;Xiting Wang;Jing Wu;Jun Zhu; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visual Diagnosis of Tree Boosting Methods; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Tree boosting, which combines weak learners (typically decision trees) to generate a strong learner, is a highly effective and widely used machine learning method. However, the development of a high performance tree boosting model is a time-consuming process that requires numerous trial-and-error experiments. To tackle this issue, we have developed a visual diagnosis tool, BOOSTVis, to help experts quickly analyze and diagnose the training process of tree boosting. In particular, we have designed a temporal confusion matrix visualization, and combined it with a t-SNE projection and a tree visualization. These visualization components work together to provide a comprehensive overview of a tree boosting model, and enable an effective diagnosis of an unsatisfactory training process. Two case studies that were conducted on the Otto Group Product Classification Challenge dataset demonstrate that BOOSTVis can provide informative feedback and guidance to improve understanding and diagnosis of tree boosting algorithms."}, {"color": "orange", "id": 1427, "label": 1427, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1427 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2744458\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jian Zhao;Maoyuan Sun;Francine Chen;Patrick Chiu; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: BiDots: Visual Exploration of Weighted Biclusters; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Discovering and analyzing biclusters, i.e., two sets of related entities with close relationships, is a critical task in many real-world applications, such as exploring entity co-occurrences in intelligence analysis, and studying gene expression in bio-informatics. While the output of biclustering techniques can offer some initial low-level insights, visual approaches are required on top of that due to the algorithmic output complexity. This paper proposes a visualization technique, called BiDots, that allows analysts to interactively explore biclusters over multiple domains. BiDots overcomes several limitations of existing bicluster visualizations by encoding biclusters in a more compact and cluster-driven manner. A set of handy interactions is incorporated to support flexible analysis of biclustering results. More importantly, BiDots addresses the cases of weighted biclusters, which has been underexploited in the literature. The design of BiDots is grounded by a set of analytical tasks derived from previous work. We demonstrate its usefulness and effectiveness for exploring computed biclusters with an investigative document analysis task, in which suspicious people and activities are identified from a text corpus."}, {"color": "red", "id": 1428, "label": 1428, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1428 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2744459\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: G. Elisabeta Marai; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Activity-Centered Domain Characterization for Problem-Driven Scientific Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Although visualization design models exist in the literature in the form of higher-level methodological frameworks, these models do not present a clear methodological prescription for the domain characterization step. This work presents a framework and end-to-end model for requirements engineering in problem-driven visualization application design. The framework and model are based on the activity-centered design paradigm, which is an enhancement of human-centered design. The proposed activity-centered approach focuses on user tasks and activities, and allows an explicit link between the requirements engineering process with the abstraction stage - and its evaluation - of existing, higher-level visualization design models. In a departure from existing visualization design models, the resulting model: assigns value to a visualization based on user activities; ranks user tasks before the user data; partitions requirements in activity-related capabilities and nonfunctional characteristics and constraints; and explicitly incorporates the user workflows into the requirements process. A further merit of this model is its explicit integration of functional specifications, a concept this work adapts from the software engineering literature, into the visualization design nested model. A quantitative evaluation using two sets of interdisciplinary projects supports the merits of the activity-centered model. The result is a practical roadmap to the domain characterization step of visualization design for problem-driven data visualization. Following this domain characterization model can help remove a number of pitfalls that have been identified multiple times in the visualization design literature."}, {"color": "orange", "id": 1432, "label": 1432, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1432 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2744683\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Alsallakh Bilal;Amin Jourabloo;Mao Ye;Xiaoming Liu;Liu Ren; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Do Convolutional Neural Networks Learn Class Hierarchy?; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Convolutional Neural Networks (CNNs) currently achieve state-of-the-art accuracy in image classification. With a growing number of classes, the accuracy usually drops as the possibilities of confusion increase. Interestingly, the class confusion patterns follow a hierarchical structure over the classes. We present visual-analytics methods to reveal and analyze this hierarchy of similar classes in relation with CNN-internal data. We found that this hierarchy not only dictates the confusion patterns between the classes, it furthermore dictates the learning behavior of CNNs. In particular, the early layers in these networks develop feature detectors that can separate high-level groups of classes quite well, even after a few training epochs. In contrast, the latter layers require substantially more epochs to develop specialized feature detectors that can separate individual classes. We demonstrate how these insights are key to significant improvement in accuracy by designing hierarchy-aware CNNs that accelerate model convergence and alleviate overfitting. We further demonstrate how our methods help in identifying various quality issues in the training data."}, {"color": "orange", "id": 1436, "label": 1436, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1436 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2744718\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Minsuk Kahng;Pierre Y. Andrews;Aditya Kalro;Duen Horng (Polo) Chau; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: ActiVis: Visual Exploration of Industry-Scale Deep Neural Network Models; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: While deep learning models have achieved state-of-the-art accuracies for many prediction tasks, understanding these models remains a challenge. Despite the recent interest in developing visual tools to help users interpret deep learning models, the complexity and wide variety of models deployed in industry, and the large-scale datasets that they used, pose unique design challenges that are inadequately addressed by existing work. Through participatory design sessions with over 15 researchers and engineers at Facebook, we have developed, deployed, and iteratively improved ActiVis, an interactive visualization system for interpreting large-scale deep learning models and results. By tightly integrating multiple coordinated views, such as a computation graph overview of the model architecture, and a neuron activation view for pattern discovery and comparison, users can explore complex deep neural network models at both the instance-and subset-level. ActiVis has been deployed on Facebook\u0027s machine learning platform. We present case studies with Facebook researchers and engineers, and usage scenarios of how ActiVis may work with different models."}, {"color": "orange", "id": 1439, "label": 1439, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1439 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2744805\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Dominik Sacha;Matthias Kraus;J\u00fcrgen Bernard;Michael Behrisch;Tobias Schreck;Yuki Asano;Daniel A. Keim; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: SOMFlow: Guided Exploratory Cluster Analysis with Self-Organizing Maps and Analytic Provenance; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Clustering is a core building block for data analysis, aiming to extract otherwise hidden structures and relations from raw datasets, such as particular groups that can be effectively related, compared, and interpreted. A plethora of visual-interactive cluster analysis techniques has been proposed to date, however, arriving at useful clusterings often requires several rounds of user interactions to fine-tune the data preprocessing and algorithms. We present a multi-stage Visual Analytics (VA) approach for iterative cluster refinement together with an implementation (SOMFlow) that uses Self-Organizing Maps (SOM) to analyze time series data. It supports exploration by offering the analyst a visual platform to analyze intermediate results, adapt the underlying computations, iteratively partition the data, and to reflect previous analytical activities. The history of previous decisions is explicitly visualized within a flow graph, allowing to compare earlier cluster refinements and to explore relations. We further leverage quality and interestingness measures to guide the analyst in the discovery of useful patterns, relations, and data partitions. We conducted two pair analytics experiments together with a subject matter expert in speech intonation research to demonstrate that the approach is effective for interactive data analysis, supporting enhanced understanding of clustering results as well as the interactive process itself."}, {"color": "orange", "id": 1440, "label": 1440, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1440 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2744818\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: J\u00fcrgen Bernard;Marco Hutter;Matthias Zeppelzauer;Dieter Fellner;Michael Sedlmair; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Comparing Visual-Interactive Labeling with Active Learning: An Experimental Study; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Labeling data instances is an important task in machine learning and visual analytics. Both fields provide a broad set of labeling strategies, whereby machine learning (and in particular active learning) follows a rather model-centered approach and visual analytics employs rather user-centered approaches (visual-interactive labeling). Both approaches have individual strengths and weaknesses. In this work, we conduct an experiment with three parts to assess and compare the performance of these different labeling strategies. In our study, we (1) identify different visual labeling strategies for user-centered labeling, (2) investigate strengths and weaknesses of labeling strategies for different labeling tasks and task complexities, and (3) shed light on the effect of using different visual encodings to guide the visual-interactive labeling process. We further compare labeling of single versus multiple instances at a time, and quantify the impact on efficiency. We systematically compare the performance of visual interactive labeling with that of active learning. Our main findings are that visual-interactive labeling can outperform active learning, given the condition that dimension reduction separates well the class distributions. Moreover, using dimension reduction in combination with additional visual encodings that expose the internal state of the learning model turns out to improve the performance of visual-interactive labeling."}, {"color": "orange", "id": 1441, "label": 1441, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1441 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2744843\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Arjun Srinivasan;Hyunwoo Park;Alex Endert;Rahul C. Basole; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Graphiti: Interactive Specification of Attribute-Based Edges for Network Modeling and Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Network visualizations, often in the form of node-link diagrams, are an effective means to understand relationships between entities, discover entities with interesting characteristics, and to identify clusters. While several existing tools allow users to visualize pre-defined networks, creating these networks from raw data remains a challenging task, often requiring users to program custom scripts or write complex SQL commands. Some existing tools also allow users to both visualize and model networks. Interaction techniques adopted by these tools often assume users know the exact conditions for defining edges in the resulting networks. This assumption may not always hold true, however. In cases where users do not know much about attributes in the dataset or when there are several attributes to choose from, users may not know which attributes they could use to formulate linking conditions. We propose an alternate interaction technique to model networks that allows users to demonstrate to the system a subset of nodes and links they wish to see in the resulting network. The system, in response, recommends conditions that can be used to model networks based on the specified nodes and links. In this paper, we show how such a demonstration-based interaction technique can be used to model networks by employing it in a prototype tool, Graphiti. Through multiple usage scenarios, we show how Graphiti not only allows users to model networks from a tabular dataset but also facilitates updating a pre-defined network with additional edge types."}, {"color": "orange", "id": 1442, "label": 1442, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1442 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2744878\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Kanit Wongsuphasawat;Daniel Smilkov;James Wexler;Jimbo Wilson;Dandelion Man\u00e9;Doug Fritz;Dilip Krishnan;Fernanda B. Vi\u00e9gas;Martin Wattenberg; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visualizing Dataflow Graphs of Deep Learning Models in TensorFlow; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present a design study of the TensorFlow Graph Visualizer, part of the TensorFlow machine intelligence platform. This tool helps users understand complex machine learning architectures by visualizing their underlying dataflow graphs. The tool works by applying a series of graph transformations that enable standard layout techniques to produce a legible interactive diagram. To declutter the graph, we decouple non-critical nodes from the layout. To provide an overview, we build a clustered graph using the hierarchical structure annotated in the source code. To support exploration of nested structure on demand, we perform edge bundling to enable stable and responsive cluster expansion. Finally, we detect and highlight repeated structures to emphasize a model\u0027s modular composition. To demonstrate the utility of the visualizer, we describe example usage scenarios and report user feedback. Overall, users find the visualizer useful for understanding, debugging, and sharing the structures of their models."}, {"color": "orange", "id": 1444, "label": 1444, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1444 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2744938\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Mengchen Liu;Jiaxin Shi;Kelei Cao;Jun Zhu;Shixia Liu; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Analyzing the Training Processes of Deep Generative Models; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Among the many types of deep models, deep generative models (DGMs) provide a solution to the important problem of unsupervised and semi-supervised learning. However, training DGMs requires more skill, experience, and know-how because their training is more complex than other types of deep models such as convolutional neural networks (CNNs). We develop a visual analytics approach for better understanding and diagnosing the training process of a DGM. To help experts understand the overall training process, we first extract a large amount of time series data that represents training dynamics (e.g., activation changes over time). A blue-noise polyline sampling scheme is then introduced to select time series samples, which can both preserve outliers and reduce visual clutter. To further investigate the root cause of a failed training process, we propose a credit assignment algorithm that indicates how other neurons contribute to the output of the neuron causing the training failure. Two case studies are conducted with machine learning experts to demonstrate how our approach helps understand and diagnose the training processes of DGMs. We also show how our approach can be directly used to analyze other types of deep models, such as CNNs."}, {"color": "orange", "id": 1445, "label": 1445, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1445 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2745078\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Emily Wall;Subhajit Das;Ravish Chawla;Bharath Kalidindi;Eli T. Brown;Alex Endert; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Podium: Ranking Data Using Mixed-Initiative Visual Analytics; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: People often rank and order data points as a vital part of making decisions. Multi-attribute ranking systems are a common tool used to make these data-driven decisions. Such systems often take the form of a table-based visualization in which users assign weights to the attributes representing the quantifiable importance of each attribute to a decision, which the system then uses to compute a ranking of the data. However, these systems assume that users are able to quantify their conceptual understanding of how important particular attributes are to a decision. This is not always easy or even possible for users to do. Rather, people often have a more holistic understanding of the data. They form opinions that data point A is better than data point B but do not necessarily know which attributes are important. To address these challenges, we present a visual analytic application to help people rank multi-variate data points. We developed a prototype system, Podium, that allows users to drag rows in the table to rank order data points based on their perception of the relative value of the data. Podium then infers a weighting model using Ranking SVM that satisfies the user\u0027s data preferences as closely as possible. Whereas past systems help users understand the relationships between data points based on changes to attribute weights, our approach helps users to understand the attributes that might inform their understanding of the data. We present two usage scenarios to describe some of the potential uses of our proposed technique: (1) understanding which attributes contribute to a user\u0027s subjective preferences for data, and (2) deconstructing attributes of importance for existing rankings. Our proposed approach makes powerful machine learning techniques more usable to those who may not have expertise in these areas."}, {"color": "orange", "id": 1446, "label": 1446, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1446 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2745080\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Mennatallah El-Assady;Rita Sevastjanova;Fabian Sperrle;Daniel Keim;Christopher Collins; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Progressive Learning of Topic Modeling Parameters: A Visual Analytics Framework; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Topic modeling algorithms are widely used to analyze the thematic composition of text corpora but remain difficult to interpret and adjust. Addressing these limitations, we present a modular visual analytics framework, tackling the understandability and adaptability of topic models through a user-driven reinforcement learning process which does not require a deep understanding of the underlying topic modeling algorithms. Given a document corpus, our approach initializes two algorithm configurations based on a parameter space analysis that enhances document separability. We abstract the model complexity in an interactive visual workspace for exploring the automatic matching results of two models, investigating topic summaries, analyzing parameter distributions, and reviewing documents. The main contribution of our work is an iterative decision-making technique in which users provide a document-based relevance feedback that allows the framework to converge to a user-endorsed topic distribution. We also report feedback from a two-stage study which shows that our technique results in topic model quality improvements on two independent measures."}, {"color": "orange", "id": 1447, "label": 1447, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1447 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2745083\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Yuanzhe Chen;Panpan Xu;Liu Ren; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Sequence Synopsis: Optimize Visual Summary of Temporal Event Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Event sequences analysis plays an important role in many application domains such as customer behavior analysis, electronic health record analysis and vehicle fault diagnosis. Real-world event sequence data is often noisy and complex with high event cardinality, making it a challenging task to construct concise yet comprehensive overviews for such data. In this paper, we propose a novel visualization technique based on the minimum description length (MDL) principle to construct a coarse-level overview of event sequence data while balancing the information loss in it. The method addresses a fundamental trade-off in visualization design: reducing visual clutter vs. increasing the information content in a visualization. The method enables simultaneous sequence clustering and pattern extraction and is highly tolerant to noises such as missing or additional events in the data. Based on this approach we propose a visual analytics framework with multiple levels-of-detail to facilitate interactive data exploration. We demonstrate the usability and effectiveness of our approach through case studies with two real-world datasets. One dataset showcases a new application domain for event sequence visualization, i.e., fault development path analysis in vehicles for predictive maintenance. We also discuss the strengths and limitations of the proposed method based on user feedback."}, {"color": "orange", "id": 1451, "label": 1451, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1451 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2745118\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Michael Glueck;Mahdi Pakdaman Naeini;Finale Doshi-Velez;Fanny Chevalier;Azam Khan;Daniel Wigdor;Michael Brudno; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: PhenoLines: Phenotype Comparison Visualizations for Disease Subtyping via Topic Models; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: PhenoLines is a visual analysis tool for the interpretation of disease subtypes, derived from the application of topic models to clinical data. Topic models enable one to mine cross-sectional patient comorbidity data (e.g., electronic health records) and construct disease subtypes-each with its own temporally evolving prevalence and co-occurrence of phenotypes-without requiring aligned longitudinal phenotype data for all patients. However, the dimensionality of topic models makes interpretation challenging, and de facto analyses provide little intuition regarding phenotype relevance or phenotype interrelationships. PhenoLines enables one to compare phenotype prevalence within and across disease subtype topics, thus supporting subtype characterization, a task that involves identifying a proposed subtype\u0027s dominant phenotypes, ages of effect, and clinical validity. We contribute a data transformation workflow that employs the Human Phenotype Ontology to hierarchically organize phenotypes and aggregate the evolving probabilities produced by topic models. We introduce a novel measure of phenotype relevance that can be used to simplify the resulting topology. The design of PhenoLines was motivated by formative interviews with machine learning and clinical experts. We describe the collaborative design process, distill high-level tasks, and report on initial evaluations with machine learning experts and a medical domain expert. These results suggest that PhenoLines demonstrates promising approaches to support the characterization and optimization of topic models."}, {"color": "blue", "id": 1452, "label": 1452, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1452 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2745138\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Evanthia Dimara;Anastasia Bezerianos;Pierre Dragicevic; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Conceptual and Methodological Issues in Evaluating Multidimensional Visualizations for Decision Support; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We explore how to rigorously evaluate multidimensional visualizations for their ability to support decision making. We first define multi-attribute choice tasks, a type of decision task commonly performed with such visualizations. We then identify which of the existing multidimensional visualizations are compatible with such tasks, and set out to evaluate three elementary visualizations: parallel coordinates, scatterplot matrices and tabular visualizations. Our method consists in first giving participants low-level analytic tasks, in order to ensure that they properly understood the visualizations and their interactions. Participants are then given multi-attribute choice tasks consisting of choosing holiday packages. We assess decision support through multiple objective and subjective metrics, including a decision accuracy metric based on the consistency between the choice made and self-reported preferences for attributes. We found the three visualizations to be comparable on most metrics, with a slight advantage for tabular visualizations. In particular, tabular visualizations allow participants to reach decisions faster. Thus, although decision time is typically not central in assessing decision support, it can be used as a tie-breaker when visualizations achieve similar decision accuracy. Our results also suggest that indirect methods for assessing choice confidence may allow to better distinguish between visualizations than direct ones. We finally discuss the limitations of our methods and directions for future work, such as the need for more sensitive metrics of decision support."}, {"color": "orange", "id": 1457, "label": 1457, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1457 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2745178\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Alexander Kumpf;Bianca Tost;Marlene Baumgart;Michael Riemer;R\u00fcdiger Westermann;Marc Rautenhaus; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visualizing Confidence in Cluster-Based Ensemble Weather Forecast Analyses; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In meteorology, cluster analysis is frequently used to determine representative trends in ensemble weather predictions in a selected spatio-temporal region, e.g., to reduce a set of ensemble members to simplify and improve their analysis. Identified clusters (i.e., groups of similar members), however, can be very sensitive to small changes of the selected region, so that clustering results can be misleading and bias subsequent analyses. In this article, we - a team of visualization scientists and meteorologists-deliver visual analytics solutions to analyze the sensitivity of clustering results with respect to changes of a selected region. We propose an interactive visual interface that enables simultaneous visualization of a) the variation in composition of identified clusters (i.e., their robustness), b) the variability in cluster membership for individual ensemble members, and c) the uncertainty in the spatial locations of identified trends. We demonstrate that our solution shows meteorologists how representative a clustering result is, and with respect to which changes in the selected region it becomes unstable. Furthermore, our solution helps to identify those ensemble members which stably belong to a given cluster and can thus be considered similar. In a real-world application case we show how our approach is used to analyze the clustering behavior of different regions in a forecast of \u201cTropical Cyclone Karl\u201d, guiding the user towards the cluster robustness information required for subsequent ensemble analysis."}, {"color": "orange", "id": 1458, "label": 1458, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1458 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2745180\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Darren Edge;Nathalie Henry Riche;Jonathan Larson;Christopher White; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Beyond Tasks: An Activity Typology for Visual Analytics; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: As Visual Analytics (VA) research grows and diversifies to encompass new systems, techniques, and use contexts, gaining a holistic view of analytic practices is becoming ever more challenging. However, such a view is essential for researchers and practitioners seeking to develop systems for broad audiences that span multiple domains. In this paper, we interpret VA research through the lens of Activity Theory (AT) - a framework for modelling human activities that has been influential in the field of Human-Computer Interaction. We first provide an overview of Activity Theory, showing its potential for thinking beyond tasks, representations, and interactions to the broader systems of activity in which interactive tools are embedded and used. Next, we describe how Activity Theory can be used as an organizing framework in the construction of activity typologies, building and expanding upon the tradition of abstract task taxonomies in the field of Information Visualization. We then apply the resulting process to create an activity typology for Visual Analytics, synthesizing a wide range of systems and activity concepts from the literature. Finally, we use this typology as the foundation of an activity-centered design process, highlighting both tensions and opportunities in the design space of VA systems."}, {"color": "orange", "id": 1459, "label": 1459, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1459 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2745181\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Manuel Stein;Halldor Janetzko;Andreas Lamprecht;Thorsten Breitkreutz;Philipp Zimmermann;Bastian Goldl\u00fccke;Tobias Schreck;Gennady Andrienko;Michael Grossniklaus;Daniel A. Keim; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Bring It to the Pitch: Combining Video and Movement Data to Enhance Team Sport Analysis; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Analysts in professional team sport regularly perform analysis to gain strategic and tactical insights into player and team behavior. Goals of team sport analysis regularly include identification of weaknesses of opposing teams, or assessing performance and improvement potential of a coached team. Current analysis workflows are typically based on the analysis of team videos. Also, analysts can rely on techniques from Information Visualization, to depict e.g., player or ball trajectories. However, video analysis is typically a time-consuming process, where the analyst needs to memorize and annotate scenes. In contrast, visualization typically relies on an abstract data model, often using abstract visual mappings, and is not directly linked to the observed movement context anymore. We propose a visual analytics system that tightly integrates team sport video recordings with abstract visualization of underlying trajectory data. We apply appropriate computer vision techniques to extract trajectory data from video input. Furthermore, we apply advanced trajectory and movement analysis techniques to derive relevant team sport analytic measures for region, event and player analysis in the case of soccer analysis. Our system seamlessly integrates video and visualization modalities, enabling analysts to draw on the advantages of both analysis forms. Several expert studies conducted with team sport analysts indicate the effectiveness of our integrated approach."}, {"color": "orange", "id": 1462, "label": 1462, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1462 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2745258\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: John Wenskovitch;Ian Crandell;Naren Ramakrishnan;Leanna House;Scotland Leman;Chris North; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Towards a Systematic Combination of Dimension Reduction and Clustering in Visual Analytics; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Dimension reduction algorithms and clustering algorithms are both frequently used techniques in visual analytics. Both families of algorithms assist analysts in performing related tasks regarding the similarity of observations and finding groups in datasets. Though initially used independently, recent works have incorporated algorithms from each family into the same visualization systems. However, these algorithmic combinations are often ad hoc or disconnected, working independently and in parallel rather than integrating some degree of interdependence. A number of design decisions must be addressed when employing dimension reduction and clustering algorithms concurrently in a visualization system, including the selection of each algorithm, the order in which they are processed, and how to present and interact with the resulting projection. This paper contributes an overview of combining dimension reduction and clustering into a visualization system, discussing the challenges inherent in developing a visualization system that makes use of both families of algorithms."}, {"color": "blue", "id": 1463, "label": 1463, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1463 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2745278\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Bram C.M. Cappers;Jarke J. van Wijk; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Exploring Multivariate Event Sequences Using Rules, Aggregations, and Selections; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Multivariate event sequences are ubiquitous: travel history, telecommunication conversations, and server logs are some examples. Besides standard properties such as type and timestamp, events often have other associated multivariate data. Current exploration and analysis methods either focus on the temporal analysis of a single attribute or the structural analysis of the multivariate data only. We present an approach where users can explore event sequences at multivariate and sequential level simultaneously by interactively defining a set of rewrite rules using multivariate regular expressions. Users can store resulting patterns as new types of events or attributes to interactively enrich or simplify event sequences for further investigation. In Eventpad we provide a bottom-up glyph-oriented approach for multivariate event sequence analysis by searching, clustering, and aligning them according to newly defined domain specific properties. We illustrate the effectiveness of our approach with real-world data sets including telecommunication traffic and hospital treatments."}, {"color": "orange", "id": 1464, "label": 1464, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1464 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2745279\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jian Zhao;Michael Glueck;Petra Isenberg;Fanny Chevalier;Azam Khan; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Supporting Handoff in Asynchronous Collaborative Sensemaking Using Knowledge-Transfer Graphs; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: During asynchronous collaborative analysis, handoff of partial findings is challenging because externalizations produced by analysts may not adequately communicate their investigative process. To address this challenge, we developed techniques to automatically capture and help encode tacit aspects of the investigative process based on an analyst\u0027s interactions, and streamline explicit authoring of handoff annotations. We designed our techniques to mediate awareness of analysis coverage, support explicit communication of progress and uncertainty with annotation, and implicit communication through playback of investigation histories. To evaluate our techniques, we developed an interactive visual analysis system, KTGraph, that supports an asynchronous investigative document analysis task. We conducted a two-phase user study to characterize a set of handoff strategies and to compare investigative performance with and without our techniques. The results suggest that our techniques promote the use of more effective handoff strategies, help increase an awareness of prior investigative process and insights, as well as improve final investigative outcomes."}, {"color": "orange", "id": 1467, "label": 1467, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1467 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2745320\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Shunan Guo;Ke Xu;Rongwen Zhao;David Gotz;Hongyuan Zha;Nan Cao; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: EventThread: Visual Summarization and Stage Analysis of Event Sequence Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Event sequence data such as electronic health records, a person\u0027s academic records, or car service records, are ordered series of events which have occurred over a period of time. Analyzing collections of event sequences can reveal common or semantically important sequential patterns. For example, event sequence analysis might reveal frequently used care plans for treating a disease, typical publishing patterns of professors, and the patterns of service that result in a well-maintained car. It is challenging, however, to visually explore large numbers of event sequences, or sequences with large numbers of event types. Existing methods focus on extracting explicitly matching patterns of events using statistical analysis to create stages of event progression over time. However, these methods fail to capture latent clusters of similar but not identical evolutions of event sequences. In this paper, we introduce a novel visualization system named EventThread which clusters event sequences into threads based on tensor analysis and visualizes the latent stage categories and evolution patterns by interactively grouping the threads by similarity into time-specific clusters. We demonstrate the effectiveness of EventThread through usage scenarios in three different application domains and via interviews with an expert user."}, {"color": "blue", "id": 1469, "label": 1469, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1469 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2745878\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jonathan C. Roberts;Panagiotis D. Ritsos;James R. Jackson;Christopher Headleand; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: The Explanatory Visualization Framework: An Active Learning Framework for Teaching Creative Computing Using Explanatory Visualizations; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Visualizations are nowadays appearing in popular media and are used everyday in the workplace. This democratisation of visualization challenges educators to develop effective learning strategies, in order to train the next generation of creative visualization specialists. There is high demand for skilled individuals who can analyse a problem, consider alternative designs, develop new visualizations, and be creative and innovative. Our three-stage framework, leads the learner through a series of tasks, each designed to develop different skills necessary for coming up with creative, innovative, effective, and purposeful visualizations. For that, we get the learners to create an explanatory visualization of an algorithm of their choice. By making an algorithm choice, and by following an active-learning and project-based strategy, the learners take ownership of a particular visualization challenge. They become enthusiastic to develop good results and learn different creative skills on their learning journey."}, {"color": "blue", "id": 1470, "label": 1470, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1470 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2745919\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Yunhai Wang;Yanyan Wang;Yinqi Sun;Lifeng Zhu;Kecheng Lu;Chi-Wing Fu;Michael Sedlmair;Oliver Deussen;Baoquan Chen; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Revisiting Stress Majorization as a Unified Framework for Interactive Constrained Graph Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present an improved stress majorization method that incorporates various constraints, including directional constraints without the necessity of solving a constraint optimization problem. This is achieved by reformulating the stress function to impose constraints on both the edge vectors and lengths instead of just on the edge lengths (node distances). This is a unified framework for both constrained and unconstrained graph visualizations, where we can model most existing layout constraints, as well as develop new ones such as the star shapes and cluster separation constraints within stress majorization. This improvement also allows us to parallelize computation with an efficient GPU conjugant gradient solver, which yields fast and stable solutions, even for large graphs. As a result, we allow the constraint-based exploration of large graphs with 10K nodes - an approach which previous methods cannot support."}, {"color": "blue", "id": 1472, "label": 1472, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1472 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2745958\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jagoda Walny;Samuel Huron;Charles Perin;Tiffany Wun;Richard Pusch;Sheelagh Carpendale; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Active Reading of Visualizations; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We investigate whether the notion of active reading for text might be usefully applied to visualizations. Through a qualitative study we explored whether people apply observable active reading techniques when reading paper-based node-link visualizations. Participants used a range of physical actions while reading, and from these we synthesized an initial set of active reading techniques for visualizations. To learn more about the potential impact such techniques may have on visualization reading, we implemented support for one type of physical action from our observations (making freeform marks) in an interactive node-link visualization. Results from our quantitative study of this implementation show that interactive support for active reading techniques can improve the accuracy of performing low-level visualization tasks. Together, our studies suggest that the active reading space is ripe for research exploration within visualization and can lead to new interactions that make for a more flexible and effective visualization reading experience."}, {"color": "blue", "id": 1474, "label": 1474, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1474 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2017.2746018\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Cristian Felix;Steven Franconeri;Enrico Bertini; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Taking Word Clouds Apart: An Empirical Investigation of the Design Space for Keyword Summaries; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In this paper we present a set of four user studies aimed at exploring the visual design space of what we call keyword summaries: lists of words with associated quantitative values used to help people derive an intuition of what information a given document collection (or part of it) may contain. We seek to systematically study how different visual representations may affect people\u0027s performance in extracting information out of keyword summaries. To this purpose, we first create a design space of possible visual representations and compare the possible solutions in this design space through a variety of representative tasks and performance metrics. Other researchers have, in the past, studied some aspects of effectiveness with word clouds, however, the existing literature is somewhat scattered and do not seem to address the problem in a sufficiently systematic and holistic manner. The results of our studies showed a strong dependency on the tasks users are performing. In this paper we present details of our methodology, the results, as well as, guidelines on how to design effective keyword summaries based in our discoveries."}, {"color": "orange", "id": 1475, "label": 1475, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1475 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2017.8585484\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Haeyong Chung;Sai Prashanth Dasari;Santhosh Nandhakumar;Christopher Andrews; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: CRICTO: Supporting Sensemaking through Crowdsourced Information Schematization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present CRICTO, a new crowdsourcing visual analytics environment for making sense of and analyzing text data, whereby multiple crowdworkers are able to parallelize the simple information schematization tasks of relating and connecting entities across documents. The diverse links from these schematization tasks are then automatically combined and the system visualizes them based on the semantic types of the linkages. CRICTO also includes several tools that allow analysts to interactively explore and refine crowdworkers\u0027 results to better support their own sensemaking processes. We evaluated CRICTO\u0027s techniques and analysis workflow with deployments of CRICTO using Amazon Mechanical Turk and a user study that assess the effect of crowdsourced schematization in sensemaking tasks. The results of our evaluation show that CRICTO\u0027s crowdsourcing approaches and workflow help analysts explore diverse aspects of datasets, and uncover more accurate hidden stories embedded in the text datasets."}, {"color": "orange", "id": 1476, "label": 1476, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1476 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2017.8585487\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Dustin Arendt;Meg Pirrung; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: The y of it Matters, Even for Storyline Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Storylines are adept at communicating complex change by encoding time on the x-axis and using the proximity of lines in the y direction to represent interaction between entities. The original definition of a storyline visualization requires data defined in terms of explicit interaction groups. Relaxing this definition allows storyline visualization to be applied more generally, but this creates questions about how the y-coordinate should encode interactions when this is tied to a particular place or state. To answer this question, we conducted a design study where we considered two layout algorithm design alternatives within a geo-temporal analysis tool written to solve part of the VAST Challenge 2014. We measured the performance of users at overview and detail oriented tasks between two storyline layout algorithms. To the best of our knowledge, this paper is the first work to question the design principles for storyline visualization, and what we found surprised us. For overview tasks with the alternative layout, which has a consistent encoding for the y-coordinate, users performed moderately better (p \u0026lt;; .05) than the storyline layout based on existing design constraints and aesthetic criteria. Our empirical findings were also supported by first-hand accounts taken from interviews with multiple expert analysts, who suggested that the inconsistent meaning of the y-axis was misleading. These findings led us to design a new storyline layout algorithm that is a \u201cbest of both\u201d where the y-axis has a consistent meaning but aesthetic criteria (e.g., line crossings) are considered."}, {"color": "orange", "id": 1478, "label": 1478, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1478 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2017.8585505\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Stefan J\u00e4nicke;David Joseph Wrisley; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Interactive Visual Alignment of Medieval Text Versions; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Textual criticism consists of the identification and analysis of variant readings among different versions of a text. Being a relatively simple task for modern languages, the collation of medieval text traditions ranges from the complex to the virtually impossible depending on the degree of instability of textual transmission. We present a visual analytics environment that supports computationally aligning such complex textual differences typical of orally inflected medieval poetry. For the purpose of analyzing alignment, we provide interactive visualizations for different text hierarchy levels, specifically, a meso reading view to support investigating repetition and variance at the line level across text segments. In addition to outlining important aspects of our interdisciplinary collaboration, we emphasize the utility of the proposed system by various usage scenarios in medieval French literature."}, {"color": "orange", "id": 1480, "label": 1480, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1480 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2017.8585613\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Dominik J\u00e4ckle;Michael Hund;Michael Behrisch;Daniel A. Keim;Tobias Schreck; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Pattern Trails: Visual Analysis of Pattern Transitions in Subspaces; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Subspace analysis methods have gained interest for identifying patterns in subspaces of high-dimensional data. Existing techniques allow to visualize and compare patterns in subspaces. However, many subspace analysis methods produce an abundant amount of patterns, which often remain redundant and are difficult to relate. Creating effective layouts for comparison of subspace patterns remains challenging. We introduce Pattern Trails, a novel approach for visually ordering and comparing subspace patterns. Central to our approach is the notion of pattern transitions as an interpretable structure imposed to order and compare patterns between subspaces. The basic idea is to visualize projections of subspaces side-by-side, and indicate changes between adjacent patterns in the subspaces by a linked representation, hence introducing pattern transitions. Our contributions comprise a systematization for how pairs of subspace patterns can be compared, and how changes can be interpreted in terms of pattern transitions. We also contribute a technique for visual subspace analysis based on a data-driven similarity measure between subspace representations. This measure is useful to order the patterns, and interactively group subspaces to reduce redundancy. We demonstrate the usefulness of our approach by application to several use cases, indicating that data can be meaningfully ordered and interpreted in terms of pattern transitions."}, {"color": "orange", "id": 1481, "label": 1481, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1481 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2017.8585638\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Siming Chen;Shuai Chen;Lijing Lin;Xiaoru Yuan;Jie Liang;Xiaolong Zhang; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: E-Map: A Visual Analytics Approach for Exploring Significant Event Evolutions in Social Media; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Significant events are often discussed and spread through social media, involving many people. Reposting activities and opinions expressed in social media offer good opportunities to understand the evolution of events. However, the dynamics of reposting activities and the diversity of user comments pose challenges to understand event-related social media data. We propose E-Map, a visual analytics approach that uses map-like visualization tools to help multi-faceted analysis of social media data on a significant event and in-depth understanding of the development of the event. E-Map transforms extracted keywords, messages, and reposting behaviors into map features such as cities, towns, and rivers to build a structured and semantic space for users to explore. It also visualizes complex posting and reposting behaviors as simple trajectories and connections that can be easily followed. By supporting multi-level spatial temporal exploration, E-Map helps to reveal the patterns of event development and key players in an event, disclosing the ways they shape and affect the development of the event. Two cases analysing real-world events confirm the capacities of E-Map in facilitating the analysis of event evolution with social media data."}, {"color": "orange", "id": 1486, "label": 1486, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1486 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2017.8585669\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Emily Wall;Leslie M. Blaha;Lyndsey Franklin;Alex Endert; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Warning, Bias May Occur: A Proposed Approach to Detecting Cognitive Bias in Interactive Visual Analytics; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Visual analytic tools combine the complementary strengths of humans and machines in human-in-the-loop systems. Humans provide invaluable domain expertise and sensemaking capabilities to this discourse with analytic models; however, little consideration has yet been given to the ways inherent human biases might shape the visual analytic process. In this paper, we establish a conceptual framework for considering bias assessment through human-in-the-loop systems and lay the theoretical foundations for bias measurement. We propose six preliminary metrics to systematically detect and quantify bias from user interactions and demonstrate how the metrics might be implemented in an existing visual analytic system, InterAxis. We discuss how our proposed metrics could be used by visual analytic systems to mitigate the negative effects of cognitive biases by making users aware of biased processes throughout their analyses."}, {"color": "orange", "id": 1488, "label": 1488, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1488 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2017.8585721\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Yao Ming;Shaozu Cao;Ruixiang Zhang;Zhen Li;Yuanzhe Chen;Yangqiu Song;Huamin Qu; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Understanding Hidden Memories of Recurrent Neural Networks; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Recurrent neural networks (RNNs) have been successfully applied to various natural language processing (NLP) tasks and achieved better results than conventional methods. However, the lack of understanding of the mechanisms behind their effectiveness limits further improvements on their architectures. In this paper, we present a visual analytics method for understanding and comparing RNN models for NLP tasks. We propose a technique to explain the function of individual hidden state units based on their expected response to input texts. We then co-cluster hidden state units and words based on the expected response and visualize co-clustering results as memory chips and word clouds to provide more structured knowledge on RNNs\u0027 hidden states. We also propose a glyph-based sequence visualization based on aggregate information to analyze the behavior of an RNN\u0027s hidden state at the sentence-level. The usability and effectiveness of our method are demonstrated through case studies and reviews from domain experts."}, {"color": "red", "id": 1490, "label": 1490, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1490 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2864432\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Guillaume Favelier;Noura Faraj;Brian Summa;Julien Tierny; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Persistence Atlas for Critical Point Variability in Ensembles; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: This paper presents a new approach for the visualization and analysis of the spatial variability of features of interest represented by critical points in ensemble data. Our framework, called Persistence Atlas, enables the visualization of the dominant spatial patterns of critical points, along with statistics regarding their occurrence in the ensemble. The persistence atlas represents in the geometrical domain each dominant pattern in the form of a confidence map for the appearance of critical points. As a by-product, our method also provides 2-dimensional layouts of the entire ensemble, highlighting the main trends at a global level. Our approach is based on the new notion of Persistence Map, a measure of the geometrical density in critical points which leverages the robustness to noise of topological persistence to better emphasize salient features. We show how to leverage spectral embedding to represent the ensemble members as points in a low-dimensional Euclidean space, where distances between points measure the dissimilarities between critical point layouts and where statistical tasks, such as clustering, can be easily carried out. Further, we show how the notion of mandatory critical point can be leveraged to evaluate for each cluster confidence regions for the appearance of critical points. Most of the steps of this framework can be trivially parallelized and we show how to efficiently implement them. Extensive experiments demonstrate the relevance of our approach. The accuracy of the confidence regions provided by the persistence atlas is quantitatively evaluated and compared to a baseline strategy using an off-the-shelf clustering approach. We illustrate the importance of the persistence atlas in a variety of real-life datasets, where clear trends in feature layouts are identified and analyzed. We provide a lightweight VTK-based C++ implementation of our approach that can be used for reproduction purposes."}, {"color": "orange", "id": 1495, "label": 1495, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1495 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2864499\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jiawei Zhang;Yang Wang;Piero Molino;Lezhi Li;David S. Ebert; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Manifold: A Model-Agnostic Framework for Interpretation and Diagnosis of Machine Learning Models; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Interpretation and diagnosis of machine learning models have gained renewed interest in recent years with breakthroughs in new approaches. We present Manifold, a framework that utilizes visual analysis techniques to support interpretation, debugging, and comparison of machine learning models in a more transparent and interactive manner. Conventional techniques usually focus on visualizing the internal logic of a specific model type (i.e., deep neural networks), lacking the ability to extend to a more complex scenario where different model types are integrated. To this end, Manifold is designed as a generic framework that does not rely on or access the internal logic of the model and solely observes the input (i.e., instances or features) and the output (i.e., the predicted result and probability distribution). We describe the workflow of Manifold as an iterative process consisting of three major phases that are commonly involved in the model development and diagnosis process: inspection (hypothesis), explanation (reasoning), and refinement (verification). The visual components supporting these tasks include a scatterplot-based visual summary that overviews the models\u0027 outcome and a customizable tabular view that reveals feature discrimination. We demonstrate current applications of the framework on the classification and regression tasks and discuss other potential machine learning use scenarios where Manifold can be applied."}, {"color": "orange", "id": 1496, "label": 1496, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1496 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2864500\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Minsuk Kahng;Nikhil Thorat;Duen Horng (Polo) Chau;Fernanda B. Vi\u00e9gas;Martin Wattenberg; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: GAN Lab: Understanding Complex Deep Generative Models using Interactive Visual Experimentation; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Recent success in deep learning has generated immense interest among practitioners and students, inspiring many to learn about this new technology. While visual and interactive approaches have been successfully developed to help people more easily learn deep learning, most existing tools focus on simpler models. In this work, we present GAN Lab, the first interactive visualization tool designed for non-experts to learn and experiment with Generative Adversarial Networks (GANs), a popular class of complex deep learning models. With GAN Lab, users can interactively train generative models and visualize the dynamic training process\u0027s intermediate results. GAN Lab tightly integrates an model overview graph that summarizes GAN\u0027s structure, and a layered distributions view that helps users interpret the interplay between submodels. GAN Lab introduces new interactive experimentation features for learning complex deep learning models, such as step-by-step training at multiple levels of abstraction for understanding intricate training dynamics. Implemented using TensorFlow.js, GAN Lab is accessible to anyone via modern web browsers, without the need for installation or specialized hardware, overcoming a major practical challenge in deploying interactive tools for deep learning."}, {"color": "orange", "id": 1497, "label": 1497, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1497 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2864503\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Zhiguang Zhou;Linhao Meng;Cheng Tang;Ying Zhao;Zhiyong Guo;Miaoxin Hu;Wei Chen; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visual Abstraction of Large Scale Geospatial Origin-Destination Movement Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: A variety of human movement datasets are represented in an Origin-Destination(OD) form, such as taxi trips, mobile phone locations, etc. As a commonly-used method to visualize OD data, flow map always fails to discover patterns of human mobility, due to massive intersections and occlusions of lines on a 2D geographical map. A large number of techniques have been proposed to reduce visual clutter of flow maps, such as filtering, clustering and edge bundling, but the correlations of OD flows are often neglected, which makes the simplified OD flow map present little semantic information. In this paper, a characterization of OD flows is established based on an analogy between OD flows and natural language processing (NPL) terms. Then, an iterative multi-objective sampling scheme is designed to select OD flows in a vectorized representation space. To enhance the readability of sampled OD flows, a set of meaningful visual encodings are designed to present the interactions of OD flows. We design and implement a visual exploration system that supports visual inspection and quantitative evaluation from a variety of perspectives. Case studies based on real-world datasets and interviews with domain experts have demonstrated the effectiveness of our system in reducing the visual clutter and enhancing correlations of OD flows."}, {"color": "orange", "id": 1498, "label": 1498, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1498 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2864504\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Junpeng Wang;Liang Gou;Han-Wei Shen;Hao Yang; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: DQNViz: A Visual Analytics Approach to Understand Deep Q-Networks; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Deep Q-Network (DQN), as one type of deep reinforcement learning model, targets to train an intelligent agent that acquires optimal actions while interacting with an environment. The model is well known for its ability to surpass professional human players across many Atari 2600 games. Despite the superhuman performance, in-depth understanding of the model and interpreting the sophisticated behaviors of the DQN agent remain to be challenging tasks, due to the long-time model training process and the large number of experiences dynamically generated by the agent. In this work, we propose DQNViz, a visual analytics system to expose details of the blind training process in four levels, and enable users to dive into the large experience space of the agent for comprehensive analysis. As an initial attempt in visualizing DQN models, our work focuses more on Atari games with a simple action space, most notably the Breakout game. From our visual analytics of the agent\u0027s experiences, we extract useful action/reward patterns that help to interpret the model and control the training. Through multiple case studies conducted together with deep learning experts, we demonstrate that DQNViz can effectively help domain experts to understand, diagnose, and potentially improve DQN models."}, {"color": "red", "id": 1504, "label": 1504, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1504 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2864510\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Johannes Weissenb\u00f6ck;Bernhard Fr\u00f6hler;Eduard Gr\u00f6ller;Johann Kastner;Christoph Heinzl; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Dynamic Volume Lines: Visual Comparison of 3D Volumes through Space-filling Curves; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The comparison of many members of an ensemble is difficult, tedious, and error-prone, which is aggravated by often just subtle differences. In this paper, we introduce Dynamic Volume Lines for the interactive visual analysis and comparison of sets of 3D volumes. Each volume is linearized along a Hilbert space-filling curve into a 1D Hilbert line plot, which depicts the intensities over the Hilbert indices. We present a nonlinear scaling of these 1D Hilbert line plots based on the intensity variations in the ensemble of 3D volumes, which enables a more effective use of the available screen space. The nonlinear scaling builds the basis for our interactive visualization techniques. An interactive histogram heatmap of the intensity frequencies serves as overview visualization. When zooming in, the frequencies are replaced by detailed 1D Hilbert line plots and optional functional boxplots. To focus on important regions of the volume ensemble, nonlinear scaling is incorporated into the plots. An interactive scaling widget depicts the local ensemble variations. Our brushing and linking interface reveals, for example, regions with a high ensemble variation by showing the affected voxels in a 3D spatial view. We show the applicability of our concepts using two case studies on ensembles of 3D volumes resulting from tomographic reconstruction. In the first case study, we evaluate an artificial specimen from simulated industrial 3D X-ray computed tomography (XCT). In the second case study, a real-world XCT foam specimen is investigated. Our results show that Dynamic Volume Lines can identify regions with high local intensity variations, allowing the user to draw conclusions, for example, about the choice of reconstruction parameters. Furthermore, it is possible to detect ring artifacts in reconstructions volumes."}, {"color": "orange", "id": 1509, "label": 1509, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1509 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2864769\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Mennatallah El-Assady;Fabian Sperrle;Oliver Deussen;Daniel Keim;Christopher Collins; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visual Analytics for Topic Model Optimization based on User-Steerable Speculative Execution; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: To effectively assess the potential consequences of human interventions in model-driven analytics systems, we establish the concept of speculative execution as a visual analytics paradigm for creating user-steerable preview mechanisms. This paper presents an explainable, mixed-initiative topic modeling framework that integrates speculative execution into the algorithmic decision-making process. Our approach visualizes the model-space of our novel incremental hierarchical topic modeling algorithm, unveiling its inner-workings. We support the active incorporation of the user\u0027s domain knowledge in every step through explicit model manipulation interactions. In addition, users can initialize the model with expected topic seeds, the backbone priors. For a more targeted optimization, the modeling process automatically triggers a speculative execution of various optimization strategies, and requests feedback whenever the measured model quality deteriorates. Users compare the proposed optimizations to the current model state and preview their effect on the next model iterations, before applying one of them. This supervised human-in-the-Ioop process targets maximum improvement for minimum feedback and has proven to be effective in three independent studies that confirm topic model quality improvements."}, {"color": "red", "id": 1510, "label": 1510, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1510 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2864801\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Subhashis Hazarika;Soumya Dutta;Han-Wei Shen;Jen-Ping Chen; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: CoDDA: A Flexible Copula-based Distribution Driven Analysis Framework for Large-Scale Multivariate Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: CoDDA (Copula-based Distribution Driven Analysis) is a flexible framework for large-scale multivariate datasets. A common strategy to deal with large-scale scientific simulation data is to partition the simulation domain and create statistical data summaries. Instead of storing the high-resolution raw data from the simulation, storing the compact statistical data summaries results in reduced storage overhead and alleviated I/O bottleneck. Such summaries, often represented in the form of statistical probability distributions, can serve various post-hoc analysis and visualization tasks. However, for multivariate simulation data using standard multivariate distributions for creating data summaries is not feasible. They are either storage inefficient or are computationally expensive to be estimated in simulation time (in situ) for large number of variables. In this work, using copula functions, we propose a flexible multivariate distribution-based data modeling and analysis framework that offers significant data reduction and can be used in an in situ environment. The framework also facilitates in storing the associated spatial information along with the multivariate distributions in an efficient representation. Using the proposed multivariate data summaries, we perform various multivariate post-hoc analyses like query-driven visualization and sampling-based visualization. We evaluate our proposed method on multiple real-world multivariate scientific datasets. To demonstrate the efficacy of our framework in an in situ environment, we apply it on a large-scale flow simulation."}, {"color": "orange", "id": 1514, "label": 1514, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1514 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2864812\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Yao Ming;Huamin Qu;Enrico Bertini; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: RuleMatrix: Visualizing and Understanding Classifiers with Rules; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: With the growing adoption of machine learning techniques, there is a surge of research interest towards making machine learning systems more transparent and interpretable. Various visualizations have been developed to help model developers understand, diagnose, and refine machine learning models. However, a large number of potential but neglected users are the domain experts with little knowledge of machine learning but are expected to work with machine learning systems. In this paper, we present an interactive visualization technique to help users with little expertise in machine learning to understand, explore and validate predictive models. By viewing the model as a black box, we extract a standardized rule-based knowledge representation from its input-output behavior. Then, we design RuleMatrix, a matrix-based visualization of rules to help users navigate and verify the rules and the black-box model. We evaluate the effectiveness of RuleMatrix via two use cases and a usability study."}, {"color": "red", "id": 1517, "label": 1517, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1517 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2864815\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Bo Ma;Alireza Entezari; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: An Interactive Framework for Visualization of Weather Forecast Ensembles; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Numerical Weather Prediction (NWP) ensembles are commonly used to assess the uncertainty and confidence in weather forecasts. Spaghetti plots are conventional tools for meteorologists to directly examine the uncertainty exhibited by ensembles, where they simultaneously visualize isocontours of all ensemble members. To avoid visual clutter in practical usages, one needs to select a small number of informative isovalues for visual analysis. Moreover, due to the complex topology and variation of ensemble isocontours, it is often a challenging task to interpret the spaghetti plot for even a single isovalue in large ensembles. In this paper, we propose an interactive framework for uncertainty visualization of weather forecast ensembles that significantly improves and expands the utility of spaghetti plots in ensemble analysis. Complementary to state-of-the-art methods, our approach provides a complete framework for visual exploration of ensemble isocontours, including isovalue selection, interactive isocontour variability exploration, and interactive sub-region selection and re-analysis. Our framework is built upon the high-density clustering paradigm, where the mode structure of the density function is represented as a hierarchy of nested subsets of the data. We generalize the high-density clustering for isocontours and propose a bandwidth selection method for estimating the density function of ensemble isocontours. We present novel visualizations based on high-density clustering results, called the mode plot and the simplified spaghetti plot. The proposed mode plot visually encodes the structure provided by the high-density clustering result and summarizes the distribution of ensemble isocontours. It also enables the selection of subsets of interesting isocontours, which are interactively highlighted in a linked spaghetti plot for providing spatial context. To provide an interpretable overview of the positional variability of isocontours, our system allows for selection of informative isovalues from the simplified spaghetti plot. Due to the spatial variability of ensemble isocontours, the system allows for interactive selection and focus on sub-regions for local uncertainty and clustering re-analysis. We examine a number of ensemble datasets to establish the utility of our approach and discuss its advantages over state-of-the-art visual analysis tools for ensemble data."}, {"color": "orange", "id": 1520, "label": 1520, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1520 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2864825\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Ke Xu;Meng Xia;Xing Mu;Yun Wang;Nan Cao; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: EnsembleLens: Ensemble-based Visual Exploration of Anomaly Detection Algorithms with Multidimensional Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The results of anomaly detection are sensitive to the choice of detection algorithms as they are specialized for different properties of data, especially for multidimensional data. Thus, it is vital to select the algorithm appropriately. To systematically select the algorithms, ensemble analysis techniques have been developed to support the assembly and comparison of heterogeneous algorithms. However, challenges remain due to the absence of the ground truth, interpretation, or evaluation of these anomaly detectors. In this paper, we present a visual analytics system named EnsembleLens that evaluates anomaly detection algorithms based on the ensemble analysis process. The system visualizes the ensemble processes and results by a set of novel visual designs and multiple coordinated contextual views to meet the requirements of correlation analysis, assessment and reasoning of anomaly detection algorithms. We also introduce an interactive analysis workflow that dynamically produces contextualized and interpretable data summaries that allow further refinements of exploration results based on user feedback. We demonstrate the effectiveness of EnsembleLens through a quantitative evaluation, three case studies with real-world data and interviews with two domain experts."}, {"color": "orange", "id": 1521, "label": 1521, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1521 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2864826\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Gromit Yeuk-Yin Chan;Panpan Xu;Zeng Dai;Liu Ren; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: VIBR: Visualizing Bipartite Relations at Scale with the Minimum Description Length Principle; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Bipartite graphs model the key relations in many large scale real-world data: customers purchasing items, legislators voting for bills, people\u0027s affiliation with different social groups, faults occurring in vehicles, etc. However, it is challenging to visualize large scale bipartite graphs with tens of thousands or even more nodes or edges. In this paper, we propose a novel visual summarization technique for bipartite graphs based on the minimum description length (MDL) principle. The method simultaneously groups the two different set of nodes and constructs aggregated bipartite relations with balanced granularity and precision. It addresses the key trade-off that often occurs for visualizing large scale and noisy data: acquiring a clear and uncluttered overview while maximizing the information content in it. We formulate the visual summarization task as a co-clustering problem and propose an efficient algorithm based on locality sensitive hashing (LSH) that can easily scale to large graphs under reasonable interactive time constraints that previous related methods cannot satisfy. The method leads to the opportunity of introducing a visual analytics framework with multiple levels-of-detail to facilitate interactive data exploration. In the framework, we also introduce a compact visual design inspired by adjacency list representation of graphs as the building block for a small multiples display to compare the bipartite relations for different subsets of data. We showcase the applicability and effectiveness of our approach by applying it on synthetic data with ground truth and performing case studies on real-world datasets from two application domains including roll-call vote record analysis and vehicle fault pattern analysis. Interviews with experts in the political science community and the automotive industry further highlight the benefits of our approach."}, {"color": "blue", "id": 1524, "label": 1524, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1524 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2864836\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Jo Wood;Alexander Kachkaev;Jason Dykes; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Design Exposition with Literate Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We propose a new approach to the visualization design and communication process, literate visualization, based upon and extending, Donald Knuth\u0027s idea of literate programming. It integrates the process of writing data visualization code with description of the design choices that led to the implementation (design exposition). We develop a model of design exposition characterised by four visualization designer architypes: the evaluator, the autonomist, the didacticist and the rationalist. The model is used to justify the key characteristics of literate visualization: `notebook\u0027 documents that integrate live coding input, rendered output and textual narrative; low cost of authoring textual narrative; guidelines to encourage structured visualization design and its documentation. We propose narrative schemas for structuring and validating a wide range of visualization design approaches and models, and branching narratives for capturing alternative designs and design views. We describe a new open source literate visualization environment, litvis, based on a declarative interface to Vega and Vega-Lite through the functional programming language Elm combined with markdown for formatted narrative. We informally assess the approach, its implementation and potential by considering three examples spanning a range of design abstractions: new visualization idioms; validation though visualization algebra; and feminist data visualization. We argue that the rich documentation of the design process provided by literate visualization offers the potential to improve the validity of visualization design and so benefit both academic visualization and visualization practice."}, {"color": "orange", "id": 1525, "label": 1525, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1525 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2864838\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Dominik Sacha;Matthias Kraus;Daniel A. Keim;Min Chen; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: VIS4ML: An Ontology for Visual Analytics Assisted Machine Learning; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: While many VA workflows make use of machine-learned models to support analytical tasks, VA workflows have become increasingly important in understanding and improving Machine Learning (ML) processes. In this paper, we propose an ontology (VIS4ML) for a subarea of VA, namely \u201cVA-assisted ML\u201d. The purpose of VIS4ML is to describe and understand existing VA workflows used in ML as well as to detect gaps in ML processes and the potential of introducing advanced VA techniques to such processes. Ontologies have been widely used to map out the scope of a topic in biology, medicine, and many other disciplines. We adopt the scholarly methodologies for constructing VIS4ML, including the specification, conceptualization, formalization, implementation, and validation of ontologies. In particular, we reinterpret the traditional VA pipeline to encompass model-development workflows. We introduce necessary definitions, rules, syntaxes, and visual notations for formulating VIS4ML and make use of semantic web technologies for implementing it in the Web Ontology Language (OWL). VIS4ML captures the high-level knowledge about previous workflows where VA is used to assist in ML. It is consistent with the established VA concepts and will continue to evolve along with the future developments in VA and ML. While this ontology is an effort for building the theoretical foundation of VA, it can be used by practitioners in real-world applications to optimize model-development workflows by systematically examining the potential benefits that can be brought about by either machine or human capabilities. Meanwhile, VIS4ML is intended to be extensible and will continue to be updated to reflect future advancements in using VA for building high-quality data-analytical models or for building such models rapidly."}, {"color": "red", "id": 1527, "label": 1527, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1527 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2864841\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Min Shih;Charles Rozhon;Kwan-Liu Ma; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: A Declarative Grammar of Flexible Volume Visualization Pipelines; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: This paper presents a declarative grammar for conveniently and effectively specifying advanced volume visualizations. Existing methods for creating volume visualizations either lack the flexibility to specify sophisticated visualizations or are difficult to use for those unfamiliar with volume rendering implementation and parameterization. Our design provides the ability to quickly create expressive visualizations without knowledge of the volume rendering implementation. It attempts to capture aspects of those difficult but powerful methods while remaining flexible and easy to use. As a proof of concept, our current implementation of the grammar allows users to combine multiple data variables in various ways and define transfer functions for diverse input data. The grammar also has the ability to describe advanced shading effects and create animations. We demonstrate the power and flexibility of our approach using multiple practical volume visualizations."}, {"color": "orange", "id": 1528, "label": 1528, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1528 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2864843\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Shixia Liu;Changjian Chen;Yafeng Lu;Fangxin Ouyang;Bin Wang; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: An Interactive Method to Improve Crowdsourced Annotations; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: In order to effectively infer correct labels from noisy crowdsourced annotations, learning-from-crowds models have introduced expert validation. However, little research has been done on facilitating the validation procedure. In this paper, we propose an interactive method to assist experts in verifying uncertain instance labels and unreliable workers. Given the instance labels and worker reliability inferred from a learning-from-crowds model, candidate instances and workers are selected for expert validation. The influence of verified results is propagated to relevant instances and workers through the learning-from-crowds model. To facilitate the validation of annotations, we have developed a confusion visualization to indicate the confusing classes for further exploration, a constrained projection method to show the uncertain labels in context, and a scatter-plot-based visualization to illustrate worker reliability. The three visualizations are tightly integrated with the learning-from-crowds model to provide an iterative and progressive environment for data validation. Two case studies were conducted that demonstrate our approach offers an efficient method for validating and improving crowdsourced annotations."}, {"color": "orange", "id": 1529, "label": 1529, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1529 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2864844\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Hong Wang;Yafeng Lu;Shade T. Shutters;Michael Steptoe;Feng Wang;Steven Landis;Ross Maciejewski; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: A Visual Analytics Framework for Spatiotemporal Trade Network Analysis; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Economic globalization is increasing connectedness among regions of the world, creating complex interdependencies within various supply chains. Recent studies have indicated that changes and disruptions within such networks can serve as indicators for increased risks of violence and armed conflicts. This is especially true of countries that may not be able to compete for scarce commodities during supply shocks. Thus, network-induced vulnerability to supply disruption is typically exported from wealthier populations to disadvantaged populations. As such, researchers and stakeholders concerned with supply chains, political science, environmental studies, etc. need tools to explore the complex dynamics within global trade networks and how the structure of these networks relates to regional instability. However, the multivariate, spatiotemporal nature of the network structure creates a bottleneck in the extraction and analysis of correlations and anomalies for exploratory data analysis and hypothesis generation. Working closely with experts in political science and sustainability, we have developed a highly coordinated, multi-view framework that utilizes anomaly detection, network analytics, and spatiotemporal visualization methods for exploring the relationship between global trade networks and regional instability. Requirements for analysis and initial research questions to be investigated are elicited from domain experts, and a variety of visual encoding techniques for rapid assessment of analysis and correlations between trade goods, network patterns, and time series signatures are explored. We demonstrate the application of our framework through case studies focusing on armed conflicts in Africa, regional instability measures, and their relationship to international global trade."}, {"color": "red", "id": 1533, "label": 1533, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1533 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2864848\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Attila Gyulassy;Peer-Timo Bremer;Valerio Pascucci; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Shared-Memory Parallel Computation of Morse-Smale Complexes with Improved Accuracy; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Topological techniques have proven to be a powerful tool in the analysis and visualization of large-scale scientific data. In particular, the Morse-Smale complex and its various components provide a rich framework for robust feature definition and computation. Consequently, there now exist a number of approaches to compute Morse-Smale complexes for large-scale data in parallel. However, existing techniques are based on discrete concepts which produce the correct topological structure but are known to introduce grid artifacts in the resulting geometry. Here, we present a new approach that combines parallel streamline computation with combinatorial methods to construct a high-quality discrete Morse-Smale complex. In addition to being invariant to the orientation of the underlying grid, this algorithm allows users to selectively build a subset of features using high-quality geometry. In particular, a user may specifically select which ascending/descending manifolds are reconstructed with improved accuracy, focusing computational effort where it matters for subsequent analysis. This approach computes Morse-Smale complexes for larger data than previously feasible with significant speedups. We demonstrate and validate our approach using several examples from a variety of different scientific domains, and evaluate the performance of our method."}, {"color": "red", "id": 1534, "label": 1534, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1534 (SciVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2864849\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Timothy Luciani;Andrew Burks;Cassiano Sugiyama;Jonathan Komperda;G. Elisabeta Marai; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Details-First, Show Context, Overview Last: Supporting Exploration of Viscous Fingers in Large-Scale Ensemble Simulations; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Visualization research often seeks designs that first establish an overview of the data, in accordance to the information seeking mantra: \u201cOverview first, zoom and filter, then details on demand\u201d. However, in computational fluid dynamics (CFD), as well as in other domains, there are many situations where such a spatial overview is not relevant or practical for users, for example when the experts already have a good mental overview of the data, or when an analysis of a large overall structure may not be related to the specific, information-driven tasks of users. Using scientific workflow theory and, as a vehicle, the problem of viscous finger evolution, we advocate an alternative model that allows domain experts to explore features of interest first, then explore the context around those features, and finally move to a potentially unfamiliar summarization overview. In a model instantiation, we show how a computational back-end can identify and track over time low-level, small features, then be used to filter the context of those features while controlling the complexity of the visualization, and finally to summarize and compare simulations. We demonstrate the effectiveness of this approach with an online web-based exploration of a total volume of data approaching half a billion seven-dimensional data points, and report supportive feedback provided by domain experts with respect to both the instantiation and the theoretical model."}, {"color": "blue", "id": 1539, "label": 1539, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1539 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2864884\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Brian Ondov;Nicole Jardine;Niklas Elmqvist;Steven Franconeri; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Face to Face: Evaluating Visual Comparison; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Data are often viewed as a single set of values, but those values frequently must be compared with another set. The existing evaluations of designs that facilitate these comparisons tend to be based on intuitive reasoning, rather than quantifiable measures. We build on this work with a series of crowdsourced experiments that use low-level perceptual comparison tasks that arise frequently in comparisons within data visualizations (e.g., which value changes the most between the two sets of data?). Participants completed these tasks across a variety of layouts: overlaid, two arrangements of juxtaposed small multiples, mirror-symmetric small multiples, and animated transitions. A staircase procedure sought the difficulty level (e.g., value change delta) that led to equivalent accuracy for each layout. Confirming prior intuition, we observe high levels of performance for overlaid versus standard small multiples. However, we also find performance improvements for both mirror symmetric small multiples and animated transitions. While some results are incongruent with common wisdom in data visualization, they align with previous work in perceptual psychology, and thus have potentially strong implications for visual comparison designs."}, {"color": "orange", "id": 1540, "label": 1540, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1540 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2864885\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Shunan Guo;Zhuochen Jin;David Gotz;Fan Du;Hongyuan Zha;Nan Cao; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Visual Progression Analysis of Event Sequence Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Event sequence data is common to a broad range of application domains, from security to health care to scholarly communication. This form of data captures information about the progression of events for an individual entity (e.g., a computer network device; a patient; an author) in the form of a series of time-stamped observations. Moreover, each event is associated with an event type (e.g., a computer login attempt, or a hospital discharge). Analyses of event sequence data have been shown to help reveal important temporal patterns, such as clinical paths resulting in improved outcomes, or an understanding of common career trajectories for scholars. Moreover, recent research has demonstrated a variety of techniques designed to overcome methodological challenges such as large volumes of data and high dimensionality. However, the effective identification and analysis of latent stages of progression, which can allow for variation within different but similarly evolving event sequences, remain a significant challenge with important real-world motivations. In this paper, we propose an unsupervised stage analysis algorithm to identify semantically meaningful progression stages as well as the critical events which help define those stages. The algorithm follows three key steps: (1) event representation estimation, (2) event sequence warping and alignment, and (3) sequence segmentation. We also present a novel visualization system, ET\u003csup\u003e2\u003c/sup\u003e, which interactively illustrates the results of the stage analysis algorithm to help reveal evolution patterns across stages. Finally, we report three forms of evaluation for ET\u003csup\u003e2\u003c/sup\u003e: (1) case studies with two real-world datasets, (2) interviews with domain expert users, and (3) a performance evaluation on the progression analysis algorithm and the visualization design."}, {"color": "orange", "id": 1541, "label": 1541, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1541 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2864886\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Po-Ming Law;Zhicheng Liu;Sana Malik;Rahul C. Basole; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: MAQUI: Interweaving Queries and Pattern Mining for Recursive Event Sequence Exploration; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Exploring event sequences by defining queries alone or by using mining algorithms alone is often not sufficient to support analysis. Analysts often interweave querying and mining in a recursive manner during event sequence analysis: sequences extracted as query results are used for mining patterns, patterns generated are incorporated into a new query for segmenting the sequences, and the resulting segments are mined or queried again. To support flexible analysis, we propose a framework that describes the process of interwoven querying and mining. Based on this framework, we developed MAQUI, a Mining And Querying User Interface that enables recursive event sequence exploration. To understand the efficacy of MAQUI, we conducted two case studies with domain experts. The findings suggest that the capability of interweaving querying and mining helps the participants articulate their questions and gain novel insights from their data."}, {"color": "blue", "id": 1544, "label": 1544, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1544 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2864899\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Tan Tang;Sadia Rubab;Jiewen Lai;Weiwei Cui;Lingyun Yu;Yingcai Wu; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: iStoryline: Effective Convergence to Hand-drawn Storylines; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Storyline visualization techniques have progressed significantly to generate illustrations of complex stories automatically. However, the visual layouts of storylines are not enhanced accordingly despite the improvement in the performance and extension of its application area. Existing methods attempt to achieve several shared optimization goals, such as reducing empty space and minimizing line crossings and wiggles. However, these goals do not always produce optimal results when compared to hand-drawn storylines. We conducted a preliminary study to learn how users translate a narrative into a hand-drawn storyline and check whether the visual elements in hand-drawn illustrations can be mapped back to appropriate narrative contexts. We also compared the hand-drawn storylines with storylines generated by the state-of-the-art methods and found they have significant differences. Our findings led to a design space that summarizes (1) how artists utilize narrative elements and (2) the sequence of actions artists follow to portray expressive and attractive storylines. We developed iStoryline, an authoring tool for integrating high-level user interactions into optimization algorithms and achieving a balance between hand-drawn storylines and automatic layouts. iStoryline allows users to create novel storyline visualizations easily according to their preferences by modifying the automatically generated layouts. The effectiveness and usability of iStoryline are studied with qualitative evaluations."}, {"color": "blue", "id": 1548, "label": 1548, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1548 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2864907\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Michael Correll;Mingwei Li;Gordon Kindlmann;Carlos Scheidegger; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Looks Good To Me: Visualizations As Sanity Checks; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Famous examples such as Anscombe\u0027s Quartet highlight that one of the core benefits of visualizations is allowing people to discover visual patterns that might otherwise be hidden by summary statistics. This visual inspection is particularly important in exploratory data analysis, where analysts can use visualizations such as histograms and dot plots to identify data quality issues. Yet, these visualizations are driven by parameters such as histogram bin size or mark opacity that have a great deal of impact on the final visual appearance of the chart, but are rarely optimized to make important features visible. In this paper, we show that data flaws have varying impact on the visual features of visualizations, and that the adversarial or merely uncritical setting of design parameters of visualizations can obscure the visual signatures of these flaws. Drawing on the framework of Algebraic Visualization Design, we present the results of a crowdsourced study showing that common visualization types can appear to reasonably summarize distributional data while hiding large and important flaws such as missing data and extraneous modes. We make use of these results to propose additional best practices for visualizations of distributions for data quality tasks."}, {"color": "blue", "id": 1550, "label": 1550, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1550 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2864911\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Yunhai Wang;Yanyan Wang;Haifeng Zhang;Yinqi Sun;Chi-Wing Fu;Michael Sedlmair;Baoquan Chen;Oliver Deussen; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Structure-aware Fisheye Views for Efficient Large Graph Exploration; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Traditional fisheye views for exploring large graphs introduce substantial distortions that often lead to a decreased readability of paths and other interesting structures. To overcome these problems, we propose a framework for structure-aware fisheye views. Using edge orientations as constraints for graph layout optimization allows us not only to reduce spatial and temporal distortions during fisheye zooms, but also to improve the readability of the graph structure. Furthermore, the framework enables us to optimize fisheye lenses towards specific tasks and design a family of new lenses: polyfocal, cluster, and path lenses. A GPU implementation lets us process large graphs with up to 15,000 nodes at interactive rates. A comprehensive evaluation, a user study, and two case studies demonstrate that our structure-aware fisheye views improve layout readability and user performance."}, {"color": "blue", "id": 1552, "label": 1552, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1552 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2864913\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Nina Mccurdy;Julie Gerdes;Miriah Meyer; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: A Framework for Externalizing Implicit Error Using Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: This paper presents a framework for externalizing and analyzing expert knowledge about discrepancies in data through the use of visualization. Grounded in an 18-month design study with global health experts, the framework formalizes the notion of data discrepancies as implicit error, both in global health data and more broadly. We use the term implicit error to describe measurement error that is inherent to and pervasive throughout a dataset, but that isn\u0027t explicitly accounted for or defined. Instead, implicit error exists in the minds of experts, is mainly qualitative, and is accounted for subjectively during expert interpretation of the data. Externalizing knowledge surrounding implicit error can assist in synchronizing, validating, and enhancing interpretation, and can inform error analysis and mitigation. The framework consists of a description of implicit error components that are important for downstream analysis, along with a process model for externalizing and analyzing implicit error using visualization. As a second contribution, we provide a rich, reflective, and verifiable description of our research process as an exemplar summary toward the ongoing inquiry into ways of increasing the validity and transferability of design study research."}, {"color": "blue", "id": 1553, "label": 1553, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1553 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2864914\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Hayeong Song;Danielle Albers Szafir; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Where\u0027s My Data? Evaluating Visualizations with Missing Data; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Many real-world datasets are incomplete due to factors such as data collection failures or misalignments between fused datasets. Visualizations of incomplete datasets should allow analysts to draw conclusions from their data while effectively reasoning about the quality of the data and resulting conclusions. We conducted a pair of crowdsourced studies to measure how the methods used to impute and visualize missing data may influence analysts\u0027 perceptions of data quality and their confidence in their conclusions. Our experiments used different design choices for line graphs and bar charts to estimate averages and trends in incomplete time series datasets. Our results provide preliminary guidance for visualization designers to consider when working with incomplete data in different domains and scenarios."}, {"color": "orange", "id": 1554, "label": 1554, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1554 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2865018\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Dongyu Liu;Panpan Xu;Liu Ren; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: TPFlow: Progressive Partition and Multidimensional Pattern Extraction for Large-Scale Spatio-Temporal Data Analysis; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Consider a multi-dimensional spatio-temporal (ST) dataset where each entry is a numerical measure defined by the corresponding temporal, spatial and other domain-specific dimensions. A typical approach to explore such data utilizes interactive visualizations with multiple coordinated views. Each view displays the aggregated measures along one or two dimensions. By brushing on the views, analysts can obtain detailed information. However, this approach often cannot provide sufficient guidance for analysts to identify patterns hidden within subsets of data. Without a priori hypotheses, analysts need to manually select and iterate through different slices to search for patterns, which can be a tedious and lengthy process. In this work, we model multidimensional ST data as tensors and propose a novel piecewise rank-one tensor decomposition algorithm which supports automatically slicing the data into homogeneous partitions and extracting the latent patterns in each partition for comparison and visual summarization. The algorithm optimizes a quantitative measure about how faithfully the extracted patterns visually represent the original data. Based on the algorithm we further propose a visual analytics framework that supports a top-down, progressive partitioning workflow for level-of-detail multidimensional ST data exploration. We demonstrate the general applicability and effectiveness of our technique on three datasets from different application domains: regional sales trend analysis, customer traffic analysis in department stores, and taxi trip analysis with origin-destination (OD) data. We further interview domain experts to verify the usability of the prototype."}, {"color": "orange", "id": 1555, "label": 1555, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1555 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2865020\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Ying Zhao;Feng Luo;Minghui Chen;Yingchao Wang;Jiazhi Xia;Fangfang Zhou;Yunhai Wang;Yi Chen;Wei Chen; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Evaluating Multi-Dimensional Visualizations for Understanding Fuzzy Clusters; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Fuzzy clustering assigns a probability of membership for a datum to a cluster, which veritably reflects real-world clustering scenarios but significantly increases the complexity of understanding fuzzy clusters. Many studies have demonstrated that visualization techniques for multi-dimensional data are beneficial to understand fuzzy clusters. However, no empirical evidence exists on the effectiveness and efficiency of these visualization techniques in solving analytical tasks featured by fuzzy clusters. In this paper, we conduct a controlled experiment to evaluate the ability of fuzzy clusters analysis to use four multi-dimensional visualization techniques, namely, parallel coordinate plot, scatterplot matrix, principal component analysis, and Radviz. First, we define the analytical tasks and their representative questions specific to fuzzy clusters analysis. Then, we design objective questionnaires to compare the accuracy, time, and satisfaction in using the four techniques to solve the questions. We also design subjective questionnaires to collect the experience of the volunteers with the four techniques in terms of ease of use, informativeness, and helpfulness. With a complete experiment process and a detailed result analysis, we test against four hypotheses that are formulated on the basis of our experience, and provide instructive guidance for analysts in selecting appropriate and efficient visualization techniques to analyze fuzzy clusters."}, {"color": "orange", "id": 1562, "label": 1562, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1562 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2865027\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Bum Chul Kwon;Min-Je Choi;Joanne Taery Kim;Edward Choi;Young Bin Kim;Soonwook Kwon;Jimeng Sun;Jaegul Choo; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: RetainVis: Visual Analytics with Interpretable and Interactive Recurrent Neural Networks on Electronic Medical Records; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We have recently seen many successful applications of recurrent neural networks (RNNs) on electronic medical records (EMRs), which contain histories of patients\u0027 diagnoses, medications, and other various events, in order to predict the current and future states of patients. Despite the strong performance of RNNs, it is often challenging for users to understand why the model makes a particular prediction. Such black-box nature of RNNs can impede its wide adoption in clinical practice. Furthermore, we have no established methods to interactively leverage users\u0027 domain expertise and prior knowledge as inputs for steering the model. Therefore, our design study aims to provide a visual analytics solution to increase interpretability and interactivity of RNNs via a joint effort of medical experts, artificial intelligence scientists, and visual analytics researchers. Following the iterative design process between the experts, we design, implement, and evaluate a visual analytics tool called RetainVis, which couples a newly improved, interpretable, and interactive RNN-based model called RetainEX and visualizations for users\u0027 exploration of EMR data in the context of prediction tasks. Our study shows the effective use of RetainVis for gaining insights into how individual medical codes contribute to making risk predictions, using EMRs of patients with heart failure and cataract symptoms. Our study also demonstrates how we made substantial changes to the state-of-the-art RNN model called RETAIN in order to make use of temporal information and increase interactivity. This study will provide a useful guideline for researchers that aim to design an interpretable and interactive visual analytics tool for RNNs."}, {"color": "orange", "id": 1565, "label": 1565, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1565 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2865039\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Akhilesh Camisetty;Chaitanya Chandurkar;Maoyuan Sun;David Koop; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Enhancing Web-based Analytics Applications through Provenance; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Visual analytics systems continue to integrate new technologies and leverage modern environments for exploration and collaboration, making tools and techniques available to a wide audience through web browsers. Many of these systems have been developed with rich interactions, offering users the opportunity to examine details and explore hypotheses that have not been directly encoded by a designer. Understanding is enhanced when users can replay and revisit the steps in the sensemaking process, and in collaborative settings, it is especially important to be able to review not only the current state but also what decisions were made along the way. Unfortunately, many web-based systems lack the ability to capture such reasoning, and the path to a result is transient, forgotten when a user moves to a new view. This paper explores the requirements to augment existing client-side web applications with support for capturing, reviewing, sharing, and reusing steps in the reasoning process. Furthermore, it considers situations where decisions are made with streaming data, and the insights gained from revisiting those choices when more data is available. It presents a proof of concept, the Shareable Interactive Manipulation Provenance framework (SIMProv.js), that addresses these requirements in a modern, client-side JavaScript library, and describes how it can be integrated with existing frameworks."}, {"color": "orange", "id": 1571, "label": 1571, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1571 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2865047\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Michelle Dowling;John Wenskovitch;J.T. Fry;Scotland Leman;Leanna House;Chris North; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: SIRIUS: Dual, Symmetric, Interactive Dimension Reductions; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Much research has been done regarding how to visualize and interact with observations and attributes of high-dimensional data for exploratory data analysis. From the analyst\u0027s perceptual and cognitive perspective, current visualization approaches typically treat the observations of the high-dimensional dataset very differently from the attributes. Often, the attributes are treated as inputs (e.g., sliders), and observations as outputs (e.g., projection plots), thus emphasizing investigation of the observations. However, there are many cases in which analysts wish to investigate both the observations and the attributes of the dataset, suggesting a symmetry between how analysts think about attributes and observations. To address this, we define SIRIUS (Symmetric Interactive Representations In a Unified System), a symmetric, dual projection technique to support exploratory data analysis of high-dimensional data. We provide an example implementation of SIRIUS and demonstrate how this symmetry affords additional insights."}, {"color": "orange", "id": 1572, "label": 1572, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1572 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2865049\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Juri Buchm\u00fcller;Dominik J\u00e4ckle;Eren Cakmak;Ulrik Brandes;Daniel A. Keim; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: MotionRugs: Visualizing Collective Trends in Space and Time; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Understanding the movement patterns of collectives, such as flocks of birds or fish swarms, is an interesting open research question. The collectives are driven by mutual objectives or react to individual direction changes and external influence factors and stimuli. The challenge in visualizing collective movement data is to show space and time of hundreds of movements at the same time to enable the detection of spatiotemporal patterns. In this paper, we propose MotionRugs, a novel space efficient technique for visualizing moving groups of entities. Building upon established space-partitioning strategies, our approach reduces the spatial dimensions in each time step to a one-dimensional ordered representation of the individual entities. By design, MotionRugs provides an overlap-free, compact overview of the development of group movements over time and thus, enables analysts to visually identify and explore group-specific temporal patterns. We demonstrate the usefulness of our approach in the field of fish swarm analysis and report on initial feedback of domain experts from the field of collective behavior."}, {"color": "orange", "id": 1573, "label": 1573, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1573 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2865051\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Daniel Orban;Daniel F. Keefe;Ayan Biswas;James Ahrens;David Rogers; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Drag and Track: A Direct Manipulation Interface for Contextualizing Data Instances within a Continuous Parameter Space; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present a direct manipulation technique that allows material scientists to interactively highlight relevant parameterized simulation instances located in dimensionally reduced spaces, enabling a user-defined understanding of a continuous parameter space. Our goals are two-fold: first, to build a user-directed intuition of dimensionally reduced data, and second, to provide a mechanism for creatively exploring parameter relationships in parameterized simulation sets, called ensembles. We start by visualizing ensemble data instances in dimensionally reduced scatter plots. To understand these abstract views, we employ user-defined virtual data instances that, through direct manipulation, search an ensemble for similar instances. Users can create multiple of these direct manipulation queries to visually annotate the spaces with sets of highlighted ensemble data instances. User-defined goals are therefore translated into custom illustrations that are projected onto the dimensionally reduced spaces. Combined forward and inverse searches of the parameter space follow naturally allowing for continuous parameter space prediction and visual query comparison in the context of an ensemble. The potential for this visualization technique is confirmed via expert user feedback for a shock physics application and synthetic model analysis."}, {"color": "blue", "id": 1575, "label": 1575, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1575 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2865076\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Yixuan Zhang;Kartik Chanana;Cody Dunne; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: IDMVis: Temporal Event Sequence Visualization for Type 1 Diabetes Treatment Decision Support; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Type 1 diabetes is a chronic, incurable autoimmune disease affecting millions of Americans in which the body stops producing insulin and blood glucose levels rise. The goal of intensive diabetes management is to lower average blood glucose through frequent adjustments to insulin protocol, diet, and behavior. Manual logs and medical device data are collected by patients, but these multiple sources are presented in disparate visualization designs to the clinician-making temporal inference difficult. We conducted a design study over 18 months with clinicians performing intensive diabetes management. We present a data abstraction and novel hierarchical task abstraction for this domain. We also contribute IDMVis: a visualization tool for temporal event sequences with multidimensional, interrelated data. IDMVis includes a novel technique for folding and aligning records by dual sentinel events and scaling the intermediate timeline. We validate our design decisions based on our domain abstractions, best practices, and through a qualitative evaluation with six clinicians. The results of this study indicate that IDMVis accurately reflects the workflow of clinicians. Using IDMVis, clinicians are able to identify issues of data quality such as missing or conflicting data, reconstruct patient records when data is missing, differentiate between days with different patterns, and promote educational interventions after identifying discrepancies."}, {"color": "blue", "id": 1576, "label": 1576, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1576 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2865077\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Anna Gogolou;Theophanis Tsandilas;Themis Palpanas;Anastasia Bezerianos; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Comparing Similarity Perception in Time Series Visualizations; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: A common challenge faced by many domain experts working with time series data is how to identify and compare similar patterns. This operation is fundamental in high-level tasks, such as detecting recurring phenomena or creating clusters of similar temporal sequences. While automatic measures exist to compute time series similarity, human intervention is often required to visually inspect these automatically generated results. The visualization literature has examined similarity perception and its relation to automatic similarity measures for line charts, but has not yet considered if alternative visual representations, such as horizon graphs and colorfields, alter this perception. Motivated by how neuroscientists evaluate epileptiform patterns, we conducted two experiments that study how these three visualization techniques affect similarity perception in EEG signals. We seek to understand if the time series results returned from automatic similarity measures are perceived in a similar manner, irrespective of the visualization technique; and if what people perceive as similar with each visualization aligns with different automatic measures and their similarity constraints. Our findings indicate that horizon graphs align with similarity measures that allow local variations in temporal position or speed (i.e., dynamic time warping) more than the two other techniques. On the other hand, horizon graphs do not align with measures that are insensitive to amplitude and y-offset scaling (i.e., measures based on z-normalization), but the inverse seems to be the case for line charts and colorfields. Overall, our work indicates that the choice of visualization affects what temporal patterns we consider as similar, i.e., the notion of similarity in time series is not visualization independent."}, {"color": "blue", "id": 1577, "label": 1577, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1577 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2865117\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Mi Feng;Evan Peck;Lane Harrison; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Patterns and Pace: Quantifying Diverse Exploration Behavior with Visualizations on the Web; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: The diverse and vibrant ecosystem of interactive visualizations on the web presents an opportunity for researchers and practitioners to observe and analyze how everyday people interact with data visualizations. However, existing metrics of visualization interaction behavior used in research do not fully reveal the breadth of peoples\u0027 open-ended explorations with visualizations. One possible way to address this challenge is to determine high-level goals for visualization interaction metrics, and infer corresponding features from user interaction data that characterize different aspects of peoples\u0027 explorations of visualizations. In this paper, we identify needs for visualization behavior measurement, and develop corresponding candidate features that can be inferred from users\u0027 interaction data. We then propose metrics that capture novel aspects of peoples\u0027 open-ended explorations, including exploration uniqueness and exploration pacing. We evaluate these metrics along with four other metrics recently proposed in visualization literature by applying them to interaction data from prior visualization studies. The results of these evaluations suggest that these new metrics 1) reveal new characteristics of peoples\u0027 use of visualizations, 2) can be used to evaluate statistical differences between visualization designs, and 3) are statistically independent of prior metrics used in visualization research. We discuss implications of these results for future studies, including the potential for applying these metrics in visualization interaction analysis, as well as emerging challenges in developing and selecting metrics depicting visualization explorations."}, {"color": "blue", "id": 1580, "label": 1580, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1580 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2865126\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Di Weng;Ran Chen;Zikun Deng;Feiran Wu;Jingmin Chen;Yingcai Wu; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: SRVis: Towards Better Spatial Integration in Ranking Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Interactive ranking techniques have substantially promoted analysts\u0027 ability in making judicious and informed decisions effectively based on multiple criteria. However, the existing techniques cannot satisfactorily support the analysis tasks involved in ranking large-scale spatial alternatives, such as selecting optimal locations for chain stores, where the complex spatial contexts involved are essential to the decision-making process. Limitations observed in the prior attempts of integrating rankings with spatial contexts motivate us to develop a context-integrated visual ranking technique. Based on a set of generic design requirements we summarized by collaborating with domain experts, we propose SRVis, a novel spatial ranking visualization technique that supports efficient spatial multi-criteria decision-making processes by addressing three major challenges in the aforementioned context integration, namely, a) the presentation of spatial rankings and contexts, b) the scalability of rankings\u0027 visual representations, and c) the analysis of context-integrated spatial rankings. Specifically, we encode massive rankings and their cause with scalable matrix-based visualizations and stacked bar charts based on a novel two-phase optimization framework that minimizes the information loss, and the flexible spatial filtering and intuitive comparative analysis are adopted to enable the in-depth evaluation of the rankings and assist users in selecting the best spatial alternative. The effectiveness of the proposed technique has been evaluated and demonstrated with an empirical study of optimization methods, two case studies, and expert interviews."}, {"color": "blue", "id": 1582, "label": 1582, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1582 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2865139\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Wei Chen;Fangzhou Guo;Dongming Han;Jacheng Pan;Xiaotao Nie;Jiazhi Xia;Xiaolong Zhang; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Structure-Based Suggestive Exploration: A New Approach for Effective Exploration of Large Networks; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: When analyzing a visualized network, users need to explore different sections of the network to gain insight. However, effective exploration of large networks is often a challenge. While various tools are available for users to explore the global and local features of a network, these tools usually require significant interaction activities, such as repetitive navigation actions to follow network nodes and edges. In this paper, we propose a structure-based suggestive exploration approach to support effective exploration of large networks by suggesting appropriate structures upon user request. Encoding nodes with vectorized representations by transforming information of surrounding structures of nodes into a high dimensional space, our approach can identify similar structures within a large network, enable user interaction with multiple similar structures simultaneously, and guide the exploration of unexplored structures. We develop a web-based visual exploration system to incorporate this suggestive exploration approach and compare performances of our approach under different vectorizing methods and networks. We also present the usability and effectiveness of our approach through a controlled user study with two datasets."}, {"color": "blue", "id": 1584, "label": 1584, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1584 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2865142\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Tanja Blascheck;Lonni Besan\u00e7on;Anastasia Bezerianos;Bongshin Lee;Petra Isenberg; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Glanceable Visualization: Studies of Data Comparison Performance on Smartwatches; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present the results of two perception studies to assess how quickly people can perform a simple data comparison task for small-scale visualizations on a smartwatch. The main goal of these studies is to extend our understanding of design constraints for smartwatch visualizations. Previous work has shown that a vast majority of smartwatch interactions last under 5 s. It is still unknown what people can actually perceive from visualizations during such short glances, in particular with such a limited display space of smartwatches. To shed light on this question, we conducted two perception studies that assessed the lower bounds of task time for a simple data comparison task. We tested three chart types common on smartwatches: bar charts, donut charts, and radial bar charts with three different data sizes: 7, 12, and 24 data values. In our first study, we controlled the differences of the two target bars to be compared, while the second study varied the difference randomly. For both studies, we found that participants performed the task on average in \u0026lt;;300 ms for the bar chart, \u0026lt;;220 ms for the donut chart, and in \u0026lt;; 1780 ms for the radial bar chart. Thresholds in the second study per chart type were on average 1.14-1.35\u00d7 higher than in the first study. Our results show that bar and donut charts should be preferred on smartwatch displays when quick data comparisons are necessary."}, {"color": "blue", "id": 1585, "label": 1585, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1585 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2865144\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Sriram Karthik Badam;Andreas Mathisen;Roman R\u00e4dle;Clemens N. Klokmose;Niklas Elmqvist; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Vistrates: A Component Model for Ubiquitous Analytics; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Visualization tools are often specialized for specific tasks, which turns the user\u0027s analytical workflow into a fragmented process performed across many tools. In this paper, we present a component model design for data visualization to promote modular designs of visualization tools that enhance their analytical scope. Rather than fragmenting tasks across tools, the component model supports unification, where components-the building blocks of this model-can be assembled to support a wide range of tasks. Furthermore, the model also provides additional key properties, such as support for collaboration, sharing across multiple devices, and adaptive usage depending on expertise, from creating visualizations using dropdown menus, through instantiating components, to actually modifying components or creating entirely new ones from scratch using JavaScript or Python source code. To realize our model, we introduce Vistrates, a literate computing platform for developing, assembling, and sharing visualization components. From a visualization perspective, Vistrates features cross-cutting components for visual representations, interaction, collaboration, and device responsiveness maintained in a component repository. From a development perspective, Vistrates offers a collaborative programming environment where novices and experts alike can compose component pipelines for specific analytical activities. Finally, we present several Vistrates use cases that span the full range of the classic \u201canytime\u201d and \u201canywhere\u201d motto for ubiquitous analysis: from mobile and on-the-go usage, through office settings, to collaborative smart environments covering a variety of tasks and devices.."}, {"color": "blue", "id": 1586, "label": 1586, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1586 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2865145\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Arjun Srinivasan;Steven M. Drucker;Alex Endert;John Stasko; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Augmenting Visualizations with Interactive Data Facts to Facilitate Interpretation and Communication; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Recently, an increasing number of visualization systems have begun to incorporate natural language generation (NLG) capabilities into their interfaces. NLG-based visualization systems typically leverage a suite of statistical functions to automatically extract key facts about the underlying data and surface them as natural language sentences alongside visualizations. With current systems, users are typically required to read the system-generated sentences and mentally map them back to the accompanying visualization. However, depending on the features of the visualization (e.g., visualization type, data density) and the complexity of the data fact, mentally mapping facts to visualizations can be a challenging task. Furthermore, more than one visualization could be used to illustrate a single data fact. Unfortunately, current tools provide little or no support for users to explore such alternatives. In this paper, we explore how system-generated data facts can be treated as interactive widgets to help users interpret visualizations and communicate their findings. We present Voder, a system that lets users interact with automatically-generated data facts to explore both alternative visualizations to convey a data fact as well as a set of embellishments to highlight a fact within a visualization. Leveraging data facts as interactive widgets, Voder also facilitates data fact-based visualization search. To assess Voder\u0027s design and features, we conducted a preliminary user study with 12 participants having varying levels of experience with visualization tools. Participant feedback suggested that interactive data facts aided them in interpreting visualizations. Participants also stated that the suggestions surfaced through the facts helped them explore alternative visualizations and embellishments to communicate individual data facts."}, {"color": "blue", "id": 1589, "label": 1589, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1589 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2865149\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Carolina Nobre;Marc Streit;Alexander Lex; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Juniper: A Tree+Table Approach to Multivariate Graph Visualization; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Analyzing large, multivariate graphs is an important problem in many domains, yet such graphs are challenging to visualize. In this paper, we introduce a novel, scalable, tree-table multivariate graph visualization technique, which makes many tasks related to multivariate graph analysis easier to achieve. The core principle we follow is to selectively query for nodes or subgraphs of interest and visualize these subgraphs as a spanning tree of the graph. The tree is laid out linearly, which enables us to juxtapose the nodes with a table visualization where diverse attributes can be shown. We also use this table as an adjacency matrix, so that the resulting technique is a hybrid node-link/adjacency matrix technique. We implement this concept in Juniper and complement it with a set of interaction techniques that enable analysts to dynamically grow, restructure, and aggregate the tree, as well as change the layout or show paths between nodes. We demonstrate the utility of our tool in usage scenarios for different multivariate networks: a bipartite network of scholars, papers, and citation metrics and a multitype network of story characters, places, books, etc."}, {"color": "blue", "id": 1590, "label": 1590, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1590 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2865151\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Timothy Major;Rahul C. Basole; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Graphicle: Exploring Units, Networks, and Context in a Blended Visualization Approach; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Many real-world datasets are large, multivariate, and relational in nature and relevant associated decisions frequently require a simultaneous consideration of both attributes and connections. Existing visualization systems and approaches, however, often make an explicit trade-off between either affording rich exploration of individual data units and their attributes or exploration of the underlying network structure. In doing so, important analysis opportunities and insights are potentially missed. In this study, we aim to address this gap by (1) considering visualizations and interaction techniques that blend the spectrum between unit and network visualizations, (2) discussing the nature of different forms of contexts and the challenges in implementing them, and (3) demonstrating the value of our approach for visual exploration of multivariate, relational data for a real-world use case. Specifically, we demonstrate through a system called Graphicle how network structure can be layered on top of unit visualization techniques to create new opportunities for visual exploration of physician characteristics and referral data. We report on the design, implementation, and evaluation of the system and effectiveness of our blended approach."}, {"color": "blue", "id": 1591, "label": 1591, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1591 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2865152\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Ronell Sicat;Jiabao Li;Junyoung Choi;Maxime Cordeil;Won-Ki Jeong;Benjamin Bach;Hanspeter Pfister; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: DXR: A Toolkit for Building Immersive Data Visualizations; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: This paper presents DXR, a toolkit for building immersive data visualizations based on the Unity development platform. Over the past years, immersive data visualizations in augmented and virtual reality (AR, VR) have been emerging as a promising medium for data sense-making beyond the desktop. However, creating immersive visualizations remains challenging, and often require complex low-level programming and tedious manual encoding of data attributes to geometric and visual properties. These can hinder the iterative idea-to-prototype process, especially for developers without experience in 3D graphics, AR, and VR programming. With DXR, developers can efficiently specify visualization designs using a concise declarative visualization grammar inspired by Vega-Lite. DXR further provides a GUI for easy and quick edits and previews of visualization designs in-situ, i.e., while immersed in the virtual world. DXR also provides reusable templates and customizable graphical marks, enabling unique and engaging visualizations. We demonstrate the flexibility of DXR through several examples spanning a wide range of applications."}, {"color": "blue", "id": 1592, "label": 1592, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1592 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2865158\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Donghao Ren;Bongshin Lee;Matthew Brehmer; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Charticulator: Interactive Construction of Bespoke Chart Layouts; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present Charticulator, an interactive authoring tool that enables the creation of bespoke and reusable chart layouts. Charticulator is our response to most existing chart construction interfaces that require authors to choose from predefined chart layouts, thereby precluding the construction of novel charts. In contrast, Charticulator transforms a chart specification into mathematical layout constraints and automatically computes a set of layout attributes using a constraint-solving algorithm to realize the chart. It allows for the articulation of compound marks or glyphs as well as links between these glyphs, all without requiring any coding or knowledge of constraint satisfaction. Furthermore, thanks to the constraint-based layout approach, Charticulator can export chart designs into reusable templates that can be imported into other visualization tools. In addition to describing Charticulator\u0027s conceptual framework and design, we present three forms of evaluation: a gallery to illustrate its expressiveness, a user study to verify its usability, and a click-count comparison between Charticulator and three existing tools. Finally, we discuss the limitations and potentials of Charticulator as well as directions for future research. Charticulator is available with its source code at https://charticulator.com."}, {"color": "blue", "id": 1593, "label": 1593, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1593 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2865159\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Mathieu Le Goc;Charles Perin;Sean Follmer;Jean-Daniel Fekete;Pierre Dragicevic; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Dynamic Composite Data Physicalization Using Wheeled Micro-Robots; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: This paper introduces dynamic composite physicalizations, a new class of physical visualizations that use collections of self-propelled objects to represent data. Dynamic composite physicalizations can be used both to give physical form to well-known interactive visualization techniques, and to explore new visualizations and interaction paradigms. We first propose a design space characterizing composite physicalizations based on previous work in the fields of Information Visualization and Human Computer Interaction. We illustrate dynamic composite physicalizations in two scenarios demonstrating potential benefits for collaboration and decision making, as well as new opportunities for physical interaction. We then describe our implementation using wheeled micro-robots capable of locating themselves and sensing user input, before discussing limitations and opportunities for future work."}, {"color": "blue", "id": 1594, "label": 1594, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1594 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2865191\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Christophe Hurter;Nathalie Henry Riche;Steven M. Drucker;Maxime Cordeil;Richard Alligier;Romain Vuillemot; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: FiberClay: Sculpting Three Dimensional Trajectories to Reveal Structural Insights; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Visualizing 3D trajectories to extract insights about their similarities and spatial configuration is a critical task in several domains. Air traffic controllers for example deal with large quantities of aircrafts routes to optimize safety in airspace and neuroscientists attempt to understand neuronal pathways in the human brain by visualizing bundles of fibers from DTI images. Extracting insights from masses of 3D trajectories is challenging as the multiple three dimensional lines have complex geometries, may overlap, cross or even merge with each other, making it impossible to follow individual ones in dense areas. As trajectories are inherently spatial and three dimensional, we propose FiberClay: a system to display and interact with 3D trajectories in immersive environments. FiberClay renders a large quantity of trajectories in real time using GP-GPU techniques. FiberClay also introduces a new set of interactive techniques for composing complex queries in 3D space leveraging immersive environment controllers and user position. These techniques enable an analyst to select and compare sets of trajectories with specific geometries and data properties. We conclude by discussing insights found using FiberClay with domain experts in air traffic control and neurology."}, {"color": "blue", "id": 1595, "label": 1595, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1595 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2865192\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Yalong Yang;Tim Dwyer;Bernhard Jenny;Kim Marriott;Maxime Cordeil;Haohui Chen; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Origin-Destination Flow Maps in Immersive Environments; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Immersive virtual- and augmented-reality headsets can overlay a flat image against any surface or hang virtual objects in the space around the user. The technology is rapidly improving and may, in the long term, replace traditional flat panel displays in many situations. When displays are no longer intrinsically flat, how should we use the space around the user for abstract data visualisation? In this paper, we ask this question with respect to origin-destination flow data in a global geographic context. We report on the findings of three studies exploring different spatial encodings for flow maps. The first experiment focuses on different 2D and 3D encodings for flows on flat maps. We find that participants are significantly more accurate with raised flow paths whose height is proportional to flow distance but fastest with traditional straight line 2D flows. In our second and third experiment we compared flat maps, 3D globes and a novel interactive design we call\u003ci\u003eMapsLink\u003c/i\u003e, involving a pair of linked flat maps. We find that participants took significantly more time with MapsLink than other flow maps while the 3D globe with raised flows was the fastest, most accurate, and most preferred method. Our work suggests that\u003ci\u003ecareful\u003c/i\u003euse of the third spatial dimension can resolve visual clutter in complex flow maps."}, {"color": "blue", "id": 1597, "label": 1597, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1597 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2865194\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Rebecca Faust;David Glickenstein;Carlos Scheidegger; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: DimReader: Axis lines that explain non-linear projections; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Non-linear dimensionality reduction (NDR) methods such as LLE and t-SNE are popular with visualization researchers and experienced data analysts, but present serious problems of interpretation. In this paper, we present DimReader, a technique that recovers readable axes from such techniques. DimReader is based on analyzing infinitesimal perturbations of the dataset with respect to variables of interest. The perturbations define exactly how we want to change each point in the original dataset and we measure the effect that these changes have on the projection. The recovered axes are in direct analogy with the axis lines (grid lines) of traditional scatterplots. We also present methods for discovering perturbations on the input data that change the projection the most. The calculation of the perturbations is efficient and easily integrated into programs written in modern programming languages. We present results of DimReader on a variety of NDR methods and datasets both synthetic and real-life, and show how it can be used to compare different NDR methods. Finally, we discuss limitations of our proposal and situations where further research is needed."}, {"color": "blue", "id": 1598, "label": 1598, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1598 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2865230\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Shusen Liu;Zhimin Li;Tao Li;Vivek Srikumar;Valerio Pascucci;Peer-Timo Bremer; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: NLIZE: A Perturbation-Driven Visual Interrogation Tool for Analyzing and Interpreting Natural Language Inference Models; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: With the recent advances in deep learning, neural network models have obtained state-of-the-art performances for many linguistic tasks in natural language processing. However, this rapid progress also brings enormous challenges. The opaque nature of a neural network model leads to hard-to-debug-systems and difficult-to-interpret mechanisms. Here, we introduce a visualization system that, through a tight yet flexible integration between visualization elements and the underlying model, allows a user to interrogate the model by perturbing the input, internal state, and prediction while observing changes in other parts of the pipeline. We use the natural language inference problem as an example to illustrate how a perturbation-driven paradigm can help domain experts assess the potential limitation of a model, probe its inner states, and interpret and form hypotheses about fundamental model mechanisms such as attention."}, {"color": "blue", "id": 1599, "label": 1599, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1599 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2865231\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Hariharan Subramonyam;Eytan Adar; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: SmartCues: A Multitouch Query Approach for Details-on-Demand through Dynamically Computed Overlays; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Details-on-demand is a crucial feature in the visual information-seeking process but is often only implemented in highly constrained settings. The most common solution, hover queries (i.e., tooltips), are fast and expressive but are usually limited to single mark (e.g., a bar in a bar chart). `Queries\u0027 to retrieve details for more complex sets of objects (e.g., comparisons between pairs of elements, averages across multiple items, trend lines, etc.) are difficult for end-users to invoke explicitly. Further, the output of these queries require complex annotations and overlays which need to be displayed and dismissed on demand to avoid clutter. In this work we introduce SmartCues, a library to support details-on-demand through dynamically computed overlays. For end-users, SmartCues provides multitouch interactions to construct complex queries for a variety of details. For designers, SmartCues offers an interaction library that can be used out-of-the-box, and can be extended for new charts and detail types. We demonstrate how SmartCues can be implemented across a wide array of visualization types and, through a lab study, show that end users can effectively use SmartCues."}, {"color": "blue", "id": 1601, "label": 1601, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1601 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2865233\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Evanthia Dimara;Gilles Bailly;Anastasia Bezerianos;Steven Franconeri; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Mitigating the Attraction Effect with Visualizations; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Human decisions are prone to biases, and this is no less true for decisions made within data visualizations. Bias mitigation strategies often focus on the person, by educating people about their biases, typically with little success. We focus instead on the system, presenting the first evidence that altering the design of an interactive visualization tool can mitigate a strong bias - the attraction effect. Participants viewed 2D scatterplots where choices between superior alternatives were affected by the placement of other suboptimal points. We found that highlighting the superior alternatives weakened the bias, but did not eliminate it. We then tested an interactive approach where participants completely removed locally dominated points from the view, inspired by the elimination by aspects strategy in the decision-making literature. This approach strongly decreased the bias, leading to a counterintuitive suggestion: tools that allow removing inappropriately salient or distracting data from a view may help lead users to make more rational decisions."}, {"color": "blue", "id": 1605, "label": 1605, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1605 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2865240\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Dominik Moritz;Chenglong Wang;Greg L. Nelson;Halden Lin;Adam M. Smith;Bill Howe;Jeffrey Heer; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Formalizing Visualization Design Knowledge as Constraints: Actionable and Extensible Models in Draco; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: There exists a gap between visualization design guidelines and their application in visualization tools. While empirical studies can provide design guidance, we lack a formal framework for representing design knowledge, integrating results across studies, and applying this knowledge in automated design tools that promote effective encodings and facilitate visual exploration. We propose modeling visualization design knowledge as a collection of constraints, in conjunction with a method to learn weights for soft constraints from experimental data. Using constraints, we can take theoretical design knowledge and express it in a concrete, extensible, and testable form: the resulting models can recommend visualization designs and can easily be augmented with additional constraints or updated weights. We implement our approach in Draco, a constraint-based system based on Answer Set Programming (ASP). We demonstrate how to construct increasingly sophisticated automated visualization design systems, including systems based on weights learned directly from the results of graphical perception experiments."}, {"color": "blue", "id": 1606, "label": 1606, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1606 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2865241\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Ethan Kerzner;Sarah Goodwin;Jason Dykes;Sara Jones;Miriah Meyer; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: A Framework for Creative Visualization-Opportunities Workshops; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Applied visualization researchers often work closely with domain collaborators to explore new and useful applications of visualization. The early stages of collaborations are typically time consuming for all stakeholders as researchers piece together an understanding of domain challenges from disparate discussions and meetings. A number of recent projects, however, report on the use of creative visualization-opportunities (CVO) workshops to accelerate the early stages of applied work, eliciting a wealth of requirements in a few days of focused work. Yet, there is no established guidance for how to use such workshops effectively. In this paper, we present the results of a 2-year collaboration in which we analyzed the use of 17 workshops in 10 visualization contexts. Its primary contribution is a framework for CVO workshops that: 1) identifies a process model for using workshops; 2) describes a structure of what happens within effective workshops; 3) recommends 25 actionable guidelines for future workshops; and 4) presents an example workshop and workshop methods. The creation of this framework exemplifies the use of critical reflection to learn about visualization in practice from diverse studies and experience."}, {"color": "blue", "id": 1607, "label": 1607, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1607 (InfoVis)  - \u003ca href=\"http://dx.doi.org/10.1109/TVCG.2018.2865264\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Gabriel Ryan;Abigail Mosca;Remco Chang;Eugene Wu; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: At a Glance: Pixel Approximate Entropy as a Measure of Line Chart Complexity; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: When inspecting information visualizations under time critical settings, such as emergency response or monitoring the heart rate in a surgery room, the user only has a small amount of time to view the visualization \u201cat a glance\u201d. In these settings, it is important to provide a quantitative measure of the visualization to understand whether or not the visualization is too \u201ccomplex\u201d to accurately judge at a glance. This paper proposes Pixel Approximate Entropy (PAE), which adapts the approximate entropy statistical measure commonly used to quantify regularity and unpredictability in time-series data, as a measure of visual complexity for line charts. We show that PAE is correlated with user-perceived chart complexity, and that increased chart PAE correlates with reduced judgement accuracy. `We also find that the correlation between PAE values and participants\u0027 judgment increases when the user has less time to examine the line charts."}, {"color": "orange", "id": 1611, "label": 1611, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1611 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2018.8802415\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Po-Ming Law;Yanhong Wu;Rahul C. Basole; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Segue: Overviewing Evolution Patterns of Egocentric Networks by Interactive Construction of Spatial Layouts; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Getting the overall picture of how a large number of ego-networks evolve is a common yet challenging task. Existing techniques often require analysts to inspect the evolution patterns of ego-networks one after another. In this study, we explore an approach that allows analysts to interactively create spatial layouts in which each dot is a dynamic ego-network. These spatial layouts provide overviews of the evolution patterns of ego-networks, thereby revealing different global patterns such as trends, clusters and outliers in evolution patterns. To let analysts interactively construct interpretable spatial layouts, we propose a data transformation pipeline, with which analysts can adjust the spatial layouts and convert dynamic ego-networks into event sequences to aid interpretations of the spatial positions. Based on this transformation pipeline, we develop Segue, a visual analysis system that supports thorough exploration of the evolution patterns of ego-networks. Through two usage scenarios, we demonstrate how analysts can gain insights into the overall evolution patterns of a large collection of ego-networks by interactively creating different spatial layouts."}, {"color": "orange", "id": 1612, "label": 1612, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1612 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2018.8802424\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: John Wenskovitch;Lauren Bradel;Michelle Dowling;Leanna House;Chris North; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: The Effect of Semantic Interaction on Foraging in Text Analysis; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Completing text analysis tasks is a continuous sensemaking loop of foraging for information and incrementally synthesizing it into hypotheses. Past research has shown the advantages of using spatial workspaces as a means for synthesizing information through externalizing hypotheses and creating spatial schemas. However, spatializing the entirety of datasets becomes prohibitive as the number of documents available to the analysts grows, particularly when only a small subset are relevant to the task at hand. StarSPIRE is a visual analytics tool designed to explore collections of documents, leveraging users\u0027 semantic interactions to steer (1) a synthesis model that aids in document layout, and (2) a foraging model to automatically retrieve new relevant information. In contrast to traditional keyword search foraging (KSF), \u201csemantic interaction foraging\u201d (SIF) occurs as a result of the user\u0027s synthesis actions. To quantify the value of semantic interaction foraging, we use StarSPIRE to evaluate its utility for an intelligence analysis sensemaking task. Semantic interaction foraging accounted for 26% of useful documents found, and it also resulted in increased synthesis interactions and improved sensemaking task performance by users in comparison to only using keyword search."}, {"color": "orange", "id": 1615, "label": 1615, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1615 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2018.8802486\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Michael Blumenschein;Michael Behrisch;Stefanie Schmid;Simon Butscher;Deborah R. Wahl;Karoline Villinger;Britta Renner;Harald Reiterer;Daniel A. Keim; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: SMARTexplore: Simplifying High-Dimensional Data Analysis through a Table-Based Visual Analytics Approach; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: We present SMARTEXPLORE, a novel visual analytics technique that simplifies the identification and understanding of clusters, correlations, and complex patterns in high-dimensional data. The analysis is integrated into an interactive table-based visualization that maintains a consistent and familiar representation throughout the analysis. The visualization is tightly coupled with pattern matching, subspace analysis, reordering, and layout algorithms. To increase the analyst\u0027s trust in the revealed patterns, SMARTEXPLORE automatically selects and computes statistical measures based on dimension and data properties. While existing approaches to analyzing high-dimensional data (e.g., planar projections and Parallel coordinates) have proven effective, they typically have steep learning curves for non-visualization experts. Our evaluation, based on three expert case studies, confirms that non-visualization experts successfully reveal patterns in high-dimensional data when using SMARTEXPLORE."}, {"color": "orange", "id": 1616, "label": 1616, "shape": "dot", "title": "\u003cb\u003ePaper id\u003c/b\u003e: 1616 (VAST)  - \u003ca href=\"http://dx.doi.org/10.1109/VAST.2018.8802509\" target=\"_blank\"\u003eLink\u003c/a\u003e; \u003cbr\u003e\u003cb\u003eAuthors: \u003c/b\u003e: Mengchen Liu;Shixia Liu;Hang Su;Kelei Cao;Jun Zhu; \u003cbr\u003e\u003cb\u003eTitle\u003c/b\u003e: Analyzing the Noise Robustness of Deep Neural Networks; \u003cbr\u003e\u003cb\u003eAbstract\u003c/b\u003e: Deep neural networks (DNNs) are vulnerable to maliciously generated adversarial examples. These examples are intentionally designed by making imperceptible perturbations and often mislead a DNN into making an incorrect prediction. This phenomenon means that there is significant risk in applying DNNs to safety-critical applications, such as driverless cars. To address this issue, we present a visual analytics approach to explain the primary cause of the wrong predictions introduced by adversarial examples. The key is to analyze the datapaths of the adversarial examples and compare them with those of the normal examples. A datapath is a group of critical neurons and their connections. To this end, we formulate the datapath extraction as a subset selection problem and approximately solve it based on back-propagation. A multi-level visualization consisting of a segmented DAG (layer level), an Euler diagram (feature map level), and a heat map (neuron level), has been designed to help experts investigate datapaths from the high-level layers to the detailed neuron activations. Two case studies are conducted that demonstrate the promise of our approach in support of explaining the working mechanism of adversarial examples."}]);
        edges = new vis.DataSet([{"from": 6, "to": 70, "width": 4.0}, {"from": 6, "to": 351, "width": 7.0}, {"from": 6, "to": 402, "width": 5.0}, {"from": 6, "to": 474, "width": 4.0}, {"from": 6, "to": 476, "width": 5.0}, {"from": 6, "to": 516, "width": 5.0}, {"from": 6, "to": 685, "width": 5.0}, {"from": 6, "to": 811, "width": 4.0}, {"from": 6, "to": 827, "width": 4.0}, {"from": 21, "to": 50, "width": 4.0}, {"from": 21, "to": 60, "width": 4.0}, {"from": 21, "to": 107, "width": 4.0}, {"from": 21, "to": 238, "width": 6.0}, {"from": 21, "to": 307, "width": 4.0}, {"from": 22, "to": 44, "width": 4.0}, {"from": 33, "to": 252, "width": 4.0}, {"from": 37, "to": 106, "width": 4.0}, {"from": 37, "to": 119, "width": 4.0}, {"from": 50, "to": 60, "width": 6.0}, {"from": 50, "to": 107, "width": 5.0}, {"from": 50, "to": 169, "width": 4.0}, {"from": 59, "to": 108, "width": 7.0}, {"from": 59, "to": 148, "width": 9.0}, {"from": 59, "to": 171, "width": 9.0}, {"from": 59, "to": 185, "width": 5.0}, {"from": 59, "to": 244, "width": 8.0}, {"from": 59, "to": 260, "width": 5.0}, {"from": 59, "to": 287, "width": 6.0}, {"from": 59, "to": 307, "width": 5.0}, {"from": 59, "to": 396, "width": 4.0}, {"from": 59, "to": 472, "width": 8.0}, {"from": 59, "to": 499, "width": 9.0}, {"from": 59, "to": 557, "width": 6.0}, {"from": 59, "to": 597, "width": 4.0}, {"from": 60, "to": 107, "width": 7.0}, {"from": 60, "to": 108, "width": 5.0}, {"from": 60, "to": 167, "width": 4.0}, {"from": 60, "to": 169, "width": 7.0}, {"from": 60, "to": 208, "width": 4.0}, {"from": 60, "to": 238, "width": 7.0}, {"from": 60, "to": 269, "width": 7.0}, {"from": 60, "to": 307, "width": 8.0}, {"from": 60, "to": 323, "width": 5.0}, {"from": 60, "to": 380, "width": 4.0}, {"from": 71, "to": 400, "width": 6.0}, {"from": 71, "to": 552, "width": 5.0}, {"from": 80, "to": 106, "width": 5.0}, {"from": 86, "to": 101, "width": 5.0}, {"from": 105, "to": 224, "width": 4.0}, {"from": 105, "to": 616, "width": 4.0}, {"from": 105, "to": 667, "width": 7.0}, {"from": 106, "to": 122, "width": 6.0}, {"from": 106, "to": 311, "width": 4.0}, {"from": 106, "to": 641, "width": 6.0}, {"from": 107, "to": 204, "width": 4.0}, {"from": 107, "to": 238, "width": 7.0}, {"from": 107, "to": 307, "width": 7.0}, {"from": 107, "to": 323, "width": 6.0}, {"from": 107, "to": 380, "width": 4.0}, {"from": 107, "to": 423, "width": 4.0}, {"from": 108, "to": 169, "width": 10.0}, {"from": 108, "to": 208, "width": 7.0}, {"from": 108, "to": 238, "width": 6.0}, {"from": 108, "to": 244, "width": 4.0}, {"from": 108, "to": 267, "width": 4.0}, {"from": 108, "to": 269, "width": 5.0}, {"from": 108, "to": 307, "width": 6.0}, {"from": 108, "to": 308, "width": 4.0}, {"from": 108, "to": 314, "width": 4.0}, {"from": 108, "to": 323, "width": 10.0}, {"from": 108, "to": 329, "width": 11.0}, {"from": 108, "to": 389, "width": 7.0}, {"from": 108, "to": 396, "width": 5.0}, {"from": 108, "to": 477, "width": 11.0}, {"from": 108, "to": 560, "width": 4.0}, {"from": 108, "to": 641, "width": 11.0}, {"from": 108, "to": 933, "width": 4.0}, {"from": 108, "to": 979, "width": 5.0}, {"from": 108, "to": 1134, "width": 7.0}, {"from": 108, "to": 1347, "width": 6.0}, {"from": 119, "to": 314, "width": 4.0}, {"from": 124, "to": 215, "width": 4.0}, {"from": 126, "to": 351, "width": 4.0}, {"from": 128, "to": 148, "width": 4.0}, {"from": 128, "to": 171, "width": 6.0}, {"from": 128, "to": 212, "width": 7.0}, {"from": 128, "to": 240, "width": 6.0}, {"from": 128, "to": 260, "width": 4.0}, {"from": 128, "to": 396, "width": 6.0}, {"from": 130, "to": 132, "width": 5.0}, {"from": 130, "to": 324, "width": 4.0}, {"from": 139, "to": 472, "width": 4.0}, {"from": 141, "to": 171, "width": 4.0}, {"from": 141, "to": 210, "width": 4.0}, {"from": 141, "to": 252, "width": 5.0}, {"from": 141, "to": 262, "width": 7.0}, {"from": 141, "to": 312, "width": 4.0}, {"from": 144, "to": 262, "width": 4.0}, {"from": 148, "to": 171, "width": 11.0}, {"from": 148, "to": 185, "width": 5.0}, {"from": 148, "to": 212, "width": 4.0}, {"from": 148, "to": 216, "width": 6.0}, {"from": 148, "to": 240, "width": 4.0}, {"from": 148, "to": 244, "width": 5.0}, {"from": 148, "to": 396, "width": 7.0}, {"from": 148, "to": 472, "width": 9.0}, {"from": 164, "to": 316, "width": 4.0}, {"from": 166, "to": 228, "width": 6.0}, {"from": 166, "to": 256, "width": 4.0}, {"from": 166, "to": 262, "width": 8.0}, {"from": 166, "to": 325, "width": 5.0}, {"from": 166, "to": 459, "width": 4.0}, {"from": 167, "to": 204, "width": 4.0}, {"from": 167, "to": 238, "width": 6.0}, {"from": 167, "to": 307, "width": 4.0}, {"from": 167, "to": 380, "width": 4.0}, {"from": 169, "to": 208, "width": 15.0}, {"from": 169, "to": 269, "width": 9.0}, {"from": 169, "to": 307, "width": 4.0}, {"from": 169, "to": 323, "width": 5.0}, {"from": 169, "to": 477, "width": 8.0}, {"from": 169, "to": 560, "width": 6.0}, {"from": 169, "to": 641, "width": 7.0}, {"from": 171, "to": 185, "width": 8.0}, {"from": 171, "to": 212, "width": 7.0}, {"from": 171, "to": 216, "width": 4.0}, {"from": 171, "to": 240, "width": 5.0}, {"from": 171, "to": 244, "width": 7.0}, {"from": 171, "to": 260, "width": 4.0}, {"from": 171, "to": 287, "width": 4.0}, {"from": 171, "to": 396, "width": 8.0}, {"from": 171, "to": 472, "width": 7.0}, {"from": 171, "to": 479, "width": 5.0}, {"from": 171, "to": 499, "width": 5.0}, {"from": 171, "to": 557, "width": 7.0}, {"from": 171, "to": 597, "width": 4.0}, {"from": 171, "to": 652, "width": 4.0}, {"from": 171, "to": 662, "width": 5.0}, {"from": 176, "to": 423, "width": 4.0}, {"from": 182, "to": 414, "width": 4.0}, {"from": 182, "to": 802, "width": 5.0}, {"from": 185, "to": 206, "width": 4.0}, {"from": 185, "to": 216, "width": 6.0}, {"from": 185, "to": 244, "width": 10.0}, {"from": 185, "to": 287, "width": 4.0}, {"from": 185, "to": 472, "width": 8.0}, {"from": 185, "to": 479, "width": 4.0}, {"from": 185, "to": 499, "width": 6.0}, {"from": 185, "to": 557, "width": 5.0}, {"from": 185, "to": 595, "width": 4.0}, {"from": 185, "to": 599, "width": 4.0}, {"from": 185, "to": 662, "width": 6.0}, {"from": 191, "to": 210, "width": 10.0}, {"from": 191, "to": 257, "width": 4.0}, {"from": 204, "to": 238, "width": 6.0}, {"from": 204, "to": 307, "width": 5.0}, {"from": 204, "to": 456, "width": 5.0}, {"from": 204, "to": 755, "width": 4.0}, {"from": 204, "to": 868, "width": 4.0}, {"from": 206, "to": 472, "width": 4.0}, {"from": 208, "to": 269, "width": 8.0}, {"from": 208, "to": 314, "width": 4.0}, {"from": 208, "to": 323, "width": 6.0}, {"from": 208, "to": 396, "width": 4.0}, {"from": 208, "to": 477, "width": 7.0}, {"from": 208, "to": 560, "width": 6.0}, {"from": 208, "to": 641, "width": 7.0}, {"from": 210, "to": 256, "width": 4.0}, {"from": 210, "to": 257, "width": 4.0}, {"from": 210, "to": 262, "width": 5.0}, {"from": 210, "to": 263, "width": 4.0}, {"from": 212, "to": 240, "width": 10.0}, {"from": 212, "to": 260, "width": 4.0}, {"from": 216, "to": 244, "width": 6.0}, {"from": 216, "to": 472, "width": 7.0}, {"from": 224, "to": 323, "width": 4.0}, {"from": 224, "to": 400, "width": 7.0}, {"from": 224, "to": 476, "width": 4.0}, {"from": 228, "to": 256, "width": 5.0}, {"from": 228, "to": 257, "width": 8.0}, {"from": 228, "to": 262, "width": 8.0}, {"from": 228, "to": 263, "width": 4.0}, {"from": 228, "to": 264, "width": 6.0}, {"from": 228, "to": 267, "width": 7.0}, {"from": 228, "to": 290, "width": 8.0}, {"from": 228, "to": 325, "width": 11.0}, {"from": 228, "to": 459, "width": 6.0}, {"from": 231, "to": 325, "width": 4.0}, {"from": 238, "to": 244, "width": 4.0}, {"from": 238, "to": 307, "width": 16.0}, {"from": 238, "to": 314, "width": 4.0}, {"from": 238, "to": 316, "width": 4.0}, {"from": 238, "to": 323, "width": 8.0}, {"from": 238, "to": 329, "width": 5.0}, {"from": 238, "to": 380, "width": 7.0}, {"from": 238, "to": 384, "width": 4.0}, {"from": 238, "to": 389, "width": 8.0}, {"from": 238, "to": 423, "width": 12.0}, {"from": 238, "to": 456, "width": 6.0}, {"from": 238, "to": 473, "width": 4.0}, {"from": 238, "to": 550, "width": 4.0}, {"from": 238, "to": 551, "width": 8.0}, {"from": 238, "to": 641, "width": 7.0}, {"from": 238, "to": 662, "width": 4.0}, {"from": 238, "to": 746, "width": 8.0}, {"from": 238, "to": 755, "width": 5.0}, {"from": 238, "to": 771, "width": 4.0}, {"from": 238, "to": 827, "width": 6.0}, {"from": 238, "to": 868, "width": 6.0}, {"from": 238, "to": 872, "width": 13.0}, {"from": 238, "to": 874, "width": 4.0}, {"from": 238, "to": 878, "width": 6.0}, {"from": 238, "to": 1043, "width": 4.0}, {"from": 238, "to": 1299, "width": 5.0}, {"from": 240, "to": 260, "width": 4.0}, {"from": 240, "to": 312, "width": 4.0}, {"from": 240, "to": 396, "width": 4.0}, {"from": 243, "to": 472, "width": 4.0}, {"from": 243, "to": 479, "width": 8.0}, {"from": 243, "to": 814, "width": 4.0}, {"from": 243, "to": 897, "width": 4.0}, {"from": 243, "to": 1205, "width": 5.0}, {"from": 244, "to": 247, "width": 4.0}, {"from": 244, "to": 260, "width": 4.0}, {"from": 244, "to": 265, "width": 5.0}, {"from": 244, "to": 287, "width": 12.0}, {"from": 244, "to": 308, "width": 4.0}, {"from": 244, "to": 312, "width": 5.0}, {"from": 244, "to": 329, "width": 5.0}, {"from": 244, "to": 396, "width": 7.0}, {"from": 244, "to": 462, "width": 4.0}, {"from": 244, "to": 472, "width": 12.0}, {"from": 244, "to": 479, "width": 4.0}, {"from": 244, "to": 499, "width": 11.0}, {"from": 244, "to": 557, "width": 9.0}, {"from": 244, "to": 595, "width": 6.0}, {"from": 244, "to": 597, "width": 7.0}, {"from": 244, "to": 637, "width": 4.0}, {"from": 244, "to": 662, "width": 15.0}, {"from": 244, "to": 684, "width": 4.0}, {"from": 244, "to": 827, "width": 4.0}, {"from": 244, "to": 828, "width": 4.0}, {"from": 244, "to": 829, "width": 4.0}, {"from": 250, "to": 552, "width": 5.0}, {"from": 250, "to": 567, "width": 4.0}, {"from": 250, "to": 649, "width": 4.0}, {"from": 252, "to": 262, "width": 9.0}, {"from": 252, "to": 388, "width": 9.0}, {"from": 252, "to": 467, "width": 7.0}, {"from": 252, "to": 653, "width": 11.0}, {"from": 252, "to": 664, "width": 7.0}, {"from": 254, "to": 940, "width": 4.0}, {"from": 256, "to": 262, "width": 11.0}, {"from": 256, "to": 325, "width": 5.0}, {"from": 256, "to": 388, "width": 6.0}, {"from": 257, "to": 262, "width": 5.0}, {"from": 257, "to": 267, "width": 8.0}, {"from": 257, "to": 325, "width": 8.0}, {"from": 257, "to": 351, "width": 4.0}, {"from": 257, "to": 387, "width": 4.0}, {"from": 257, "to": 453, "width": 4.0}, {"from": 260, "to": 312, "width": 4.0}, {"from": 260, "to": 396, "width": 4.0}, {"from": 262, "to": 264, "width": 6.0}, {"from": 262, "to": 267, "width": 12.0}, {"from": 262, "to": 275, "width": 4.0}, {"from": 262, "to": 290, "width": 5.0}, {"from": 262, "to": 308, "width": 5.0}, {"from": 262, "to": 312, "width": 8.0}, {"from": 262, "to": 317, "width": 4.0}, {"from": 262, "to": 325, "width": 12.0}, {"from": 262, "to": 388, "width": 17.0}, {"from": 262, "to": 396, "width": 4.0}, {"from": 262, "to": 397, "width": 4.0}, {"from": 262, "to": 453, "width": 4.0}, {"from": 262, "to": 459, "width": 5.0}, {"from": 262, "to": 475, "width": 4.0}, {"from": 262, "to": 558, "width": 6.0}, {"from": 262, "to": 641, "width": 4.0}, {"from": 262, "to": 664, "width": 9.0}, {"from": 262, "to": 668, "width": 4.0}, {"from": 262, "to": 750, "width": 4.0}, {"from": 264, "to": 267, "width": 4.0}, {"from": 264, "to": 290, "width": 5.0}, {"from": 264, "to": 325, "width": 6.0}, {"from": 265, "to": 312, "width": 5.0}, {"from": 266, "to": 632, "width": 5.0}, {"from": 267, "to": 290, "width": 7.0}, {"from": 267, "to": 308, "width": 4.0}, {"from": 267, "to": 325, "width": 11.0}, {"from": 267, "to": 351, "width": 7.0}, {"from": 267, "to": 396, "width": 4.0}, {"from": 267, "to": 453, "width": 4.0}, {"from": 267, "to": 677, "width": 6.0}, {"from": 267, "to": 790, "width": 4.0}, {"from": 269, "to": 292, "width": 4.0}, {"from": 269, "to": 323, "width": 5.0}, {"from": 269, "to": 477, "width": 9.0}, {"from": 269, "to": 560, "width": 6.0}, {"from": 269, "to": 682, "width": 4.0}, {"from": 275, "to": 388, "width": 5.0}, {"from": 285, "to": 458, "width": 5.0}, {"from": 285, "to": 767, "width": 8.0}, {"from": 285, "to": 940, "width": 8.0}, {"from": 285, "to": 1053, "width": 5.0}, {"from": 287, "to": 472, "width": 6.0}, {"from": 287, "to": 499, "width": 8.0}, {"from": 287, "to": 557, "width": 8.0}, {"from": 287, "to": 597, "width": 7.0}, {"from": 287, "to": 662, "width": 9.0}, {"from": 290, "to": 325, "width": 6.0}, {"from": 303, "to": 351, "width": 4.0}, {"from": 303, "to": 356, "width": 4.0}, {"from": 307, "to": 312, "width": 5.0}, {"from": 307, "to": 314, "width": 5.0}, {"from": 307, "to": 316, "width": 5.0}, {"from": 307, "to": 320, "width": 4.0}, {"from": 307, "to": 323, "width": 4.0}, {"from": 307, "to": 329, "width": 4.0}, {"from": 307, "to": 380, "width": 10.0}, {"from": 307, "to": 383, "width": 6.0}, {"from": 307, "to": 389, "width": 7.0}, {"from": 307, "to": 396, "width": 5.0}, {"from": 307, "to": 419, "width": 5.0}, {"from": 307, "to": 423, "width": 10.0}, {"from": 307, "to": 456, "width": 5.0}, {"from": 307, "to": 477, "width": 4.0}, {"from": 307, "to": 547, "width": 4.0}, {"from": 307, "to": 550, "width": 5.0}, {"from": 307, "to": 551, "width": 6.0}, {"from": 307, "to": 641, "width": 4.0}, {"from": 307, "to": 662, "width": 5.0}, {"from": 307, "to": 685, "width": 5.0}, {"from": 307, "to": 746, "width": 4.0}, {"from": 307, "to": 755, "width": 7.0}, {"from": 307, "to": 827, "width": 5.0}, {"from": 307, "to": 872, "width": 7.0}, {"from": 307, "to": 874, "width": 4.0}, {"from": 307, "to": 970, "width": 4.0}, {"from": 307, "to": 1040, "width": 5.0}, {"from": 307, "to": 1134, "width": 4.0}, {"from": 308, "to": 325, "width": 4.0}, {"from": 308, "to": 388, "width": 4.0}, {"from": 308, "to": 396, "width": 6.0}, {"from": 308, "to": 479, "width": 4.0}, {"from": 308, "to": 558, "width": 6.0}, {"from": 308, "to": 640, "width": 6.0}, {"from": 308, "to": 652, "width": 4.0}, {"from": 308, "to": 669, "width": 4.0}, {"from": 308, "to": 1024, "width": 4.0}, {"from": 311, "to": 676, "width": 4.0}, {"from": 312, "to": 384, "width": 4.0}, {"from": 312, "to": 388, "width": 5.0}, {"from": 312, "to": 400, "width": 4.0}, {"from": 312, "to": 479, "width": 4.0}, {"from": 312, "to": 557, "width": 4.0}, {"from": 312, "to": 662, "width": 5.0}, {"from": 312, "to": 868, "width": 4.0}, {"from": 314, "to": 323, "width": 5.0}, {"from": 314, "to": 384, "width": 9.0}, {"from": 314, "to": 389, "width": 4.0}, {"from": 314, "to": 396, "width": 4.0}, {"from": 314, "to": 755, "width": 5.0}, {"from": 314, "to": 1014, "width": 4.0}, {"from": 316, "to": 323, "width": 7.0}, {"from": 316, "to": 385, "width": 4.0}, {"from": 316, "to": 423, "width": 4.0}, {"from": 316, "to": 882, "width": 4.0}, {"from": 320, "to": 416, "width": 4.0}, {"from": 322, "to": 959, "width": 4.0}, {"from": 323, "to": 327, "width": 7.0}, {"from": 323, "to": 337, "width": 4.0}, {"from": 323, "to": 351, "width": 14.0}, {"from": 323, "to": 356, "width": 9.0}, {"from": 323, "to": 389, "width": 8.0}, {"from": 323, "to": 402, "width": 5.0}, {"from": 323, "to": 403, "width": 5.0}, {"from": 323, "to": 416, "width": 5.0}, {"from": 323, "to": 423, "width": 8.0}, {"from": 323, "to": 424, "width": 4.0}, {"from": 323, "to": 477, "width": 5.0}, {"from": 323, "to": 524, "width": 4.0}, {"from": 323, "to": 547, "width": 4.0}, {"from": 323, "to": 641, "width": 8.0}, {"from": 323, "to": 746, "width": 4.0}, {"from": 323, "to": 755, "width": 5.0}, {"from": 323, "to": 1043, "width": 5.0}, {"from": 325, "to": 351, "width": 5.0}, {"from": 325, "to": 388, "width": 5.0}, {"from": 325, "to": 391, "width": 8.0}, {"from": 325, "to": 396, "width": 5.0}, {"from": 325, "to": 453, "width": 6.0}, {"from": 325, "to": 459, "width": 5.0}, {"from": 325, "to": 526, "width": 5.0}, {"from": 325, "to": 555, "width": 4.0}, {"from": 325, "to": 558, "width": 5.0}, {"from": 325, "to": 559, "width": 4.0}, {"from": 325, "to": 641, "width": 6.0}, {"from": 325, "to": 668, "width": 5.0}, {"from": 325, "to": 669, "width": 6.0}, {"from": 325, "to": 677, "width": 4.0}, {"from": 325, "to": 680, "width": 4.0}, {"from": 325, "to": 750, "width": 5.0}, {"from": 325, "to": 790, "width": 5.0}, {"from": 325, "to": 864, "width": 5.0}, {"from": 325, "to": 913, "width": 8.0}, {"from": 325, "to": 972, "width": 4.0}, {"from": 325, "to": 1020, "width": 4.0}, {"from": 325, "to": 1024, "width": 4.0}, {"from": 325, "to": 1051, "width": 6.0}, {"from": 325, "to": 1220, "width": 4.0}, {"from": 327, "to": 351, "width": 4.0}, {"from": 327, "to": 389, "width": 4.0}, {"from": 327, "to": 1172, "width": 4.0}, {"from": 329, "to": 351, "width": 4.0}, {"from": 329, "to": 389, "width": 6.0}, {"from": 329, "to": 547, "width": 4.0}, {"from": 329, "to": 551, "width": 6.0}, {"from": 329, "to": 641, "width": 6.0}, {"from": 329, "to": 672, "width": 4.0}, {"from": 329, "to": 867, "width": 4.0}, {"from": 329, "to": 1134, "width": 5.0}, {"from": 330, "to": 461, "width": 5.0}, {"from": 337, "to": 389, "width": 5.0}, {"from": 344, "to": 408, "width": 4.0}, {"from": 344, "to": 500, "width": 4.0}, {"from": 345, "to": 426, "width": 4.0}, {"from": 349, "to": 351, "width": 4.0}, {"from": 351, "to": 354, "width": 5.0}, {"from": 351, "to": 356, "width": 5.0}, {"from": 351, "to": 383, "width": 4.0}, {"from": 351, "to": 389, "width": 4.0}, {"from": 351, "to": 402, "width": 7.0}, {"from": 351, "to": 403, "width": 5.0}, {"from": 351, "to": 416, "width": 7.0}, {"from": 351, "to": 420, "width": 9.0}, {"from": 351, "to": 423, "width": 6.0}, {"from": 351, "to": 428, "width": 4.0}, {"from": 351, "to": 474, "width": 4.0}, {"from": 351, "to": 516, "width": 7.0}, {"from": 351, "to": 524, "width": 7.0}, {"from": 351, "to": 604, "width": 4.0}, {"from": 351, "to": 675, "width": 6.0}, {"from": 351, "to": 685, "width": 6.0}, {"from": 351, "to": 696, "width": 4.0}, {"from": 351, "to": 755, "width": 6.0}, {"from": 351, "to": 790, "width": 6.0}, {"from": 351, "to": 811, "width": 4.0}, {"from": 351, "to": 826, "width": 5.0}, {"from": 351, "to": 865, "width": 4.0}, {"from": 351, "to": 909, "width": 4.0}, {"from": 353, "to": 940, "width": 4.0}, {"from": 354, "to": 389, "width": 4.0}, {"from": 356, "to": 423, "width": 5.0}, {"from": 356, "to": 473, "width": 4.0}, {"from": 356, "to": 524, "width": 4.0}, {"from": 356, "to": 617, "width": 4.0}, {"from": 356, "to": 641, "width": 5.0}, {"from": 356, "to": 675, "width": 4.0}, {"from": 356, "to": 683, "width": 4.0}, {"from": 356, "to": 1043, "width": 7.0}, {"from": 358, "to": 396, "width": 6.0}, {"from": 380, "to": 383, "width": 5.0}, {"from": 380, "to": 389, "width": 5.0}, {"from": 380, "to": 423, "width": 6.0}, {"from": 380, "to": 456, "width": 5.0}, {"from": 380, "to": 550, "width": 4.0}, {"from": 380, "to": 551, "width": 5.0}, {"from": 380, "to": 662, "width": 4.0}, {"from": 380, "to": 673, "width": 5.0}, {"from": 380, "to": 746, "width": 4.0}, {"from": 380, "to": 872, "width": 4.0}, {"from": 383, "to": 419, "width": 4.0}, {"from": 383, "to": 423, "width": 5.0}, {"from": 383, "to": 551, "width": 5.0}, {"from": 383, "to": 675, "width": 4.0}, {"from": 384, "to": 400, "width": 4.0}, {"from": 384, "to": 637, "width": 5.0}, {"from": 384, "to": 802, "width": 4.0}, {"from": 387, "to": 453, "width": 5.0}, {"from": 388, "to": 453, "width": 4.0}, {"from": 388, "to": 467, "width": 6.0}, {"from": 388, "to": 645, "width": 5.0}, {"from": 388, "to": 653, "width": 6.0}, {"from": 388, "to": 659, "width": 5.0}, {"from": 388, "to": 664, "width": 11.0}, {"from": 388, "to": 779, "width": 4.0}, {"from": 388, "to": 974, "width": 4.0}, {"from": 389, "to": 416, "width": 4.0}, {"from": 389, "to": 423, "width": 16.0}, {"from": 389, "to": 501, "width": 10.0}, {"from": 389, "to": 524, "width": 5.0}, {"from": 389, "to": 547, "width": 5.0}, {"from": 389, "to": 641, "width": 4.0}, {"from": 389, "to": 677, "width": 4.0}, {"from": 389, "to": 880, "width": 4.0}, {"from": 389, "to": 1033, "width": 5.0}, {"from": 389, "to": 1043, "width": 4.0}, {"from": 389, "to": 1045, "width": 4.0}, {"from": 391, "to": 750, "width": 4.0}, {"from": 391, "to": 864, "width": 4.0}, {"from": 391, "to": 1051, "width": 4.0}, {"from": 392, "to": 459, "width": 7.0}, {"from": 392, "to": 554, "width": 5.0}, {"from": 392, "to": 641, "width": 4.0}, {"from": 392, "to": 642, "width": 5.0}, {"from": 392, "to": 927, "width": 4.0}, {"from": 396, "to": 407, "width": 4.0}, {"from": 396, "to": 468, "width": 5.0}, {"from": 396, "to": 472, "width": 6.0}, {"from": 396, "to": 479, "width": 7.0}, {"from": 396, "to": 499, "width": 4.0}, {"from": 396, "to": 551, "width": 5.0}, {"from": 396, "to": 557, "width": 4.0}, {"from": 396, "to": 558, "width": 4.0}, {"from": 396, "to": 560, "width": 4.0}, {"from": 396, "to": 637, "width": 4.0}, {"from": 396, "to": 641, "width": 6.0}, {"from": 396, "to": 652, "width": 5.0}, {"from": 396, "to": 662, "width": 5.0}, {"from": 396, "to": 872, "width": 4.0}, {"from": 396, "to": 882, "width": 6.0}, {"from": 396, "to": 907, "width": 4.0}, {"from": 396, "to": 913, "width": 4.0}, {"from": 396, "to": 1307, "width": 4.0}, {"from": 397, "to": 454, "width": 4.0}, {"from": 399, "to": 462, "width": 5.0}, {"from": 400, "to": 476, "width": 7.0}, {"from": 400, "to": 514, "width": 4.0}, {"from": 400, "to": 516, "width": 4.0}, {"from": 400, "to": 548, "width": 4.0}, {"from": 400, "to": 616, "width": 6.0}, {"from": 400, "to": 641, "width": 6.0}, {"from": 400, "to": 667, "width": 8.0}, {"from": 400, "to": 791, "width": 7.0}, {"from": 400, "to": 823, "width": 4.0}, {"from": 402, "to": 403, "width": 4.0}, {"from": 402, "to": 474, "width": 7.0}, {"from": 402, "to": 476, "width": 6.0}, {"from": 402, "to": 516, "width": 5.0}, {"from": 403, "to": 516, "width": 4.0}, {"from": 414, "to": 689, "width": 4.0}, {"from": 414, "to": 802, "width": 5.0}, {"from": 414, "to": 863, "width": 4.0}, {"from": 414, "to": 959, "width": 6.0}, {"from": 414, "to": 961, "width": 5.0}, {"from": 416, "to": 423, "width": 4.0}, {"from": 416, "to": 502, "width": 4.0}, {"from": 416, "to": 524, "width": 5.0}, {"from": 419, "to": 1040, "width": 4.0}, {"from": 420, "to": 423, "width": 4.0}, {"from": 420, "to": 524, "width": 4.0}, {"from": 420, "to": 675, "width": 4.0}, {"from": 422, "to": 514, "width": 4.0}, {"from": 423, "to": 424, "width": 4.0}, {"from": 423, "to": 456, "width": 7.0}, {"from": 423, "to": 501, "width": 9.0}, {"from": 423, "to": 502, "width": 4.0}, {"from": 423, "to": 524, "width": 4.0}, {"from": 423, "to": 551, "width": 5.0}, {"from": 423, "to": 607, "width": 4.0}, {"from": 423, "to": 617, "width": 4.0}, {"from": 423, "to": 675, "width": 4.0}, {"from": 423, "to": 755, "width": 4.0}, {"from": 423, "to": 761, "width": 4.0}, {"from": 423, "to": 868, "width": 6.0}, {"from": 423, "to": 872, "width": 10.0}, {"from": 423, "to": 878, "width": 6.0}, {"from": 423, "to": 880, "width": 4.0}, {"from": 423, "to": 1043, "width": 6.0}, {"from": 423, "to": 1045, "width": 5.0}, {"from": 423, "to": 1172, "width": 6.0}, {"from": 423, "to": 1458, "width": 4.0}, {"from": 428, "to": 551, "width": 4.0}, {"from": 428, "to": 604, "width": 5.0}, {"from": 453, "to": 1024, "width": 5.0}, {"from": 455, "to": 477, "width": 4.0}, {"from": 455, "to": 641, "width": 4.0}, {"from": 455, "to": 990, "width": 4.0}, {"from": 456, "to": 457, "width": 4.0}, {"from": 456, "to": 462, "width": 5.0}, {"from": 456, "to": 475, "width": 4.0}, {"from": 456, "to": 550, "width": 7.0}, {"from": 456, "to": 551, "width": 5.0}, {"from": 456, "to": 552, "width": 4.0}, {"from": 456, "to": 641, "width": 4.0}, {"from": 456, "to": 655, "width": 9.0}, {"from": 456, "to": 667, "width": 4.0}, {"from": 456, "to": 755, "width": 21.0}, {"from": 456, "to": 790, "width": 4.0}, {"from": 456, "to": 868, "width": 10.0}, {"from": 456, "to": 872, "width": 14.0}, {"from": 456, "to": 874, "width": 7.0}, {"from": 456, "to": 878, "width": 5.0}, {"from": 456, "to": 892, "width": 5.0}, {"from": 456, "to": 909, "width": 4.0}, {"from": 456, "to": 918, "width": 5.0}, {"from": 456, "to": 990, "width": 4.0}, {"from": 456, "to": 995, "width": 7.0}, {"from": 456, "to": 1020, "width": 4.0}, {"from": 456, "to": 1046, "width": 4.0}, {"from": 456, "to": 1146, "width": 6.0}, {"from": 457, "to": 475, "width": 5.0}, {"from": 458, "to": 481, "width": 4.0}, {"from": 458, "to": 495, "width": 6.0}, {"from": 458, "to": 610, "width": 4.0}, {"from": 458, "to": 767, "width": 7.0}, {"from": 458, "to": 940, "width": 7.0}, {"from": 458, "to": 1053, "width": 4.0}, {"from": 459, "to": 554, "width": 14.0}, {"from": 459, "to": 640, "width": 5.0}, {"from": 459, "to": 641, "width": 6.0}, {"from": 459, "to": 642, "width": 14.0}, {"from": 459, "to": 927, "width": 6.0}, {"from": 459, "to": 968, "width": 5.0}, {"from": 462, "to": 872, "width": 4.0}, {"from": 467, "to": 653, "width": 8.0}, {"from": 467, "to": 664, "width": 5.0}, {"from": 467, "to": 974, "width": 6.0}, {"from": 468, "to": 494, "width": 5.0}, {"from": 468, "to": 802, "width": 5.0}, {"from": 468, "to": 959, "width": 4.0}, {"from": 470, "to": 477, "width": 5.0}, {"from": 472, "to": 479, "width": 6.0}, {"from": 472, "to": 499, "width": 8.0}, {"from": 472, "to": 557, "width": 7.0}, {"from": 472, "to": 558, "width": 4.0}, {"from": 472, "to": 595, "width": 7.0}, {"from": 472, "to": 597, "width": 4.0}, {"from": 472, "to": 598, "width": 4.0}, {"from": 472, "to": 599, "width": 4.0}, {"from": 472, "to": 637, "width": 4.0}, {"from": 472, "to": 662, "width": 11.0}, {"from": 472, "to": 794, "width": 4.0}, {"from": 472, "to": 828, "width": 6.0}, {"from": 472, "to": 829, "width": 4.0}, {"from": 472, "to": 897, "width": 6.0}, {"from": 472, "to": 900, "width": 4.0}, {"from": 472, "to": 904, "width": 4.0}, {"from": 473, "to": 477, "width": 4.0}, {"from": 473, "to": 608, "width": 4.0}, {"from": 473, "to": 641, "width": 4.0}, {"from": 473, "to": 746, "width": 7.0}, {"from": 473, "to": 1043, "width": 5.0}, {"from": 474, "to": 476, "width": 8.0}, {"from": 474, "to": 516, "width": 6.0}, {"from": 476, "to": 516, "width": 9.0}, {"from": 476, "to": 548, "width": 4.0}, {"from": 476, "to": 549, "width": 5.0}, {"from": 476, "to": 616, "width": 4.0}, {"from": 476, "to": 641, "width": 4.0}, {"from": 476, "to": 667, "width": 4.0}, {"from": 477, "to": 551, "width": 4.0}, {"from": 477, "to": 560, "width": 11.0}, {"from": 477, "to": 604, "width": 4.0}, {"from": 477, "to": 641, "width": 16.0}, {"from": 477, "to": 682, "width": 5.0}, {"from": 477, "to": 867, "width": 4.0}, {"from": 477, "to": 933, "width": 4.0}, {"from": 477, "to": 942, "width": 4.0}, {"from": 477, "to": 979, "width": 6.0}, {"from": 477, "to": 991, "width": 4.0}, {"from": 477, "to": 1130, "width": 6.0}, {"from": 477, "to": 1134, "width": 5.0}, {"from": 477, "to": 1307, "width": 6.0}, {"from": 477, "to": 1347, "width": 6.0}, {"from": 479, "to": 493, "width": 5.0}, {"from": 479, "to": 557, "width": 4.0}, {"from": 479, "to": 559, "width": 4.0}, {"from": 479, "to": 573, "width": 4.0}, {"from": 479, "to": 631, "width": 5.0}, {"from": 479, "to": 652, "width": 7.0}, {"from": 479, "to": 662, "width": 4.0}, {"from": 479, "to": 814, "width": 6.0}, {"from": 479, "to": 830, "width": 4.0}, {"from": 479, "to": 1205, "width": 9.0}, {"from": 479, "to": 1326, "width": 4.0}, {"from": 482, "to": 802, "width": 4.0}, {"from": 484, "to": 767, "width": 4.0}, {"from": 484, "to": 1053, "width": 4.0}, {"from": 494, "to": 690, "width": 4.0}, {"from": 494, "to": 802, "width": 4.0}, {"from": 495, "to": 940, "width": 5.0}, {"from": 498, "to": 512, "width": 4.0}, {"from": 498, "to": 553, "width": 4.0}, {"from": 499, "to": 557, "width": 9.0}, {"from": 499, "to": 597, "width": 7.0}, {"from": 499, "to": 662, "width": 8.0}, {"from": 499, "to": 897, "width": 4.0}, {"from": 499, "to": 1369, "width": 4.0}, {"from": 501, "to": 502, "width": 5.0}, {"from": 501, "to": 551, "width": 4.0}, {"from": 501, "to": 617, "width": 4.0}, {"from": 501, "to": 624, "width": 5.0}, {"from": 501, "to": 698, "width": 4.0}, {"from": 501, "to": 761, "width": 4.0}, {"from": 501, "to": 864, "width": 4.0}, {"from": 501, "to": 872, "width": 4.0}, {"from": 501, "to": 1045, "width": 4.0}, {"from": 501, "to": 1172, "width": 5.0}, {"from": 501, "to": 1179, "width": 4.0}, {"from": 501, "to": 1181, "width": 5.0}, {"from": 501, "to": 1458, "width": 4.0}, {"from": 502, "to": 607, "width": 4.0}, {"from": 502, "to": 683, "width": 4.0}, {"from": 502, "to": 1458, "width": 4.0}, {"from": 507, "to": 516, "width": 4.0}, {"from": 507, "to": 1052, "width": 5.0}, {"from": 512, "to": 600, "width": 4.0}, {"from": 512, "to": 873, "width": 4.0}, {"from": 516, "to": 549, "width": 5.0}, {"from": 516, "to": 555, "width": 4.0}, {"from": 516, "to": 616, "width": 4.0}, {"from": 516, "to": 790, "width": 4.0}, {"from": 516, "to": 811, "width": 4.0}, {"from": 516, "to": 826, "width": 4.0}, {"from": 516, "to": 948, "width": 4.0}, {"from": 516, "to": 1052, "width": 5.0}, {"from": 524, "to": 608, "width": 4.0}, {"from": 524, "to": 617, "width": 4.0}, {"from": 524, "to": 675, "width": 8.0}, {"from": 524, "to": 683, "width": 4.0}, {"from": 524, "to": 865, "width": 5.0}, {"from": 524, "to": 1043, "width": 5.0}, {"from": 526, "to": 974, "width": 4.0}, {"from": 547, "to": 550, "width": 4.0}, {"from": 547, "to": 551, "width": 6.0}, {"from": 547, "to": 641, "width": 4.0}, {"from": 547, "to": 672, "width": 9.0}, {"from": 547, "to": 867, "width": 6.0}, {"from": 547, "to": 1076, "width": 4.0}, {"from": 548, "to": 614, "width": 6.0}, {"from": 548, "to": 616, "width": 8.0}, {"from": 548, "to": 638, "width": 4.0}, {"from": 548, "to": 667, "width": 14.0}, {"from": 548, "to": 754, "width": 4.0}, {"from": 548, "to": 823, "width": 5.0}, {"from": 548, "to": 826, "width": 4.0}, {"from": 548, "to": 863, "width": 4.0}, {"from": 548, "to": 909, "width": 6.0}, {"from": 548, "to": 937, "width": 6.0}, {"from": 548, "to": 954, "width": 9.0}, {"from": 548, "to": 1020, "width": 5.0}, {"from": 548, "to": 1068, "width": 4.0}, {"from": 549, "to": 616, "width": 5.0}, {"from": 549, "to": 667, "width": 5.0}, {"from": 550, "to": 551, "width": 6.0}, {"from": 550, "to": 673, "width": 5.0}, {"from": 550, "to": 746, "width": 4.0}, {"from": 550, "to": 868, "width": 4.0}, {"from": 550, "to": 872, "width": 6.0}, {"from": 550, "to": 1040, "width": 4.0}, {"from": 551, "to": 607, "width": 4.0}, {"from": 551, "to": 609, "width": 4.0}, {"from": 551, "to": 641, "width": 4.0}, {"from": 551, "to": 670, "width": 4.0}, {"from": 551, "to": 673, "width": 7.0}, {"from": 551, "to": 683, "width": 4.0}, {"from": 551, "to": 698, "width": 4.0}, {"from": 551, "to": 746, "width": 4.0}, {"from": 551, "to": 761, "width": 4.0}, {"from": 551, "to": 867, "width": 5.0}, {"from": 551, "to": 868, "width": 5.0}, {"from": 551, "to": 872, "width": 11.0}, {"from": 551, "to": 878, "width": 5.0}, {"from": 551, "to": 882, "width": 5.0}, {"from": 551, "to": 981, "width": 4.0}, {"from": 551, "to": 1040, "width": 4.0}, {"from": 551, "to": 1043, "width": 4.0}, {"from": 551, "to": 1134, "width": 4.0}, {"from": 551, "to": 1181, "width": 5.0}, {"from": 551, "to": 1273, "width": 4.0}, {"from": 551, "to": 1288, "width": 4.0}, {"from": 551, "to": 1458, "width": 4.0}, {"from": 551, "to": 1464, "width": 4.0}, {"from": 551, "to": 1585, "width": 4.0}, {"from": 552, "to": 567, "width": 4.0}, {"from": 552, "to": 641, "width": 4.0}, {"from": 552, "to": 649, "width": 6.0}, {"from": 552, "to": 754, "width": 4.0}, {"from": 552, "to": 872, "width": 4.0}, {"from": 552, "to": 1125, "width": 4.0}, {"from": 553, "to": 667, "width": 5.0}, {"from": 553, "to": 1068, "width": 4.0}, {"from": 554, "to": 640, "width": 5.0}, {"from": 554, "to": 642, "width": 10.0}, {"from": 554, "to": 669, "width": 4.0}, {"from": 554, "to": 750, "width": 4.0}, {"from": 554, "to": 927, "width": 6.0}, {"from": 554, "to": 968, "width": 4.0}, {"from": 554, "to": 1051, "width": 4.0}, {"from": 554, "to": 1462, "width": 4.0}, {"from": 555, "to": 616, "width": 4.0}, {"from": 555, "to": 641, "width": 4.0}, {"from": 555, "to": 667, "width": 5.0}, {"from": 555, "to": 790, "width": 4.0}, {"from": 555, "to": 823, "width": 4.0}, {"from": 555, "to": 1200, "width": 7.0}, {"from": 555, "to": 1296, "width": 5.0}, {"from": 557, "to": 597, "width": 8.0}, {"from": 557, "to": 644, "width": 4.0}, {"from": 557, "to": 652, "width": 4.0}, {"from": 557, "to": 662, "width": 9.0}, {"from": 557, "to": 674, "width": 4.0}, {"from": 557, "to": 828, "width": 4.0}, {"from": 557, "to": 829, "width": 5.0}, {"from": 557, "to": 897, "width": 4.0}, {"from": 557, "to": 900, "width": 4.0}, {"from": 557, "to": 1153, "width": 4.0}, {"from": 557, "to": 1369, "width": 4.0}, {"from": 558, "to": 640, "width": 4.0}, {"from": 558, "to": 644, "width": 4.0}, {"from": 558, "to": 669, "width": 6.0}, {"from": 559, "to": 652, "width": 5.0}, {"from": 559, "to": 907, "width": 6.0}, {"from": 560, "to": 577, "width": 4.0}, {"from": 560, "to": 641, "width": 11.0}, {"from": 560, "to": 678, "width": 4.0}, {"from": 560, "to": 682, "width": 5.0}, {"from": 560, "to": 942, "width": 5.0}, {"from": 560, "to": 979, "width": 5.0}, {"from": 560, "to": 1130, "width": 4.0}, {"from": 560, "to": 1307, "width": 5.0}, {"from": 561, "to": 641, "width": 4.0}, {"from": 561, "to": 661, "width": 4.0}, {"from": 565, "to": 897, "width": 4.0}, {"from": 569, "to": 755, "width": 4.0}, {"from": 571, "to": 641, "width": 4.0}, {"from": 572, "to": 641, "width": 4.0}, {"from": 595, "to": 598, "width": 4.0}, {"from": 595, "to": 662, "width": 7.0}, {"from": 595, "to": 829, "width": 5.0}, {"from": 595, "to": 897, "width": 5.0}, {"from": 595, "to": 900, "width": 4.0}, {"from": 595, "to": 904, "width": 4.0}, {"from": 595, "to": 1041, "width": 5.0}, {"from": 595, "to": 1190, "width": 5.0}, {"from": 595, "to": 1281, "width": 4.0}, {"from": 596, "to": 687, "width": 4.0}, {"from": 597, "to": 662, "width": 7.0}, {"from": 597, "to": 674, "width": 5.0}, {"from": 598, "to": 637, "width": 4.0}, {"from": 598, "to": 662, "width": 5.0}, {"from": 598, "to": 684, "width": 5.0}, {"from": 598, "to": 685, "width": 6.0}, {"from": 598, "to": 688, "width": 7.0}, {"from": 598, "to": 827, "width": 7.0}, {"from": 598, "to": 897, "width": 4.0}, {"from": 598, "to": 1041, "width": 4.0}, {"from": 604, "to": 641, "width": 4.0}, {"from": 604, "to": 677, "width": 4.0}, {"from": 604, "to": 682, "width": 4.0}, {"from": 607, "to": 683, "width": 5.0}, {"from": 607, "to": 872, "width": 4.0}, {"from": 607, "to": 1288, "width": 4.0}, {"from": 607, "to": 1464, "width": 5.0}, {"from": 608, "to": 675, "width": 4.0}, {"from": 608, "to": 1464, "width": 5.0}, {"from": 609, "to": 683, "width": 4.0}, {"from": 609, "to": 872, "width": 4.0}, {"from": 609, "to": 880, "width": 4.0}, {"from": 614, "to": 667, "width": 5.0}, {"from": 616, "to": 667, "width": 12.0}, {"from": 616, "to": 754, "width": 4.0}, {"from": 616, "to": 791, "width": 5.0}, {"from": 616, "to": 823, "width": 4.0}, {"from": 616, "to": 826, "width": 4.0}, {"from": 616, "to": 954, "width": 5.0}, {"from": 616, "to": 1052, "width": 4.0}, {"from": 616, "to": 1169, "width": 4.0}, {"from": 616, "to": 1186, "width": 4.0}, {"from": 616, "to": 1200, "width": 6.0}, {"from": 616, "to": 1296, "width": 4.0}, {"from": 617, "to": 1043, "width": 6.0}, {"from": 617, "to": 1458, "width": 4.0}, {"from": 624, "to": 698, "width": 4.0}, {"from": 624, "to": 872, "width": 4.0}, {"from": 631, "to": 1205, "width": 5.0}, {"from": 632, "to": 929, "width": 4.0}, {"from": 635, "to": 872, "width": 4.0}, {"from": 637, "to": 685, "width": 4.0}, {"from": 637, "to": 794, "width": 6.0}, {"from": 637, "to": 873, "width": 5.0}, {"from": 637, "to": 897, "width": 5.0}, {"from": 638, "to": 667, "width": 5.0}, {"from": 638, "to": 767, "width": 4.0}, {"from": 638, "to": 826, "width": 4.0}, {"from": 638, "to": 940, "width": 5.0}, {"from": 638, "to": 1053, "width": 4.0}, {"from": 639, "to": 653, "width": 5.0}, {"from": 639, "to": 690, "width": 5.0}, {"from": 639, "to": 802, "width": 4.0}, {"from": 639, "to": 959, "width": 6.0}, {"from": 639, "to": 961, "width": 5.0}, {"from": 640, "to": 641, "width": 4.0}, {"from": 640, "to": 652, "width": 4.0}, {"from": 640, "to": 669, "width": 6.0}, {"from": 640, "to": 972, "width": 5.0}, {"from": 640, "to": 1051, "width": 4.0}, {"from": 640, "to": 1201, "width": 4.0}, {"from": 641, "to": 642, "width": 5.0}, {"from": 641, "to": 652, "width": 5.0}, {"from": 641, "to": 655, "width": 4.0}, {"from": 641, "to": 667, "width": 5.0}, {"from": 641, "to": 670, "width": 4.0}, {"from": 641, "to": 678, "width": 5.0}, {"from": 641, "to": 682, "width": 5.0}, {"from": 641, "to": 696, "width": 4.0}, {"from": 641, "to": 746, "width": 4.0}, {"from": 641, "to": 755, "width": 4.0}, {"from": 641, "to": 791, "width": 4.0}, {"from": 641, "to": 809, "width": 5.0}, {"from": 641, "to": 823, "width": 6.0}, {"from": 641, "to": 826, "width": 4.0}, {"from": 641, "to": 827, "width": 5.0}, {"from": 641, "to": 872, "width": 11.0}, {"from": 641, "to": 909, "width": 4.0}, {"from": 641, "to": 918, "width": 5.0}, {"from": 641, "to": 927, "width": 4.0}, {"from": 641, "to": 933, "width": 5.0}, {"from": 641, "to": 940, "width": 5.0}, {"from": 641, "to": 942, "width": 6.0}, {"from": 641, "to": 954, "width": 4.0}, {"from": 641, "to": 960, "width": 5.0}, {"from": 641, "to": 968, "width": 5.0}, {"from": 641, "to": 972, "width": 4.0}, {"from": 641, "to": 979, "width": 13.0}, {"from": 641, "to": 980, "width": 4.0}, {"from": 641, "to": 987, "width": 4.0}, {"from": 641, "to": 991, "width": 4.0}, {"from": 641, "to": 1130, "width": 9.0}, {"from": 641, "to": 1134, "width": 9.0}, {"from": 641, "to": 1187, "width": 4.0}, {"from": 641, "to": 1304, "width": 4.0}, {"from": 641, "to": 1307, "width": 6.0}, {"from": 641, "to": 1347, "width": 11.0}, {"from": 642, "to": 927, "width": 8.0}, {"from": 642, "to": 968, "width": 7.0}, {"from": 642, "to": 969, "width": 5.0}, {"from": 642, "to": 1129, "width": 4.0}, {"from": 644, "to": 662, "width": 4.0}, {"from": 644, "to": 897, "width": 5.0}, {"from": 645, "to": 659, "width": 4.0}, {"from": 645, "to": 664, "width": 5.0}, {"from": 649, "to": 791, "width": 4.0}, {"from": 649, "to": 832, "width": 4.0}, {"from": 652, "to": 907, "width": 5.0}, {"from": 652, "to": 913, "width": 4.0}, {"from": 653, "to": 659, "width": 4.0}, {"from": 653, "to": 664, "width": 7.0}, {"from": 653, "to": 959, "width": 4.0}, {"from": 653, "to": 974, "width": 8.0}, {"from": 653, "to": 1024, "width": 5.0}, {"from": 653, "to": 1337, "width": 4.0}, {"from": 653, "to": 1529, "width": 4.0}, {"from": 655, "to": 755, "width": 13.0}, {"from": 655, "to": 892, "width": 7.0}, {"from": 655, "to": 995, "width": 4.0}, {"from": 657, "to": 660, "width": 4.0}, {"from": 657, "to": 669, "width": 4.0}, {"from": 657, "to": 939, "width": 4.0}, {"from": 658, "to": 830, "width": 4.0}, {"from": 659, "to": 664, "width": 5.0}, {"from": 659, "to": 732, "width": 4.0}, {"from": 659, "to": 779, "width": 5.0}, {"from": 659, "to": 1342, "width": 4.0}, {"from": 659, "to": 1419, "width": 4.0}, {"from": 661, "to": 747, "width": 4.0}, {"from": 661, "to": 887, "width": 4.0}, {"from": 662, "to": 666, "width": 4.0}, {"from": 662, "to": 673, "width": 4.0}, {"from": 662, "to": 674, "width": 7.0}, {"from": 662, "to": 738, "width": 4.0}, {"from": 662, "to": 794, "width": 4.0}, {"from": 662, "to": 828, "width": 8.0}, {"from": 662, "to": 829, "width": 6.0}, {"from": 662, "to": 868, "width": 6.0}, {"from": 662, "to": 872, "width": 6.0}, {"from": 662, "to": 873, "width": 8.0}, {"from": 662, "to": 878, "width": 4.0}, {"from": 662, "to": 897, "width": 8.0}, {"from": 662, "to": 900, "width": 5.0}, {"from": 662, "to": 904, "width": 4.0}, {"from": 662, "to": 907, "width": 5.0}, {"from": 662, "to": 943, "width": 4.0}, {"from": 662, "to": 990, "width": 4.0}, {"from": 662, "to": 1084, "width": 4.0}, {"from": 662, "to": 1132, "width": 4.0}, {"from": 662, "to": 1153, "width": 9.0}, {"from": 662, "to": 1205, "width": 6.0}, {"from": 662, "to": 1274, "width": 7.0}, {"from": 662, "to": 1281, "width": 4.0}, {"from": 662, "to": 1369, "width": 9.0}, {"from": 662, "to": 1555, "width": 5.0}, {"from": 662, "to": 1607, "width": 4.0}, {"from": 662, "to": 1615, "width": 5.0}, {"from": 664, "to": 668, "width": 4.0}, {"from": 664, "to": 779, "width": 4.0}, {"from": 664, "to": 959, "width": 4.0}, {"from": 664, "to": 974, "width": 5.0}, {"from": 664, "to": 1332, "width": 4.0}, {"from": 664, "to": 1419, "width": 4.0}, {"from": 667, "to": 696, "width": 10.0}, {"from": 667, "to": 754, "width": 6.0}, {"from": 667, "to": 767, "width": 6.0}, {"from": 667, "to": 791, "width": 8.0}, {"from": 667, "to": 823, "width": 6.0}, {"from": 667, "to": 826, "width": 8.0}, {"from": 667, "to": 909, "width": 13.0}, {"from": 667, "to": 937, "width": 8.0}, {"from": 667, "to": 948, "width": 7.0}, {"from": 667, "to": 954, "width": 14.0}, {"from": 667, "to": 1020, "width": 7.0}, {"from": 667, "to": 1066, "width": 4.0}, {"from": 667, "to": 1068, "width": 6.0}, {"from": 667, "to": 1069, "width": 8.0}, {"from": 667, "to": 1098, "width": 5.0}, {"from": 667, "to": 1175, "width": 4.0}, {"from": 667, "to": 1186, "width": 4.0}, {"from": 667, "to": 1366, "width": 4.0}, {"from": 668, "to": 669, "width": 4.0}, {"from": 668, "to": 1201, "width": 4.0}, {"from": 668, "to": 1332, "width": 4.0}, {"from": 669, "to": 1051, "width": 5.0}, {"from": 669, "to": 1201, "width": 4.0}, {"from": 670, "to": 673, "width": 4.0}, {"from": 670, "to": 809, "width": 4.0}, {"from": 670, "to": 933, "width": 4.0}, {"from": 671, "to": 990, "width": 4.0}, {"from": 672, "to": 867, "width": 4.0}, {"from": 673, "to": 698, "width": 4.0}, {"from": 673, "to": 766, "width": 4.0}, {"from": 673, "to": 807, "width": 4.0}, {"from": 673, "to": 872, "width": 7.0}, {"from": 673, "to": 1040, "width": 7.0}, {"from": 673, "to": 1136, "width": 6.0}, {"from": 674, "to": 828, "width": 4.0}, {"from": 674, "to": 1153, "width": 6.0}, {"from": 674, "to": 1274, "width": 4.0}, {"from": 674, "to": 1369, "width": 5.0}, {"from": 675, "to": 865, "width": 6.0}, {"from": 675, "to": 1043, "width": 5.0}, {"from": 677, "to": 678, "width": 4.0}, {"from": 678, "to": 942, "width": 4.0}, {"from": 680, "to": 864, "width": 4.0}, {"from": 682, "to": 942, "width": 4.0}, {"from": 683, "to": 938, "width": 4.0}, {"from": 683, "to": 1040, "width": 4.0}, {"from": 683, "to": 1043, "width": 5.0}, {"from": 683, "to": 1172, "width": 4.0}, {"from": 683, "to": 1288, "width": 5.0}, {"from": 683, "to": 1464, "width": 5.0}, {"from": 684, "to": 688, "width": 4.0}, {"from": 684, "to": 827, "width": 4.0}, {"from": 685, "to": 797, "width": 4.0}, {"from": 685, "to": 827, "width": 17.0}, {"from": 685, "to": 948, "width": 5.0}, {"from": 685, "to": 1096, "width": 4.0}, {"from": 685, "to": 1182, "width": 4.0}, {"from": 685, "to": 1267, "width": 4.0}, {"from": 686, "to": 873, "width": 4.0}, {"from": 688, "to": 811, "width": 4.0}, {"from": 688, "to": 833, "width": 5.0}, {"from": 688, "to": 1050, "width": 4.0}, {"from": 688, "to": 1324, "width": 4.0}, {"from": 688, "to": 1327, "width": 4.0}, {"from": 688, "to": 1328, "width": 4.0}, {"from": 689, "to": 690, "width": 5.0}, {"from": 689, "to": 961, "width": 4.0}, {"from": 690, "to": 802, "width": 8.0}, {"from": 690, "to": 862, "width": 4.0}, {"from": 690, "to": 935, "width": 4.0}, {"from": 690, "to": 959, "width": 9.0}, {"from": 690, "to": 961, "width": 12.0}, {"from": 690, "to": 1056, "width": 4.0}, {"from": 690, "to": 1199, "width": 4.0}, {"from": 691, "to": 823, "width": 5.0}, {"from": 691, "to": 863, "width": 4.0}, {"from": 691, "to": 909, "width": 4.0}, {"from": 691, "to": 954, "width": 5.0}, {"from": 696, "to": 826, "width": 6.0}, {"from": 696, "to": 909, "width": 9.0}, {"from": 696, "to": 948, "width": 6.0}, {"from": 696, "to": 1018, "width": 4.0}, {"from": 696, "to": 1020, "width": 5.0}, {"from": 696, "to": 1097, "width": 6.0}, {"from": 698, "to": 872, "width": 5.0}, {"from": 732, "to": 1026, "width": 4.0}, {"from": 738, "to": 827, "width": 5.0}, {"from": 739, "to": 929, "width": 4.0}, {"from": 740, "to": 967, "width": 5.0}, {"from": 746, "to": 778, "width": 5.0}, {"from": 746, "to": 809, "width": 4.0}, {"from": 746, "to": 872, "width": 5.0}, {"from": 746, "to": 882, "width": 4.0}, {"from": 746, "to": 1392, "width": 5.0}, {"from": 750, "to": 793, "width": 5.0}, {"from": 750, "to": 864, "width": 4.0}, {"from": 750, "to": 1051, "width": 5.0}, {"from": 750, "to": 1582, "width": 4.0}, {"from": 754, "to": 767, "width": 4.0}, {"from": 754, "to": 791, "width": 6.0}, {"from": 754, "to": 909, "width": 4.0}, {"from": 754, "to": 937, "width": 7.0}, {"from": 754, "to": 954, "width": 6.0}, {"from": 754, "to": 1094, "width": 4.0}, {"from": 755, "to": 793, "width": 6.0}, {"from": 755, "to": 872, "width": 10.0}, {"from": 755, "to": 874, "width": 7.0}, {"from": 755, "to": 880, "width": 5.0}, {"from": 755, "to": 892, "width": 7.0}, {"from": 755, "to": 950, "width": 6.0}, {"from": 755, "to": 995, "width": 10.0}, {"from": 755, "to": 1020, "width": 4.0}, {"from": 755, "to": 1125, "width": 4.0}, {"from": 755, "to": 1146, "width": 5.0}, {"from": 755, "to": 1415, "width": 7.0}, {"from": 755, "to": 1428, "width": 4.0}, {"from": 761, "to": 872, "width": 6.0}, {"from": 761, "to": 1172, "width": 4.0}, {"from": 761, "to": 1181, "width": 5.0}, {"from": 761, "to": 1458, "width": 4.0}, {"from": 761, "to": 1464, "width": 4.0}, {"from": 762, "to": 983, "width": 4.0}, {"from": 763, "to": 967, "width": 4.0}, {"from": 766, "to": 797, "width": 4.0}, {"from": 766, "to": 865, "width": 4.0}, {"from": 766, "to": 872, "width": 5.0}, {"from": 767, "to": 937, "width": 4.0}, {"from": 767, "to": 940, "width": 15.0}, {"from": 767, "to": 1053, "width": 13.0}, {"from": 767, "to": 1187, "width": 7.0}, {"from": 767, "to": 1319, "width": 5.0}, {"from": 778, "to": 1377, "width": 4.0}, {"from": 779, "to": 1342, "width": 4.0}, {"from": 779, "to": 1419, "width": 4.0}, {"from": 781, "to": 889, "width": 5.0}, {"from": 787, "to": 890, "width": 4.0}, {"from": 790, "to": 913, "width": 7.0}, {"from": 790, "to": 956, "width": 4.0}, {"from": 790, "to": 1051, "width": 5.0}, {"from": 790, "to": 1185, "width": 4.0}, {"from": 791, "to": 823, "width": 5.0}, {"from": 791, "to": 826, "width": 4.0}, {"from": 791, "to": 832, "width": 6.0}, {"from": 791, "to": 918, "width": 4.0}, {"from": 791, "to": 954, "width": 8.0}, {"from": 791, "to": 1066, "width": 4.0}, {"from": 791, "to": 1125, "width": 4.0}, {"from": 791, "to": 1193, "width": 4.0}, {"from": 791, "to": 1372, "width": 5.0}, {"from": 791, "to": 1576, "width": 4.0}, {"from": 793, "to": 864, "width": 4.0}, {"from": 793, "to": 1051, "width": 4.0}, {"from": 794, "to": 827, "width": 4.0}, {"from": 794, "to": 828, "width": 4.0}, {"from": 794, "to": 873, "width": 4.0}, {"from": 794, "to": 897, "width": 5.0}, {"from": 794, "to": 1041, "width": 4.0}, {"from": 797, "to": 827, "width": 7.0}, {"from": 797, "to": 865, "width": 4.0}, {"from": 797, "to": 1096, "width": 6.0}, {"from": 800, "to": 934, "width": 6.0}, {"from": 800, "to": 1027, "width": 5.0}, {"from": 802, "to": 935, "width": 5.0}, {"from": 802, "to": 959, "width": 8.0}, {"from": 802, "to": 961, "width": 9.0}, {"from": 802, "to": 1056, "width": 5.0}, {"from": 806, "to": 872, "width": 4.0}, {"from": 807, "to": 872, "width": 4.0}, {"from": 809, "to": 933, "width": 4.0}, {"from": 811, "to": 826, "width": 4.0}, {"from": 811, "to": 827, "width": 6.0}, {"from": 811, "to": 833, "width": 5.0}, {"from": 811, "to": 948, "width": 5.0}, {"from": 811, "to": 1050, "width": 4.0}, {"from": 814, "to": 830, "width": 4.0}, {"from": 814, "to": 1205, "width": 5.0}, {"from": 823, "to": 826, "width": 4.0}, {"from": 823, "to": 863, "width": 5.0}, {"from": 823, "to": 909, "width": 5.0}, {"from": 823, "to": 937, "width": 4.0}, {"from": 823, "to": 954, "width": 9.0}, {"from": 823, "to": 1069, "width": 5.0}, {"from": 823, "to": 1070, "width": 7.0}, {"from": 826, "to": 832, "width": 5.0}, {"from": 826, "to": 863, "width": 9.0}, {"from": 826, "to": 909, "width": 10.0}, {"from": 826, "to": 937, "width": 4.0}, {"from": 826, "to": 954, "width": 6.0}, {"from": 826, "to": 1018, "width": 4.0}, {"from": 826, "to": 1020, "width": 4.0}, {"from": 826, "to": 1068, "width": 4.0}, {"from": 826, "to": 1069, "width": 4.0}, {"from": 826, "to": 1070, "width": 4.0}, {"from": 826, "to": 1097, "width": 6.0}, {"from": 826, "to": 1171, "width": 4.0}, {"from": 826, "to": 1216, "width": 4.0}, {"from": 826, "to": 1366, "width": 4.0}, {"from": 826, "to": 1451, "width": 4.0}, {"from": 827, "to": 865, "width": 4.0}, {"from": 827, "to": 872, "width": 4.0}, {"from": 827, "to": 873, "width": 4.0}, {"from": 827, "to": 904, "width": 4.0}, {"from": 827, "to": 930, "width": 6.0}, {"from": 827, "to": 948, "width": 6.0}, {"from": 827, "to": 1045, "width": 4.0}, {"from": 827, "to": 1096, "width": 6.0}, {"from": 827, "to": 1182, "width": 8.0}, {"from": 827, "to": 1267, "width": 6.0}, {"from": 827, "to": 1281, "width": 4.0}, {"from": 827, "to": 1329, "width": 5.0}, {"from": 828, "to": 897, "width": 4.0}, {"from": 828, "to": 904, "width": 4.0}, {"from": 828, "to": 1041, "width": 4.0}, {"from": 828, "to": 1132, "width": 4.0}, {"from": 828, "to": 1153, "width": 6.0}, {"from": 828, "to": 1205, "width": 4.0}, {"from": 828, "to": 1274, "width": 5.0}, {"from": 828, "to": 1369, "width": 7.0}, {"from": 828, "to": 1555, "width": 4.0}, {"from": 828, "to": 1607, "width": 4.0}, {"from": 829, "to": 897, "width": 7.0}, {"from": 829, "to": 904, "width": 4.0}, {"from": 829, "to": 1041, "width": 4.0}, {"from": 829, "to": 1190, "width": 4.0}, {"from": 829, "to": 1281, "width": 4.0}, {"from": 829, "to": 1369, "width": 5.0}, {"from": 831, "to": 1132, "width": 4.0}, {"from": 832, "to": 1193, "width": 4.0}, {"from": 833, "to": 1050, "width": 4.0}, {"from": 863, "to": 909, "width": 6.0}, {"from": 863, "to": 954, "width": 4.0}, {"from": 864, "to": 913, "width": 4.0}, {"from": 864, "to": 953, "width": 4.0}, {"from": 864, "to": 956, "width": 4.0}, {"from": 864, "to": 1026, "width": 5.0}, {"from": 864, "to": 1051, "width": 5.0}, {"from": 864, "to": 1589, "width": 4.0}, {"from": 865, "to": 1043, "width": 5.0}, {"from": 865, "to": 1096, "width": 4.0}, {"from": 865, "to": 1464, "width": 4.0}, {"from": 867, "to": 872, "width": 5.0}, {"from": 867, "to": 933, "width": 4.0}, {"from": 867, "to": 1134, "width": 5.0}, {"from": 867, "to": 1309, "width": 5.0}, {"from": 867, "to": 1336, "width": 4.0}, {"from": 868, "to": 872, "width": 16.0}, {"from": 868, "to": 878, "width": 8.0}, {"from": 868, "to": 990, "width": 4.0}, {"from": 872, "to": 874, "width": 8.0}, {"from": 872, "to": 878, "width": 8.0}, {"from": 872, "to": 880, "width": 5.0}, {"from": 872, "to": 882, "width": 5.0}, {"from": 872, "to": 892, "width": 4.0}, {"from": 872, "to": 900, "width": 5.0}, {"from": 872, "to": 950, "width": 5.0}, {"from": 872, "to": 990, "width": 9.0}, {"from": 872, "to": 994, "width": 4.0}, {"from": 872, "to": 995, "width": 4.0}, {"from": 872, "to": 1040, "width": 6.0}, {"from": 872, "to": 1043, "width": 4.0}, {"from": 872, "to": 1046, "width": 4.0}, {"from": 872, "to": 1057, "width": 4.0}, {"from": 872, "to": 1146, "width": 4.0}, {"from": 872, "to": 1172, "width": 4.0}, {"from": 872, "to": 1179, "width": 4.0}, {"from": 872, "to": 1181, "width": 4.0}, {"from": 872, "to": 1192, "width": 4.0}, {"from": 872, "to": 1277, "width": 4.0}, {"from": 872, "to": 1415, "width": 4.0}, {"from": 872, "to": 1458, "width": 4.0}, {"from": 872, "to": 1599, "width": 4.0}, {"from": 873, "to": 904, "width": 4.0}, {"from": 873, "to": 990, "width": 8.0}, {"from": 873, "to": 1041, "width": 4.0}, {"from": 873, "to": 1046, "width": 5.0}, {"from": 873, "to": 1050, "width": 5.0}, {"from": 873, "to": 1099, "width": 4.0}, {"from": 874, "to": 950, "width": 4.0}, {"from": 874, "to": 990, "width": 5.0}, {"from": 880, "to": 892, "width": 5.0}, {"from": 880, "to": 995, "width": 4.0}, {"from": 880, "to": 1428, "width": 4.0}, {"from": 880, "to": 1458, "width": 4.0}, {"from": 880, "to": 1606, "width": 4.0}, {"from": 882, "to": 912, "width": 5.0}, {"from": 882, "to": 1392, "width": 4.0}, {"from": 888, "to": 890, "width": 5.0}, {"from": 888, "to": 1144, "width": 4.0}, {"from": 889, "to": 985, "width": 4.0}, {"from": 890, "to": 944, "width": 5.0}, {"from": 890, "to": 996, "width": 4.0}, {"from": 890, "to": 1030, "width": 4.0}, {"from": 890, "to": 1035, "width": 5.0}, {"from": 890, "to": 1144, "width": 5.0}, {"from": 890, "to": 1211, "width": 4.0}, {"from": 892, "to": 992, "width": 4.0}, {"from": 892, "to": 995, "width": 6.0}, {"from": 892, "to": 1125, "width": 4.0}, {"from": 894, "to": 990, "width": 5.0}, {"from": 896, "to": 939, "width": 4.0}, {"from": 897, "to": 907, "width": 5.0}, {"from": 897, "to": 1041, "width": 5.0}, {"from": 897, "to": 1190, "width": 4.0}, {"from": 897, "to": 1274, "width": 4.0}, {"from": 897, "to": 1369, "width": 5.0}, {"from": 900, "to": 904, "width": 5.0}, {"from": 900, "to": 990, "width": 4.0}, {"from": 900, "to": 1040, "width": 4.0}, {"from": 900, "to": 1041, "width": 4.0}, {"from": 900, "to": 1132, "width": 4.0}, {"from": 900, "to": 1190, "width": 6.0}, {"from": 900, "to": 1281, "width": 5.0}, {"from": 900, "to": 1399, "width": 4.0}, {"from": 900, "to": 1405, "width": 4.0}, {"from": 904, "to": 1041, "width": 5.0}, {"from": 904, "to": 1281, "width": 4.0}, {"from": 907, "to": 972, "width": 5.0}, {"from": 907, "to": 979, "width": 4.0}, {"from": 907, "to": 981, "width": 4.0}, {"from": 907, "to": 1134, "width": 6.0}, {"from": 907, "to": 1292, "width": 4.0}, {"from": 907, "to": 1377, "width": 5.0}, {"from": 909, "to": 928, "width": 4.0}, {"from": 909, "to": 937, "width": 6.0}, {"from": 909, "to": 948, "width": 9.0}, {"from": 909, "to": 954, "width": 10.0}, {"from": 909, "to": 1018, "width": 4.0}, {"from": 909, "to": 1020, "width": 8.0}, {"from": 909, "to": 1068, "width": 5.0}, {"from": 909, "to": 1069, "width": 6.0}, {"from": 909, "to": 1070, "width": 4.0}, {"from": 909, "to": 1097, "width": 7.0}, {"from": 909, "to": 1098, "width": 5.0}, {"from": 909, "to": 1366, "width": 5.0}, {"from": 913, "to": 956, "width": 4.0}, {"from": 913, "to": 1026, "width": 4.0}, {"from": 922, "to": 959, "width": 4.0}, {"from": 922, "to": 1405, "width": 4.0}, {"from": 927, "to": 968, "width": 8.0}, {"from": 927, "to": 969, "width": 6.0}, {"from": 927, "to": 1129, "width": 6.0}, {"from": 928, "to": 1070, "width": 6.0}, {"from": 928, "to": 1185, "width": 4.0}, {"from": 928, "to": 1481, "width": 4.0}, {"from": 930, "to": 1096, "width": 4.0}, {"from": 930, "to": 1612, "width": 4.0}, {"from": 933, "to": 979, "width": 7.0}, {"from": 933, "to": 980, "width": 4.0}, {"from": 933, "to": 1309, "width": 6.0}, {"from": 934, "to": 1027, "width": 5.0}, {"from": 934, "to": 1081, "width": 5.0}, {"from": 935, "to": 961, "width": 4.0}, {"from": 937, "to": 954, "width": 11.0}, {"from": 937, "to": 1020, "width": 10.0}, {"from": 937, "to": 1066, "width": 4.0}, {"from": 937, "to": 1068, "width": 5.0}, {"from": 937, "to": 1069, "width": 7.0}, {"from": 937, "to": 1098, "width": 4.0}, {"from": 937, "to": 1366, "width": 4.0}, {"from": 938, "to": 1043, "width": 4.0}, {"from": 939, "to": 1220, "width": 5.0}, {"from": 940, "to": 1053, "width": 13.0}, {"from": 940, "to": 1187, "width": 8.0}, {"from": 940, "to": 1319, "width": 6.0}, {"from": 940, "to": 1367, "width": 4.0}, {"from": 942, "to": 979, "width": 7.0}, {"from": 942, "to": 1130, "width": 5.0}, {"from": 942, "to": 1307, "width": 5.0}, {"from": 942, "to": 1591, "width": 4.0}, {"from": 944, "to": 1211, "width": 5.0}, {"from": 948, "to": 1020, "width": 5.0}, {"from": 948, "to": 1046, "width": 4.0}, {"from": 948, "to": 1097, "width": 8.0}, {"from": 948, "to": 1098, "width": 4.0}, {"from": 948, "to": 1446, "width": 4.0}, {"from": 950, "to": 1125, "width": 4.0}, {"from": 954, "to": 960, "width": 4.0}, {"from": 954, "to": 1020, "width": 11.0}, {"from": 954, "to": 1066, "width": 7.0}, {"from": 954, "to": 1068, "width": 11.0}, {"from": 954, "to": 1069, "width": 11.0}, {"from": 954, "to": 1070, "width": 8.0}, {"from": 954, "to": 1098, "width": 5.0}, {"from": 954, "to": 1100, "width": 5.0}, {"from": 954, "to": 1175, "width": 4.0}, {"from": 954, "to": 1216, "width": 4.0}, {"from": 954, "to": 1366, "width": 6.0}, {"from": 954, "to": 1372, "width": 4.0}, {"from": 956, "to": 1059, "width": 4.0}, {"from": 957, "to": 1462, "width": 4.0}, {"from": 959, "to": 961, "width": 15.0}, {"from": 959, "to": 974, "width": 4.0}, {"from": 959, "to": 1031, "width": 6.0}, {"from": 959, "to": 1056, "width": 5.0}, {"from": 959, "to": 1184, "width": 4.0}, {"from": 959, "to": 1264, "width": 4.0}, {"from": 961, "to": 1031, "width": 4.0}, {"from": 961, "to": 1056, "width": 8.0}, {"from": 961, "to": 1063, "width": 4.0}, {"from": 961, "to": 1064, "width": 5.0}, {"from": 961, "to": 1094, "width": 4.0}, {"from": 961, "to": 1133, "width": 5.0}, {"from": 961, "to": 1184, "width": 5.0}, {"from": 961, "to": 1199, "width": 5.0}, {"from": 961, "to": 1223, "width": 4.0}, {"from": 961, "to": 1264, "width": 4.0}, {"from": 961, "to": 1572, "width": 4.0}, {"from": 965, "to": 1217, "width": 4.0}, {"from": 967, "to": 1191, "width": 5.0}, {"from": 968, "to": 969, "width": 8.0}, {"from": 968, "to": 972, "width": 4.0}, {"from": 968, "to": 1129, "width": 7.0}, {"from": 968, "to": 1217, "width": 4.0}, {"from": 968, "to": 1282, "width": 5.0}, {"from": 969, "to": 1129, "width": 7.0}, {"from": 969, "to": 1217, "width": 4.0}, {"from": 969, "to": 1282, "width": 5.0}, {"from": 972, "to": 1201, "width": 4.0}, {"from": 972, "to": 1377, "width": 4.0}, {"from": 973, "to": 1139, "width": 4.0}, {"from": 973, "to": 1264, "width": 4.0}, {"from": 974, "to": 1337, "width": 4.0}, {"from": 974, "to": 1419, "width": 5.0}, {"from": 974, "to": 1497, "width": 4.0}, {"from": 974, "to": 1529, "width": 4.0}, {"from": 979, "to": 980, "width": 7.0}, {"from": 979, "to": 1130, "width": 6.0}, {"from": 979, "to": 1134, "width": 6.0}, {"from": 979, "to": 1304, "width": 4.0}, {"from": 979, "to": 1307, "width": 9.0}, {"from": 979, "to": 1347, "width": 5.0}, {"from": 979, "to": 1377, "width": 4.0}, {"from": 979, "to": 1585, "width": 4.0}, {"from": 979, "to": 1591, "width": 4.0}, {"from": 980, "to": 1079, "width": 4.0}, {"from": 980, "to": 1307, "width": 4.0}, {"from": 980, "to": 1593, "width": 4.0}, {"from": 981, "to": 1329, "width": 4.0}, {"from": 981, "to": 1585, "width": 5.0}, {"from": 983, "to": 1194, "width": 4.0}, {"from": 985, "to": 1166, "width": 4.0}, {"from": 987, "to": 991, "width": 4.0}, {"from": 987, "to": 1130, "width": 4.0}, {"from": 987, "to": 1167, "width": 6.0}, {"from": 987, "to": 1347, "width": 4.0}, {"from": 990, "to": 994, "width": 4.0}, {"from": 990, "to": 1040, "width": 4.0}, {"from": 990, "to": 1041, "width": 4.0}, {"from": 990, "to": 1046, "width": 5.0}, {"from": 990, "to": 1086, "width": 4.0}, {"from": 990, "to": 1190, "width": 4.0}, {"from": 990, "to": 1277, "width": 4.0}, {"from": 990, "to": 1281, "width": 5.0}, {"from": 990, "to": 1289, "width": 4.0}, {"from": 990, "to": 1295, "width": 6.0}, {"from": 990, "to": 1405, "width": 6.0}, {"from": 990, "to": 1407, "width": 4.0}, {"from": 990, "to": 1415, "width": 7.0}, {"from": 990, "to": 1428, "width": 4.0}, {"from": 990, "to": 1575, "width": 4.0}, {"from": 992, "to": 995, "width": 5.0}, {"from": 992, "to": 1146, "width": 4.0}, {"from": 992, "to": 1428, "width": 4.0}, {"from": 992, "to": 1606, "width": 4.0}, {"from": 994, "to": 1074, "width": 4.0}, {"from": 994, "to": 1415, "width": 4.0}, {"from": 995, "to": 1125, "width": 4.0}, {"from": 995, "to": 1146, "width": 6.0}, {"from": 995, "to": 1359, "width": 4.0}, {"from": 995, "to": 1428, "width": 5.0}, {"from": 995, "to": 1524, "width": 4.0}, {"from": 995, "to": 1606, "width": 4.0}, {"from": 996, "to": 1144, "width": 4.0}, {"from": 1012, "to": 1200, "width": 4.0}, {"from": 1012, "to": 1405, "width": 4.0}, {"from": 1018, "to": 1020, "width": 4.0}, {"from": 1018, "to": 1097, "width": 6.0}, {"from": 1018, "to": 1171, "width": 4.0}, {"from": 1018, "to": 1451, "width": 5.0}, {"from": 1020, "to": 1068, "width": 10.0}, {"from": 1020, "to": 1069, "width": 8.0}, {"from": 1020, "to": 1070, "width": 5.0}, {"from": 1020, "to": 1097, "width": 4.0}, {"from": 1020, "to": 1098, "width": 7.0}, {"from": 1020, "to": 1175, "width": 6.0}, {"from": 1020, "to": 1183, "width": 4.0}, {"from": 1020, "to": 1216, "width": 4.0}, {"from": 1020, "to": 1226, "width": 5.0}, {"from": 1020, "to": 1296, "width": 4.0}, {"from": 1020, "to": 1366, "width": 8.0}, {"from": 1020, "to": 1451, "width": 4.0}, {"from": 1020, "to": 1481, "width": 4.0}, {"from": 1022, "to": 1584, "width": 4.0}, {"from": 1026, "to": 1201, "width": 4.0}, {"from": 1026, "to": 1292, "width": 4.0}, {"from": 1026, "to": 1441, "width": 4.0}, {"from": 1026, "to": 1590, "width": 4.0}, {"from": 1027, "to": 1081, "width": 5.0}, {"from": 1027, "to": 1082, "width": 4.0}, {"from": 1027, "to": 1408, "width": 4.0}, {"from": 1030, "to": 1035, "width": 5.0}, {"from": 1030, "to": 1144, "width": 4.0}, {"from": 1030, "to": 1222, "width": 5.0}, {"from": 1030, "to": 1457, "width": 4.0}, {"from": 1031, "to": 1056, "width": 4.0}, {"from": 1031, "to": 1064, "width": 5.0}, {"from": 1031, "to": 1240, "width": 5.0}, {"from": 1031, "to": 1291, "width": 4.0}, {"from": 1034, "to": 1053, "width": 4.0}, {"from": 1034, "to": 1187, "width": 4.0}, {"from": 1035, "to": 1144, "width": 6.0}, {"from": 1040, "to": 1281, "width": 5.0}, {"from": 1040, "to": 1288, "width": 4.0}, {"from": 1041, "to": 1046, "width": 4.0}, {"from": 1041, "to": 1050, "width": 4.0}, {"from": 1041, "to": 1281, "width": 5.0}, {"from": 1041, "to": 1324, "width": 4.0}, {"from": 1042, "to": 1405, "width": 4.0}, {"from": 1043, "to": 1288, "width": 4.0}, {"from": 1043, "to": 1458, "width": 5.0}, {"from": 1043, "to": 1464, "width": 7.0}, {"from": 1043, "to": 1475, "width": 4.0}, {"from": 1044, "to": 1053, "width": 7.0}, {"from": 1044, "to": 1091, "width": 4.0}, {"from": 1044, "to": 1155, "width": 4.0}, {"from": 1044, "to": 1187, "width": 5.0}, {"from": 1044, "to": 1367, "width": 4.0}, {"from": 1044, "to": 1447, "width": 6.0}, {"from": 1044, "to": 1463, "width": 6.0}, {"from": 1045, "to": 1172, "width": 5.0}, {"from": 1046, "to": 1097, "width": 4.0}, {"from": 1046, "to": 1267, "width": 4.0}, {"from": 1046, "to": 1277, "width": 5.0}, {"from": 1046, "to": 1281, "width": 7.0}, {"from": 1046, "to": 1462, "width": 5.0}, {"from": 1048, "to": 1264, "width": 4.0}, {"from": 1048, "to": 1405, "width": 5.0}, {"from": 1050, "to": 1324, "width": 7.0}, {"from": 1050, "to": 1325, "width": 6.0}, {"from": 1050, "to": 1423, "width": 5.0}, {"from": 1051, "to": 1201, "width": 8.0}, {"from": 1051, "to": 1327, "width": 4.0}, {"from": 1051, "to": 1427, "width": 4.0}, {"from": 1051, "to": 1582, "width": 5.0}, {"from": 1052, "to": 1096, "width": 4.0}, {"from": 1052, "to": 1097, "width": 4.0}, {"from": 1052, "to": 1169, "width": 4.0}, {"from": 1052, "to": 1171, "width": 4.0}, {"from": 1052, "to": 1185, "width": 5.0}, {"from": 1052, "to": 1200, "width": 4.0}, {"from": 1052, "to": 1296, "width": 4.0}, {"from": 1052, "to": 1362, "width": 4.0}, {"from": 1053, "to": 1091, "width": 4.0}, {"from": 1053, "to": 1187, "width": 12.0}, {"from": 1053, "to": 1216, "width": 4.0}, {"from": 1053, "to": 1319, "width": 4.0}, {"from": 1053, "to": 1367, "width": 4.0}, {"from": 1053, "to": 1447, "width": 7.0}, {"from": 1053, "to": 1463, "width": 5.0}, {"from": 1053, "to": 1467, "width": 4.0}, {"from": 1053, "to": 1541, "width": 4.0}, {"from": 1056, "to": 1063, "width": 4.0}, {"from": 1056, "to": 1064, "width": 5.0}, {"from": 1056, "to": 1090, "width": 5.0}, {"from": 1056, "to": 1135, "width": 5.0}, {"from": 1056, "to": 1184, "width": 5.0}, {"from": 1056, "to": 1199, "width": 4.0}, {"from": 1056, "to": 1264, "width": 5.0}, {"from": 1059, "to": 1427, "width": 4.0}, {"from": 1059, "to": 1521, "width": 4.0}, {"from": 1063, "to": 1064, "width": 4.0}, {"from": 1063, "to": 1135, "width": 4.0}, {"from": 1063, "to": 1199, "width": 4.0}, {"from": 1063, "to": 1264, "width": 4.0}, {"from": 1063, "to": 1497, "width": 4.0}, {"from": 1064, "to": 1135, "width": 4.0}, {"from": 1064, "to": 1240, "width": 4.0}, {"from": 1064, "to": 1264, "width": 4.0}, {"from": 1066, "to": 1068, "width": 4.0}, {"from": 1066, "to": 1091, "width": 4.0}, {"from": 1066, "to": 1186, "width": 4.0}, {"from": 1066, "to": 1366, "width": 5.0}, {"from": 1068, "to": 1069, "width": 8.0}, {"from": 1068, "to": 1070, "width": 6.0}, {"from": 1068, "to": 1098, "width": 4.0}, {"from": 1068, "to": 1175, "width": 6.0}, {"from": 1068, "to": 1186, "width": 4.0}, {"from": 1068, "to": 1366, "width": 6.0}, {"from": 1068, "to": 1481, "width": 5.0}, {"from": 1069, "to": 1070, "width": 8.0}, {"from": 1069, "to": 1098, "width": 9.0}, {"from": 1069, "to": 1100, "width": 4.0}, {"from": 1069, "to": 1175, "width": 6.0}, {"from": 1069, "to": 1216, "width": 4.0}, {"from": 1069, "to": 1365, "width": 5.0}, {"from": 1069, "to": 1366, "width": 9.0}, {"from": 1069, "to": 1446, "width": 4.0}, {"from": 1069, "to": 1481, "width": 6.0}, {"from": 1070, "to": 1098, "width": 5.0}, {"from": 1070, "to": 1099, "width": 5.0}, {"from": 1070, "to": 1100, "width": 5.0}, {"from": 1070, "to": 1215, "width": 4.0}, {"from": 1070, "to": 1216, "width": 4.0}, {"from": 1070, "to": 1296, "width": 5.0}, {"from": 1070, "to": 1366, "width": 6.0}, {"from": 1070, "to": 1368, "width": 4.0}, {"from": 1070, "to": 1372, "width": 4.0}, {"from": 1070, "to": 1481, "width": 7.0}, {"from": 1084, "to": 1369, "width": 4.0}, {"from": 1086, "to": 1405, "width": 4.0}, {"from": 1086, "to": 1415, "width": 4.0}, {"from": 1091, "to": 1187, "width": 6.0}, {"from": 1091, "to": 1319, "width": 5.0}, {"from": 1091, "to": 1447, "width": 5.0}, {"from": 1091, "to": 1463, "width": 4.0}, {"from": 1096, "to": 1267, "width": 4.0}, {"from": 1096, "to": 1612, "width": 4.0}, {"from": 1097, "to": 1446, "width": 4.0}, {"from": 1098, "to": 1100, "width": 4.0}, {"from": 1098, "to": 1175, "width": 6.0}, {"from": 1098, "to": 1183, "width": 4.0}, {"from": 1098, "to": 1266, "width": 4.0}, {"from": 1098, "to": 1327, "width": 6.0}, {"from": 1098, "to": 1365, "width": 5.0}, {"from": 1098, "to": 1366, "width": 8.0}, {"from": 1098, "to": 1446, "width": 6.0}, {"from": 1098, "to": 1451, "width": 5.0}, {"from": 1098, "to": 1481, "width": 5.0}, {"from": 1098, "to": 1509, "width": 4.0}, {"from": 1099, "to": 1481, "width": 6.0}, {"from": 1100, "to": 1366, "width": 4.0}, {"from": 1101, "to": 1415, "width": 4.0}, {"from": 1103, "to": 1222, "width": 4.0}, {"from": 1125, "to": 1389, "width": 4.0}, {"from": 1125, "to": 1407, "width": 5.0}, {"from": 1125, "to": 1428, "width": 6.0}, {"from": 1125, "to": 1451, "width": 4.0}, {"from": 1125, "to": 1524, "width": 5.0}, {"from": 1125, "to": 1580, "width": 4.0}, {"from": 1125, "to": 1606, "width": 5.0}, {"from": 1126, "to": 1205, "width": 5.0}, {"from": 1129, "to": 1217, "width": 5.0}, {"from": 1129, "to": 1282, "width": 7.0}, {"from": 1129, "to": 1292, "width": 4.0}, {"from": 1130, "to": 1134, "width": 6.0}, {"from": 1130, "to": 1167, "width": 4.0}, {"from": 1130, "to": 1304, "width": 5.0}, {"from": 1130, "to": 1307, "width": 6.0}, {"from": 1130, "to": 1329, "width": 4.0}, {"from": 1130, "to": 1347, "width": 9.0}, {"from": 1130, "to": 1406, "width": 4.0}, {"from": 1130, "to": 1592, "width": 4.0}, {"from": 1132, "to": 1153, "width": 4.0}, {"from": 1132, "to": 1274, "width": 4.0}, {"from": 1133, "to": 1594, "width": 4.0}, {"from": 1134, "to": 1307, "width": 5.0}, {"from": 1134, "to": 1347, "width": 9.0}, {"from": 1134, "to": 1406, "width": 5.0}, {"from": 1134, "to": 1585, "width": 4.0}, {"from": 1134, "to": 1592, "width": 4.0}, {"from": 1135, "to": 1199, "width": 4.0}, {"from": 1135, "to": 1264, "width": 6.0}, {"from": 1136, "to": 1141, "width": 4.0}, {"from": 1136, "to": 1341, "width": 4.0}, {"from": 1139, "to": 1277, "width": 4.0}, {"from": 1144, "to": 1195, "width": 4.0}, {"from": 1144, "to": 1211, "width": 4.0}, {"from": 1144, "to": 1222, "width": 4.0}, {"from": 1144, "to": 1238, "width": 4.0}, {"from": 1144, "to": 1333, "width": 4.0}, {"from": 1144, "to": 1334, "width": 4.0}, {"from": 1144, "to": 1457, "width": 4.0}, {"from": 1145, "to": 1168, "width": 5.0}, {"from": 1146, "to": 1347, "width": 4.0}, {"from": 1146, "to": 1359, "width": 6.0}, {"from": 1146, "to": 1428, "width": 5.0}, {"from": 1153, "to": 1274, "width": 5.0}, {"from": 1153, "to": 1369, "width": 7.0}, {"from": 1153, "to": 1607, "width": 6.0}, {"from": 1153, "to": 1615, "width": 4.0}, {"from": 1155, "to": 1187, "width": 4.0}, {"from": 1155, "to": 1226, "width": 4.0}, {"from": 1155, "to": 1271, "width": 4.0}, {"from": 1155, "to": 1447, "width": 4.0}, {"from": 1155, "to": 1463, "width": 4.0}, {"from": 1165, "to": 1211, "width": 4.0}, {"from": 1167, "to": 1347, "width": 4.0}, {"from": 1167, "to": 1527, "width": 4.0}, {"from": 1167, "to": 1591, "width": 4.0}, {"from": 1168, "to": 1189, "width": 4.0}, {"from": 1168, "to": 1342, "width": 4.0}, {"from": 1169, "to": 1171, "width": 4.0}, {"from": 1169, "to": 1185, "width": 4.0}, {"from": 1169, "to": 1200, "width": 6.0}, {"from": 1171, "to": 1215, "width": 4.0}, {"from": 1171, "to": 1307, "width": 4.0}, {"from": 1171, "to": 1311, "width": 4.0}, {"from": 1171, "to": 1366, "width": 4.0}, {"from": 1171, "to": 1451, "width": 6.0}, {"from": 1171, "to": 1458, "width": 4.0}, {"from": 1171, "to": 1481, "width": 4.0}, {"from": 1172, "to": 1179, "width": 5.0}, {"from": 1172, "to": 1181, "width": 5.0}, {"from": 1172, "to": 1229, "width": 4.0}, {"from": 1172, "to": 1273, "width": 4.0}, {"from": 1172, "to": 1278, "width": 4.0}, {"from": 1172, "to": 1288, "width": 6.0}, {"from": 1172, "to": 1415, "width": 5.0}, {"from": 1172, "to": 1445, "width": 4.0}, {"from": 1172, "to": 1458, "width": 5.0}, {"from": 1172, "to": 1464, "width": 5.0}, {"from": 1172, "to": 1486, "width": 4.0}, {"from": 1175, "to": 1184, "width": 4.0}, {"from": 1175, "to": 1365, "width": 6.0}, {"from": 1175, "to": 1366, "width": 7.0}, {"from": 1175, "to": 1481, "width": 5.0}, {"from": 1176, "to": 1481, "width": 4.0}, {"from": 1179, "to": 1181, "width": 4.0}, {"from": 1179, "to": 1370, "width": 4.0}, {"from": 1181, "to": 1486, "width": 4.0}, {"from": 1181, "to": 1577, "width": 4.0}, {"from": 1182, "to": 1267, "width": 8.0}, {"from": 1182, "to": 1329, "width": 7.0}, {"from": 1182, "to": 1462, "width": 4.0}, {"from": 1182, "to": 1571, "width": 4.0}, {"from": 1184, "to": 1365, "width": 4.0}, {"from": 1184, "to": 1481, "width": 4.0}, {"from": 1185, "to": 1362, "width": 4.0}, {"from": 1185, "to": 1366, "width": 4.0}, {"from": 1185, "to": 1478, "width": 4.0}, {"from": 1186, "to": 1296, "width": 5.0}, {"from": 1186, "to": 1311, "width": 4.0}, {"from": 1186, "to": 1362, "width": 5.0}, {"from": 1186, "to": 1366, "width": 5.0}, {"from": 1186, "to": 1446, "width": 4.0}, {"from": 1187, "to": 1271, "width": 4.0}, {"from": 1187, "to": 1310, "width": 4.0}, {"from": 1187, "to": 1319, "width": 5.0}, {"from": 1187, "to": 1367, "width": 4.0}, {"from": 1187, "to": 1447, "width": 6.0}, {"from": 1187, "to": 1463, "width": 5.0}, {"from": 1187, "to": 1541, "width": 4.0}, {"from": 1190, "to": 1281, "width": 7.0}, {"from": 1191, "to": 1307, "width": 4.0}, {"from": 1199, "to": 1262, "width": 5.0}, {"from": 1199, "to": 1264, "width": 5.0}, {"from": 1200, "to": 1296, "width": 5.0}, {"from": 1201, "to": 1327, "width": 4.0}, {"from": 1201, "to": 1377, "width": 5.0}, {"from": 1201, "to": 1427, "width": 6.0}, {"from": 1205, "to": 1555, "width": 4.0}, {"from": 1211, "to": 1400, "width": 5.0}, {"from": 1216, "to": 1529, "width": 4.0}, {"from": 1217, "to": 1282, "width": 4.0}, {"from": 1218, "to": 1295, "width": 6.0}, {"from": 1220, "to": 1223, "width": 4.0}, {"from": 1222, "to": 1334, "width": 4.0}, {"from": 1223, "to": 1497, "width": 5.0}, {"from": 1223, "to": 1529, "width": 4.0}, {"from": 1226, "to": 1366, "width": 4.0}, {"from": 1235, "to": 1446, "width": 4.0}, {"from": 1241, "to": 1324, "width": 5.0}, {"from": 1241, "to": 1328, "width": 4.0}, {"from": 1261, "to": 1408, "width": 5.0}, {"from": 1262, "to": 1264, "width": 4.0}, {"from": 1264, "to": 1291, "width": 4.0}, {"from": 1264, "to": 1580, "width": 6.0}, {"from": 1267, "to": 1281, "width": 4.0}, {"from": 1267, "to": 1329, "width": 4.0}, {"from": 1267, "to": 1445, "width": 4.0}, {"from": 1267, "to": 1462, "width": 4.0}, {"from": 1267, "to": 1486, "width": 6.0}, {"from": 1271, "to": 1310, "width": 4.0}, {"from": 1271, "to": 1447, "width": 4.0}, {"from": 1271, "to": 1463, "width": 5.0}, {"from": 1271, "to": 1541, "width": 4.0}, {"from": 1273, "to": 1353, "width": 6.0}, {"from": 1274, "to": 1369, "width": 5.0}, {"from": 1274, "to": 1399, "width": 4.0}, {"from": 1274, "to": 1607, "width": 5.0}, {"from": 1276, "to": 1451, "width": 4.0}, {"from": 1278, "to": 1464, "width": 4.0}, {"from": 1278, "to": 1486, "width": 4.0}, {"from": 1281, "to": 1323, "width": 4.0}, {"from": 1281, "to": 1329, "width": 4.0}, {"from": 1281, "to": 1405, "width": 4.0}, {"from": 1281, "to": 1439, "width": 4.0}, {"from": 1281, "to": 1440, "width": 4.0}, {"from": 1281, "to": 1462, "width": 7.0}, {"from": 1281, "to": 1480, "width": 5.0}, {"from": 1281, "to": 1486, "width": 4.0}, {"from": 1281, "to": 1571, "width": 4.0}, {"from": 1281, "to": 1597, "width": 4.0}, {"from": 1282, "to": 1292, "width": 4.0}, {"from": 1288, "to": 1458, "width": 4.0}, {"from": 1288, "to": 1464, "width": 5.0}, {"from": 1291, "to": 1404, "width": 4.0}, {"from": 1291, "to": 1554, "width": 4.0}, {"from": 1292, "to": 1590, "width": 4.0}, {"from": 1292, "to": 1615, "width": 4.0}, {"from": 1295, "to": 1452, "width": 4.0}, {"from": 1296, "to": 1365, "width": 4.0}, {"from": 1296, "to": 1366, "width": 6.0}, {"from": 1296, "to": 1474, "width": 4.0}, {"from": 1296, "to": 1481, "width": 4.0}, {"from": 1302, "to": 1510, "width": 4.0}, {"from": 1304, "to": 1307, "width": 6.0}, {"from": 1304, "to": 1329, "width": 4.0}, {"from": 1304, "to": 1347, "width": 5.0}, {"from": 1304, "to": 1592, "width": 4.0}, {"from": 1307, "to": 1329, "width": 5.0}, {"from": 1307, "to": 1347, "width": 5.0}, {"from": 1307, "to": 1390, "width": 4.0}, {"from": 1307, "to": 1585, "width": 5.0}, {"from": 1307, "to": 1591, "width": 4.0}, {"from": 1307, "to": 1592, "width": 5.0}, {"from": 1309, "to": 1336, "width": 4.0}, {"from": 1310, "to": 1319, "width": 4.0}, {"from": 1310, "to": 1447, "width": 4.0}, {"from": 1310, "to": 1463, "width": 4.0}, {"from": 1311, "to": 1446, "width": 4.0}, {"from": 1311, "to": 1509, "width": 4.0}, {"from": 1319, "to": 1367, "width": 4.0}, {"from": 1319, "to": 1447, "width": 5.0}, {"from": 1319, "to": 1463, "width": 4.0}, {"from": 1324, "to": 1325, "width": 5.0}, {"from": 1324, "to": 1327, "width": 6.0}, {"from": 1324, "to": 1328, "width": 7.0}, {"from": 1324, "to": 1403, "width": 4.0}, {"from": 1324, "to": 1423, "width": 6.0}, {"from": 1324, "to": 1432, "width": 4.0}, {"from": 1324, "to": 1436, "width": 5.0}, {"from": 1325, "to": 1423, "width": 6.0}, {"from": 1326, "to": 1334, "width": 4.0}, {"from": 1326, "to": 1457, "width": 4.0}, {"from": 1327, "to": 1328, "width": 10.0}, {"from": 1327, "to": 1366, "width": 5.0}, {"from": 1327, "to": 1403, "width": 8.0}, {"from": 1327, "to": 1421, "width": 7.0}, {"from": 1327, "to": 1432, "width": 6.0}, {"from": 1327, "to": 1436, "width": 7.0}, {"from": 1327, "to": 1442, "width": 6.0}, {"from": 1327, "to": 1444, "width": 8.0}, {"from": 1327, "to": 1488, "width": 4.0}, {"from": 1328, "to": 1403, "width": 6.0}, {"from": 1328, "to": 1421, "width": 5.0}, {"from": 1328, "to": 1436, "width": 5.0}, {"from": 1328, "to": 1442, "width": 5.0}, {"from": 1329, "to": 1390, "width": 4.0}, {"from": 1329, "to": 1406, "width": 4.0}, {"from": 1329, "to": 1486, "width": 4.0}, {"from": 1332, "to": 1582, "width": 4.0}, {"from": 1333, "to": 1457, "width": 5.0}, {"from": 1333, "to": 1490, "width": 5.0}, {"from": 1333, "to": 1517, "width": 4.0}, {"from": 1334, "to": 1457, "width": 4.0}, {"from": 1334, "to": 1490, "width": 4.0}, {"from": 1334, "to": 1504, "width": 4.0}, {"from": 1334, "to": 1517, "width": 4.0}, {"from": 1341, "to": 1472, "width": 4.0}, {"from": 1342, "to": 1419, "width": 4.0}, {"from": 1347, "to": 1406, "width": 5.0}, {"from": 1347, "to": 1592, "width": 5.0}, {"from": 1359, "to": 1428, "width": 4.0}, {"from": 1359, "to": 1469, "width": 4.0}, {"from": 1359, "to": 1524, "width": 4.0}, {"from": 1359, "to": 1606, "width": 4.0}, {"from": 1362, "to": 1446, "width": 4.0}, {"from": 1362, "to": 1481, "width": 4.0}, {"from": 1365, "to": 1366, "width": 5.0}, {"from": 1365, "to": 1481, "width": 8.0}, {"from": 1366, "to": 1372, "width": 4.0}, {"from": 1366, "to": 1446, "width": 5.0}, {"from": 1366, "to": 1451, "width": 5.0}, {"from": 1366, "to": 1476, "width": 4.0}, {"from": 1366, "to": 1481, "width": 9.0}, {"from": 1366, "to": 1497, "width": 4.0}, {"from": 1366, "to": 1529, "width": 4.0}, {"from": 1367, "to": 1447, "width": 6.0}, {"from": 1367, "to": 1463, "width": 5.0}, {"from": 1368, "to": 1481, "width": 5.0}, {"from": 1369, "to": 1399, "width": 7.0}, {"from": 1369, "to": 1607, "width": 4.0}, {"from": 1369, "to": 1615, "width": 4.0}, {"from": 1370, "to": 1375, "width": 4.0}, {"from": 1379, "to": 1452, "width": 4.0}, {"from": 1379, "to": 1553, "width": 4.0}, {"from": 1380, "to": 1533, "width": 4.0}, {"from": 1383, "to": 1553, "width": 4.0}, {"from": 1390, "to": 1406, "width": 4.0}, {"from": 1390, "to": 1585, "width": 5.0}, {"from": 1390, "to": 1592, "width": 6.0}, {"from": 1399, "to": 1480, "width": 5.0}, {"from": 1400, "to": 1490, "width": 4.0}, {"from": 1402, "to": 1405, "width": 4.0}, {"from": 1403, "to": 1421, "width": 8.0}, {"from": 1403, "to": 1423, "width": 4.0}, {"from": 1403, "to": 1432, "width": 8.0}, {"from": 1403, "to": 1436, "width": 11.0}, {"from": 1403, "to": 1442, "width": 8.0}, {"from": 1403, "to": 1444, "width": 8.0}, {"from": 1403, "to": 1488, "width": 6.0}, {"from": 1405, "to": 1407, "width": 7.0}, {"from": 1405, "to": 1415, "width": 4.0}, {"from": 1405, "to": 1445, "width": 4.0}, {"from": 1405, "to": 1462, "width": 5.0}, {"from": 1406, "to": 1422, "width": 4.0}, {"from": 1406, "to": 1548, "width": 4.0}, {"from": 1406, "to": 1585, "width": 4.0}, {"from": 1406, "to": 1592, "width": 5.0}, {"from": 1408, "to": 1459, "width": 4.0}, {"from": 1415, "to": 1458, "width": 4.0}, {"from": 1415, "to": 1472, "width": 4.0}, {"from": 1419, "to": 1497, "width": 4.0}, {"from": 1421, "to": 1432, "width": 7.0}, {"from": 1421, "to": 1436, "width": 8.0}, {"from": 1421, "to": 1442, "width": 6.0}, {"from": 1421, "to": 1444, "width": 6.0}, {"from": 1421, "to": 1488, "width": 5.0}, {"from": 1423, "to": 1432, "width": 6.0}, {"from": 1423, "to": 1436, "width": 7.0}, {"from": 1423, "to": 1444, "width": 5.0}, {"from": 1423, "to": 1488, "width": 4.0}, {"from": 1423, "to": 1514, "width": 4.0}, {"from": 1427, "to": 1521, "width": 6.0}, {"from": 1428, "to": 1524, "width": 6.0}, {"from": 1428, "to": 1534, "width": 4.0}, {"from": 1428, "to": 1606, "width": 5.0}, {"from": 1432, "to": 1436, "width": 11.0}, {"from": 1432, "to": 1442, "width": 6.0}, {"from": 1432, "to": 1444, "width": 7.0}, {"from": 1432, "to": 1488, "width": 7.0}, {"from": 1432, "to": 1495, "width": 5.0}, {"from": 1432, "to": 1514, "width": 5.0}, {"from": 1432, "to": 1525, "width": 4.0}, {"from": 1436, "to": 1442, "width": 8.0}, {"from": 1436, "to": 1444, "width": 8.0}, {"from": 1436, "to": 1488, "width": 9.0}, {"from": 1436, "to": 1514, "width": 4.0}, {"from": 1440, "to": 1480, "width": 5.0}, {"from": 1442, "to": 1444, "width": 6.0}, {"from": 1442, "to": 1488, "width": 4.0}, {"from": 1444, "to": 1488, "width": 4.0}, {"from": 1444, "to": 1528, "width": 4.0}, {"from": 1445, "to": 1486, "width": 8.0}, {"from": 1445, "to": 1571, "width": 4.0}, {"from": 1445, "to": 1601, "width": 4.0}, {"from": 1445, "to": 1611, "width": 4.0}, {"from": 1446, "to": 1451, "width": 4.0}, {"from": 1446, "to": 1509, "width": 4.0}, {"from": 1447, "to": 1463, "width": 7.0}, {"from": 1447, "to": 1467, "width": 4.0}, {"from": 1447, "to": 1541, "width": 8.0}, {"from": 1447, "to": 1611, "width": 4.0}, {"from": 1452, "to": 1601, "width": 4.0}, {"from": 1457, "to": 1490, "width": 4.0}, {"from": 1457, "to": 1517, "width": 4.0}, {"from": 1458, "to": 1464, "width": 7.0}, {"from": 1458, "to": 1475, "width": 6.0}, {"from": 1458, "to": 1565, "width": 4.0}, {"from": 1458, "to": 1585, "width": 5.0}, {"from": 1462, "to": 1571, "width": 5.0}, {"from": 1462, "to": 1599, "width": 4.0}, {"from": 1462, "to": 1612, "width": 5.0}, {"from": 1463, "to": 1541, "width": 5.0}, {"from": 1464, "to": 1475, "width": 6.0}, {"from": 1464, "to": 1552, "width": 4.0}, {"from": 1464, "to": 1565, "width": 5.0}, {"from": 1464, "to": 1585, "width": 5.0}, {"from": 1469, "to": 1524, "width": 4.0}, {"from": 1469, "to": 1606, "width": 5.0}, {"from": 1470, "to": 1550, "width": 5.0}, {"from": 1480, "to": 1597, "width": 4.0}, {"from": 1480, "to": 1615, "width": 4.0}, {"from": 1486, "to": 1577, "width": 4.0}, {"from": 1486, "to": 1611, "width": 4.0}, {"from": 1490, "to": 1517, "width": 6.0}, {"from": 1495, "to": 1496, "width": 4.0}, {"from": 1495, "to": 1514, "width": 5.0}, {"from": 1495, "to": 1525, "width": 8.0}, {"from": 1495, "to": 1528, "width": 5.0}, {"from": 1495, "to": 1562, "width": 5.0}, {"from": 1495, "to": 1598, "width": 4.0}, {"from": 1495, "to": 1616, "width": 5.0}, {"from": 1496, "to": 1498, "width": 7.0}, {"from": 1496, "to": 1514, "width": 7.0}, {"from": 1496, "to": 1525, "width": 7.0}, {"from": 1496, "to": 1562, "width": 6.0}, {"from": 1496, "to": 1598, "width": 7.0}, {"from": 1496, "to": 1616, "width": 7.0}, {"from": 1497, "to": 1529, "width": 6.0}, {"from": 1498, "to": 1514, "width": 6.0}, {"from": 1498, "to": 1525, "width": 6.0}, {"from": 1498, "to": 1562, "width": 5.0}, {"from": 1498, "to": 1598, "width": 6.0}, {"from": 1498, "to": 1616, "width": 6.0}, {"from": 1514, "to": 1525, "width": 8.0}, {"from": 1514, "to": 1562, "width": 7.0}, {"from": 1514, "to": 1598, "width": 6.0}, {"from": 1514, "to": 1616, "width": 7.0}, {"from": 1517, "to": 1520, "width": 4.0}, {"from": 1517, "to": 1573, "width": 4.0}, {"from": 1524, "to": 1606, "width": 7.0}, {"from": 1525, "to": 1528, "width": 4.0}, {"from": 1525, "to": 1562, "width": 7.0}, {"from": 1525, "to": 1598, "width": 7.0}, {"from": 1525, "to": 1616, "width": 8.0}, {"from": 1527, "to": 1591, "width": 7.0}, {"from": 1527, "to": 1592, "width": 4.0}, {"from": 1529, "to": 1595, "width": 4.0}, {"from": 1534, "to": 1606, "width": 4.0}, {"from": 1539, "to": 1605, "width": 4.0}, {"from": 1540, "to": 1541, "width": 5.0}, {"from": 1541, "to": 1611, "width": 4.0}, {"from": 1544, "to": 1585, "width": 4.0}, {"from": 1548, "to": 1605, "width": 4.0}, {"from": 1562, "to": 1598, "width": 5.0}, {"from": 1562, "to": 1616, "width": 6.0}, {"from": 1571, "to": 1612, "width": 4.0}, {"from": 1582, "to": 1589, "width": 6.0}, {"from": 1582, "to": 1590, "width": 4.0}, {"from": 1585, "to": 1592, "width": 5.0}, {"from": 1586, "to": 1599, "width": 4.0}, {"from": 1589, "to": 1590, "width": 4.0}, {"from": 1591, "to": 1592, "width": 6.0}, {"from": 1598, "to": 1616, "width": 7.0}]);

        // adding nodes and edges to the graph
        data = {nodes: nodes, edges: edges};

        var options = {"physics": {"stabilization": false, "barnesHut": {"centralGravity": 0.1, "gravitationalConstant": -5000}}, "edges": {"smooth": {"type": "continuous"}}};
        
        

        

        network = new vis.Network(container, data, options);
	 
        
        // make a custom popup
        var popup = document.createElement("div");
        popup.className = 'popup';
        popupTimeout = null;
        popup.addEventListener('mouseover', function () {
            console.log(popup)
            if (popupTimeout !== null) {
                clearTimeout(popupTimeout);
                popupTimeout = null;
            }
        });
        popup.addEventListener('mouseout', function () {
            if (popupTimeout === null) {
                hidePopup();
            }
        });
        container.appendChild(popup);


        // use the popup event to show
        network.on("showPopup", function (params) {
            showPopup(params);
        });

        // use the hide event to hide it
        network.on("hidePopup", function (params) {
            hidePopup();
        });


        // hiding the popup through css
        function hidePopup() {
            popupTimeout = setTimeout(function () { popup.style.display = 'none'; }, 500);
        }

        // showing the popup
        function showPopup(nodeId) {
            // get the data from the vis.DataSet
            var nodeData = nodes.get([nodeId]);
            popup.innerHTML = nodeData[0].title;

            // get the position of the node
            var posCanvas = network.getPositions([nodeId])[nodeId];

            // get the bounding box of the node
            var boundingBox = network.getBoundingBox(nodeId);

            //position tooltip:
            posCanvas.x = posCanvas.x + 0.5 * (boundingBox.right - boundingBox.left);

            // convert coordinates to the DOM space
            var posDOM = network.canvasToDOM(posCanvas);

            // Give it an offset
            posDOM.x += 10;
            posDOM.y -= 20;

            // show and place the tooltip.
            popup.style.display = 'block';
            popup.style.top = posDOM.y + 'px';
            popup.style.left = posDOM.x + 'px';
        }
        


        return network;

    }

    drawGraph();

</script>
</body>
</html>